# Module 1: Installation and Setup

**Duration**: 10 minutes  
**Objective**: Get Ollama Distributed installed and running on your system

Welcome to your first hands-on module! In this session, you'll install Ollama Distributed and verify everything is working correctly.

## ğŸ¯ What You'll Learn

By the end of this module, you will:
- âœ… Build Ollama Distributed from source
- âœ… Verify your installation is working
- âœ… Run your first CLI command
- âœ… Understand the basic directory structure

## ğŸ“‹ Prerequisites Check

Before we start, let's verify your system is ready:

### System Requirements
```bash
# Check Go version (need 1.21+)
go version

# Check available disk space (need 2GB+)
df -h ~

# Check memory (need 4GB+ recommended)
free -h
```

**âœ… Checkpoint 1**: Confirm you have Go 1.21+ and adequate disk space.

## ğŸ› ï¸ Installation Process

### Step 1: Get the Source Code

If you don't already have the project:

```bash
# Navigate to your workspace
cd ~/workspace

# Check if project exists
ls -la ollamamax/
```

The project should already be available at `/home/kp/ollamamax/`.

### Step 2: Build the CLI Tool

Let's build the main CLI tool:

```bash
# Navigate to the project
cd /home/kp/ollamamax

# Build the CLI tool
go build -o bin/ollama-distributed ./cmd/ollama-distributed

# Verify the build succeeded
ls -la bin/ollama-distributed
```

**Expected Output:**
```
-rwxr-xr-x 1 user user 3600000 Aug 28 01:30 bin/ollama-distributed
```

**âœ… Checkpoint 2**: Confirm the binary was created successfully.

### Step 3: Test the Installation

Let's verify the CLI tool works:

```bash
# Test the CLI help
./bin/ollama-distributed --help

# Check version
./bin/ollama-distributed --version
```

**Expected Output:**
```
ğŸš€ OllamaMax - Enterprise Distributed AI Platform

A distributed, enterprise-grade version of Ollama that transforms the single-node
architecture into a horizontally scalable, fault-tolerant platform.

Features:
  ğŸŒ Distributed AI model serving across multiple nodes
  ğŸ”’ Enterprise-grade security with JWT authentication
  ğŸ“Š Real-time performance monitoring and optimization
  ğŸ¨ Beautiful web interface for easy management
  âš¡ Automatic load balancing and failover
  ğŸ”„ Seamless model distribution and synchronization
```

**âœ… Checkpoint 3**: CLI help displays properly and shows all available commands.

### Step 4: Explore Available Commands

Let's see what commands are available:

```bash
# List all available commands
./bin/ollama-distributed --help
```

You should see these main commands:
- `quickstart` - ğŸš€ Instant setup with sensible defaults
- `setup` - âš™ï¸ Interactive setup wizard
- `start` - ğŸƒ Start the OllamaMax node
- `status` - ğŸ¥ Show comprehensive cluster health status
- `validate` - ğŸ” Validate configuration and environment
- `examples` - ğŸ’¡ Show usage examples and common patterns
- `tutorial` - ğŸ“š Interactive getting started tutorial
- `troubleshoot` - ğŸ”§ Diagnostic tools and common issue fixes
- `proxy` - ğŸ”— Model management and proxy operations

**âœ… Checkpoint 4**: All expected commands are listed and display help text.

## ğŸ§ª Hands-On Exercise 1: First Run

Let's test the validate command to ensure everything is working:

```bash
# Run validation to check your system
./bin/ollama-distributed validate --quick
```

**Expected Output:**
```
ğŸ” OllamaMax Configuration Validation
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… Configuration file syntax: passed
âœ… API port availability: passed
âœ… System resources: passed
âœ… Directory permissions: passed
âœ… Network connectivity: passed

ğŸ“Š Validation Summary
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… All validations passed - ready to start!
```

**ğŸ“ Exercise Questions:**
1. What validation checks are performed?
2. What would happen if a port was already in use?
3. How would you get more detailed validation information?

**ğŸ’¡ Answers:**
1. Five checks: config syntax, port availability, system resources, directory permissions, network connectivity
2. The validation would fail and show which port is blocked
3. Run `./bin/ollama-distributed validate --help` to see more options

**âœ… Checkpoint 5**: Validation passes successfully.

## ğŸ§ª Hands-On Exercise 2: Directory Structure

Let's explore what gets created when you run Ollama Distributed:

```bash
# Check the current directory structure
ls -la

# Look at the bin directory
ls -la bin/

# Check what directories would be created (without actually running)
./bin/ollama-distributed quickstart --help
```

**Learning Point**: Ollama Distributed creates a `~/.ollamamax/` directory for configuration and data.

## ğŸ”§ Troubleshooting Common Issues

### Issue 1: Build Fails
**Problem**: `go build` command fails
**Solution**:
```bash
# Ensure you're in the right directory
pwd
# Should show: /home/kp/ollamamax

# Check Go version
go version
# Should be 1.21 or higher

# Try building with verbose output
go build -v -o bin/ollama-distributed ./cmd/ollama-distributed
```

### Issue 2: Permission Denied
**Problem**: Cannot execute the binary
**Solution**:
```bash
# Make the binary executable
chmod +x bin/ollama-distributed

# Try running again
./bin/ollama-distributed --help
```

### Issue 3: Command Not Found
**Problem**: Binary seems to build but doesn't run
**Solution**:
```bash
# Use the full path
/home/kp/ollamamax/bin/ollama-distributed --help

# Or add to PATH temporarily
export PATH=$PATH:/home/kp/ollamamax/bin
ollama-distributed --help
```

## ğŸ“Š Module 1 Assessment

### Knowledge Check âœ‹
Answer these questions to test your understanding:

1. **Q**: What command would you use to validate your installation?
   **A**: `./bin/ollama-distributed validate --quick`

2. **Q**: Where does Ollama Distributed store its configuration files?
   **A**: `~/.ollamamax/` directory

3. **Q**: What are the minimum system requirements?
   **A**: Go 1.21+, 4GB RAM, 2GB disk space

4. **Q**: How do you see all available commands?
   **A**: `./bin/ollama-distributed --help`

### Practical Check âœ‹
Verify you can complete these tasks:

- [ ] Build the binary successfully
- [ ] Run `--help` and see command list  
- [ ] Execute `validate --quick` with all checks passing
- [ ] Understand the directory structure

## ğŸ‰ Module 1 Complete!

**Congratulations!** You have successfully:

âœ… **Installed** Ollama Distributed from source  
âœ… **Verified** your installation is working correctly  
âœ… **Tested** basic CLI functionality  
âœ… **Understood** the project structure  

## ğŸ“š What's Next?

You're now ready for **Module 2: Node Configuration** where you'll:
- Configure your first node
- Use the interactive setup wizard
- Customize settings for your environment
- Learn about different configuration profiles

**Time to continue:** [Module 2: Node Configuration â†’](./module-2-configuration.md)

## ğŸ’¡ Pro Tips

1. **Save the Path**: Consider adding the bin directory to your PATH for easier access
2. **Keep Learning**: The `--help` flag works with every command for detailed information
3. **Stay Updated**: The project is actively developed, so features may evolve
4. **Practice**: Try different commands and explore the CLI interface

---

**Module 1 Status**: âœ… Complete  
**Next Module**: [Node Configuration â†’](./module-2-configuration.md)  
**Total Progress**: 1/5 modules (20%)