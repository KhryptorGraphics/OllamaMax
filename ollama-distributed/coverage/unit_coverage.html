
<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>node: Go Coverage Report</title>
		<style>
			body {
				background: black;
				color: rgb(80, 80, 80);
			}
			body, pre, #legend span {
				font-family: Menlo, monospace;
				font-weight: bold;
			}
			#topbar {
				background: black;
				position: fixed;
				top: 0; left: 0; right: 0;
				height: 42px;
				border-bottom: 1px solid rgb(80, 80, 80);
			}
			#content {
				margin-top: 50px;
			}
			#nav, #legend {
				float: left;
				margin-left: 10px;
			}
			#legend {
				margin-top: 12px;
			}
			#nav {
				margin-top: 10px;
			}
			#legend span {
				margin: 0 5px;
			}
			.cov0 { color: rgb(192, 0, 0) }
.cov1 { color: rgb(128, 128, 128) }
.cov2 { color: rgb(116, 140, 131) }
.cov3 { color: rgb(104, 152, 134) }
.cov4 { color: rgb(92, 164, 137) }
.cov5 { color: rgb(80, 176, 140) }
.cov6 { color: rgb(68, 188, 143) }
.cov7 { color: rgb(56, 200, 146) }
.cov8 { color: rgb(44, 212, 149) }
.cov9 { color: rgb(32, 224, 152) }
.cov10 { color: rgb(20, 236, 155) }

		</style>
	</head>
	<body>
		<div id="topbar">
			<div id="nav">
				<select id="files">
				
				<option value="file0">github.com/ollama/ollama-distributed/cmd/node/main.go (0.0%)</option>
				
				<option value="file1">github.com/ollama/ollama-distributed/internal/auth/auth.go (70.5%)</option>
				
				<option value="file2">github.com/ollama/ollama-distributed/internal/auth/integration.go (0.0%)</option>
				
				<option value="file3">github.com/ollama/ollama-distributed/internal/auth/jwt.go (36.7%)</option>
				
				<option value="file4">github.com/ollama/ollama-distributed/internal/auth/middleware.go (0.0%)</option>
				
				<option value="file5">github.com/ollama/ollama-distributed/internal/auth/routes.go (0.0%)</option>
				
				<option value="file6">github.com/ollama/ollama-distributed/internal/auth/server_example.go (0.0%)</option>
				
				<option value="file7">github.com/ollama/ollama-distributed/internal/auth/types.go (0.0%)</option>
				
				<option value="file8">github.com/ollama/ollama-distributed/internal/config/config.go (0.0%)</option>
				
				<option value="file9">github.com/ollama/ollama-distributed/internal/metrics/metrics.go (0.0%)</option>
				
				<option value="file10">github.com/ollama/ollama-distributed/internal/storage/distributed.go (0.0%)</option>
				
				<option value="file11">github.com/ollama/ollama-distributed/internal/storage/interface.go (0.0%)</option>
				
				<option value="file12">github.com/ollama/ollama-distributed/internal/storage/local.go (65.8%)</option>
				
				<option value="file13">github.com/ollama/ollama-distributed/internal/storage/metadata.go (67.4%)</option>
				
				<option value="file14">github.com/ollama/ollama-distributed/internal/storage/replication.go (49.5%)</option>
				
				<option value="file15">github.com/ollama/ollama-distributed/pkg/api/compatibility.go (0.0%)</option>
				
				<option value="file16">github.com/ollama/ollama-distributed/pkg/api/fallback.go (0.0%)</option>
				
				<option value="file17">github.com/ollama/ollama-distributed/pkg/api/integration.go (0.0%)</option>
				
				<option value="file18">github.com/ollama/ollama-distributed/pkg/api/routes.go (0.0%)</option>
				
				<option value="file19">github.com/ollama/ollama-distributed/pkg/api/routes_integration.go (0.0%)</option>
				
				<option value="file20">github.com/ollama/ollama-distributed/pkg/api/runner.go (0.0%)</option>
				
				<option value="file21">github.com/ollama/ollama-distributed/pkg/api/server.go (0.0%)</option>
				
				<option value="file22">github.com/ollama/ollama-distributed/pkg/config/types.go (0.0%)</option>
				
				<option value="file23">github.com/ollama/ollama-distributed/pkg/consensus/engine.go (0.0%)</option>
				
				<option value="file24">github.com/ollama/ollama-distributed/pkg/integration/ollama_client_stubs.go (0.0%)</option>
				
				<option value="file25">github.com/ollama/ollama-distributed/pkg/models/cas_store.go (0.0%)</option>
				
				<option value="file26">github.com/ollama/ollama-distributed/pkg/models/delta_tracker.go (0.0%)</option>
				
				<option value="file27">github.com/ollama/ollama-distributed/pkg/models/distributed_model_manager.go (0.0%)</option>
				
				<option value="file28">github.com/ollama/ollama-distributed/pkg/models/distribution.go (0.0%)</option>
				
				<option value="file29">github.com/ollama/ollama-distributed/pkg/models/ollama_integration.go (0.0%)</option>
				
				<option value="file30">github.com/ollama/ollama-distributed/pkg/models/replication_manager.go (0.0%)</option>
				
				<option value="file31">github.com/ollama/ollama-distributed/pkg/models/sync_manager.go (0.0%)</option>
				
				<option value="file32">github.com/ollama/ollama-distributed/pkg/p2p/discovery/discovery.go (0.0%)</option>
				
				<option value="file33">github.com/ollama/ollama-distributed/pkg/p2p/discovery/strategies.go (0.0%)</option>
				
				<option value="file34">github.com/ollama/ollama-distributed/pkg/p2p/host/host.go (0.0%)</option>
				
				<option value="file35">github.com/ollama/ollama-distributed/pkg/p2p/node.go (0.0%)</option>
				
				<option value="file36">github.com/ollama/ollama-distributed/pkg/p2p/resources/advertiser.go (0.0%)</option>
				
				<option value="file37">github.com/ollama/ollama-distributed/pkg/p2p/resources/discovery_types.go (0.0%)</option>
				
				<option value="file38">github.com/ollama/ollama-distributed/pkg/p2p/routing/content.go (0.0%)</option>
				
				<option value="file39">github.com/ollama/ollama-distributed/pkg/p2p/security/security.go (0.0%)</option>
				
				<option value="file40">github.com/ollama/ollama-distributed/pkg/scheduler/engine.go (0.0%)</option>
				
				<option value="file41">github.com/ollama/ollama-distributed/pkg/scheduler/fault_tolerance/fault_tolerance_manager.go (0.0%)</option>
				
				<option value="file42">github.com/ollama/ollama-distributed/pkg/scheduler/fault_tolerance/health_checker_impls.go (0.0%)</option>
				
				<option value="file43">github.com/ollama/ollama-distributed/pkg/scheduler/fault_tolerance/recovery_strategies.go (0.0%)</option>
				
				<option value="file44">github.com/ollama/ollama-distributed/pkg/scheduler/loadbalancer/algorithms.go (0.0%)</option>
				
				<option value="file45">github.com/ollama/ollama-distributed/pkg/scheduler/loadbalancer/intelligent_load_balancer.go (0.0%)</option>
				
				<option value="file46">github.com/ollama/ollama-distributed/pkg/scheduler/orchestration/aggregation_strategies.go (0.0%)</option>
				
				<option value="file47">github.com/ollama/ollama-distributed/pkg/scheduler/orchestration/orchestration_engine.go (0.0%)</option>
				
				</select>
			</div>
			<div id="legend">
				<span>not tracked</span>
			
				<span class="cov0">no coverage</span>
				<span class="cov1">low coverage</span>
				<span class="cov2">*</span>
				<span class="cov3">*</span>
				<span class="cov4">*</span>
				<span class="cov5">*</span>
				<span class="cov6">*</span>
				<span class="cov7">*</span>
				<span class="cov8">*</span>
				<span class="cov9">*</span>
				<span class="cov10">high coverage</span>
			
			</div>
		</div>
		<div id="content">
		
		<pre class="file" id="file0" style="display: none">package main

import (
        "context"
        "fmt"
        "log"
        "net"
        "os"
        "os/signal"
        "syscall"
        "time"

        "github.com/libp2p/go-libp2p/core/peer"
        "github.com/multiformats/go-multiaddr"
        "github.com/ollama/ollama-distributed/internal/config"
        "github.com/ollama/ollama-distributed/pkg/api"
        "github.com/ollama/ollama-distributed/pkg/consensus"
        "github.com/ollama/ollama-distributed/pkg/p2p"
        "github.com/ollama/ollama-distributed/pkg/scheduler"
        "github.com/spf13/cobra"
        "github.com/spf13/viper"
)

var (
        cfgFile string
        version = "dev"
)

func main() <span class="cov0" title="0">{
        rootCmd := &amp;cobra.Command{
                Use:   "ollama-distributed",
                Short: "Distributed Ollama Platform",
                Long: `A distributed, enterprise-grade version of Ollama that transforms 
the single-node architecture into a horizontally scalable, fault-tolerant platform.`,
                Version: version,
        }

        rootCmd.PersistentFlags().StringVar(&amp;cfgFile, "config", "", "config file (default is $HOME/.ollama-distributed.yaml)")
        rootCmd.AddCommand(startCmd())
        rootCmd.AddCommand(statusCmd())
        rootCmd.AddCommand(joinCmd())

        if err := rootCmd.Execute(); err != nil </span><span class="cov0" title="0">{
                log.Fatal(err)
        }</span>
}

func startCmd() *cobra.Command <span class="cov0" title="0">{
        cmd := &amp;cobra.Command{
                Use:   "start",
                Short: "Start a distributed Ollama node",
                Long:  "Start a distributed Ollama node with P2P networking and consensus",
                RunE:  runStart,
        }

        cmd.Flags().String("listen", "0.0.0.0:11434", "Address to listen on")
        cmd.Flags().String("p2p-listen", "0.0.0.0:4001", "P2P listen address")
        cmd.Flags().StringSlice("bootstrap", []string{}, "Bootstrap peers")
        cmd.Flags().String("data-dir", "./data", "Data directory")
        cmd.Flags().Bool("enable-web", true, "Enable web control panel")
        cmd.Flags().String("web-listen", "0.0.0.0:8080", "Web panel listen address")

        return cmd
}</span>

func statusCmd() *cobra.Command <span class="cov0" title="0">{
        return &amp;cobra.Command{
                Use:   "status",
                Short: "Show node status",
                Long:  "Show the current status of the distributed Ollama node",
                RunE:  runStatus,
        }
}</span>

func joinCmd() *cobra.Command <span class="cov0" title="0">{
        cmd := &amp;cobra.Command{
                Use:   "join",
                Short: "Join an existing cluster",
                Long:  "Join an existing distributed Ollama cluster",
                RunE:  runJoin,
        }

        cmd.Flags().StringSlice("peers", []string{}, "Peer addresses to join")
        cmd.MarkFlagRequired("peers")

        return cmd
}</span>

func runStart(cmd *cobra.Command, args []string) error <span class="cov0" title="0">{
        cfg, err := config.Load(cfgFile)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to load config: %w", err)
        }</span>

        // Override config with CLI flags
        <span class="cov0" title="0">if listen, _ := cmd.Flags().GetString("listen"); listen != "" </span><span class="cov0" title="0">{
                cfg.API.Listen = listen
        }</span>
        <span class="cov0" title="0">if p2pListen, _ := cmd.Flags().GetString("p2p-listen"); p2pListen != "" </span><span class="cov0" title="0">{
                cfg.P2P.Listen = p2pListen
        }</span>
        <span class="cov0" title="0">if bootstrap, _ := cmd.Flags().GetStringSlice("bootstrap"); len(bootstrap) &gt; 0 </span><span class="cov0" title="0">{
                cfg.P2P.Bootstrap = bootstrap
        }</span>
        <span class="cov0" title="0">if dataDir, _ := cmd.Flags().GetString("data-dir"); dataDir != "" </span><span class="cov0" title="0">{
                cfg.Storage.DataDir = dataDir
        }</span>

        <span class="cov0" title="0">ctx, cancel := context.WithCancel(context.Background())
        defer cancel()

        // Initialize P2P networking
        p2pNode, err := p2p.NewNode(ctx, &amp;cfg.P2P)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create P2P node: %w", err)
        }</span>

        // Initialize consensus engine
        <span class="cov0" title="0">consensusEngine, err := consensus.NewEngine(&amp;cfg.Consensus, p2pNode)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create consensus engine: %w", err)
        }</span>

        // Initialize scheduler
        <span class="cov0" title="0">schedulerEngine, err := scheduler.NewEngine(&amp;cfg.Scheduler, p2pNode, consensusEngine)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create scheduler: %w", err)
        }</span>

        // Initialize API server
        <span class="cov0" title="0">apiServer, err := api.NewServer(&amp;cfg.API, p2pNode, consensusEngine, schedulerEngine)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create API server: %w", err)
        }</span>

        // Start all services
        <span class="cov0" title="0">if err := p2pNode.Start(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start P2P node: %w", err)
        }</span>

        <span class="cov0" title="0">if err := consensusEngine.Start(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start consensus engine: %w", err)
        }</span>

        <span class="cov0" title="0">if err := schedulerEngine.Start(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start scheduler: %w", err)
        }</span>

        <span class="cov0" title="0">if err := apiServer.Start(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start API server: %w", err)
        }</span>

        <span class="cov0" title="0">log.Printf("Distributed Ollama node started successfully")
        log.Printf("API server listening on: %s", cfg.API.Listen)
        log.Printf("P2P node listening on: %s", cfg.P2P.Listen)
        log.Printf("Node ID: %s", p2pNode.ID())

        // Wait for interrupt signal
        sigChan := make(chan os.Signal, 1)
        signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)
        &lt;-sigChan

        log.Println("Shutting down...")

        // Graceful shutdown
        shutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)
        defer shutdownCancel()

        if err := apiServer.Shutdown(shutdownCtx); err != nil </span><span class="cov0" title="0">{
                log.Printf("API server shutdown error: %v", err)
        }</span>

        <span class="cov0" title="0">if err := schedulerEngine.Shutdown(shutdownCtx); err != nil </span><span class="cov0" title="0">{
                log.Printf("Scheduler shutdown error: %v", err)
        }</span>

        <span class="cov0" title="0">if err := consensusEngine.Shutdown(shutdownCtx); err != nil </span><span class="cov0" title="0">{
                log.Printf("Consensus engine shutdown error: %v", err)
        }</span>

        <span class="cov0" title="0">if err := p2pNode.Stop(); err != nil </span><span class="cov0" title="0">{
                log.Printf("P2P node shutdown error: %v", err)
        }</span>

        <span class="cov0" title="0">log.Println("Shutdown complete")
        return nil</span>
}

func runStatus(cmd *cobra.Command, args []string) error <span class="cov0" title="0">{
        cfg, err := config.Load(cfgFile)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to load config: %w", err)
        }</span>

        <span class="cov0" title="0">fmt.Printf("Ollama Distributed Node Status\n")
        fmt.Printf("==============================\n\n")

        // Connect to existing node to get status
        ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
        defer cancel()

        // Try to connect to the API server to get status
        apiAddr := cfg.API.Listen
        fmt.Printf("üîó API Server: %s\n", apiAddr)

        // Initialize a temporary P2P node to check cluster status
        p2pNode, err := p2p.NewNode(ctx, &amp;cfg.P2P)
        if err != nil </span><span class="cov0" title="0">{
                fmt.Printf("‚ùå Failed to initialize P2P node: %v\n", err)
                return nil // Don't fail entirely, show what we can
        }</span>

        // Start P2P node temporarily to get peer information
        <span class="cov0" title="0">if err := p2pNode.Start(); err != nil </span><span class="cov0" title="0">{
                fmt.Printf("‚ùå Failed to start P2P node: %v\n", err)
        }</span> else<span class="cov0" title="0"> {
                defer p2pNode.Stop()
                
                // Wait a moment for peer discovery
                time.Sleep(2 * time.Second)

                // Get node information
                nodeStatus := p2pNode.GetStatus()
                metrics := p2pNode.GetMetrics()
                capabilities := p2pNode.GetCapabilities()
                resourceMetrics := p2pNode.GetResourceMetrics()

                // Display node health and basic info
                fmt.Printf("üìä Node Health\n")
                fmt.Printf("   ID: %s\n", nodeStatus.ID)
                fmt.Printf("   Status: %s\n", getStatusString(nodeStatus.Started))
                fmt.Printf("   Uptime: %v\n", nodeStatus.Uptime)
                fmt.Printf("   Last Activity: %v\n", nodeStatus.LastActivity.Format(time.RFC3339))
                fmt.Printf("\n")

                // Display peer and cluster information
                fmt.Printf("üåê Cluster Status\n")
                fmt.Printf("   Connected Peers: %d\n", nodeStatus.ConnectedPeers)
                fmt.Printf("   Total Connections: %d\n", metrics.TotalConnections)
                fmt.Printf("   Connection Errors: %d\n", metrics.ConnectionErrors)
                fmt.Printf("   Peers Discovered: %d\n", metrics.PeersDiscovered)
                
                // Show listen addresses
                fmt.Printf("   Listen Addresses:\n")
                for _, addr := range nodeStatus.ListenAddresses </span><span class="cov0" title="0">{
                        fmt.Printf("     - %s\n", addr.String())
                }</span>
                <span class="cov0" title="0">fmt.Printf("\n")

                // Display resource utilization
                fmt.Printf("üíª Resource Utilization\n")
                if resourceMetrics != nil </span><span class="cov0" title="0">{
                        fmt.Printf("   CPU Usage: %.1f%%\n", resourceMetrics.CPUUsage)
                        fmt.Printf("   Memory Usage: %s\n", formatBytes(resourceMetrics.MemoryUsage))
                        fmt.Printf("   Disk Usage: %s\n", formatBytes(resourceMetrics.DiskUsage))
                        fmt.Printf("   Network RX: %s/s\n", formatBytes(resourceMetrics.NetworkRx))
                        fmt.Printf("   Network TX: %s/s\n", formatBytes(resourceMetrics.NetworkTx))
                }</span> else<span class="cov0" title="0"> {
                        fmt.Printf("   Resource metrics unavailable\n")
                }</span>
                <span class="cov0" title="0">fmt.Printf("\n")

                // Display node capabilities
                fmt.Printf("‚ö° Node Capabilities\n")
                if capabilities != nil </span><span class="cov0" title="0">{
                        fmt.Printf("   CPU Cores: %d\n", capabilities.CPUCores)
                        fmt.Printf("   Memory: %s\n", formatBytes(capabilities.Memory))
                        fmt.Printf("   Storage: %s\n", formatBytes(capabilities.Storage))
                        fmt.Printf("   Supported Models: %v\n", capabilities.SupportedModels)
                        fmt.Printf("   Available: %t\n", capabilities.Available)
                        fmt.Printf("   Load Factor: %.2f\n", capabilities.LoadFactor)
                }</span> else<span class="cov0" title="0"> {
                        fmt.Printf("   Capabilities not configured\n")
                }</span>
                <span class="cov0" title="0">fmt.Printf("\n")

                // Display performance metrics
                fmt.Printf("üìà Performance Metrics\n")
                fmt.Printf("   Authentication Attempts: %d\n", metrics.AuthAttempts)
                fmt.Printf("   Authentication Successes: %d\n", metrics.AuthSuccesses)
                fmt.Printf("   Authentication Failures: %d\n", metrics.AuthFailures)
                fmt.Printf("   Content Published: %d\n", metrics.ContentPublished)
                fmt.Printf("   Content Requests: %d\n", metrics.ContentRequests)
                fmt.Printf("   Content Provided: %d\n", metrics.ContentProvided)
                fmt.Printf("   Average Latency: %v\n", metrics.AverageLatency)
                fmt.Printf("   Message Throughput: %d msg/s\n", metrics.MessageThroughput)
                fmt.Printf("\n")

                // Display consensus status if available
                fmt.Printf("üó≥Ô∏è  Consensus Status\n")
                fmt.Printf("   Consensus Engine: %s\n", getConsensusStatus(cfg))
                fmt.Printf("   Data Directory: %s\n", cfg.Consensus.DataDir)
                fmt.Printf("   Bind Address: %s\n", cfg.Consensus.BindAddr)
                fmt.Printf("\n")

                // Display scheduler status
                fmt.Printf("üéØ Scheduler Status\n")
                fmt.Printf("   Algorithm: %s\n", cfg.Scheduler.Algorithm)
                fmt.Printf("   Load Balancing: %s\n", cfg.Scheduler.LoadBalancing)
                fmt.Printf("   Worker Count: %d\n", cfg.Scheduler.WorkerCount)
                fmt.Printf("   Queue Size: %d\n", cfg.Scheduler.QueueSize)
                fmt.Printf("\n")</span>
        }

        <span class="cov0" title="0">fmt.Printf("‚úÖ Status check completed\n")
        return nil</span>
}

func runJoin(cmd *cobra.Command, args []string) error <span class="cov0" title="0">{
        cfg, err := config.Load(cfgFile)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to load config: %w", err)
        }</span>

        <span class="cov0" title="0">peers, _ := cmd.Flags().GetStringSlice("peers")
        if len(peers) == 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("no peers specified, use --peers flag to specify peer addresses")
        }</span>

        <span class="cov0" title="0">fmt.Printf("Joining Ollama Distributed Cluster\n")
        fmt.Printf("=================================\n\n")

        ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
        defer cancel()

        // Initialize P2P networking
        fmt.Printf("üîß Initializing P2P node...\n")
        p2pNode, err := p2p.NewNode(ctx, &amp;cfg.P2P)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create P2P node: %w", err)
        }</span>

        // Start P2P node
        <span class="cov0" title="0">fmt.Printf("üöÄ Starting P2P networking...\n")
        if err := p2pNode.Start(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start P2P node: %w", err)
        }</span>
        <span class="cov0" title="0">defer p2pNode.Stop()

        nodeID := p2pNode.ID()
        fmt.Printf("üìç Node ID: %s\n\n", nodeID)

        // Connect to specified peers
        fmt.Printf("üåê Connecting to peers...\n")
        var successfulConnections int
        var connectionErrors []string

        for i, peerAddr := range peers </span><span class="cov0" title="0">{
                fmt.Printf("   [%d/%d] Connecting to %s...", i+1, len(peers), peerAddr)
                
                if err := connectToPeer(ctx, p2pNode, peerAddr); err != nil </span><span class="cov0" title="0">{
                        fmt.Printf(" ‚ùå Failed: %v\n", err)
                        connectionErrors = append(connectionErrors, fmt.Sprintf("%s: %v", peerAddr, err))
                }</span> else<span class="cov0" title="0"> {
                        fmt.Printf(" ‚úÖ Connected\n")
                        successfulConnections++
                }</span>
        }

        <span class="cov0" title="0">if successfulConnections == 0 </span><span class="cov0" title="0">{
                fmt.Printf("\n‚ùå Failed to connect to any peers\n")
                for _, errMsg := range connectionErrors </span><span class="cov0" title="0">{
                        fmt.Printf("   - %s\n", errMsg)
                }</span>
                <span class="cov0" title="0">return fmt.Errorf("no successful peer connections")</span>
        }

        <span class="cov0" title="0">fmt.Printf("\n‚úÖ Connected to %d/%d peers\n\n", successfulConnections, len(peers))

        // Wait for peer discovery and cluster state synchronization
        fmt.Printf("üîç Discovering cluster topology...\n")
        time.Sleep(5 * time.Second)

        // Get current cluster state
        connectedPeers := p2pNode.GetConnectedPeers()
        fmt.Printf("   Found %d peers in cluster\n", len(connectedPeers))

        // Initialize consensus engine and join cluster
        fmt.Printf("üó≥Ô∏è  Joining consensus cluster...\n")
        consensusEngine, err := consensus.NewEngine(&amp;cfg.Consensus, p2pNode)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create consensus engine: %w", err)
        }</span>

        // Start consensus engine (it will automatically try to join the cluster)
        <span class="cov0" title="0">if err := consensusEngine.Start(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start consensus engine: %w", err)
        }</span>
        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                shutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 10*time.Second)
                defer shutdownCancel()
                consensusEngine.Shutdown(shutdownCtx)
        }</span>()

        // Wait for consensus participation
        <span class="cov0" title="0">fmt.Printf("‚è≥ Waiting for consensus participation...\n")
        time.Sleep(10 * time.Second)

        // Check consensus status
        if consensusEngine.IsLeader() </span><span class="cov0" title="0">{
                fmt.Printf("üëë This node is now the cluster leader\n")
        }</span> else<span class="cov0" title="0"> {
                leaderAddr := consensusEngine.Leader()
                if leaderAddr != "" </span><span class="cov0" title="0">{
                        fmt.Printf("üì° Following leader: %s\n", leaderAddr)
                }</span> else<span class="cov0" title="0"> {
                        fmt.Printf("‚è≥ Waiting for leader election...\n")
                }</span>
        }

        // Initialize scheduler
        <span class="cov0" title="0">fmt.Printf("üéØ Joining scheduler network...\n")
        schedulerEngine, err := scheduler.NewEngine(&amp;cfg.Scheduler, p2pNode, consensusEngine)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create scheduler: %w", err)
        }</span>

        <span class="cov0" title="0">if err := schedulerEngine.Start(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start scheduler: %w", err)
        }</span>
        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                shutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 10*time.Second)
                defer shutdownCancel()
                schedulerEngine.Shutdown(shutdownCtx)
        }</span>()

        // Sync cluster state
        <span class="cov0" title="0">fmt.Printf("üîÑ Synchronizing cluster state...\n")
        time.Sleep(3 * time.Second)

        // Display final cluster state
        fmt.Printf("\nüìä Cluster Join Summary\n")
        fmt.Printf("   Node ID: %s\n", nodeID)
        fmt.Printf("   Connected Peers: %d\n", len(p2pNode.GetConnectedPeers()))
        fmt.Printf("   Consensus Status: %s\n", getConsensusJoinStatus(consensusEngine))
        fmt.Printf("   Scheduler Status: %s\n", getSchedulerStatus(schedulerEngine))

        // Final validation
        if len(p2pNode.GetConnectedPeers()) &gt; 0 </span><span class="cov0" title="0">{
                fmt.Printf("\n‚úÖ Successfully joined cluster!\n")
                fmt.Printf("üí° You can now start the full node with: ollama-distributed start\n")
                return nil
        }</span> else<span class="cov0" title="0"> {
                fmt.Printf("\n‚ö†Ô∏è  Joined with warnings - no active peer connections\n")
                return nil
        }</span>
}

// Helper functions for status display

func getStatusString(started bool) string <span class="cov0" title="0">{
        if started </span><span class="cov0" title="0">{
                return "‚úÖ Online"
        }</span>
        <span class="cov0" title="0">return "‚ùå Offline"</span>
}

func formatBytes(bytes int64) string <span class="cov0" title="0">{
        const unit = 1024
        if bytes &lt; unit </span><span class="cov0" title="0">{
                return fmt.Sprintf("%d B", bytes)
        }</span>
        <span class="cov0" title="0">div, exp := int64(unit), 0
        for n := bytes / unit; n &gt;= unit; n /= unit </span><span class="cov0" title="0">{
                div *= unit
                exp++
        }</span>
        <span class="cov0" title="0">return fmt.Sprintf("%.1f %cB", float64(bytes)/float64(div), "KMGTPE"[exp])</span>
}

func getConsensusStatus(cfg *config.Config) string <span class="cov0" title="0">{
        if cfg.Consensus.Bootstrap </span><span class="cov0" title="0">{
                return "Bootstrap mode"
        }</span>
        <span class="cov0" title="0">return "Follower mode"</span>
}

func connectToPeer(ctx context.Context, p2pNode *p2p.P2PNode, peerAddr string) error <span class="cov0" title="0">{
        // Parse multiaddr format peer address
        // Example: /ip4/192.168.1.100/tcp/4001/p2p/QmPeerID
        maddr, err := multiaddr.NewMultiaddr(peerAddr)
        if err != nil </span><span class="cov0" title="0">{
                // Try simpler format: ip:port
                if host, port, err := net.SplitHostPort(peerAddr); err == nil </span><span class="cov0" title="0">{
                        maddr, err = multiaddr.NewMultiaddr(fmt.Sprintf("/ip4/%s/tcp/%s", host, port))
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("invalid peer address format: %w", err)
                        }</span>
                } else<span class="cov0" title="0"> {
                        return fmt.Errorf("invalid peer address format: %w", err)
                }</span>
        }

        // Extract peer info from multiaddr
        <span class="cov0" title="0">peerInfo, err := peer.AddrInfoFromP2pAddr(maddr)
        if err != nil </span><span class="cov0" title="0">{
                // If no peer ID in address, try to connect anyway
                // This is a simplified connection attempt
                return fmt.Errorf("could not extract peer info: %w", err)
        }</span>

        // Connect to the peer
        <span class="cov0" title="0">return p2pNode.ConnectToPeer(ctx, *peerInfo)</span>
}

func getConsensusJoinStatus(engine *consensus.Engine) string <span class="cov0" title="0">{
        if engine.IsLeader() </span><span class="cov0" title="0">{
                return "Leader"
        }</span>
        <span class="cov0" title="0">leader := engine.Leader()
        if leader != "" </span><span class="cov0" title="0">{
                return fmt.Sprintf("Follower (Leader: %s)", leader)
        }</span>
        <span class="cov0" title="0">return "Waiting for leader"</span>
}

func getSchedulerStatus(engine *scheduler.Engine) string <span class="cov0" title="0">{
        if engine.IsHealthy() </span><span class="cov0" title="0">{
                stats := engine.GetStats()
                return fmt.Sprintf("Healthy (%d nodes, %d models)", stats.NodesOnline, stats.ModelsTotal)
        }</span>
        <span class="cov0" title="0">return "Initializing"</span>
}

func init() <span class="cov0" title="0">{
        cobra.OnInitialize(initConfig)
}</span>

func initConfig() <span class="cov0" title="0">{
        if cfgFile != "" </span><span class="cov0" title="0">{
                viper.SetConfigFile(cfgFile)
        }</span> else<span class="cov0" title="0"> {
                home, err := os.UserHomeDir()
                if err != nil </span><span class="cov0" title="0">{
                        log.Fatal(err)
                }</span>

                <span class="cov0" title="0">viper.AddConfigPath(home)
                viper.AddConfigPath(".")
                viper.SetConfigName(".ollama-distributed")</span>
        }

        <span class="cov0" title="0">viper.AutomaticEnv()

        if err := viper.ReadInConfig(); err == nil </span><span class="cov0" title="0">{
                log.Printf("Using config file: %s", viper.ConfigFileUsed())
        }</span>
}</pre>
		
		<pre class="file" id="file1" style="display: none">package auth

import (
        "crypto/rand"
        "crypto/sha256"
        "crypto/subtle"
        "encoding/hex"
        "fmt"
        "sync"
        "time"

        "github.com/golang-jwt/jwt/v5"
        "github.com/ollama/ollama-distributed/internal/config"
        "golang.org/x/crypto/bcrypt"
)

// Manager handles all authentication operations
type Manager struct {
        config *config.AuthConfig
        
        // JWT signing key
        signingKey []byte
        
        // In-memory stores (in production, these would be backed by persistent storage)
        users          map[string]*User
        apiKeys        map[string]*APIKey
        sessions       map[string]*Session
        blacklistCache map[string]time.Time
        
        // Password hasher
        bcryptCost int
        
        // Mutex for thread safety
        mu sync.RWMutex
        
        // Background cleanup
        stopCleanup chan struct{}
}

// NewManager creates a new authentication manager
func NewManager(cfg *config.AuthConfig) (*Manager, error) <span class="cov6" title="7">{
        if cfg == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("auth config is required")
        }</span>
        
        // Generate or use provided signing key
        <span class="cov6" title="7">signingKey := []byte(cfg.SecretKey)
        if len(signingKey) == 0 </span><span class="cov0" title="0">{
                // Generate a random signing key
                signingKey = make([]byte, 32)
                if _, err := rand.Read(signingKey); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to generate signing key: %w", err)
                }</span>
        }
        
        <span class="cov6" title="7">manager := &amp;Manager{
                config:         cfg,
                signingKey:     signingKey,
                users:          make(map[string]*User),
                apiKeys:        make(map[string]*APIKey),
                sessions:       make(map[string]*Session),
                blacklistCache: make(map[string]time.Time),
                bcryptCost:     bcrypt.DefaultCost,
                stopCleanup:    make(chan struct{}),
        }
        
        // Create default admin user if none exists
        if err := manager.createDefaultAdmin(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create default admin: %w", err)
        }</span>
        
        // Start background cleanup routines
        <span class="cov6" title="7">go manager.cleanupExpiredSessions()
        go manager.cleanupBlacklist()
        
        return manager, nil</span>
}

// Close gracefully shuts down the auth manager
func (m *Manager) Close() <span class="cov6" title="7">{
        close(m.stopCleanup)
}</span>

// createDefaultAdmin creates a default admin user if no users exist
func (m *Manager) createDefaultAdmin() error <span class="cov6" title="7">{
        m.mu.Lock()
        defer m.mu.Unlock()
        
        // Check if any users exist
        if len(m.users) &gt; 0 </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        // Create default admin user
        <span class="cov6" title="7">hashedPassword, err := bcrypt.GenerateFromPassword([]byte("admin123"), m.bcryptCost)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to hash default password: %w", err)
        }</span>
        
        <span class="cov6" title="7">adminUser := &amp;User{
                ID:          generateID(),
                Username:    "admin",
                Email:       "admin@localhost",
                Role:        RoleAdmin,
                Permissions: DefaultRolePermissions[RoleAdmin],
                Metadata: map[string]string{
                        "password_hash": string(hashedPassword),
                        "created_by":    "system",
                },
                CreatedAt: time.Now(),
                UpdatedAt: time.Now(),
                Active:    true,
        }
        
        m.users[adminUser.ID] = adminUser
        
        fmt.Printf("Created default admin user (username: admin, password: admin123)\n")
        fmt.Printf("WARNING: Please change the default password immediately!\n")
        
        return nil</span>
}

// Authenticate validates credentials and returns an auth context
func (m *Manager) Authenticate(username, password string, metadata map[string]string) (*AuthContext, error) <span class="cov5" title="5">{
        m.mu.RLock()
        defer m.mu.RUnlock()
        
        // Find user by username
        var user *User
        for _, u := range m.users </span><span class="cov6" title="6">{
                if u.Username == username &amp;&amp; u.Active </span><span class="cov5" title="5">{
                        user = u
                        break</span>
                }
        }
        
        <span class="cov5" title="5">if user == nil </span><span class="cov0" title="0">{
                return nil, ErrInvalidCredentials
        }</span>
        
        // Verify password
        <span class="cov5" title="5">passwordHash := user.Metadata["password_hash"]
        if err := bcrypt.CompareHashAndPassword([]byte(passwordHash), []byte(password)); err != nil </span><span class="cov0" title="0">{
                return nil, ErrInvalidCredentials
        }</span>
        
        // Update last login
        <span class="cov5" title="5">now := time.Now()
        user.LastLoginAt = &amp;now
        user.UpdatedAt = now
        
        // Create session
        session := &amp;Session{
                ID:        generateID(),
                UserID:    user.ID,
                IPAddress: metadata["ip_address"],
                UserAgent: metadata["user_agent"],
                Metadata:  metadata,
                CreatedAt: now,
                ExpiresAt: now.Add(m.config.TokenExpiry),
                Active:    true,
        }
        
        m.sessions[session.ID] = session
        
        // Generate JWT token
        claims := &amp;Claims{
                UserID:      user.ID,
                Username:    user.Username,
                Email:       user.Email,
                Role:        user.Role,
                Permissions: user.Permissions,
                SessionID:   session.ID,
                Metadata:    user.Metadata,
                RegisteredClaims: jwt.RegisteredClaims{
                        ExpiresAt: jwt.NewNumericDate(session.ExpiresAt),
                        IssuedAt:  jwt.NewNumericDate(now),
                        NotBefore: jwt.NewNumericDate(now),
                        Issuer:    m.config.Issuer,
                        Subject:   user.ID,
                        ID:        generateID(),
                        Audience:  []string{m.config.Audience},
                },
        }
        
        token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)
        tokenString, err := token.SignedString(m.signingKey)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to sign token: %w", err)
        }</span>
        
        <span class="cov5" title="5">session.TokenID = claims.ID
        
        return &amp;AuthContext{
                User:        user,
                Session:     session,
                Claims:      claims,
                TokenString: tokenString,
                Method:      AuthMethodJWT,
        }, nil</span>
}

// ValidateToken validates a JWT token and returns the auth context
func (m *Manager) ValidateToken(tokenString string) (*AuthContext, error) <span class="cov4" title="3">{
        token, err := jwt.ParseWithClaims(tokenString, &amp;Claims{}, func(token *jwt.Token) (interface{}, error) </span><span class="cov4" title="3">{
                if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("unexpected signing method: %v", token.Header["alg"])
                }</span>
                <span class="cov4" title="3">return m.signingKey, nil</span>
        })
        
        <span class="cov4" title="3">if err != nil </span><span class="cov0" title="0">{
                return nil, ErrTokenInvalid
        }</span>
        
        <span class="cov4" title="3">claims, ok := token.Claims.(*Claims)
        if !ok || !token.Valid </span><span class="cov0" title="0">{
                return nil, ErrTokenInvalid
        }</span>
        
        // Check if token is blacklisted
        <span class="cov4" title="3">if m.isTokenBlacklisted(claims.ID) </span><span class="cov1" title="1">{
                return nil, ErrTokenBlacklisted
        }</span>
        
        <span class="cov2" title="2">m.mu.RLock()
        defer m.mu.RUnlock()
        
        // Get user
        user, exists := m.users[claims.UserID]
        if !exists || !user.Active </span><span class="cov0" title="0">{
                return nil, ErrUserNotFound
        }</span>
        
        // Get session if available
        <span class="cov2" title="2">var session *Session
        if claims.SessionID != "" </span><span class="cov2" title="2">{
                if s, exists := m.sessions[claims.SessionID]; exists &amp;&amp; s.Active </span><span class="cov2" title="2">{
                        if time.Now().After(s.ExpiresAt) </span><span class="cov0" title="0">{
                                return nil, ErrSessionExpired
                        }</span>
                        <span class="cov2" title="2">session = s</span>
                }
        }
        
        <span class="cov2" title="2">return &amp;AuthContext{
                User:        user,
                Session:     session,
                Claims:      claims,
                TokenString: tokenString,
                Method:      AuthMethodJWT,
        }, nil</span>
}

// ValidateAPIKey validates an API key and returns the auth context
func (m *Manager) ValidateAPIKey(key string) (*AuthContext, error) <span class="cov1" title="1">{
        keyHash := hashAPIKey(key)
        
        m.mu.RLock()
        defer m.mu.RUnlock()
        
        // Find API key
        var apiKey *APIKey
        for _, ak := range m.apiKeys </span><span class="cov1" title="1">{
                if subtle.ConstantTimeCompare([]byte(ak.Key), []byte(keyHash)) == 1 &amp;&amp; ak.Active </span><span class="cov1" title="1">{
                        apiKey = ak
                        break</span>
                }
        }
        
        <span class="cov1" title="1">if apiKey == nil </span><span class="cov0" title="0">{
                return nil, ErrAPIKeyNotFound
        }</span>
        
        // Check expiration
        <span class="cov1" title="1">if apiKey.ExpiresAt != nil &amp;&amp; time.Now().After(*apiKey.ExpiresAt) </span><span class="cov0" title="0">{
                return nil, ErrAPIKeyExpired
        }</span>
        
        // Get user
        <span class="cov1" title="1">user, exists := m.users[apiKey.UserID]
        if !exists || !user.Active </span><span class="cov0" title="0">{
                return nil, ErrUserNotFound
        }</span>
        
        // Update last used
        <span class="cov1" title="1">now := time.Now()
        apiKey.LastUsedAt = &amp;now
        
        return &amp;AuthContext{
                User:   user,
                APIKey: apiKey,
                Method: AuthMethodAPIKey,
        }, nil</span>
}

// CreateUser creates a new user
func (m *Manager) CreateUser(req *CreateUserRequest) (*User, error) <span class="cov4" title="3">{
        m.mu.Lock()
        defer m.mu.Unlock()
        
        // Check if username already exists
        for _, u := range m.users </span><span class="cov4" title="3">{
                if u.Username == req.Username </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("username already exists")
                }</span>
        }
        
        // Hash password
        <span class="cov4" title="3">hashedPassword, err := bcrypt.GenerateFromPassword([]byte(req.Password), m.bcryptCost)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to hash password: %w", err)
        }</span>
        
        // Set permissions based on role if not provided
        <span class="cov4" title="3">permissions := req.Permissions
        if len(permissions) == 0 </span><span class="cov2" title="2">{
                if rolePerms, exists := DefaultRolePermissions[req.Role]; exists </span><span class="cov2" title="2">{
                        permissions = rolePerms
                }</span>
        }
        
        // Create user
        <span class="cov4" title="3">user := &amp;User{
                ID:          generateID(),
                Username:    req.Username,
                Email:       req.Email,
                Role:        req.Role,
                Permissions: permissions,
                Metadata: map[string]string{
                        "password_hash": string(hashedPassword),
                },
                CreatedAt: time.Now(),
                UpdatedAt: time.Now(),
                Active:    true,
        }
        
        // Add custom metadata
        for k, v := range req.Metadata </span><span class="cov0" title="0">{
                user.Metadata[k] = v
        }</span>
        
        <span class="cov4" title="3">m.users[user.ID] = user
        
        return user, nil</span>
}

// CreateAPIKey creates a new API key for a user
func (m *Manager) CreateAPIKey(userID string, req *CreateAPIKeyRequest) (*APIKey, string, error) <span class="cov1" title="1">{
        m.mu.Lock()
        defer m.mu.Unlock()
        
        // Check if user exists
        user, exists := m.users[userID]
        if !exists || !user.Active </span><span class="cov0" title="0">{
                return nil, "", ErrUserNotFound
        }</span>
        
        // Generate API key
        <span class="cov1" title="1">rawKey := generateAPIKey()
        keyHash := hashAPIKey(rawKey)
        
        // Set permissions
        permissions := req.Permissions
        if len(permissions) == 0 </span><span class="cov0" title="0">{
                permissions = user.Permissions
        }</span>
        
        <span class="cov1" title="1">apiKey := &amp;APIKey{
                ID:          generateID(),
                Name:        req.Name,
                Key:         keyHash,
                UserID:      userID,
                Permissions: permissions,
                Metadata:    req.Metadata,
                ExpiresAt:   req.ExpiresAt,
                CreatedAt:   time.Now(),
                Active:      true,
        }
        
        if apiKey.Metadata == nil </span><span class="cov1" title="1">{
                apiKey.Metadata = make(map[string]string)
        }</span>
        
        <span class="cov1" title="1">m.apiKeys[apiKey.ID] = apiKey
        
        return apiKey, rawKey, nil</span>
}

// RevokeToken adds a token to the blacklist
func (m *Manager) RevokeToken(tokenID string, expiry time.Time) <span class="cov1" title="1">{
        m.mu.Lock()
        defer m.mu.Unlock()
        
        m.blacklistCache[tokenID] = expiry
}</span>

// RevokeSession revokes a session
func (m *Manager) RevokeSession(sessionID string) error <span class="cov0" title="0">{
        m.mu.Lock()
        defer m.mu.Unlock()
        
        session, exists := m.sessions[sessionID]
        if !exists </span><span class="cov0" title="0">{
                return ErrSessionNotFound
        }</span>
        
        <span class="cov0" title="0">session.Active = false
        
        // Also blacklist the associated token
        if session.TokenID != "" </span><span class="cov0" title="0">{
                m.blacklistCache[session.TokenID] = session.ExpiresAt
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// RevokeAPIKey revokes an API key
func (m *Manager) RevokeAPIKey(keyID string) error <span class="cov0" title="0">{
        m.mu.Lock()
        defer m.mu.Unlock()
        
        apiKey, exists := m.apiKeys[keyID]
        if !exists </span><span class="cov0" title="0">{
                return ErrAPIKeyNotFound
        }</span>
        
        <span class="cov0" title="0">apiKey.Active = false
        
        return nil</span>
}

// HasPermission checks if the auth context has a specific permission
func (m *Manager) HasPermission(ctx *AuthContext, permission string) bool <span class="cov5" title="5">{
        if ctx == nil || ctx.User == nil </span><span class="cov0" title="0">{
                return false
        }</span>
        
        // Admin role has all permissions
        <span class="cov5" title="5">if ctx.User.Role == RoleAdmin </span><span class="cov2" title="2">{
                return true
        }</span>
        
        // Check user permissions
        <span class="cov4" title="3">for _, perm := range ctx.User.Permissions </span><span class="cov5" title="5">{
                if perm == permission || perm == PermissionSystemAdmin </span><span class="cov2" title="2">{
                        return true
                }</span>
        }
        
        // Check API key permissions if using API key auth
        <span class="cov1" title="1">if ctx.Method == AuthMethodAPIKey &amp;&amp; ctx.APIKey != nil </span><span class="cov0" title="0">{
                for _, perm := range ctx.APIKey.Permissions </span><span class="cov0" title="0">{
                        if perm == permission || perm == PermissionSystemAdmin </span><span class="cov0" title="0">{
                                return true
                        }</span>
                }
        }
        
        <span class="cov1" title="1">return false</span>
}

// isTokenBlacklisted checks if a token is blacklisted
func (m *Manager) isTokenBlacklisted(tokenID string) bool <span class="cov4" title="3">{
        m.mu.RLock()
        defer m.mu.RUnlock()
        
        expiry, exists := m.blacklistCache[tokenID]
        if !exists </span><span class="cov2" title="2">{
                return false
        }</span>
        
        // Check if blacklist entry has expired
        <span class="cov1" title="1">if time.Now().After(expiry) </span><span class="cov0" title="0">{
                delete(m.blacklistCache, tokenID)
                return false
        }</span>
        
        <span class="cov1" title="1">return true</span>
}

// Background cleanup routines
func (m *Manager) cleanupExpiredSessions() <span class="cov6" title="7">{
        ticker := time.NewTicker(30 * time.Minute)
        defer ticker.Stop()
        
        for </span><span class="cov6" title="7">{
                select </span>{
                case &lt;-ticker.C:<span class="cov0" title="0">
                        m.mu.Lock()
                        now := time.Now()
                        for id, session := range m.sessions </span><span class="cov0" title="0">{
                                if now.After(session.ExpiresAt) </span><span class="cov0" title="0">{
                                        delete(m.sessions, id)
                                }</span>
                        }
                        <span class="cov0" title="0">m.mu.Unlock()</span>
                case &lt;-m.stopCleanup:<span class="cov6" title="7">
                        return</span>
                }
        }
}

func (m *Manager) cleanupBlacklist() <span class="cov6" title="7">{
        ticker := time.NewTicker(time.Hour)
        defer ticker.Stop()
        
        for </span><span class="cov6" title="7">{
                select </span>{
                case &lt;-ticker.C:<span class="cov0" title="0">
                        m.mu.Lock()
                        now := time.Now()
                        for tokenID, expiry := range m.blacklistCache </span><span class="cov0" title="0">{
                                if now.After(expiry) </span><span class="cov0" title="0">{
                                        delete(m.blacklistCache, tokenID)
                                }</span>
                        }
                        <span class="cov0" title="0">m.mu.Unlock()</span>
                case &lt;-m.stopCleanup:<span class="cov6" title="7">
                        return</span>
                }
        }
}

// Utility functions
func generateID() string <span class="cov10" title="24">{
        bytes := make([]byte, 16)
        rand.Read(bytes)
        return hex.EncodeToString(bytes)
}</span>

func generateAPIKey() string <span class="cov2" title="2">{
        bytes := make([]byte, 32)
        rand.Read(bytes)
        return "ok_" + hex.EncodeToString(bytes)
}</span>

func hashAPIKey(key string) string <span class="cov4" title="3">{
        hash := sha256.Sum256([]byte(key))
        return hex.EncodeToString(hash[:])
}</pre>
		
		<pre class="file" id="file2" style="display: none">package auth

import (
        "fmt"
        "log"

        "github.com/gin-gonic/gin"
        "github.com/ollama/ollama-distributed/internal/config"
)

// Integration provides easy integration with the existing API server
type Integration struct {
        AuthManager       *Manager
        JWTManager        *JWTManager
        MiddlewareManager *MiddlewareManager
        Routes            *Routes
}

// NewIntegration creates a complete authentication integration
func NewIntegration(cfg *config.AuthConfig) (*Integration, error) <span class="cov0" title="0">{
        // Create auth manager
        authManager, err := NewManager(cfg)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create auth manager: %w", err)
        }</span>
        
        // Create JWT manager
        <span class="cov0" title="0">jwtManager, err := NewJWTManager(cfg)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create JWT manager: %w", err)
        }</span>
        
        // Create middleware manager
        <span class="cov0" title="0">middlewareManager := NewMiddlewareManager(authManager, jwtManager, cfg)
        
        // Create routes
        routes := NewRoutes(authManager, jwtManager, middlewareManager)
        
        return &amp;Integration{
                AuthManager:       authManager,
                JWTManager:        jwtManager,
                MiddlewareManager: middlewareManager,
                Routes:            routes,
        }, nil</span>
}

// SetupRouter configures a Gin router with authentication
func (i *Integration) SetupRouter() *gin.Engine <span class="cov0" title="0">{
        router := gin.New()
        
        // Register authentication routes
        i.Routes.RegisterRoutes(router)
        
        return router
}</span>

// ProtectAPIRoutes adds authentication to existing API routes
func (i *Integration) ProtectAPIRoutes(router *gin.Engine) <span class="cov0" title="0">{
        // Apply authentication middleware to protected API routes
        api := router.Group("/api/v1")
        api.Use(i.MiddlewareManager.AuthRequired())
        
        // Node management - requires node permissions
        nodeRoutes := api.Group("/nodes")
        nodeRoutes.Use(i.MiddlewareManager.RequireAnyPermission(
                PermissionNodeRead,
                PermissionNodeWrite,
                PermissionNodeAdmin,
        ))
        
        // Model management - requires model permissions
        modelRoutes := api.Group("/models")
        modelRoutes.Use(i.MiddlewareManager.RequireAnyPermission(
                PermissionModelRead,
                PermissionModelWrite,
                PermissionModelAdmin,
        ))
        
        // Cluster management - requires cluster permissions
        clusterRoutes := api.Group("/cluster")
        clusterRoutes.Use(i.MiddlewareManager.RequireAnyPermission(
                PermissionClusterRead,
                PermissionClusterWrite,
                PermissionClusterAdmin,
        ))
        
        // Inference - requires inference permissions
        inferenceRoutes := api.Group("/")
        inferenceRoutes.Use(i.MiddlewareManager.RequireAnyPermission(
                PermissionInferenceRead,
                PermissionInferenceWrite,
        ))
        
        // Metrics - requires metrics permissions
        metricsRoutes := api.Group("/metrics")
        metricsRoutes.Use(i.MiddlewareManager.RequirePermission(PermissionMetricsRead))
}</span>

// CreateServiceToken creates a service token for internal communication
func (i *Integration) CreateServiceToken(serviceID, serviceName string) (string, error) <span class="cov0" title="0">{
        permissions := []string{
                PermissionNodeRead,
                PermissionModelRead,
                PermissionInferenceWrite,
                PermissionClusterRead,
        }
        
        return i.JWTManager.GenerateServiceToken(serviceID, serviceName, permissions)
}</span>

// CreateAdminToken creates an admin token for administrative tasks
func (i *Integration) CreateAdminToken(adminID, adminName string) (string, error) <span class="cov0" title="0">{
        permissions := DefaultRolePermissions[RoleAdmin]
        return i.JWTManager.GenerateServiceToken(adminID, adminName, permissions)
}</span>

// Close gracefully shuts down the authentication system
func (i *Integration) Close() <span class="cov0" title="0">{
        i.AuthManager.Close()
}</span>

// Example integration with existing server
func ExampleIntegration() <span class="cov0" title="0">{
        // Load configuration
        cfg := &amp;config.AuthConfig{
                Enabled:     true,
                Method:      "jwt",
                TokenExpiry: 24 * 3600, // 24 hours in seconds
                SecretKey:   "your-secret-key",
                Issuer:      "ollama-distributed",
                Audience:    "ollama-api",
        }
        
        // Create authentication integration
        authIntegration, err := NewIntegration(cfg)
        if err != nil </span><span class="cov0" title="0">{
                log.Fatalf("Failed to create auth integration: %v", err)
        }</span>
        <span class="cov0" title="0">defer authIntegration.Close()
        
        // Setup router with authentication
        router := gin.New()
        
        // Register authentication routes
        authIntegration.Routes.RegisterRoutes(router)
        
        // Protect existing API routes
        authIntegration.ProtectAPIRoutes(router)
        
        // Example: Add a protected endpoint
        protected := router.Group("/api/v1/protected")
        protected.Use(authIntegration.MiddlewareManager.AuthRequired())
        protected.Use(authIntegration.MiddlewareManager.RequirePermission(PermissionSystemAdmin))
        </span><span class="cov0" title="0">{
                protected.GET("/admin-only", func(c *gin.Context) </span><span class="cov0" title="0">{
                        user := GetCurrentUser(c)
                        c.JSON(200, gin.H{
                                "message": "This is an admin-only endpoint",
                                "user":    user.Username,
                                "role":    user.Role,
                        })
                }</span>)
        }
        
        // Example: Create a service token
        <span class="cov0" title="0">serviceToken, err := authIntegration.CreateServiceToken("node-1", "Ollama Node 1")
        if err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to create service token: %v", err)
        }</span> else<span class="cov0" title="0"> {
                log.Printf("Service token created: %s", serviceToken)
        }</span>
        
        // Start server
        <span class="cov0" title="0">log.Println("Starting server with authentication on :8080")
        router.Run(":8080")</span>
}

// MiddlewareHelpers provides helper functions for common middleware patterns
type MiddlewareHelpers struct {
        integration *Integration
}

// NewMiddlewareHelpers creates middleware helpers
func NewMiddlewareHelpers(integration *Integration) *MiddlewareHelpers <span class="cov0" title="0">{
        return &amp;MiddlewareHelpers{integration: integration}
}</span>

// RequireNodePermission creates middleware for node operations
func (mh *MiddlewareHelpers) RequireNodePermission(operation string) gin.HandlerFunc <span class="cov0" title="0">{
        switch operation </span>{
        case "read":<span class="cov0" title="0">
                return mh.integration.MiddlewareManager.RequirePermission(PermissionNodeRead)</span>
        case "write":<span class="cov0" title="0">
                return mh.integration.MiddlewareManager.RequirePermission(PermissionNodeWrite)</span>
        case "admin":<span class="cov0" title="0">
                return mh.integration.MiddlewareManager.RequirePermission(PermissionNodeAdmin)</span>
        default:<span class="cov0" title="0">
                return mh.integration.MiddlewareManager.RequirePermission(PermissionNodeRead)</span>
        }
}

// RequireModelPermission creates middleware for model operations
func (mh *MiddlewareHelpers) RequireModelPermission(operation string) gin.HandlerFunc <span class="cov0" title="0">{
        switch operation </span>{
        case "read":<span class="cov0" title="0">
                return mh.integration.MiddlewareManager.RequirePermission(PermissionModelRead)</span>
        case "write":<span class="cov0" title="0">
                return mh.integration.MiddlewareManager.RequirePermission(PermissionModelWrite)</span>
        case "admin":<span class="cov0" title="0">
                return mh.integration.MiddlewareManager.RequirePermission(PermissionModelAdmin)</span>
        default:<span class="cov0" title="0">
                return mh.integration.MiddlewareManager.RequirePermission(PermissionModelRead)</span>
        }
}

// RequireClusterPermission creates middleware for cluster operations
func (mh *MiddlewareHelpers) RequireClusterPermission(operation string) gin.HandlerFunc <span class="cov0" title="0">{
        switch operation </span>{
        case "read":<span class="cov0" title="0">
                return mh.integration.MiddlewareManager.RequirePermission(PermissionClusterRead)</span>
        case "write":<span class="cov0" title="0">
                return mh.integration.MiddlewareManager.RequirePermission(PermissionClusterWrite)</span>
        case "admin":<span class="cov0" title="0">
                return mh.integration.MiddlewareManager.RequirePermission(PermissionClusterAdmin)</span>
        default:<span class="cov0" title="0">
                return mh.integration.MiddlewareManager.RequirePermission(PermissionClusterRead)</span>
        }
}

// RequireInferencePermission creates middleware for inference operations
func (mh *MiddlewareHelpers) RequireInferencePermission(operation string) gin.HandlerFunc <span class="cov0" title="0">{
        switch operation </span>{
        case "read":<span class="cov0" title="0">
                return mh.integration.MiddlewareManager.RequirePermission(PermissionInferenceRead)</span>
        case "write":<span class="cov0" title="0">
                return mh.integration.MiddlewareManager.RequirePermission(PermissionInferenceWrite)</span>
        default:<span class="cov0" title="0">
                return mh.integration.MiddlewareManager.RequirePermission(PermissionInferenceRead)</span>
        }
}

// Example usage in existing API handlers
func ExampleAPIIntegration(authIntegration *Integration) <span class="cov0" title="0">{
        router := gin.New()
        helpers := NewMiddlewareHelpers(authIntegration)
        
        // Register auth routes
        authIntegration.Routes.RegisterRoutes(router)
        
        // Protected API routes
        api := router.Group("/api/v1")
        api.Use(authIntegration.MiddlewareManager.AuthRequired())
        
        // Node management with granular permissions
        nodes := api.Group("/nodes")
        </span><span class="cov0" title="0">{
                nodes.GET("", helpers.RequireNodePermission("read"), func(c *gin.Context) </span><span class="cov0" title="0">{
                        // Get nodes logic
                        c.JSON(200, gin.H{"nodes": []string{}})
                }</span>)
                
                <span class="cov0" title="0">nodes.POST("", helpers.RequireNodePermission("write"), func(c *gin.Context) </span><span class="cov0" title="0">{
                        // Create node logic
                        c.JSON(201, gin.H{"message": "Node created"})
                }</span>)
                
                <span class="cov0" title="0">nodes.DELETE("/:id", helpers.RequireNodePermission("admin"), func(c *gin.Context) </span><span class="cov0" title="0">{
                        // Delete node logic
                        c.JSON(200, gin.H{"message": "Node deleted"})
                }</span>)
        }
        
        // Model management with granular permissions
        <span class="cov0" title="0">models := api.Group("/models")
        </span><span class="cov0" title="0">{
                models.GET("", helpers.RequireModelPermission("read"), func(c *gin.Context) </span><span class="cov0" title="0">{
                        // Get models logic
                        c.JSON(200, gin.H{"models": []string{}})
                }</span>)
                
                <span class="cov0" title="0">models.POST("/:name/download", helpers.RequireModelPermission("write"), func(c *gin.Context) </span><span class="cov0" title="0">{
                        // Download model logic
                        c.JSON(200, gin.H{"message": "Download started"})
                }</span>)
                
                <span class="cov0" title="0">models.DELETE("/:name", helpers.RequireModelPermission("admin"), func(c *gin.Context) </span><span class="cov0" title="0">{
                        // Delete model logic
                        c.JSON(200, gin.H{"message": "Model deleted"})
                }</span>)
        }
        
        // Inference endpoints
        <span class="cov0" title="0">inference := api.Group("/")
        </span><span class="cov0" title="0">{
                inference.POST("/generate", helpers.RequireInferencePermission("write"), func(c *gin.Context) </span><span class="cov0" title="0">{
                        // Generate logic
                        user := GetCurrentUser(c)
                        c.JSON(200, gin.H{
                                "response": "Generated text",
                                "user":     user.Username,
                        })
                }</span>)
                
                <span class="cov0" title="0">inference.POST("/chat", helpers.RequireInferencePermission("write"), func(c *gin.Context) </span><span class="cov0" title="0">{
                        // Chat logic
                        c.JSON(200, gin.H{"response": "Chat response"})
                }</span>)
        }
        
        // Metrics (read-only)
        <span class="cov0" title="0">api.GET("/metrics", helpers.RequireInferencePermission("read"), func(c *gin.Context) </span><span class="cov0" title="0">{
                // Metrics logic
                c.JSON(200, gin.H{"metrics": map[string]interface{}{}})
        }</span>)
}</pre>
		
		<pre class="file" id="file3" style="display: none">package auth

import (
        "crypto/rand"
        "crypto/rsa"
        "fmt"
        "time"

        "github.com/golang-jwt/jwt/v5"
        "github.com/ollama/ollama-distributed/internal/config"
)

// JWTManager handles JWT token operations with advanced features
type JWTManager struct {
        config     *config.AuthConfig
        privateKey *rsa.PrivateKey
        publicKey  *rsa.PublicKey
        
        // Token blacklist and refresh tokens
        blacklist    map[string]time.Time
        refreshTokens map[string]*RefreshToken
}

// RefreshToken represents a refresh token
type RefreshToken struct {
        ID        string    `json:"id"`
        UserID    string    `json:"user_id"`
        TokenHash string    `json:"token_hash"`
        ExpiresAt time.Time `json:"expires_at"`
        CreatedAt time.Time `json:"created_at"`
        Used      bool      `json:"used"`
}

// TokenPair represents an access token and refresh token pair
type TokenPair struct {
        AccessToken  string    `json:"access_token"`
        RefreshToken string    `json:"refresh_token"`
        ExpiresAt    time.Time `json:"expires_at"`
        TokenType    string    `json:"token_type"`
}

// NewJWTManager creates a new JWT manager
func NewJWTManager(cfg *config.AuthConfig) (*JWTManager, error) <span class="cov10" title="2">{
        // Generate RSA key pair for signing
        privateKey, err := rsa.GenerateKey(rand.Reader, 2048)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to generate RSA key: %w", err)
        }</span>
        
        <span class="cov10" title="2">return &amp;JWTManager{
                config:        cfg,
                privateKey:    privateKey,
                publicKey:     &amp;privateKey.PublicKey,
                blacklist:     make(map[string]time.Time),
                refreshTokens: make(map[string]*RefreshToken),
        }, nil</span>
}

// GenerateTokenPair generates an access token and refresh token pair
func (jm *JWTManager) GenerateTokenPair(user *User, sessionID string, metadata map[string]string) (*TokenPair, error) <span class="cov1" title="1">{
        now := time.Now()
        accessTokenExpiry := now.Add(jm.config.TokenExpiry)
        refreshTokenExpiry := now.Add(7 * 24 * time.Hour) // 7 days for refresh token
        
        // Create access token claims
        accessClaims := &amp;Claims{
                UserID:      user.ID,
                Username:    user.Username,
                Email:       user.Email,
                Role:        user.Role,
                Permissions: user.Permissions,
                SessionID:   sessionID,
                Metadata:    metadata,
                RegisteredClaims: jwt.RegisteredClaims{
                        ExpiresAt: jwt.NewNumericDate(accessTokenExpiry),
                        IssuedAt:  jwt.NewNumericDate(now),
                        NotBefore: jwt.NewNumericDate(now),
                        Issuer:    jm.config.Issuer,
                        Subject:   user.ID,
                        ID:        generateID(),
                        Audience:  []string{jm.config.Audience},
                },
        }
        
        // Sign access token
        accessToken := jwt.NewWithClaims(jwt.SigningMethodRS256, accessClaims)
        accessTokenString, err := accessToken.SignedString(jm.privateKey)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to sign access token: %w", err)
        }</span>
        
        // Create refresh token
        <span class="cov1" title="1">refreshTokenID := generateID()
        refreshTokenString := generateAPIKey() // Reuse the secure random generation
        refreshTokenHash := hashAPIKey(refreshTokenString)
        
        refreshToken := &amp;RefreshToken{
                ID:        refreshTokenID,
                UserID:    user.ID,
                TokenHash: refreshTokenHash,
                ExpiresAt: refreshTokenExpiry,
                CreatedAt: now,
                Used:      false,
        }
        
        jm.refreshTokens[refreshTokenID] = refreshToken
        
        return &amp;TokenPair{
                AccessToken:  accessTokenString,
                RefreshToken: refreshTokenString,
                ExpiresAt:    accessTokenExpiry,
                TokenType:    "Bearer",
        }, nil</span>
}

// RefreshAccessToken generates a new access token using a refresh token
func (jm *JWTManager) RefreshAccessToken(refreshTokenString string, user *User) (*TokenPair, error) <span class="cov0" title="0">{
        refreshTokenHash := hashAPIKey(refreshTokenString)
        
        // Find the refresh token
        var refreshToken *RefreshToken
        for _, rt := range jm.refreshTokens </span><span class="cov0" title="0">{
                if rt.TokenHash == refreshTokenHash &amp;&amp; rt.UserID == user.ID &amp;&amp; !rt.Used </span><span class="cov0" title="0">{
                        if time.Now().Before(rt.ExpiresAt) </span><span class="cov0" title="0">{
                                refreshToken = rt
                                break</span>
                        }
                }
        }
        
        <span class="cov0" title="0">if refreshToken == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("invalid or expired refresh token")
        }</span>
        
        // Mark the old refresh token as used
        <span class="cov0" title="0">refreshToken.Used = true
        
        // Generate new token pair
        return jm.GenerateTokenPair(user, "", nil)</span>
}

// ValidateToken validates a JWT access token
func (jm *JWTManager) ValidateToken(tokenString string) (*Claims, error) <span class="cov10" title="2">{
        token, err := jwt.ParseWithClaims(tokenString, &amp;Claims{}, func(token *jwt.Token) (interface{}, error) </span><span class="cov10" title="2">{
                if _, ok := token.Method.(*jwt.SigningMethodRSA); !ok </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("unexpected signing method: %v", token.Header["alg"])
                }</span>
                <span class="cov10" title="2">return jm.publicKey, nil</span>
        })
        
        <span class="cov10" title="2">if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to parse token: %w", err)
        }</span>
        
        <span class="cov10" title="2">claims, ok := token.Claims.(*Claims)
        if !ok || !token.Valid </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("invalid token claims")
        }</span>
        
        // Check if token is blacklisted
        <span class="cov10" title="2">if jm.isBlacklisted(claims.ID) </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("token is blacklisted")
        }</span>
        
        <span class="cov10" title="2">return claims, nil</span>
}

// BlacklistToken adds a token to the blacklist
func (jm *JWTManager) BlacklistToken(tokenID string, expiry time.Time) <span class="cov0" title="0">{
        jm.blacklist[tokenID] = expiry
}</span>

// RevokeRefreshToken revokes a refresh token
func (jm *JWTManager) RevokeRefreshToken(refreshTokenString, userID string) error <span class="cov0" title="0">{
        refreshTokenHash := hashAPIKey(refreshTokenString)
        
        for _, rt := range jm.refreshTokens </span><span class="cov0" title="0">{
                if rt.TokenHash == refreshTokenHash &amp;&amp; rt.UserID == userID </span><span class="cov0" title="0">{
                        rt.Used = true
                        return nil
                }</span>
        }
        
        <span class="cov0" title="0">return fmt.Errorf("refresh token not found")</span>
}

// RevokeAllUserTokens revokes all tokens for a user
func (jm *JWTManager) RevokeAllUserTokens(userID string) <span class="cov0" title="0">{
        // Mark all refresh tokens as used
        for _, rt := range jm.refreshTokens </span><span class="cov0" title="0">{
                if rt.UserID == userID </span><span class="cov0" title="0">{
                        rt.Used = true
                }</span>
        }
}

// CleanupExpiredTokens removes expired tokens from memory
func (jm *JWTManager) CleanupExpiredTokens() <span class="cov0" title="0">{
        now := time.Now()
        
        // Clean up blacklist
        for tokenID, expiry := range jm.blacklist </span><span class="cov0" title="0">{
                if now.After(expiry) </span><span class="cov0" title="0">{
                        delete(jm.blacklist, tokenID)
                }</span>
        }
        
        // Clean up refresh tokens
        <span class="cov0" title="0">for id, rt := range jm.refreshTokens </span><span class="cov0" title="0">{
                if now.After(rt.ExpiresAt) || rt.Used </span><span class="cov0" title="0">{
                        delete(jm.refreshTokens, id)
                }</span>
        }
}

// GetTokenClaims extracts claims from a token without validating it (useful for expired tokens)
func (jm *JWTManager) GetTokenClaims(tokenString string) (*Claims, error) <span class="cov0" title="0">{
        token, err := jwt.ParseWithClaims(tokenString, &amp;Claims{}, func(token *jwt.Token) (interface{}, error) </span><span class="cov0" title="0">{
                return jm.publicKey, nil
        }</span>, jwt.WithoutClaimsValidation())
        
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to parse token: %w", err)
        }</span>
        
        <span class="cov0" title="0">claims, ok := token.Claims.(*Claims)
        if !ok </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("invalid token claims")
        }</span>
        
        <span class="cov0" title="0">return claims, nil</span>
}

// GenerateServiceToken generates a long-lived token for service-to-service communication
func (jm *JWTManager) GenerateServiceToken(serviceID, serviceName string, permissions []string) (string, error) <span class="cov1" title="1">{
        now := time.Now()
        expiry := now.Add(365 * 24 * time.Hour) // 1 year
        
        claims := &amp;Claims{
                UserID:      serviceID,
                Username:    serviceName,
                Role:        RoleService,
                Permissions: permissions,
                Metadata: map[string]string{
                        "token_type": "service",
                },
                RegisteredClaims: jwt.RegisteredClaims{
                        ExpiresAt: jwt.NewNumericDate(expiry),
                        IssuedAt:  jwt.NewNumericDate(now),
                        NotBefore: jwt.NewNumericDate(now),
                        Issuer:    jm.config.Issuer,
                        Subject:   serviceID,
                        ID:        generateID(),
                        Audience:  []string{jm.config.Audience},
                },
        }
        
        token := jwt.NewWithClaims(jwt.SigningMethodRS256, claims)
        return token.SignedString(jm.privateKey)
}</span>

// ValidateServiceToken validates a service token
func (jm *JWTManager) ValidateServiceToken(tokenString string) (*Claims, error) <span class="cov1" title="1">{
        claims, err := jm.ValidateToken(tokenString)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        
        // Verify this is a service token
        <span class="cov1" title="1">if claims.Metadata["token_type"] != "service" </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("not a service token")
        }</span>
        
        <span class="cov1" title="1">return claims, nil</span>
}

// CreateShortLivedToken creates a token with custom expiry (for specific operations)
func (jm *JWTManager) CreateShortLivedToken(user *User, duration time.Duration, purpose string) (string, error) <span class="cov0" title="0">{
        now := time.Now()
        expiry := now.Add(duration)
        
        claims := &amp;Claims{
                UserID:      user.ID,
                Username:    user.Username,
                Email:       user.Email,
                Role:        user.Role,
                Permissions: user.Permissions,
                Metadata: map[string]string{
                        "token_type": "short_lived",
                        "purpose":    purpose,
                },
                RegisteredClaims: jwt.RegisteredClaims{
                        ExpiresAt: jwt.NewNumericDate(expiry),
                        IssuedAt:  jwt.NewNumericDate(now),
                        NotBefore: jwt.NewNumericDate(now),
                        Issuer:    jm.config.Issuer,
                        Subject:   user.ID,
                        ID:        generateID(),
                        Audience:  []string{jm.config.Audience},
                },
        }
        
        token := jwt.NewWithClaims(jwt.SigningMethodRS256, claims)
        return token.SignedString(jm.privateKey)
}</span>

// GetPublicKey returns the public key for token verification by other services
func (jm *JWTManager) GetPublicKey() *rsa.PublicKey <span class="cov0" title="0">{
        return jm.publicKey
}</span>

// GetTokenStats returns statistics about tokens
func (jm *JWTManager) GetTokenStats() map[string]interface{} <span class="cov0" title="0">{
        activeRefreshTokens := 0
        expiredRefreshTokens := 0
        now := time.Now()
        
        for _, rt := range jm.refreshTokens </span><span class="cov0" title="0">{
                if rt.Used || now.After(rt.ExpiresAt) </span><span class="cov0" title="0">{
                        expiredRefreshTokens++
                }</span> else<span class="cov0" title="0"> {
                        activeRefreshTokens++
                }</span>
        }
        
        <span class="cov0" title="0">return map[string]interface{}{
                "active_refresh_tokens":  activeRefreshTokens,
                "expired_refresh_tokens": expiredRefreshTokens,
                "blacklisted_tokens":     len(jm.blacklist),
                "total_refresh_tokens":   len(jm.refreshTokens),
        }</span>
}

// isBlacklisted checks if a token ID is blacklisted
func (jm *JWTManager) isBlacklisted(tokenID string) bool <span class="cov10" title="2">{
        expiry, exists := jm.blacklist[tokenID]
        if !exists </span><span class="cov10" title="2">{
                return false
        }</span>
        
        <span class="cov0" title="0">if time.Now().After(expiry) </span><span class="cov0" title="0">{
                delete(jm.blacklist, tokenID)
                return false
        }</span>
        
        <span class="cov0" title="0">return true</span>
}</pre>
		
		<pre class="file" id="file4" style="display: none">package auth

import (
        "net/http"
        "strings"
        "time"

        "github.com/gin-gonic/gin"
        "github.com/ollama/ollama-distributed/internal/config"
)

// MiddlewareManager handles HTTP middleware for authentication and authorization
type MiddlewareManager struct {
        authManager *Manager
        jwtManager  *JWTManager
        config      *config.AuthConfig
}

// NewMiddlewareManager creates a new middleware manager
func NewMiddlewareManager(authManager *Manager, jwtManager *JWTManager, config *config.AuthConfig) *MiddlewareManager <span class="cov0" title="0">{
        return &amp;MiddlewareManager{
                authManager: authManager,
                jwtManager:  jwtManager,
                config:      config,
        }
}</span>

// AuthRequired middleware that requires authentication
func (mm *MiddlewareManager) AuthRequired() gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                // Skip auth if disabled
                if !mm.config.Enabled </span><span class="cov0" title="0">{
                        c.Next()
                        return
                }</span>
                
                // Skip auth for certain paths
                <span class="cov0" title="0">if mm.shouldSkipAuth(c.Request.URL.Path, c.Request.Method) </span><span class="cov0" title="0">{
                        c.Next()
                        return
                }</span>
                
                // Try to authenticate
                <span class="cov0" title="0">authCtx, err := mm.authenticate(c)
                if err != nil </span><span class="cov0" title="0">{
                        mm.handleAuthError(c, err)
                        return
                }</span>
                
                // Store auth context
                <span class="cov0" title="0">mm.setAuthContext(c, authCtx)
                c.Next()</span>
        }
}

// RequirePermission middleware that requires specific permissions
func (mm *MiddlewareManager) RequirePermission(permission string) gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                authCtx := mm.getAuthContext(c)
                if authCtx == nil </span><span class="cov0" title="0">{
                        c.JSON(http.StatusUnauthorized, gin.H{"error": "Authentication required"})
                        c.Abort()
                        return
                }</span>
                
                <span class="cov0" title="0">if !mm.authManager.HasPermission(authCtx, permission) </span><span class="cov0" title="0">{
                        c.JSON(http.StatusForbidden, gin.H{
                                "error": "Insufficient permissions",
                                "required_permission": permission,
                        })
                        c.Abort()
                        return
                }</span>
                
                <span class="cov0" title="0">c.Next()</span>
        }
}

// RequireRole middleware that requires a specific role
func (mm *MiddlewareManager) RequireRole(role string) gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                authCtx := mm.getAuthContext(c)
                if authCtx == nil </span><span class="cov0" title="0">{
                        c.JSON(http.StatusUnauthorized, gin.H{"error": "Authentication required"})
                        c.Abort()
                        return
                }</span>
                
                <span class="cov0" title="0">if authCtx.User.Role != role &amp;&amp; authCtx.User.Role != RoleAdmin </span><span class="cov0" title="0">{
                        c.JSON(http.StatusForbidden, gin.H{
                                "error": "Insufficient role",
                                "required_role": role,
                                "user_role": authCtx.User.Role,
                        })
                        c.Abort()
                        return
                }</span>
                
                <span class="cov0" title="0">c.Next()</span>
        }
}

// RequireAnyRole middleware that requires any of the specified roles
func (mm *MiddlewareManager) RequireAnyRole(roles ...string) gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                authCtx := mm.getAuthContext(c)
                if authCtx == nil </span><span class="cov0" title="0">{
                        c.JSON(http.StatusUnauthorized, gin.H{"error": "Authentication required"})
                        c.Abort()
                        return
                }</span>
                
                // Admin always has access
                <span class="cov0" title="0">if authCtx.User.Role == RoleAdmin </span><span class="cov0" title="0">{
                        c.Next()
                        return
                }</span>
                
                // Check if user has any of the required roles
                <span class="cov0" title="0">hasRole := false
                for _, role := range roles </span><span class="cov0" title="0">{
                        if authCtx.User.Role == role </span><span class="cov0" title="0">{
                                hasRole = true
                                break</span>
                        }
                }
                
                <span class="cov0" title="0">if !hasRole </span><span class="cov0" title="0">{
                        c.JSON(http.StatusForbidden, gin.H{
                                "error": "Insufficient role",
                                "required_roles": roles,
                                "user_role": authCtx.User.Role,
                        })
                        c.Abort()
                        return
                }</span>
                
                <span class="cov0" title="0">c.Next()</span>
        }
}

// RequireAnyPermission middleware that requires any of the specified permissions
func (mm *MiddlewareManager) RequireAnyPermission(permissions ...string) gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                authCtx := mm.getAuthContext(c)
                if authCtx == nil </span><span class="cov0" title="0">{
                        c.JSON(http.StatusUnauthorized, gin.H{"error": "Authentication required"})
                        c.Abort()
                        return
                }</span>
                
                // Check if user has any of the required permissions
                <span class="cov0" title="0">hasPermission := false
                for _, permission := range permissions </span><span class="cov0" title="0">{
                        if mm.authManager.HasPermission(authCtx, permission) </span><span class="cov0" title="0">{
                                hasPermission = true
                                break</span>
                        }
                }
                
                <span class="cov0" title="0">if !hasPermission </span><span class="cov0" title="0">{
                        c.JSON(http.StatusForbidden, gin.H{
                                "error": "Insufficient permissions",
                                "required_permissions": permissions,
                        })
                        c.Abort()
                        return
                }</span>
                
                <span class="cov0" title="0">c.Next()</span>
        }
}

// Optional middleware that attempts authentication but doesn't require it
func (mm *MiddlewareManager) Optional() gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                if !mm.config.Enabled </span><span class="cov0" title="0">{
                        c.Next()
                        return
                }</span>
                
                // Try to authenticate but don't fail if unsuccessful
                <span class="cov0" title="0">authCtx, _ := mm.authenticate(c)
                if authCtx != nil </span><span class="cov0" title="0">{
                        mm.setAuthContext(c, authCtx)
                }</span>
                
                <span class="cov0" title="0">c.Next()</span>
        }
}

// RateLimit middleware for API rate limiting
func (mm *MiddlewareManager) RateLimit() gin.HandlerFunc <span class="cov0" title="0">{
        // This is a simplified rate limiter
        // In production, use a proper rate limiting library like tollbooth or redis-based limiter
        requestCounts := make(map[string]map[int64]int)
        
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                // Get client identifier (IP or user ID if authenticated)
                clientID := c.ClientIP()
                if authCtx := mm.getAuthContext(c); authCtx != nil </span><span class="cov0" title="0">{
                        clientID = authCtx.User.ID
                }</span>
                
                // Current minute window
                <span class="cov0" title="0">currentMinute := time.Now().Unix() / 60
                
                if requestCounts[clientID] == nil </span><span class="cov0" title="0">{
                        requestCounts[clientID] = make(map[int64]int)
                }</span>
                
                // Clean old entries
                <span class="cov0" title="0">for minute := range requestCounts[clientID] </span><span class="cov0" title="0">{
                        if currentMinute-minute &gt; 5 </span><span class="cov0" title="0">{ // Keep last 5 minutes
                                delete(requestCounts[clientID], minute)
                        }</span>
                }
                
                // Count requests in current minute
                <span class="cov0" title="0">requestCounts[clientID][currentMinute]++
                
                // Check limit (100 requests per minute)
                if requestCounts[clientID][currentMinute] &gt; 100 </span><span class="cov0" title="0">{
                        c.JSON(http.StatusTooManyRequests, gin.H{
                                "error": "Rate limit exceeded",
                                "retry_after": 60,
                        })
                        c.Abort()
                        return
                }</span>
                
                <span class="cov0" title="0">c.Header("X-RateLimit-Limit", "100")
                c.Header("X-RateLimit-Remaining", string(rune(100-requestCounts[clientID][currentMinute])))
                c.Header("X-RateLimit-Reset", string(rune((currentMinute+1)*60)))
                
                c.Next()</span>
        }
}

// CORS middleware with authentication-aware settings
func (mm *MiddlewareManager) CORS() gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                origin := c.Request.Header.Get("Origin")
                
                // Default allowed origins
                allowedOrigins := []string{"http://localhost:8080", "https://localhost:8080"}
                
                // Check if origin is allowed
                allowed := false
                for _, allowedOrigin := range allowedOrigins </span><span class="cov0" title="0">{
                        if origin == allowedOrigin </span><span class="cov0" title="0">{
                                allowed = true
                                break</span>
                        }
                }
                
                <span class="cov0" title="0">if allowed </span><span class="cov0" title="0">{
                        c.Header("Access-Control-Allow-Origin", origin)
                }</span>
                
                <span class="cov0" title="0">c.Header("Access-Control-Allow-Methods", "GET, POST, PUT, DELETE, OPTIONS")
                c.Header("Access-Control-Allow-Headers", "Content-Type, Authorization, X-Requested-With")
                c.Header("Access-Control-Allow-Credentials", "true")
                c.Header("Access-Control-Max-Age", "3600")
                
                if c.Request.Method == "OPTIONS" </span><span class="cov0" title="0">{
                        c.AbortWithStatus(http.StatusNoContent)
                        return
                }</span>
                
                <span class="cov0" title="0">c.Next()</span>
        }
}

// SecurityHeaders middleware that adds security headers
func (mm *MiddlewareManager) SecurityHeaders() gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                c.Header("X-Content-Type-Options", "nosniff")
                c.Header("X-Frame-Options", "DENY")
                c.Header("X-XSS-Protection", "1; mode=block")
                c.Header("Referrer-Policy", "strict-origin-when-cross-origin")
                c.Header("Content-Security-Policy", "default-src 'self'")
                c.Header("Strict-Transport-Security", "max-age=31536000; includeSubDomains")
                
                c.Next()
        }</span>
}

// AuditLog middleware that logs authentication events
func (mm *MiddlewareManager) AuditLog() gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                start := time.Now()
                
                // Process request
                c.Next()
                
                // Log after request completion
                duration := time.Since(start)
                authCtx := mm.getAuthContext(c)
                
                logData := map[string]interface{}{
                        "timestamp":    start.Unix(),
                        "method":       c.Request.Method,
                        "path":         c.Request.URL.Path,
                        "status":       c.Writer.Status(),
                        "duration_ms":  duration.Milliseconds(),
                        "ip":           c.ClientIP(),
                        "user_agent":   c.Request.Header.Get("User-Agent"),
                }
                
                if authCtx != nil </span><span class="cov0" title="0">{
                        logData["user_id"] = authCtx.User.ID
                        logData["username"] = authCtx.User.Username
                        logData["auth_method"] = string(authCtx.Method)
                        if authCtx.Session != nil </span><span class="cov0" title="0">{
                                logData["session_id"] = authCtx.Session.ID
                        }</span>
                        <span class="cov0" title="0">if authCtx.APIKey != nil </span><span class="cov0" title="0">{
                                logData["api_key_id"] = authCtx.APIKey.ID
                        }</span>
                }
                
                // In production, send this to a proper logging system
                // fmt.Printf("AUDIT: %+v\n", logData)
        }
}

// Helper methods

func (mm *MiddlewareManager) authenticate(c *gin.Context) (*AuthContext, error) <span class="cov0" title="0">{
        // Try API key authentication first
        if apiKey := mm.extractAPIKey(c); apiKey != "" </span><span class="cov0" title="0">{
                return mm.authManager.ValidateAPIKey(apiKey)
        }</span>
        
        // Try JWT token authentication
        <span class="cov0" title="0">if token := mm.extractBearerToken(c); token != "" </span><span class="cov0" title="0">{
                return mm.authManager.ValidateToken(token)
        }</span>
        
        <span class="cov0" title="0">return nil, ErrInvalidCredentials</span>
}

func (mm *MiddlewareManager) extractBearerToken(c *gin.Context) string <span class="cov0" title="0">{
        authHeader := c.GetHeader("Authorization")
        if authHeader == "" </span><span class="cov0" title="0">{
                return ""
        }</span>
        
        <span class="cov0" title="0">parts := strings.SplitN(authHeader, " ", 2)
        if len(parts) != 2 || strings.ToLower(parts[0]) != "bearer" </span><span class="cov0" title="0">{
                return ""
        }</span>
        
        <span class="cov0" title="0">return parts[1]</span>
}

func (mm *MiddlewareManager) extractAPIKey(c *gin.Context) string <span class="cov0" title="0">{
        // Check Authorization header with API key
        authHeader := c.GetHeader("Authorization")
        if strings.HasPrefix(strings.ToLower(authHeader), "apikey ") </span><span class="cov0" title="0">{
                return strings.TrimPrefix(authHeader, "ApiKey ")
        }</span>
        
        // Check X-API-Key header
        <span class="cov0" title="0">if apiKey := c.GetHeader("X-API-Key"); apiKey != "" </span><span class="cov0" title="0">{
                return apiKey
        }</span>
        
        // Check query parameter
        <span class="cov0" title="0">if apiKey := c.Query("api_key"); apiKey != "" </span><span class="cov0" title="0">{
                return apiKey
        }</span>
        
        <span class="cov0" title="0">return ""</span>
}

func (mm *MiddlewareManager) shouldSkipAuth(path, method string) bool <span class="cov0" title="0">{
        // Public endpoints that don't require authentication
        publicPaths := []string{
                "/api/v1/health",
                "/api/v1/login",
                "/api/v1/register",
                "/metrics",
                "/favicon.ico",
        }
        
        for _, publicPath := range publicPaths </span><span class="cov0" title="0">{
                if path == publicPath </span><span class="cov0" title="0">{
                        return true
                }</span>
                <span class="cov0" title="0">if strings.HasPrefix(path, "/static/") </span><span class="cov0" title="0">{
                        return true
                }</span>
        }
        
        // Always allow OPTIONS requests for CORS
        <span class="cov0" title="0">if method == "OPTIONS" </span><span class="cov0" title="0">{
                return true
        }</span>
        
        <span class="cov0" title="0">return false</span>
}

func (mm *MiddlewareManager) handleAuthError(c *gin.Context, err error) <span class="cov0" title="0">{
        var status int
        var response gin.H
        
        switch err.(type) </span>{
        case AuthError:<span class="cov0" title="0">
                authErr := err.(AuthError)
                switch authErr.Code </span>{
                case "TOKEN_EXPIRED":<span class="cov0" title="0">
                        status = http.StatusUnauthorized</span>
                case "TOKEN_INVALID":<span class="cov0" title="0">
                        status = http.StatusUnauthorized</span>
                case "TOKEN_BLACKLISTED":<span class="cov0" title="0">
                        status = http.StatusUnauthorized</span>
                case "INSUFFICIENT_PERMISSIONS":<span class="cov0" title="0">
                        status = http.StatusForbidden</span>
                case "USER_NOT_FOUND":<span class="cov0" title="0">
                        status = http.StatusUnauthorized</span>
                case "USER_INACTIVE":<span class="cov0" title="0">
                        status = http.StatusUnauthorized</span>
                default:<span class="cov0" title="0">
                        status = http.StatusUnauthorized</span>
                }
                <span class="cov0" title="0">response = gin.H{
                        "error": authErr.Message,
                        "code":  authErr.Code,
                }</span>
        default:<span class="cov0" title="0">
                status = http.StatusUnauthorized
                response = gin.H{
                        "error": "Authentication required",
                }</span>
        }
        
        <span class="cov0" title="0">c.JSON(status, response)
        c.Abort()</span>
}

func (mm *MiddlewareManager) setAuthContext(c *gin.Context, authCtx *AuthContext) <span class="cov0" title="0">{
        c.Set("auth_context", authCtx)
        c.Set("user", authCtx.User)
        c.Set("user_id", authCtx.User.ID)
        c.Set("username", authCtx.User.Username)
        c.Set("role", authCtx.User.Role)
        c.Set("permissions", authCtx.User.Permissions)
        if authCtx.Session != nil </span><span class="cov0" title="0">{
                c.Set("session", authCtx.Session)
                c.Set("session_id", authCtx.Session.ID)
        }</span>
        <span class="cov0" title="0">if authCtx.APIKey != nil </span><span class="cov0" title="0">{
                c.Set("api_key", authCtx.APIKey)
                c.Set("api_key_id", authCtx.APIKey.ID)
        }</span>
}

func (mm *MiddlewareManager) getAuthContext(c *gin.Context) *AuthContext <span class="cov0" title="0">{
        if authCtx, exists := c.Get("auth_context"); exists </span><span class="cov0" title="0">{
                if ctx, ok := authCtx.(*AuthContext); ok </span><span class="cov0" title="0">{
                        return ctx
                }</span>
        }
        <span class="cov0" title="0">return nil</span>
}

// GetCurrentUser helper function to get current user from context
func GetCurrentUser(c *gin.Context) *User <span class="cov0" title="0">{
        if user, exists := c.Get("user"); exists </span><span class="cov0" title="0">{
                if u, ok := user.(*User); ok </span><span class="cov0" title="0">{
                        return u
                }</span>
        }
        <span class="cov0" title="0">return nil</span>
}

// GetCurrentUserID helper function to get current user ID from context
func GetCurrentUserID(c *gin.Context) string <span class="cov0" title="0">{
        if userID, exists := c.Get("user_id"); exists </span><span class="cov0" title="0">{
                if id, ok := userID.(string); ok </span><span class="cov0" title="0">{
                        return id
                }</span>
        }
        <span class="cov0" title="0">return ""</span>
}

// HasPermission helper function to check permissions in handlers
func HasPermission(c *gin.Context, permission string) bool <span class="cov0" title="0">{
        if permissions, exists := c.Get("permissions"); exists </span><span class="cov0" title="0">{
                if perms, ok := permissions.([]string); ok </span><span class="cov0" title="0">{
                        for _, perm := range perms </span><span class="cov0" title="0">{
                                if perm == permission || perm == PermissionSystemAdmin </span><span class="cov0" title="0">{
                                        return true
                                }</span>
                        }
                }
        }
        <span class="cov0" title="0">return false</span>
}</pre>
		
		<pre class="file" id="file5" style="display: none">package auth

import (
        "net/http"
        "time"

        "github.com/gin-gonic/gin"
)

// Routes handles authentication-related HTTP routes
type Routes struct {
        authManager       *Manager
        jwtManager        *JWTManager
        middlewareManager *MiddlewareManager
}

// NewRoutes creates a new routes handler
func NewRoutes(authManager *Manager, jwtManager *JWTManager, middlewareManager *MiddlewareManager) *Routes <span class="cov0" title="0">{
        return &amp;Routes{
                authManager:       authManager,
                jwtManager:        jwtManager,
                middlewareManager: middlewareManager,
        }
}</span>

// RegisterRoutes registers authentication routes with the Gin router
func (r *Routes) RegisterRoutes(router *gin.Engine) <span class="cov0" title="0">{
        // Apply global middleware
        router.Use(r.middlewareManager.CORS())
        router.Use(r.middlewareManager.SecurityHeaders())
        router.Use(r.middlewareManager.RateLimit())
        router.Use(r.middlewareManager.AuditLog())
        
        // Public routes (no authentication required)
        public := router.Group("/api/v1")
        </span><span class="cov0" title="0">{
                public.POST("/login", r.login)
                public.POST("/register", r.register)
                public.POST("/refresh", r.refreshToken)
                public.GET("/health", r.health)
        }</span>
        
        // Protected routes (authentication required)
        <span class="cov0" title="0">protected := router.Group("/api/v1")
        protected.Use(r.middlewareManager.AuthRequired())
        </span><span class="cov0" title="0">{
                // User management
                user := protected.Group("/user")
                </span><span class="cov0" title="0">{
                        user.GET("/profile", r.getProfile)
                        user.PUT("/profile", r.updateProfile)
                        user.POST("/change-password", r.changePassword)
                        user.POST("/logout", r.logout)
                        user.GET("/sessions", r.getSessions)
                        user.DELETE("/sessions/:session_id", r.revokeSession)
                }</span>
                
                // API key management
                <span class="cov0" title="0">apiKeys := protected.Group("/api-keys")
                </span><span class="cov0" title="0">{
                        apiKeys.GET("", r.listAPIKeys)
                        apiKeys.POST("", r.createAPIKey)
                        apiKeys.DELETE("/:key_id", r.revokeAPIKey)
                }</span>
                
                // Admin routes
                <span class="cov0" title="0">admin := protected.Group("/admin")
                admin.Use(r.middlewareManager.RequireRole(RoleAdmin))
                </span><span class="cov0" title="0">{
                        admin.GET("/users", r.listUsers)
                        admin.POST("/users", r.createUser)
                        admin.GET("/users/:user_id", r.getUser)
                        admin.PUT("/users/:user_id", r.updateUser)
                        admin.DELETE("/users/:user_id", r.deleteUser)
                        admin.POST("/users/:user_id/reset-password", r.resetUserPassword)
                        admin.GET("/stats", r.getAuthStats)
                }</span>
        }
}

// Authentication handlers

func (r *Routes) login(c *gin.Context) <span class="cov0" title="0">{
        var req LoginRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid request format"})
                return
        }</span>
        
        // Get client metadata
        <span class="cov0" title="0">metadata := map[string]string{
                "ip_address": c.ClientIP(),
                "user_agent": c.Request.Header.Get("User-Agent"),
        }
        for k, v := range req.Metadata </span><span class="cov0" title="0">{
                metadata[k] = v
        }</span>
        
        // Authenticate user
        <span class="cov0" title="0">authCtx, err := r.authManager.Authenticate(req.Username, req.Password, metadata)
        if err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusUnauthorized, gin.H{"error": "Invalid credentials"})
                return
        }</span>
        
        <span class="cov0" title="0">response := LoginResponse{
                Token:     authCtx.TokenString,
                ExpiresAt: authCtx.Session.ExpiresAt,
                User:      authCtx.User,
                SessionID: authCtx.Session.ID,
        }
        
        c.JSON(http.StatusOK, response)</span>
}

func (r *Routes) register(c *gin.Context) <span class="cov0" title="0">{
        var req CreateUserRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid request format"})
                return
        }</span>
        
        // Default role for registration
        <span class="cov0" title="0">if req.Role == "" </span><span class="cov0" title="0">{
                req.Role = RoleUser
        }</span>
        
        // Only allow certain roles for self-registration
        <span class="cov0" title="0">allowedRoles := []string{RoleUser, RoleReadOnly}
        roleAllowed := false
        for _, role := range allowedRoles </span><span class="cov0" title="0">{
                if req.Role == role </span><span class="cov0" title="0">{
                        roleAllowed = true
                        break</span>
                }
        }
        
        <span class="cov0" title="0">if !roleAllowed </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid role for registration"})
                return
        }</span>
        
        <span class="cov0" title="0">user, err := r.authManager.CreateUser(&amp;req)
        if err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        // Remove sensitive data from response
        <span class="cov0" title="0">user.Metadata = map[string]string{}
        
        c.JSON(http.StatusCreated, gin.H{"user": user})</span>
}

func (r *Routes) refreshToken(c *gin.Context) <span class="cov0" title="0">{
        var req RefreshRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid request format"})
                return
        }</span>
        
        // Get user from token (even if expired)
        <span class="cov0" title="0">_, err := r.jwtManager.GetTokenClaims(req.Token)
        if err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusUnauthorized, gin.H{"error": "Invalid token"})
                return
        }</span>
        
        // This is a simplified implementation
        // In a real system, you'd use a separate refresh token
        <span class="cov0" title="0">c.JSON(http.StatusNotImplemented, gin.H{"error": "Refresh token functionality not implemented"})</span>
}

func (r *Routes) health(c *gin.Context) <span class="cov0" title="0">{
        c.JSON(http.StatusOK, gin.H{
                "status":    "healthy",
                "service":   "auth",
                "timestamp": time.Now().Unix(),
        })
}</span>

// User management handlers

func (r *Routes) getProfile(c *gin.Context) <span class="cov0" title="0">{
        user := GetCurrentUser(c)
        if user == nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusUnauthorized, gin.H{"error": "User not found"})
                return
        }</span>
        
        // Remove sensitive data
        <span class="cov0" title="0">user.Metadata = map[string]string{}
        
        c.JSON(http.StatusOK, gin.H{"user": user})</span>
}

func (r *Routes) updateProfile(c *gin.Context) <span class="cov0" title="0">{
        user := GetCurrentUser(c)
        if user == nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusUnauthorized, gin.H{"error": "User not found"})
                return
        }</span>
        
        <span class="cov0" title="0">var req UpdateUserRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid request format"})
                return
        }</span>
        
        // Update allowed fields
        <span class="cov0" title="0">if req.Email != nil </span><span class="cov0" title="0">{
                user.Email = *req.Email
        }</span>
        <span class="cov0" title="0">if req.Metadata != nil </span><span class="cov0" title="0">{
                for k, v := range req.Metadata </span><span class="cov0" title="0">{
                        if k != "password_hash" </span><span class="cov0" title="0">{ // Prevent password hash modification
                                user.Metadata[k] = v
                        }</span>
                }
        }
        
        <span class="cov0" title="0">user.UpdatedAt = time.Now()
        
        // Remove sensitive data from response
        user.Metadata = map[string]string{}
        
        c.JSON(http.StatusOK, gin.H{"user": user})</span>
}

func (r *Routes) changePassword(c *gin.Context) <span class="cov0" title="0">{
        user := GetCurrentUser(c)
        if user == nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusUnauthorized, gin.H{"error": "User not found"})
                return
        }</span>
        
        <span class="cov0" title="0">var req ChangePasswordRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid request format"})
                return
        }</span>
        
        // This would need to be implemented in the auth manager
        <span class="cov0" title="0">c.JSON(http.StatusNotImplemented, gin.H{"error": "Password change not implemented"})</span>
}

func (r *Routes) logout(c *gin.Context) <span class="cov0" title="0">{
        authCtx := r.middlewareManager.getAuthContext(c)
        if authCtx == nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusUnauthorized, gin.H{"error": "No active session"})
                return
        }</span>
        
        // Revoke session if it exists
        <span class="cov0" title="0">if authCtx.Session != nil </span><span class="cov0" title="0">{
                r.authManager.RevokeSession(authCtx.Session.ID)
        }</span>
        
        // Blacklist the token
        <span class="cov0" title="0">if authCtx.Claims != nil </span><span class="cov0" title="0">{
                r.authManager.RevokeToken(authCtx.Claims.ID, authCtx.Claims.ExpiresAt.Time)
        }</span>
        
        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{"message": "Logged out successfully"})</span>
}

func (r *Routes) getSessions(c *gin.Context) <span class="cov0" title="0">{
        // This would need to be implemented to return user sessions
        c.JSON(http.StatusNotImplemented, gin.H{"error": "Session listing not implemented"})
}</span>

func (r *Routes) revokeSession(c *gin.Context) <span class="cov0" title="0">{
        sessionID := c.Param("session_id")
        
        err := r.authManager.RevokeSession(sessionID)
        if err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusNotFound, gin.H{"error": err.Error()})
                return
        }</span>
        
        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{"message": "Session revoked successfully"})</span>
}

// API key management handlers

func (r *Routes) listAPIKeys(c *gin.Context) <span class="cov0" title="0">{
        user := GetCurrentUser(c)
        if user == nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusUnauthorized, gin.H{"error": "User not found"})
                return
        }</span>
        
        // Filter API keys to only show current user's keys
        <span class="cov0" title="0">var userAPIKeys []APIKey
        for _, apiKey := range user.APIKeys </span><span class="cov0" title="0">{
                // Remove the actual key value for security
                apiKey.Key = ""
                userAPIKeys = append(userAPIKeys, apiKey)
        }</span>
        
        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{"api_keys": userAPIKeys})</span>
}

func (r *Routes) createAPIKey(c *gin.Context) <span class="cov0" title="0">{
        user := GetCurrentUser(c)
        if user == nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusUnauthorized, gin.H{"error": "User not found"})
                return
        }</span>
        
        <span class="cov0" title="0">var req CreateAPIKeyRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid request format"})
                return
        }</span>
        
        <span class="cov0" title="0">apiKey, rawKey, err := r.authManager.CreateAPIKey(user.ID, &amp;req)
        if err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        <span class="cov0" title="0">response := CreateAPIKeyResponse{
                APIKey: apiKey,
                Key:    rawKey,
        }
        
        // Remove the hashed key from the response
        response.APIKey.Key = ""
        
        c.JSON(http.StatusCreated, response)</span>
}

func (r *Routes) revokeAPIKey(c *gin.Context) <span class="cov0" title="0">{
        keyID := c.Param("key_id")
        
        err := r.authManager.RevokeAPIKey(keyID)
        if err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusNotFound, gin.H{"error": err.Error()})
                return
        }</span>
        
        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{"message": "API key revoked successfully"})</span>
}

// Admin handlers

func (r *Routes) listUsers(c *gin.Context) <span class="cov0" title="0">{
        // This would need to be implemented in the auth manager
        c.JSON(http.StatusNotImplemented, gin.H{"error": "User listing not implemented"})
}</span>

func (r *Routes) createUser(c *gin.Context) <span class="cov0" title="0">{
        var req CreateUserRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid request format"})
                return
        }</span>
        
        <span class="cov0" title="0">user, err := r.authManager.CreateUser(&amp;req)
        if err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        // Remove sensitive data
        <span class="cov0" title="0">user.Metadata = map[string]string{}
        
        c.JSON(http.StatusCreated, gin.H{"user": user})</span>
}

func (r *Routes) getUser(c *gin.Context) <span class="cov0" title="0">{
        userID := c.Param("user_id")
        
        // This would need to be implemented in the auth manager
        c.JSON(http.StatusNotImplemented, gin.H{"error": "User retrieval not implemented", "user_id": userID})
}</span>

func (r *Routes) updateUser(c *gin.Context) <span class="cov0" title="0">{
        userID := c.Param("user_id")
        
        var req UpdateUserRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid request format"})
                return
        }</span>
        
        // This would need to be implemented in the auth manager
        <span class="cov0" title="0">c.JSON(http.StatusNotImplemented, gin.H{"error": "User update not implemented", "user_id": userID})</span>
}

func (r *Routes) deleteUser(c *gin.Context) <span class="cov0" title="0">{
        userID := c.Param("user_id")
        
        // This would need to be implemented in the auth manager
        c.JSON(http.StatusNotImplemented, gin.H{"error": "User deletion not implemented", "user_id": userID})
}</span>

func (r *Routes) resetUserPassword(c *gin.Context) <span class="cov0" title="0">{
        userID := c.Param("user_id")
        
        // This would need to be implemented in the auth manager
        c.JSON(http.StatusNotImplemented, gin.H{"error": "Password reset not implemented", "user_id": userID})
}</span>

func (r *Routes) getAuthStats(c *gin.Context) <span class="cov0" title="0">{
        stats := r.jwtManager.GetTokenStats()
        
        // Add more stats from auth manager
        stats["timestamp"] = time.Now().Unix()
        
        c.JSON(http.StatusOK, gin.H{"stats": stats})
}</pre>
		
		<pre class="file" id="file6" style="display: none">package auth

import (
        "log"
        "time"

        "github.com/gin-gonic/gin"
        "github.com/ollama/ollama-distributed/internal/config"
)

// ExampleServerWithAuth demonstrates how to integrate the authentication system
// with the existing Ollama distributed server
func ExampleServerWithAuth() <span class="cov0" title="0">{
        // Load main configuration
        cfg, err := config.Load("")
        if err != nil </span><span class="cov0" title="0">{
                log.Fatalf("Failed to load config: %v", err)
        }</span>
        
        // Ensure auth is enabled
        <span class="cov0" title="0">if !cfg.Security.Auth.Enabled </span><span class="cov0" title="0">{
                log.Println("WARNING: Authentication is disabled. Enable it for production!")
                cfg.Security.Auth.Enabled = true
                cfg.Security.Auth.Method = "jwt"
                cfg.Security.Auth.TokenExpiry = 24 * time.Hour
                cfg.Security.Auth.SecretKey = "demo-secret-key-change-in-production"
                cfg.Security.Auth.Issuer = "ollama-distributed"
                cfg.Security.Auth.Audience = "ollama-api"
        }</span>
        
        // Create authentication integration
        <span class="cov0" title="0">authIntegration, err := NewIntegration(&amp;cfg.Security.Auth)
        if err != nil </span><span class="cov0" title="0">{
                log.Fatalf("Failed to create auth integration: %v", err)
        }</span>
        <span class="cov0" title="0">defer authIntegration.Close()
        
        // Create Gin router
        router := gin.New()
        
        // Apply global middleware
        router.Use(gin.Logger())
        router.Use(gin.Recovery())
        router.Use(authIntegration.MiddlewareManager.SecurityHeaders())
        router.Use(authIntegration.MiddlewareManager.CORS())
        router.Use(authIntegration.MiddlewareManager.RateLimit())
        router.Use(authIntegration.MiddlewareManager.AuditLog())
        
        // Register authentication routes
        authIntegration.Routes.RegisterRoutes(router)
        
        // Setup protected API routes
        setupProtectedAPIRoutes(router, authIntegration)
        
        // Setup public routes
        setupPublicRoutes(router)
        
        // Start server
        log.Printf("Starting Ollama Distributed Server with Authentication on %s", cfg.API.Listen)
        if err := router.Run(cfg.API.Listen); err != nil </span><span class="cov0" title="0">{
                log.Fatalf("Failed to start server: %v", err)
        }</span>
}

// setupProtectedAPIRoutes configures the protected API endpoints
func setupProtectedAPIRoutes(router *gin.Engine, authIntegration *Integration) <span class="cov0" title="0">{
        // Protected API routes
        api := router.Group("/api/v1")
        api.Use(authIntegration.MiddlewareManager.AuthRequired())
        
        // Create middleware helpers
        helpers := NewMiddlewareHelpers(authIntegration)
        
        // Node management endpoints
        setupNodeRoutes(api, helpers)
        
        // Model management endpoints
        setupModelRoutes(api, helpers)
        
        // Cluster management endpoints
        setupClusterRoutes(api, helpers)
        
        // Inference endpoints
        setupInferenceRoutes(api, helpers)
        
        // Monitoring endpoints
        setupMonitoringRoutes(api, helpers)
        
        // Distribution management endpoints
        setupDistributionRoutes(api, helpers)
}</span>

// setupNodeRoutes configures node management routes
func setupNodeRoutes(api *gin.RouterGroup, helpers *MiddlewareHelpers) <span class="cov0" title="0">{
        nodes := api.Group("/nodes")
        
        // List nodes - requires read permission
        nodes.GET("", helpers.RequireNodePermission("read"), func(c *gin.Context) </span><span class="cov0" title="0">{
                user := GetCurrentUser(c)
                log.Printf("User %s requested node list", user.Username)
                
                // Mock response - in real implementation, this would call the scheduler
                c.JSON(200, gin.H{
                        "nodes": []map[string]interface{}{
                                {
                                        "id":     "node-1",
                                        "status": "online",
                                        "cpu":    "50%",
                                        "memory": "60%",
                                },
                                {
                                        "id":     "node-2",
                                        "status": "online",
                                        "cpu":    "30%",
                                        "memory": "40%",
                                },
                        },
                        "total": 2,
                })
        }</span>)
        
        // Get specific node - requires read permission
        <span class="cov0" title="0">nodes.GET("/:id", helpers.RequireNodePermission("read"), func(c *gin.Context) </span><span class="cov0" title="0">{
                nodeID := c.Param("id")
                user := GetCurrentUser(c)
                log.Printf("User %s requested details for node %s", user.Username, nodeID)
                
                c.JSON(200, gin.H{
                        "node": map[string]interface{}{
                                "id":       nodeID,
                                "status":   "online",
                                "cpu":      "50%",
                                "memory":   "60%",
                                "models":   []string{"llama2", "codellama"},
                                "requests": 150,
                        },
                })
        }</span>)
        
        // Drain node - requires write permission
        <span class="cov0" title="0">nodes.POST("/:id/drain", helpers.RequireNodePermission("write"), func(c *gin.Context) </span><span class="cov0" title="0">{
                nodeID := c.Param("id")
                user := GetCurrentUser(c)
                log.Printf("User %s initiated drain for node %s", user.Username, nodeID)
                
                c.JSON(200, gin.H{
                        "message": "Node drain initiated",
                        "node_id": nodeID,
                        "status":  "draining",
                })
        }</span>)
        
        // Delete node - requires admin permission
        <span class="cov0" title="0">nodes.DELETE("/:id", helpers.RequireNodePermission("admin"), func(c *gin.Context) </span><span class="cov0" title="0">{
                nodeID := c.Param("id")
                user := GetCurrentUser(c)
                log.Printf("User %s deleted node %s", user.Username, nodeID)
                
                c.JSON(200, gin.H{
                        "message": "Node deleted successfully",
                        "node_id": nodeID,
                })
        }</span>)
}

// setupModelRoutes configures model management routes
func setupModelRoutes(api *gin.RouterGroup, helpers *MiddlewareHelpers) <span class="cov0" title="0">{
        models := api.Group("/models")
        
        // List models - requires read permission
        models.GET("", helpers.RequireModelPermission("read"), func(c *gin.Context) </span><span class="cov0" title="0">{
                user := GetCurrentUser(c)
                log.Printf("User %s requested model list", user.Username)
                
                c.JSON(200, gin.H{
                        "models": []map[string]interface{}{
                                {
                                        "name":      "llama2",
                                        "size":      "7B",
                                        "locations": []string{"node-1", "node-2"},
                                        "status":    "ready",
                                },
                                {
                                        "name":      "codellama",
                                        "size":      "13B",
                                        "locations": []string{"node-1"},
                                        "status":    "ready",
                                },
                        },
                })
        }</span>)
        
        // Download model - requires write permission
        <span class="cov0" title="0">models.POST("/:name/download", helpers.RequireModelPermission("write"), func(c *gin.Context) </span><span class="cov0" title="0">{
                modelName := c.Param("name")
                user := GetCurrentUser(c)
                log.Printf("User %s initiated download for model %s", user.Username, modelName)
                
                c.JSON(200, gin.H{
                        "message":    "Model download initiated",
                        "model_name": modelName,
                        "status":     "downloading",
                        "progress":   0,
                })
        }</span>)
        
        // Delete model - requires admin permission
        <span class="cov0" title="0">models.DELETE("/:name", helpers.RequireModelPermission("admin"), func(c *gin.Context) </span><span class="cov0" title="0">{
                modelName := c.Param("name")
                user := GetCurrentUser(c)
                log.Printf("User %s deleted model %s", user.Username, modelName)
                
                c.JSON(200, gin.H{
                        "message":    "Model deleted successfully",
                        "model_name": modelName,
                })
        }</span>)
}

// setupClusterRoutes configures cluster management routes
func setupClusterRoutes(api *gin.RouterGroup, helpers *MiddlewareHelpers) <span class="cov0" title="0">{
        cluster := api.Group("/cluster")
        
        // Get cluster status - requires read permission
        cluster.GET("/status", helpers.RequireClusterPermission("read"), func(c *gin.Context) </span><span class="cov0" title="0">{
                user := GetCurrentUser(c)
                log.Printf("User %s requested cluster status", user.Username)
                
                c.JSON(200, gin.H{
                        "status": "healthy",
                        "nodes":  2,
                        "leader": "node-1",
                        "peers":  1,
                })
        }</span>)
        
        // Join cluster - requires write permission
        <span class="cov0" title="0">cluster.POST("/join", helpers.RequireClusterPermission("write"), func(c *gin.Context) </span><span class="cov0" title="0">{
                var req map[string]interface{}
                c.ShouldBindJSON(&amp;req)
                
                user := GetCurrentUser(c)
                log.Printf("User %s initiated cluster join", user.Username)
                
                c.JSON(200, gin.H{
                        "message": "Node join initiated",
                })
        }</span>)
        
        // Leave cluster - requires admin permission
        <span class="cov0" title="0">cluster.POST("/leave", helpers.RequireClusterPermission("admin"), func(c *gin.Context) </span><span class="cov0" title="0">{
                user := GetCurrentUser(c)
                log.Printf("User %s initiated cluster leave", user.Username)
                
                c.JSON(200, gin.H{
                        "message": "Node leave initiated",
                })
        }</span>)
}

// setupInferenceRoutes configures inference routes
func setupInferenceRoutes(api *gin.RouterGroup, helpers *MiddlewareHelpers) <span class="cov0" title="0">{
        // Generate endpoint - requires write permission
        api.POST("/generate", helpers.RequireInferencePermission("write"), func(c *gin.Context) </span><span class="cov0" title="0">{
                var req map[string]interface{}
                c.ShouldBindJSON(&amp;req)
                
                user := GetCurrentUser(c)
                modelName := req["model"]
                log.Printf("User %s requested generation with model %v", user.Username, modelName)
                
                c.JSON(200, gin.H{
                        "response": "This is a generated response from the distributed Ollama system",
                        "model":    modelName,
                        "node_id":  "node-1",
                        "user":     user.Username,
                })
        }</span>)
        
        // Chat endpoint - requires write permission
        <span class="cov0" title="0">api.POST("/chat", helpers.RequireInferencePermission("write"), func(c *gin.Context) </span><span class="cov0" title="0">{
                var req map[string]interface{}
                c.ShouldBindJSON(&amp;req)
                
                user := GetCurrentUser(c)
                log.Printf("User %s initiated chat session", user.Username)
                
                c.JSON(200, gin.H{
                        "message": map[string]interface{}{
                                "role":    "assistant",
                                "content": "Hello! I'm your AI assistant powered by the distributed Ollama system.",
                        },
                        "user": user.Username,
                })
        }</span>)
        
        // Embeddings endpoint - requires write permission
        <span class="cov0" title="0">api.POST("/embeddings", helpers.RequireInferencePermission("write"), func(c *gin.Context) </span><span class="cov0" title="0">{
                var req map[string]interface{}
                c.ShouldBindJSON(&amp;req)
                
                user := GetCurrentUser(c)
                log.Printf("User %s requested embeddings", user.Username)
                
                c.JSON(200, gin.H{
                        "embeddings": []float64{0.1, 0.2, 0.3, 0.4, 0.5},
                        "model":      req["model"],
                        "user":       user.Username,
                })
        }</span>)
}

// setupMonitoringRoutes configures monitoring routes
func setupMonitoringRoutes(api *gin.RouterGroup, helpers *MiddlewareHelpers) <span class="cov0" title="0">{
        // Metrics endpoint - requires read permission
        api.GET("/metrics", helpers.RequireInferencePermission("read"), func(c *gin.Context) </span><span class="cov0" title="0">{
                user := GetCurrentUser(c)
                log.Printf("User %s requested metrics", user.Username)
                
                c.JSON(200, gin.H{
                        "metrics": map[string]interface{}{
                                "nodes_online":       2,
                                "models_loaded":      5,
                                "requests_processed": 1500,
                                "cpu_usage":          45.2,
                                "memory_usage":       62.8,
                                "network_usage":      23.1,
                        },
                        "timestamp": time.Now().Unix(),
                })
        }</span>)
        
        // Health check - no authentication required for monitoring
        <span class="cov0" title="0">api.GET("/health", func(c *gin.Context) </span><span class="cov0" title="0">{
                c.JSON(200, gin.H{
                        "status":    "healthy",
                        "timestamp": time.Now().Unix(),
                        "version":   "1.0.0",
                })
        }</span>)
        
        // Transfers endpoint
        <span class="cov0" title="0">api.GET("/transfers", helpers.RequireInferencePermission("read"), func(c *gin.Context) </span><span class="cov0" title="0">{
                user := GetCurrentUser(c)
                log.Printf("User %s requested transfer status", user.Username)
                
                c.JSON(200, gin.H{
                        "transfers": []map[string]interface{}{
                                {
                                        "id":       "transfer-1",
                                        "model":    "llama2",
                                        "status":   "completed",
                                        "progress": 100,
                                },
                        },
                })
        }</span>)
}

// setupDistributionRoutes configures distribution management routes
func setupDistributionRoutes(api *gin.RouterGroup, helpers *MiddlewareHelpers) <span class="cov0" title="0">{
        distribution := api.Group("/distribution")
        
        // Auto-configure distribution - requires admin permission
        distribution.POST("/auto-configure", helpers.RequireClusterPermission("admin"), func(c *gin.Context) </span><span class="cov0" title="0">{
                var req map[string]interface{}
                c.ShouldBindJSON(&amp;req)
                
                user := GetCurrentUser(c)
                log.Printf("User %s configured auto-distribution", user.Username)
                
                c.JSON(200, gin.H{
                        "message": "Auto-distribution configured",
                        "enabled": req["enabled"],
                })
        }</span>)
}

// setupPublicRoutes configures public routes that don't require authentication
func setupPublicRoutes(router *gin.Engine) <span class="cov0" title="0">{
        // Serve static files for web UI
        router.Static("/static", "./web/static")
        router.StaticFile("/", "./web/index.html")
        router.StaticFile("/favicon.ico", "./web/favicon.ico")
        
        // Catch-all for SPA routing
        router.NoRoute(func(c *gin.Context) </span><span class="cov0" title="0">{
                c.File("./web/index.html")
        }</span>)
}

// DemoUsage shows how to use the authentication system programmatically
func DemoUsage() <span class="cov0" title="0">{
        // Create auth config
        cfg := &amp;config.AuthConfig{
                Enabled:     true,
                Method:      "jwt",
                TokenExpiry: 24 * time.Hour,
                SecretKey:   "demo-secret-key",
                Issuer:      "ollama-distributed",
                Audience:    "ollama-api",
        }
        
        // Create auth manager
        authManager, err := NewManager(cfg)
        if err != nil </span><span class="cov0" title="0">{
                log.Fatalf("Failed to create auth manager: %v", err)
        }</span>
        <span class="cov0" title="0">defer authManager.Close()
        
        // Create a new user
        userReq := &amp;CreateUserRequest{
                Username: "demo-user",
                Email:    "demo@example.com",
                Password: "secure-password",
                Role:     RoleUser,
        }
        
        user, err := authManager.CreateUser(userReq)
        if err != nil </span><span class="cov0" title="0">{
                log.Fatalf("Failed to create user: %v", err)
        }</span>
        
        <span class="cov0" title="0">log.Printf("Created user: %s (ID: %s)", user.Username, user.ID)
        
        // Authenticate user
        authCtx, err := authManager.Authenticate("demo-user", "secure-password", map[string]string{
                "ip_address": "127.0.0.1",
                "user_agent": "demo-client",
        })
        if err != nil </span><span class="cov0" title="0">{
                log.Fatalf("Failed to authenticate: %v", err)
        }</span>
        
        <span class="cov0" title="0">log.Printf("Authentication successful! Token: %s", authCtx.TokenString[:50]+"...")
        
        // Create API key
        apiKeyReq := &amp;CreateAPIKeyRequest{
                Name:        "Demo API Key",
                Permissions: []string{PermissionModelRead, PermissionInferenceWrite},
        }
        
        apiKey, rawKey, err := authManager.CreateAPIKey(user.ID, apiKeyReq)
        if err != nil </span><span class="cov0" title="0">{
                log.Fatalf("Failed to create API key: %v", err)
        }</span>
        
        <span class="cov0" title="0">log.Printf("Created API key: %s (Key: %s)", apiKey.Name, rawKey[:20]+"...")
        
        // Validate API key
        apiAuthCtx, err := authManager.ValidateAPIKey(rawKey)
        if err != nil </span><span class="cov0" title="0">{
                log.Fatalf("Failed to validate API key: %v", err)
        }</span>
        
        <span class="cov0" title="0">log.Printf("API key validation successful for user: %s", apiAuthCtx.User.Username)
        
        // Check permissions
        hasModelRead := authManager.HasPermission(apiAuthCtx, PermissionModelRead)
        hasSystemAdmin := authManager.HasPermission(apiAuthCtx, PermissionSystemAdmin)
        
        log.Printf("User has model read permission: %v", hasModelRead)
        log.Printf("User has system admin permission: %v", hasSystemAdmin)</span>
}</pre>
		
		<pre class="file" id="file7" style="display: none">package auth

import (
        "time"

        "github.com/golang-jwt/jwt/v5"
)

// User represents a system user
type User struct {
        ID          string            `json:"id"`
        Username    string            `json:"username"`
        Email       string            `json:"email,omitempty"`
        Role        string            `json:"role"`
        Permissions []string          `json:"permissions"`
        APIKeys     []APIKey          `json:"api_keys,omitempty"`
        Metadata    map[string]string `json:"metadata,omitempty"`
        CreatedAt   time.Time         `json:"created_at"`
        UpdatedAt   time.Time         `json:"updated_at"`
        LastLoginAt *time.Time        `json:"last_login_at,omitempty"`
        Active      bool              `json:"active"`
}

// APIKey represents an API key for authentication
type APIKey struct {
        ID          string            `json:"id"`
        Name        string            `json:"name"`
        Key         string            `json:"key"`
        UserID      string            `json:"user_id"`
        Permissions []string          `json:"permissions"`
        Metadata    map[string]string `json:"metadata,omitempty"`
        ExpiresAt   *time.Time        `json:"expires_at,omitempty"`
        CreatedAt   time.Time         `json:"created_at"`
        LastUsedAt  *time.Time        `json:"last_used_at,omitempty"`
        Active      bool              `json:"active"`
}

// Session represents an authentication session
type Session struct {
        ID        string            `json:"id"`
        UserID    string            `json:"user_id"`
        TokenID   string            `json:"token_id"`
        IPAddress string            `json:"ip_address"`
        UserAgent string            `json:"user_agent"`
        Metadata  map[string]string `json:"metadata,omitempty"`
        CreatedAt time.Time         `json:"created_at"`
        ExpiresAt time.Time         `json:"expires_at"`
        Active    bool              `json:"active"`
}

// Claims represents JWT claims for the system
type Claims struct {
        UserID      string            `json:"user_id"`
        Username    string            `json:"username"`
        Email       string            `json:"email,omitempty"`
        Role        string            `json:"role"`
        Permissions []string          `json:"permissions"`
        SessionID   string            `json:"session_id,omitempty"`
        APIKeyID    string            `json:"api_key_id,omitempty"`
        Metadata    map[string]string `json:"metadata,omitempty"`
        jwt.RegisteredClaims
}

// AuthContext contains authentication information for a request
type AuthContext struct {
        User        *User     `json:"user"`
        Session     *Session  `json:"session,omitempty"`
        APIKey      *APIKey   `json:"api_key,omitempty"`
        Claims      *Claims   `json:"claims"`
        TokenString string    `json:"-"`
        Method      AuthMethod `json:"method"`
}

// AuthMethod represents the authentication method used
type AuthMethod string

const (
        AuthMethodJWT    AuthMethod = "jwt"
        AuthMethodAPIKey AuthMethod = "api_key"
        AuthMethodX509   AuthMethod = "x509"
        AuthMethodNone   AuthMethod = "none"
)

// Permission constants
const (
        PermissionNodeRead       = "node:read"
        PermissionNodeWrite      = "node:write"
        PermissionNodeAdmin      = "node:admin"
        PermissionModelRead      = "model:read"
        PermissionModelWrite     = "model:write"
        PermissionModelAdmin     = "model:admin"
        PermissionClusterRead    = "cluster:read"
        PermissionClusterWrite   = "cluster:write"
        PermissionClusterAdmin   = "cluster:admin"
        PermissionInferenceRead  = "inference:read"
        PermissionInferenceWrite = "inference:write"
        PermissionMetricsRead    = "metrics:read"
        PermissionSystemAdmin    = "system:admin"
        PermissionUserAdmin      = "user:admin"
)

// Role constants
const (
        RoleAdmin     = "admin"
        RoleOperator  = "operator"
        RoleUser      = "user"
        RoleReadOnly  = "readonly"
        RoleService   = "service"
)

// Default role permissions
var DefaultRolePermissions = map[string][]string{
        RoleAdmin: {
                PermissionSystemAdmin,
                PermissionUserAdmin,
                PermissionNodeAdmin,
                PermissionModelAdmin,
                PermissionClusterAdmin,
                PermissionInferenceWrite,
                PermissionMetricsRead,
        },
        RoleOperator: {
                PermissionNodeWrite,
                PermissionModelWrite,
                PermissionClusterWrite,
                PermissionInferenceWrite,
                PermissionMetricsRead,
        },
        RoleUser: {
                PermissionNodeRead,
                PermissionModelRead,
                PermissionClusterRead,
                PermissionInferenceWrite,
                PermissionMetricsRead,
        },
        RoleReadOnly: {
                PermissionNodeRead,
                PermissionModelRead,
                PermissionClusterRead,
                PermissionInferenceRead,
                PermissionMetricsRead,
        },
        RoleService: {
                PermissionNodeRead,
                PermissionModelRead,
                PermissionInferenceWrite,
        },
}

// AuthError represents authentication errors
type AuthError struct {
        Code    string `json:"code"`
        Message string `json:"message"`
        Details string `json:"details,omitempty"`
}

func (e AuthError) Error() string <span class="cov0" title="0">{
        if e.Details != "" </span><span class="cov0" title="0">{
                return e.Message + ": " + e.Details
        }</span>
        <span class="cov0" title="0">return e.Message</span>
}

// Common authentication errors
var (
        ErrInvalidCredentials = AuthError{
                Code:    "INVALID_CREDENTIALS",
                Message: "Invalid credentials provided",
        }
        ErrTokenExpired = AuthError{
                Code:    "TOKEN_EXPIRED",
                Message: "Authentication token has expired",
        }
        ErrTokenInvalid = AuthError{
                Code:    "TOKEN_INVALID",
                Message: "Authentication token is invalid",
        }
        ErrTokenBlacklisted = AuthError{
                Code:    "TOKEN_BLACKLISTED",
                Message: "Authentication token has been revoked",
        }
        ErrInsufficientPermissions = AuthError{
                Code:    "INSUFFICIENT_PERMISSIONS",
                Message: "Insufficient permissions for this operation",
        }
        ErrUserNotFound = AuthError{
                Code:    "USER_NOT_FOUND",
                Message: "User not found",
        }
        ErrUserInactive = AuthError{
                Code:    "USER_INACTIVE",
                Message: "User account is inactive",
        }
        ErrAPIKeyNotFound = AuthError{
                Code:    "API_KEY_NOT_FOUND",
                Message: "API key not found",
        }
        ErrAPIKeyInactive = AuthError{
                Code:    "API_KEY_INACTIVE",
                Message: "API key is inactive",
        }
        ErrAPIKeyExpired = AuthError{
                Code:    "API_KEY_EXPIRED",
                Message: "API key has expired",
        }
        ErrSessionNotFound = AuthError{
                Code:    "SESSION_NOT_FOUND",
                Message: "Session not found",
        }
        ErrSessionExpired = AuthError{
                Code:    "SESSION_EXPIRED",
                Message: "Session has expired",
        }
)

// LoginRequest represents a login request
type LoginRequest struct {
        Username string `json:"username" binding:"required"`
        Password string `json:"password" binding:"required"`
        Metadata map[string]string `json:"metadata,omitempty"`
}

// LoginResponse represents a login response
type LoginResponse struct {
        Token     string    `json:"token"`
        ExpiresAt time.Time `json:"expires_at"`
        User      *User     `json:"user"`
        SessionID string    `json:"session_id"`
}

// RefreshRequest represents a token refresh request
type RefreshRequest struct {
        Token string `json:"token" binding:"required"`
}

// CreateAPIKeyRequest represents an API key creation request
type CreateAPIKeyRequest struct {
        Name        string            `json:"name" binding:"required"`
        Permissions []string          `json:"permissions,omitempty"`
        ExpiresAt   *time.Time        `json:"expires_at,omitempty"`
        Metadata    map[string]string `json:"metadata,omitempty"`
}

// CreateAPIKeyResponse represents an API key creation response
type CreateAPIKeyResponse struct {
        APIKey *APIKey `json:"api_key"`
        Key    string  `json:"key"` // Only returned once during creation
}

// CreateUserRequest represents a user creation request
type CreateUserRequest struct {
        Username    string            `json:"username" binding:"required"`
        Email       string            `json:"email,omitempty"`
        Password    string            `json:"password" binding:"required"`
        Role        string            `json:"role" binding:"required"`
        Permissions []string          `json:"permissions,omitempty"`
        Metadata    map[string]string `json:"metadata,omitempty"`
}

// UpdateUserRequest represents a user update request
type UpdateUserRequest struct {
        Email       *string           `json:"email,omitempty"`
        Role        *string           `json:"role,omitempty"`
        Permissions []string          `json:"permissions,omitempty"`
        Metadata    map[string]string `json:"metadata,omitempty"`
        Active      *bool             `json:"active,omitempty"`
}

// ChangePasswordRequest represents a password change request
type ChangePasswordRequest struct {
        CurrentPassword string `json:"current_password" binding:"required"`
        NewPassword     string `json:"new_password" binding:"required"`
}</pre>
		
		<pre class="file" id="file8" style="display: none">package config

import (
        "fmt"
        "os"
        "path/filepath"
        "time"

        "github.com/spf13/viper"
)

// Config represents the complete configuration for a distributed Ollama node
type Config struct {
        // Node configuration
        Node        NodeConfig        `yaml:"node"`
        API         APIConfig         `yaml:"api"`
        P2P         P2PConfig         `yaml:"p2p"`
        Consensus   ConsensusConfig   `yaml:"consensus"`
        Scheduler   SchedulerConfig   `yaml:"scheduler"`
        Storage     StorageConfig     `yaml:"storage"`
        Security    SecurityConfig    `yaml:"security"`
        Web         WebConfig         `yaml:"web"`
        Metrics     MetricsConfig     `yaml:"metrics"`
        Logging     LoggingConfig     `yaml:"logging"`
        Sync        SyncConfig        `yaml:"sync"`
        Replication ReplicationConfig `yaml:"replication"`
        Distributed DistributedConfig `yaml:"distributed"`
}

// NodeConfig holds node-specific configuration
type NodeConfig struct {
        ID          string            `yaml:"id"`
        Name        string            `yaml:"name"`
        Region      string            `yaml:"region"`
        Zone        string            `yaml:"zone"`
        Environment string            `yaml:"environment"`
        Tags        map[string]string `yaml:"tags"`
}

// APIConfig holds API server configuration
type APIConfig struct {
        Listen      string        `yaml:"listen"`
        TLS         TLSConfig     `yaml:"tls"`
        Cors        CorsConfig    `yaml:"cors"`
        RateLimit   RateLimitConfig `yaml:"rate_limit"`
        Timeout     time.Duration `yaml:"timeout"`
        MaxBodySize int64         `yaml:"max_body_size"`
}

// P2PConfig holds P2P networking configuration
type P2PConfig struct {
        Listen        string   `yaml:"listen"`
        Bootstrap     []string `yaml:"bootstrap"`
        PrivateKey    string   `yaml:"private_key"`
        EnableDHT     bool     `yaml:"enable_dht"`
        EnablePubSub  bool     `yaml:"enable_pubsub"`
        ConnMgrLow    int      `yaml:"conn_mgr_low"`
        ConnMgrHigh   int      `yaml:"conn_mgr_high"`
        ConnMgrGrace  string   `yaml:"conn_mgr_grace"`
        DialTimeout   time.Duration `yaml:"dial_timeout"`
        MaxStreams    int      `yaml:"max_streams"`
}

// ConsensusConfig holds consensus engine configuration
type ConsensusConfig struct {
        DataDir          string        `yaml:"data_dir"`
        BindAddr         string        `yaml:"bind_addr"`
        AdvertiseAddr    string        `yaml:"advertise_addr"`
        Bootstrap        bool          `yaml:"bootstrap"`
        LogLevel         string        `yaml:"log_level"`
        HeartbeatTimeout time.Duration `yaml:"heartbeat_timeout"`
        ElectionTimeout  time.Duration `yaml:"election_timeout"`
        CommitTimeout    time.Duration `yaml:"commit_timeout"`
        MaxAppendEntries int           `yaml:"max_append_entries"`
        SnapshotInterval time.Duration `yaml:"snapshot_interval"`
        SnapshotThreshold uint64       `yaml:"snapshot_threshold"`
}

// SchedulerConfig holds scheduler configuration
type SchedulerConfig struct {
        Algorithm        string        `yaml:"algorithm"`
        LoadBalancing    string        `yaml:"load_balancing"`
        HealthCheckInterval time.Duration `yaml:"health_check_interval"`
        MaxRetries       int           `yaml:"max_retries"`
        RetryDelay       time.Duration `yaml:"retry_delay"`
        QueueSize        int           `yaml:"queue_size"`
        WorkerCount      int           `yaml:"worker_count"`
}

// StorageConfig holds storage configuration
type StorageConfig struct {
        DataDir     string `yaml:"data_dir"`
        ModelDir    string `yaml:"model_dir"`
        CacheDir    string `yaml:"cache_dir"`
        MaxDiskSize int64  `yaml:"max_disk_size"`
        CleanupAge  time.Duration `yaml:"cleanup_age"`
}

// SecurityConfig holds security configuration
type SecurityConfig struct {
        TLS         TLSConfig         `yaml:"tls"`
        Auth        AuthConfig        `yaml:"auth"`
        Encryption  EncryptionConfig  `yaml:"encryption"`
        Firewall    FirewallConfig    `yaml:"firewall"`
        Audit       AuditConfig       `yaml:"audit"`
}

// TLSConfig holds TLS configuration
type TLSConfig struct {
        Enabled    bool   `yaml:"enabled"`
        CertFile   string `yaml:"cert_file"`
        KeyFile    string `yaml:"key_file"`
        CAFile     string `yaml:"ca_file"`
        MinVersion string `yaml:"min_version"`
        CipherSuites []string `yaml:"cipher_suites"`
}

// AuthConfig holds authentication configuration
type AuthConfig struct {
        Enabled     bool          `yaml:"enabled"`
        Method      string        `yaml:"method"` // jwt, oauth, x509
        TokenExpiry time.Duration `yaml:"token_expiry"`
        SecretKey   string        `yaml:"secret_key"`
        Issuer      string        `yaml:"issuer"`
        Audience    string        `yaml:"audience"`
}

// EncryptionConfig holds encryption configuration
type EncryptionConfig struct {
        Algorithm string `yaml:"algorithm"`
        KeySize   int    `yaml:"key_size"`
        KeyFile   string `yaml:"key_file"`
}

// FirewallConfig holds firewall configuration
type FirewallConfig struct {
        Enabled    bool     `yaml:"enabled"`
        AllowedIPs []string `yaml:"allowed_ips"`
        BlockedIPs []string `yaml:"blocked_ips"`
        Rules      []FirewallRule `yaml:"rules"`
}

// FirewallRule represents a firewall rule
type FirewallRule struct {
        Protocol string `yaml:"protocol"`
        Port     int    `yaml:"port"`
        Action   string `yaml:"action"`
        Source   string `yaml:"source"`
}

// AuditConfig holds audit configuration
type AuditConfig struct {
        Enabled bool   `yaml:"enabled"`
        LogFile string `yaml:"log_file"`
        Format  string `yaml:"format"`
}

// CorsConfig holds CORS configuration
type CorsConfig struct {
        Enabled          bool     `yaml:"enabled"`
        AllowedOrigins   []string `yaml:"allowed_origins"`
        AllowedMethods   []string `yaml:"allowed_methods"`
        AllowedHeaders   []string `yaml:"allowed_headers"`
        ExposedHeaders   []string `yaml:"exposed_headers"`
        AllowCredentials bool     `yaml:"allow_credentials"`
        MaxAge           int      `yaml:"max_age"`
}

// RateLimitConfig holds rate limiting configuration
type RateLimitConfig struct {
        Enabled bool  `yaml:"enabled"`
        RPS     int   `yaml:"rps"`
        Burst   int   `yaml:"burst"`
        Window  time.Duration `yaml:"window"`
}

// WebConfig holds web interface configuration
type WebConfig struct {
        Enabled    bool   `yaml:"enabled"`
        Listen     string `yaml:"listen"`
        StaticDir  string `yaml:"static_dir"`
        TemplateDir string `yaml:"template_dir"`
        TLS        TLSConfig `yaml:"tls"`
}

// MetricsConfig holds metrics configuration
type MetricsConfig struct {
        Enabled    bool   `yaml:"enabled"`
        Listen     string `yaml:"listen"`
        Path       string `yaml:"path"`
        Namespace  string `yaml:"namespace"`
        Subsystem  string `yaml:"subsystem"`
}

// LoggingConfig holds logging configuration
type LoggingConfig struct {
        Level      string `yaml:"level"`
        Format     string `yaml:"format"`
        Output     string `yaml:"output"`
        File       string `yaml:"file"`
        MaxSize    int    `yaml:"max_size"`
        MaxAge     int    `yaml:"max_age"`
        MaxBackups int    `yaml:"max_backups"`
        Compress   bool   `yaml:"compress"`
}

// SyncConfig holds model synchronization configuration
type SyncConfig struct {
        DeltaDir       string        `yaml:"delta_dir"`
        CASDir         string        `yaml:"cas_dir"`
        WorkerCount    int           `yaml:"worker_count"`
        SyncInterval   time.Duration `yaml:"sync_interval"`
        ChunkSize      int64         `yaml:"chunk_size"`
        MaxRetries     int           `yaml:"max_retries"`
        RetryDelay     time.Duration `yaml:"retry_delay"`
}

// ReplicationConfig holds model replication configuration
type ReplicationConfig struct {
        WorkerCount                int           `yaml:"worker_count"`
        DefaultMinReplicas         int           `yaml:"default_min_replicas"`
        DefaultMaxReplicas         int           `yaml:"default_max_replicas"`
        DefaultReplicationFactor   int           `yaml:"default_replication_factor"`
        DefaultSyncInterval        time.Duration `yaml:"default_sync_interval"`
        PolicyEnforcementInterval  time.Duration `yaml:"policy_enforcement_interval"`
        HealthCheckInterval        time.Duration `yaml:"health_check_interval"`
        HealthCheckTimeout         time.Duration `yaml:"health_check_timeout"`
}

// DistributedConfig holds distributed model management configuration
type DistributedConfig struct {
        Storage     *StorageConfig     `yaml:"storage"`
        Sync        *SyncConfig        `yaml:"sync"`
        Replication *ReplicationConfig `yaml:"replication"`
        CASDir      string             `yaml:"cas_dir"`
        DeltaDir    string             `yaml:"delta_dir"`
}

// DefaultConfig returns a default configuration
func DefaultConfig() *Config <span class="cov0" title="0">{
        // Create storage config first
        storageConfig := StorageConfig{
                DataDir:     "./data",
                ModelDir:    "./models",
                CacheDir:    "./cache",
                MaxDiskSize: 100 * 1024 * 1024 * 1024, // 100GB
                CleanupAge:  7 * 24 * time.Hour,       // 7 days
        }
        
        // Create sync config
        syncConfig := SyncConfig{
                DeltaDir:     "./data/deltas",
                CASDir:       "./data/cas",
                WorkerCount:  3,
                SyncInterval: 5 * time.Minute,
                ChunkSize:    1024 * 1024, // 1MB
                MaxRetries:   3,
                RetryDelay:   time.Second,
        }
        
        // Create replication config
        replicationConfig := ReplicationConfig{
                WorkerCount:                3,
                DefaultMinReplicas:         1,
                DefaultMaxReplicas:         3,
                DefaultReplicationFactor:   2,
                DefaultSyncInterval:        10 * time.Minute,
                PolicyEnforcementInterval:  30 * time.Second,
                HealthCheckInterval:        30 * time.Second,
                HealthCheckTimeout:         10 * time.Second,
        }
        
        return &amp;Config{
                Node: NodeConfig{
                        ID:          "",
                        Name:        "ollama-node",
                        Region:      "us-west-2",
                        Zone:        "us-west-2a",
                        Environment: "production",
                        Tags:        make(map[string]string),
                },
                API: APIConfig{
                        Listen:      "0.0.0.0:11434",
                        Timeout:     30 * time.Second,
                        MaxBodySize: 32 * 1024 * 1024, // 32MB
                        TLS: TLSConfig{
                                Enabled:    false,
                                MinVersion: "1.2",
                        },
                        Cors: CorsConfig{
                                Enabled:          true,
                                AllowedOrigins:   []string{"http://localhost:8080", "https://localhost:8080"},
                                AllowedMethods:   []string{"GET", "POST", "PUT", "DELETE", "OPTIONS"},
                                AllowedHeaders:   []string{"Content-Type", "Authorization", "X-Requested-With"},
                                AllowCredentials: true,
                                MaxAge:           3600,
                        },
                        RateLimit: RateLimitConfig{
                                Enabled: true,
                                RPS:     1000,
                                Burst:   2000,
                                Window:  time.Minute,
                        },
                },
                P2P: P2PConfig{
                        Listen:        "/ip4/0.0.0.0/tcp/4001",
                        Bootstrap:     []string{},
                        EnableDHT:     true,
                        EnablePubSub:  true,
                        ConnMgrLow:    50,
                        ConnMgrHigh:   200,
                        ConnMgrGrace:  "30s",
                        DialTimeout:   30 * time.Second,
                        MaxStreams:    1000,
                },
                Consensus: ConsensusConfig{
                        DataDir:           "./data/consensus",
                        BindAddr:          "0.0.0.0:7000",
                        AdvertiseAddr:     "",
                        Bootstrap:         false,
                        LogLevel:          "INFO",
                        HeartbeatTimeout:  1 * time.Second,
                        ElectionTimeout:   1 * time.Second,
                        CommitTimeout:     50 * time.Millisecond,
                        MaxAppendEntries:  64,
                        SnapshotInterval:  120 * time.Second,
                        SnapshotThreshold: 8192,
                },
                Scheduler: SchedulerConfig{
                        Algorithm:           "round_robin",
                        LoadBalancing:       "least_connections",
                        HealthCheckInterval: 30 * time.Second,
                        MaxRetries:          3,
                        RetryDelay:          1 * time.Second,
                        QueueSize:           10000,
                        WorkerCount:         10,
                },
                Storage: storageConfig,
                Security: SecurityConfig{
                        TLS: TLSConfig{
                                Enabled:    true,
                                MinVersion: "1.3",
                        },
                        Auth: AuthConfig{
                                Enabled:     true,
                                Method:      "jwt",
                                TokenExpiry: 24 * time.Hour,
                        },
                        Encryption: EncryptionConfig{
                                Algorithm: "AES-256-GCM",
                                KeySize:   256,
                        },
                        Firewall: FirewallConfig{
                                Enabled: true,
                                Rules:   []FirewallRule{},
                        },
                        Audit: AuditConfig{
                                Enabled: true,
                                LogFile: "./logs/audit.log",
                                Format:  "json",
                        },
                },
                Web: WebConfig{
                        Enabled:   true,
                        Listen:    "0.0.0.0:8080",
                        StaticDir: "./web/static",
                        TLS: TLSConfig{
                                Enabled: false,
                        },
                },
                Metrics: MetricsConfig{
                        Enabled:   true,
                        Listen:    "0.0.0.0:9090",
                        Path:      "/metrics",
                        Namespace: "ollama",
                        Subsystem: "distributed",
                },
                Logging: LoggingConfig{
                        Level:      "info",
                        Format:     "json",
                        Output:     "stdout",
                        MaxSize:    100,
                        MaxAge:     30,
                        MaxBackups: 10,
                        Compress:   true,
                },
                Sync:        syncConfig,
                Replication: replicationConfig,
                Distributed: DistributedConfig{
                        Storage:     &amp;storageConfig,
                        Sync:        &amp;syncConfig,
                        Replication: &amp;replicationConfig,
                        CASDir:      "./data/cas",
                        DeltaDir:    "./data/deltas",
                },
        }
}</span>

// Load loads configuration from file
func Load(configFile string) (*Config, error) <span class="cov0" title="0">{
        config := DefaultConfig()
        
        if configFile != "" </span><span class="cov0" title="0">{
                viper.SetConfigFile(configFile)
        }</span> else<span class="cov0" title="0"> {
                // Look for config in standard locations
                viper.SetConfigName("config")
                viper.SetConfigType("yaml")
                viper.AddConfigPath(".")
                viper.AddConfigPath("./config")
                viper.AddConfigPath("$HOME/.ollama-distributed")
                viper.AddConfigPath("/etc/ollama-distributed")
        }</span>
        
        // Environment variables
        <span class="cov0" title="0">viper.SetEnvPrefix("OLLAMA")
        viper.AutomaticEnv()
        
        // Read configuration
        if err := viper.ReadInConfig(); err != nil </span><span class="cov0" title="0">{
                if _, ok := err.(viper.ConfigFileNotFoundError); !ok </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to read config file: %w", err)
                }</span>
        }
        
        // Unmarshal into config struct
        <span class="cov0" title="0">if err := viper.Unmarshal(config); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to unmarshal config: %w", err)
        }</span>
        
        // Validate and set defaults
        <span class="cov0" title="0">if err := config.Validate(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("invalid configuration: %w", err)
        }</span>
        
        <span class="cov0" title="0">return config, nil</span>
}

// Validate validates the configuration
func (c *Config) Validate() error <span class="cov0" title="0">{
        // Validate directories exist or can be created
        dirs := []string{
                c.Storage.DataDir,
                c.Storage.ModelDir,
                c.Storage.CacheDir,
                c.Consensus.DataDir,
                c.Sync.DeltaDir,
                c.Sync.CASDir,
                c.Distributed.CASDir,
                c.Distributed.DeltaDir,
        }
        
        for _, dir := range dirs </span><span class="cov0" title="0">{
                if err := os.MkdirAll(dir, 0755); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to create directory %s: %w", dir, err)
                }</span>
        }
        
        // Validate log directory
        <span class="cov0" title="0">if c.Logging.Output == "file" &amp;&amp; c.Logging.File != "" </span><span class="cov0" title="0">{
                logDir := filepath.Dir(c.Logging.File)
                if err := os.MkdirAll(logDir, 0755); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to create log directory %s: %w", logDir, err)
                }</span>
        }
        
        // Validate TLS certificates if enabled
        <span class="cov0" title="0">if c.Security.TLS.Enabled </span><span class="cov0" title="0">{
                if c.Security.TLS.CertFile == "" || c.Security.TLS.KeyFile == "" </span><span class="cov0" title="0">{
                        return fmt.Errorf("TLS enabled but cert_file or key_file not specified")
                }</span>
        }
        
        <span class="cov0" title="0">return nil</span>
}

// Save saves the configuration to a file
func (c *Config) Save(filename string) error <span class="cov0" title="0">{
        viper.Set("config", c)
        return viper.WriteConfigAs(filename)
}</pre>
		
		<pre class="file" id="file9" style="display: none">package metrics

import (
        "context"
        "fmt"
        "net/http"
        "time"

        "github.com/ollama/ollama-distributed/internal/config"
        "github.com/rs/zerolog/log"
)

// Server represents a metrics server
type Server struct {
        config *config.MetricsConfig
        server *http.Server
}

// NewServer creates a new metrics server
func NewServer(config config.MetricsConfig) (*Server, error) <span class="cov0" title="0">{
        mux := http.NewServeMux()
        
        // Add basic metrics endpoint
        mux.HandleFunc("/metrics", func(w http.ResponseWriter, r *http.Request) </span><span class="cov0" title="0">{
                w.Header().Set("Content-Type", "text/plain")
                w.WriteHeader(http.StatusOK)
                fmt.Fprintf(w, "# Ollamacron Metrics\n")
                fmt.Fprintf(w, "# TYPE ollamacron_info gauge\n")
                fmt.Fprintf(w, "ollamacron_info{version=\"dev\"} 1\n")
                fmt.Fprintf(w, "# TYPE ollamacron_uptime_seconds counter\n")
                fmt.Fprintf(w, "ollamacron_uptime_seconds %d\n", time.Now().Unix())
        }</span>)
        
        // Add health endpoint
        <span class="cov0" title="0">mux.HandleFunc("/health", func(w http.ResponseWriter, r *http.Request) </span><span class="cov0" title="0">{
                w.Header().Set("Content-Type", "application/json")
                w.WriteHeader(http.StatusOK)
                fmt.Fprintf(w, `{"status":"healthy","timestamp":"%s"}`, time.Now().Format(time.RFC3339))
        }</span>)
        
        <span class="cov0" title="0">server := &amp;http.Server{
                Addr:         config.Listen,
                Handler:      mux,
                ReadTimeout:  10 * time.Second,
                WriteTimeout: 10 * time.Second,
        }
        
        return &amp;Server{
                config: &amp;config,
                server: server,
        }, nil</span>
}

// Start starts the metrics server
func (s *Server) Start() error <span class="cov0" title="0">{
        log.Info().Str("address", s.config.Listen).Msg("Starting metrics server")
        
        go func() </span><span class="cov0" title="0">{
                if err := s.server.ListenAndServe(); err != nil &amp;&amp; err != http.ErrServerClosed </span><span class="cov0" title="0">{
                        log.Error().Err(err).Msg("Metrics server error")
                }</span>
        }()
        
        <span class="cov0" title="0">return nil</span>
}

// Shutdown shuts down the metrics server
func (s *Server) Shutdown(ctx context.Context) error <span class="cov0" title="0">{
        log.Info().Msg("Shutting down metrics server")
        return s.server.Shutdown(ctx)
}</pre>
		
		<pre class="file" id="file10" style="display: none">package storage

import (
        "context"
        "fmt"
        "io"
        "log/slog"
        "sort"
        "sync"
        "time"
)

// DistributedStorageImpl implements DistributedStorage interface
type DistributedStorageImpl struct {
        localStorage Storage
        logger       *slog.Logger
        
        // Distributed coordination
        nodeID       string
        
        // Node management
        nodes       map[string]*NodeInfo
        nodesMutex  sync.RWMutex
        
        // Replication management
        replicationMgr *ReplicationManager
        
        // Consensus and coordination
        consensusState *ConsensusState
        consensusMutex sync.RWMutex
        
        // Distributed locks
        locks       map[string]*DistributedLock
        locksMutex  sync.RWMutex
        
        // Configuration
        config *DistributedStorageConfig
        
        // Metrics and monitoring
        metrics     *DistributedMetrics
        metricsMutex sync.RWMutex
        
        // Background tasks
        ctx     context.Context
        cancel  context.CancelFunc
        started bool
        mu      sync.RWMutex
}

// DistributedStorageConfig contains configuration for distributed storage
type DistributedStorageConfig struct {
        NodeID               string        `json:"node_id"`
        ReplicationFactor    int           `json:"replication_factor"`
        ConsistencyLevel     string        `json:"consistency_level"`
        HeartbeatInterval    time.Duration `json:"heartbeat_interval"`
        ElectionTimeout      time.Duration `json:"election_timeout"`
        ReplicationTimeout   time.Duration `json:"replication_timeout"`
        MaxConcurrentRepl    int           `json:"max_concurrent_replication"`
        GossipInterval       time.Duration `json:"gossip_interval"`
        FailureDetectorTimeout time.Duration `json:"failure_detector_timeout"`
}

// ReplicationManager handles distributed replication
type ReplicationManager struct {
        storage    *DistributedStorageImpl
        logger     *slog.Logger
        
        // Replication state
        replicas      map[string]*ReplicationStatus
        replicasMutex sync.RWMutex
        
        // Worker pools
        workers     []*ReplicationWorker
        workQueue   chan *ReplicationTask
        
        // Policies
        policies      map[string]*ReplicationPolicy
        policiesMutex sync.RWMutex
        
        ctx    context.Context
        cancel context.CancelFunc
}

// ReplicationWorker handles replication tasks
type ReplicationWorker struct {
        id      int
        manager *ReplicationManager
        logger  *slog.Logger
}

// ReplicationTask represents a replication task
type ReplicationTask struct {
        Type        string    `json:"type"`
        Key         string    `json:"key"`
        SourceNode  string    `json:"source_node"`
        TargetNodes []string  `json:"target_nodes"`
        Priority    int       `json:"priority"`
        Timeout     time.Duration `json:"timeout"`
        CreatedAt   time.Time `json:"created_at"`
        Retries     int       `json:"retries"`
        MaxRetries  int       `json:"max_retries"`
}

// DistributedLock implements the Lock interface
type DistributedLock struct {
        lockID     string
        owner      string
        expiration time.Time
        storage    *DistributedStorageImpl
        released   bool
        mutex      sync.Mutex
}

// NewDistributedStorage creates a new distributed storage instance
func NewDistributedStorage(
        localStorage Storage,
        config *DistributedStorageConfig,
        logger *slog.Logger,
) (*DistributedStorageImpl, error) <span class="cov0" title="0">{
        ctx, cancel := context.WithCancel(context.Background())
        
        ds := &amp;DistributedStorageImpl{
                localStorage: localStorage,
                logger:       logger,
                nodeID:       config.NodeID,
                nodes:        make(map[string]*NodeInfo),
                locks:        make(map[string]*DistributedLock),
                config:       config,
                consensusState: &amp;ConsensusState{
                        Nodes:      make(map[string]string),
                        QuorumSize: (config.ReplicationFactor / 2) + 1,
                        IsHealthy:  true,
                },
                metrics: &amp;DistributedMetrics{
                        DataDistribution: make(map[string]int64),
                        NetworkMetrics:   &amp;NetworkMetrics{ConnectionCounts: make(map[string]int64)},
                        ConsensusMetrics: &amp;ConsensusMetrics{},
                },
                ctx:    ctx,
                cancel: cancel,
        }
        
        // Initialize replication manager
        ds.replicationMgr = &amp;ReplicationManager{
                storage:   ds,
                logger:    logger,
                replicas:  make(map[string]*ReplicationStatus),
                policies:  make(map[string]*ReplicationPolicy),
                workQueue: make(chan *ReplicationTask, 1000),
                ctx:       ctx,
                cancel:    cancel,
        }
        
        // Create replication workers
        workerCount := config.MaxConcurrentRepl
        if workerCount &lt;= 0 </span><span class="cov0" title="0">{
                workerCount = 10
        }</span>
        
        <span class="cov0" title="0">ds.replicationMgr.workers = make([]*ReplicationWorker, workerCount)
        for i := 0; i &lt; workerCount; i++ </span><span class="cov0" title="0">{
                ds.replicationMgr.workers[i] = &amp;ReplicationWorker{
                        id:      i,
                        manager: ds.replicationMgr,
                        logger:  logger,
                }
        }</span>
        
        <span class="cov0" title="0">return ds, nil</span>
}

// Start starts the distributed storage
func (ds *DistributedStorageImpl) Start(ctx context.Context) error <span class="cov0" title="0">{
        ds.mu.Lock()
        defer ds.mu.Unlock()
        
        if ds.started </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:    ErrCodeInternal,
                        Message: "distributed storage already started",
                }
        }</span>
        
        // Start local storage
        <span class="cov0" title="0">if err := ds.localStorage.Start(ctx); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start local storage: %w", err)
        }</span>
        
        // Start replication workers
        <span class="cov0" title="0">for _, worker := range ds.replicationMgr.workers </span><span class="cov0" title="0">{
                go worker.start()
        }</span>
        
        // Start background routines
        <span class="cov0" title="0">go ds.heartbeatRoutine()
        go ds.consensusMonitorRoutine()
        go ds.metricsCollectionRoutine()
        go ds.failureDetectorRoutine()
        
        ds.started = true
        ds.logger.Info("distributed storage started", "node_id", ds.nodeID)
        
        return nil</span>
}

// Stop stops the distributed storage
func (ds *DistributedStorageImpl) Stop(ctx context.Context) error <span class="cov0" title="0">{
        ds.mu.Lock()
        defer ds.mu.Unlock()
        
        if !ds.started </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        <span class="cov0" title="0">ds.cancel()
        
        // Stop local storage
        if err := ds.localStorage.Stop(ctx); err != nil </span><span class="cov0" title="0">{
                ds.logger.Error("failed to stop local storage", "error", err)
        }</span>
        
        <span class="cov0" title="0">ds.started = false
        ds.logger.Info("distributed storage stopped")
        
        return nil</span>
}

// Close closes the distributed storage
func (ds *DistributedStorageImpl) Close() error <span class="cov0" title="0">{
        return ds.Stop(context.Background())
}</span>

// Core storage operations (delegate to local storage with replication)

// Store stores an object with distributed replication
func (ds *DistributedStorageImpl) Store(ctx context.Context, key string, data io.Reader, metadata *ObjectMetadata) error <span class="cov0" title="0">{
        // First store locally
        if err := ds.localStorage.Store(ctx, key, data, metadata); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        // Get or create replication policy
        <span class="cov0" title="0">policy := ds.getReplicationPolicy(key)
        if policy == nil </span><span class="cov0" title="0">{
                policy = ds.createDefaultReplicationPolicy(key)
        }</span>
        
        // Initiate replication based on policy
        <span class="cov0" title="0">if err := ds.initiateReplication(ctx, key, policy); err != nil </span><span class="cov0" title="0">{
                ds.logger.Error("replication failed", "key", key, "error", err)
                // Don't fail the store operation if replication fails
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// Retrieve retrieves an object, potentially from replicas
func (ds *DistributedStorageImpl) Retrieve(ctx context.Context, key string) (io.ReadCloser, *ObjectMetadata, error) <span class="cov0" title="0">{
        // Try local storage first
        reader, metadata, err := ds.localStorage.Retrieve(ctx, key)
        if err == nil </span><span class="cov0" title="0">{
                return reader, metadata, nil
        }</span>
        
        // If not found locally, try replicas
        <span class="cov0" title="0">if isNotFoundError(err) </span><span class="cov0" title="0">{
                return ds.retrieveFromReplicas(ctx, key)
        }</span>
        
        <span class="cov0" title="0">return nil, nil, err</span>
}

// Delete deletes an object from all replicas
func (ds *DistributedStorageImpl) Delete(ctx context.Context, key string) error <span class="cov0" title="0">{
        // Delete locally first
        if err := ds.localStorage.Delete(ctx, key); err != nil &amp;&amp; !isNotFoundError(err) </span><span class="cov0" title="0">{
                return err
        }</span>
        
        // Delete from replicas
        <span class="cov0" title="0">if err := ds.deleteFromReplicas(ctx, key); err != nil </span><span class="cov0" title="0">{
                ds.logger.Error("failed to delete from replicas", "key", key, "error", err)
        }</span>
        
        // Remove replication status
        <span class="cov0" title="0">ds.replicationMgr.removeReplicationStatus(key)
        
        return nil</span>
}

// Exists checks if an object exists locally or on replicas
func (ds *DistributedStorageImpl) Exists(ctx context.Context, key string) (bool, error) <span class="cov0" title="0">{
        // Check locally first
        exists, err := ds.localStorage.Exists(ctx, key)
        if err != nil </span><span class="cov0" title="0">{
                return false, err
        }</span>
        <span class="cov0" title="0">if exists </span><span class="cov0" title="0">{
                return true, nil
        }</span>
        
        // Check replicas
        <span class="cov0" title="0">return ds.existsOnReplicas(ctx, key)</span>
}

// Delegate metadata operations to local storage
func (ds *DistributedStorageImpl) GetMetadata(ctx context.Context, key string) (*ObjectMetadata, error) <span class="cov0" title="0">{
        return ds.localStorage.GetMetadata(ctx, key)
}</span>

func (ds *DistributedStorageImpl) SetMetadata(ctx context.Context, key string, metadata *ObjectMetadata) error <span class="cov0" title="0">{
        return ds.localStorage.SetMetadata(ctx, key, metadata)
}</span>

func (ds *DistributedStorageImpl) UpdateMetadata(ctx context.Context, key string, updates map[string]interface{}) error <span class="cov0" title="0">{
        return ds.localStorage.UpdateMetadata(ctx, key, updates)
}</span>

// Delegate batch operations
func (ds *DistributedStorageImpl) BatchStore(ctx context.Context, operations []BatchStoreOperation) error <span class="cov0" title="0">{
        return ds.localStorage.BatchStore(ctx, operations)
}</span>

func (ds *DistributedStorageImpl) BatchDelete(ctx context.Context, keys []string) error <span class="cov0" title="0">{
        return ds.localStorage.BatchDelete(ctx, keys)
}</span>

// Delegate listing operations
func (ds *DistributedStorageImpl) List(ctx context.Context, prefix string, options *ListOptions) (*ListResult, error) <span class="cov0" title="0">{
        return ds.localStorage.List(ctx, prefix, options)
}</span>

func (ds *DistributedStorageImpl) ListKeys(ctx context.Context, prefix string) ([]string, error) <span class="cov0" title="0">{
        return ds.localStorage.ListKeys(ctx, prefix)
}</span>

// Distributed-specific operations

// Replicate replicates an object to target nodes
func (ds *DistributedStorageImpl) Replicate(ctx context.Context, key string, targetNodes []string) error <span class="cov0" title="0">{
        task := &amp;ReplicationTask{
                Type:        "replicate",
                Key:         key,
                SourceNode:  ds.nodeID,
                TargetNodes: targetNodes,
                Priority:    1,
                Timeout:     ds.config.ReplicationTimeout,
                CreatedAt:   time.Now(),
                MaxRetries:  3,
        }
        
        select </span>{
        case ds.replicationMgr.workQueue &lt;- task:<span class="cov0" title="0">
                return nil</span>
        case &lt;-ctx.Done():<span class="cov0" title="0">
                return ctx.Err()</span>
        case &lt;-time.After(5 * time.Second):<span class="cov0" title="0">
                return &amp;StorageError{
                        Code:    ErrCodeTimeout,
                        Message: "replication queue full",
                }</span>
        }
}

// GetReplicationStatus gets the replication status for a key
func (ds *DistributedStorageImpl) GetReplicationStatus(ctx context.Context, key string) (*ReplicationStatus, error) <span class="cov0" title="0">{
        ds.replicationMgr.replicasMutex.RLock()
        defer ds.replicationMgr.replicasMutex.RUnlock()
        
        status, exists := ds.replicationMgr.replicas[key]
        if !exists </span><span class="cov0" title="0">{
                return nil, &amp;StorageError{
                        Code:    ErrCodeNotFound,
                        Message: "replication status not found",
                }
        }</span>
        
        // Create a copy
        <span class="cov0" title="0">result := *status
        return &amp;result, nil</span>
}

// SetReplicationPolicy sets a replication policy for a key
func (ds *DistributedStorageImpl) SetReplicationPolicy(ctx context.Context, key string, policy *ReplicationPolicy) error <span class="cov0" title="0">{
        ds.replicationMgr.policiesMutex.Lock()
        defer ds.replicationMgr.policiesMutex.Unlock()
        
        ds.replicationMgr.policies[key] = policy
        
        // Trigger replication if necessary
        go ds.enforceReplicationPolicy(ctx, key, policy)
        
        return nil
}</span>

// Consensus and coordination operations

// ProposeWrite proposes a write operation through consensus
func (ds *DistributedStorageImpl) ProposeWrite(ctx context.Context, key string, data io.Reader, metadata *ObjectMetadata) error <span class="cov0" title="0">{
        // For now, fall back to direct store since we don't have Raft integration
        return ds.Store(ctx, key, data, metadata)
}</span>

// ProposeDelete proposes a delete operation through consensus
func (ds *DistributedStorageImpl) ProposeDelete(ctx context.Context, key string) error <span class="cov0" title="0">{
        // For now, fall back to direct delete since we don't have Raft integration
        return ds.Delete(ctx, key)
}</span>

// GetConsensusState returns the current consensus state
func (ds *DistributedStorageImpl) GetConsensusState(ctx context.Context) (*ConsensusState, error) <span class="cov0" title="0">{
        ds.consensusMutex.RLock()
        defer ds.consensusMutex.RUnlock()
        
        // Create a copy
        state := *ds.consensusState
        state.Nodes = make(map[string]string)
        for k, v := range ds.consensusState.Nodes </span><span class="cov0" title="0">{
                state.Nodes[k] = v
        }</span>
        
        <span class="cov0" title="0">return &amp;state, nil</span>
}

// Node management operations

// AddNode adds a new node to the cluster
func (ds *DistributedStorageImpl) AddNode(ctx context.Context, nodeID string, nodeInfo *NodeInfo) error <span class="cov0" title="0">{
        ds.nodesMutex.Lock()
        defer ds.nodesMutex.Unlock()
        
        nodeInfo.NodeID = nodeID
        nodeInfo.JoinedAt = time.Now()
        nodeInfo.LastSeen = time.Now()
        
        ds.nodes[nodeID] = nodeInfo
        
        // Update consensus state
        ds.consensusMutex.Lock()
        ds.consensusState.Nodes[nodeID] = "active"
        ds.consensusMutex.Unlock()
        
        ds.logger.Info("node added", "node_id", nodeID, "address", nodeInfo.Address)
        
        return nil
}</span>

// RemoveNode removes a node from the cluster
func (ds *DistributedStorageImpl) RemoveNode(ctx context.Context, nodeID string) error <span class="cov0" title="0">{
        ds.nodesMutex.Lock()
        defer ds.nodesMutex.Unlock()
        
        delete(ds.nodes, nodeID)
        
        // Update consensus state
        ds.consensusMutex.Lock()
        delete(ds.consensusState.Nodes, nodeID)
        ds.consensusMutex.Unlock()
        
        ds.logger.Info("node removed", "node_id", nodeID)
        
        return nil
}</span>

// GetNodes returns all nodes in the cluster
func (ds *DistributedStorageImpl) GetNodes(ctx context.Context) ([]*NodeInfo, error) <span class="cov0" title="0">{
        ds.nodesMutex.RLock()
        defer ds.nodesMutex.RUnlock()
        
        nodes := make([]*NodeInfo, 0, len(ds.nodes))
        for _, node := range ds.nodes </span><span class="cov0" title="0">{
                // Create a copy
                nodeCopy := *node
                nodes = append(nodes, &amp;nodeCopy)
        }</span>
        
        <span class="cov0" title="0">return nodes, nil</span>
}

// Distributed coordination

// AcquireLock acquires a distributed lock
func (ds *DistributedStorageImpl) AcquireLock(ctx context.Context, lockID string, timeout time.Duration) (Lock, error) <span class="cov0" title="0">{
        ds.locksMutex.Lock()
        defer ds.locksMutex.Unlock()
        
        // Check if lock already exists
        if lock, exists := ds.locks[lockID]; exists </span><span class="cov0" title="0">{
                if lock.IsHeld() </span><span class="cov0" title="0">{
                        return nil, &amp;StorageError{
                                Code:    ErrCodeAlreadyExists,
                                Message: "lock already held",
                        }
                }</span>
        }
        
        // Create new lock
        <span class="cov0" title="0">lock := &amp;DistributedLock{
                lockID:     lockID,
                owner:      ds.nodeID,
                expiration: time.Now().Add(timeout),
                storage:    ds,
                released:   false,
        }
        
        ds.locks[lockID] = lock
        
        return lock, nil</span>
}

// GetDistributedMetrics returns distributed metrics
func (ds *DistributedStorageImpl) GetDistributedMetrics(ctx context.Context) (*DistributedMetrics, error) <span class="cov0" title="0">{
        ds.metricsMutex.RLock()
        defer ds.metricsMutex.RUnlock()
        
        // Create a copy
        metrics := *ds.metrics
        
        // Copy maps
        metrics.DataDistribution = make(map[string]int64)
        for k, v := range ds.metrics.DataDistribution </span><span class="cov0" title="0">{
                metrics.DataDistribution[k] = v
        }</span>
        
        <span class="cov0" title="0">if ds.metrics.NetworkMetrics != nil </span><span class="cov0" title="0">{
                netMetrics := *ds.metrics.NetworkMetrics
                netMetrics.ConnectionCounts = make(map[string]int64)
                for k, v := range ds.metrics.NetworkMetrics.ConnectionCounts </span><span class="cov0" title="0">{
                        netMetrics.ConnectionCounts[k] = v
                }</span>
                <span class="cov0" title="0">metrics.NetworkMetrics = &amp;netMetrics</span>
        }
        
        <span class="cov0" title="0">if ds.metrics.ConsensusMetrics != nil </span><span class="cov0" title="0">{
                consMetrics := *ds.metrics.ConsensusMetrics
                metrics.ConsensusMetrics = &amp;consMetrics
        }</span>
        
        <span class="cov0" title="0">return &amp;metrics, nil</span>
}

// Health check for distributed storage
func (ds *DistributedStorageImpl) HealthCheck(ctx context.Context) (*HealthStatus, error) <span class="cov0" title="0">{
        // Get local health first
        localHealth, err := ds.localStorage.HealthCheck(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        
        // Add distributed-specific checks
        <span class="cov0" title="0">checks := localHealth.Checks
        if checks == nil </span><span class="cov0" title="0">{
                checks = make(map[string]CheckResult)
        }</span>
        
        // Check consensus health
        <span class="cov0" title="0">consensusCheck := ds.checkConsensusHealth()
        checks["consensus"] = consensusCheck
        
        // Check node connectivity
        connectivityCheck := ds.checkNodeConnectivity()
        checks["connectivity"] = connectivityCheck
        
        // Check replication health
        replicationCheck := ds.checkReplicationHealth()
        checks["replication"] = replicationCheck
        
        // Overall health
        healthy := localHealth.Healthy &amp;&amp; 
                consensusCheck.Status == "ok" &amp;&amp; 
                connectivityCheck.Status == "ok" &amp;&amp; 
                replicationCheck.Status == "ok"
        
        status := "healthy"
        if !healthy </span><span class="cov0" title="0">{
                status = "unhealthy"
        }</span>
        
        <span class="cov0" title="0">return &amp;HealthStatus{
                Status:    status,
                Healthy:   healthy,
                LastCheck: time.Now(),
                Checks:    checks,
        }, nil</span>
}

// GetStats returns distributed storage statistics
func (ds *DistributedStorageImpl) GetStats(ctx context.Context) (*StorageStats, error) <span class="cov0" title="0">{
        localStats, err := ds.localStorage.GetStats(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        
        // Add replication statistics
        <span class="cov0" title="0">localStats.Replication = ds.getReplicationStats()
        
        return localStats, nil</span>
}

// Helper methods

func (ds *DistributedStorageImpl) getReplicationPolicy(key string) *ReplicationPolicy <span class="cov0" title="0">{
        ds.replicationMgr.policiesMutex.RLock()
        defer ds.replicationMgr.policiesMutex.RUnlock()
        
        return ds.replicationMgr.policies[key]
}</span>

func (ds *DistributedStorageImpl) createDefaultReplicationPolicy(key string) *ReplicationPolicy <span class="cov0" title="0">{
        policy := &amp;ReplicationPolicy{
                MinReplicas:      ds.config.ReplicationFactor,
                MaxReplicas:      ds.config.ReplicationFactor * 2,
                ConsistencyLevel: ds.config.ConsistencyLevel,
                Strategy:         "eager",
                Constraints:      make(map[string]interface{}),
        }
        
        ds.replicationMgr.policiesMutex.Lock()
        ds.replicationMgr.policies[key] = policy
        ds.replicationMgr.policiesMutex.Unlock()
        
        return policy
}</span>

func (ds *DistributedStorageImpl) initiateReplication(ctx context.Context, key string, policy *ReplicationPolicy) error <span class="cov0" title="0">{
        // Select target nodes
        targetNodes := ds.selectReplicationTargets(policy)
        if len(targetNodes) == 0 </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:    ErrCodeUnavailable,
                        Message: "no suitable replication targets available",
                }
        }</span>
        
        // Create replication status
        <span class="cov0" title="0">status := &amp;ReplicationStatus{
                Key:             key,
                Policy:          policy,
                CurrentReplicas: 1, // Local copy
                HealthyReplicas: 1,
                ReplicaNodes:    append([]string{ds.nodeID}, targetNodes...),
                SyncStatus:      make(map[string]string),
                LastSync:        time.Now(),
        }
        
        ds.replicationMgr.replicasMutex.Lock()
        ds.replicationMgr.replicas[key] = status
        ds.replicationMgr.replicasMutex.Unlock()
        
        // Submit replication task
        return ds.Replicate(ctx, key, targetNodes)</span>
}

func (ds *DistributedStorageImpl) selectReplicationTargets(policy *ReplicationPolicy) []string <span class="cov0" title="0">{
        ds.nodesMutex.RLock()
        defer ds.nodesMutex.RUnlock()
        
        var candidates []*NodeInfo
        
        // Filter by preferred nodes first
        if len(policy.PreferredNodes) &gt; 0 </span><span class="cov0" title="0">{
                for _, nodeID := range policy.PreferredNodes </span><span class="cov0" title="0">{
                        if node, exists := ds.nodes[nodeID]; exists &amp;&amp; nodeID != ds.nodeID </span><span class="cov0" title="0">{
                                candidates = append(candidates, node)
                        }</span>
                }
        }
        
        // Add other available nodes if needed
        <span class="cov0" title="0">if len(candidates) &lt; policy.MinReplicas </span><span class="cov0" title="0">{
                for nodeID, node := range ds.nodes </span><span class="cov0" title="0">{
                        if nodeID == ds.nodeID </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        
                        // Check if already in candidates
                        <span class="cov0" title="0">found := false
                        for _, candidate := range candidates </span><span class="cov0" title="0">{
                                if candidate.NodeID == nodeID </span><span class="cov0" title="0">{
                                        found = true
                                        break</span>
                                }
                        }
                        <span class="cov0" title="0">if found </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        
                        // Check excluded nodes
                        <span class="cov0" title="0">excluded := false
                        for _, excludedID := range policy.ExcludedNodes </span><span class="cov0" title="0">{
                                if excludedID == nodeID </span><span class="cov0" title="0">{
                                        excluded = true
                                        break</span>
                                }
                        }
                        <span class="cov0" title="0">if excluded </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        
                        <span class="cov0" title="0">candidates = append(candidates, node)
                        if len(candidates) &gt;= policy.MinReplicas </span><span class="cov0" title="0">{
                                break</span>
                        }
                }
        }
        
        // Sort by availability and select top candidates
        <span class="cov0" title="0">sort.Slice(candidates, func(i, j int) bool </span><span class="cov0" title="0">{
                return candidates[i].Available &gt; candidates[j].Available
        }</span>)
        
        <span class="cov0" title="0">var targets []string
        for i, candidate := range candidates </span><span class="cov0" title="0">{
                if i &gt;= policy.MinReplicas </span><span class="cov0" title="0">{
                        break</span>
                }
                <span class="cov0" title="0">targets = append(targets, candidate.NodeID)</span>
        }
        
        <span class="cov0" title="0">return targets</span>
}

func (ds *DistributedStorageImpl) retrieveFromReplicas(ctx context.Context, key string) (io.ReadCloser, *ObjectMetadata, error) <span class="cov0" title="0">{
        // Get replication status
        status, err := ds.GetReplicationStatus(ctx, key)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, err
        }</span>
        
        // Try to retrieve from healthy replicas
        <span class="cov0" title="0">for _, nodeID := range status.ReplicaNodes </span><span class="cov0" title="0">{
                if nodeID == ds.nodeID </span><span class="cov0" title="0">{
                        continue</span> // Skip local node
                }
                
                // TODO: Implement remote retrieval from peer node
                // This would involve network communication with the peer
                <span class="cov0" title="0">ds.logger.Debug("attempting to retrieve from replica", "key", key, "node", nodeID)</span>
        }
        
        <span class="cov0" title="0">return nil, nil, &amp;StorageError{
                Code:    ErrCodeNotFound,
                Message: "object not found on any replica",
        }</span>
}

func (ds *DistributedStorageImpl) deleteFromReplicas(ctx context.Context, key string) error <span class="cov0" title="0">{
        // Get replication status
        status, err := ds.GetReplicationStatus(ctx, key)
        if err != nil </span><span class="cov0" title="0">{
                return nil // No replicas to delete from
        }</span>
        
        // Send delete requests to replicas
        <span class="cov0" title="0">for _, nodeID := range status.ReplicaNodes </span><span class="cov0" title="0">{
                if nodeID == ds.nodeID </span><span class="cov0" title="0">{
                        continue</span> // Skip local node
                }
                
                // TODO: Implement remote deletion
                <span class="cov0" title="0">ds.logger.Debug("deleting from replica", "key", key, "node", nodeID)</span>
        }
        
        <span class="cov0" title="0">return nil</span>
}

func (ds *DistributedStorageImpl) existsOnReplicas(ctx context.Context, key string) (bool, error) <span class="cov0" title="0">{
        // Get replication status
        status, err := ds.GetReplicationStatus(ctx, key)
        if err != nil </span><span class="cov0" title="0">{
                return false, nil // No replicas
        }</span>
        
        // Check replicas
        <span class="cov0" title="0">for _, nodeID := range status.ReplicaNodes </span><span class="cov0" title="0">{
                if nodeID == ds.nodeID </span><span class="cov0" title="0">{
                        continue</span> // Skip local node
                }
                
                // TODO: Implement remote existence check
                <span class="cov0" title="0">ds.logger.Debug("checking existence on replica", "key", key, "node", nodeID)</span>
        }
        
        <span class="cov0" title="0">return false, nil</span>
}

func (ds *DistributedStorageImpl) enforceReplicationPolicy(ctx context.Context, key string, policy *ReplicationPolicy) {<span class="cov0" title="0">
        // TODO: Implement policy enforcement
        // This would check current replication status and adjust as needed
}</span>

// Health check methods

func (ds *DistributedStorageImpl) checkConsensusHealth() CheckResult <span class="cov0" title="0">{
        start := time.Now()
        
        return CheckResult{
                Status:  "ok",
                Message: "consensus simulation healthy",
                Latency: time.Since(start).Milliseconds(),
                Time:    time.Now(),
        }
}</span>

func (ds *DistributedStorageImpl) checkNodeConnectivity() CheckResult <span class="cov0" title="0">{
        start := time.Now()
        
        ds.nodesMutex.RLock()
        totalNodes := len(ds.nodes)
        connectedNodes := 0
        
        for _, node := range ds.nodes </span><span class="cov0" title="0">{
                if time.Since(node.LastSeen) &lt; ds.config.FailureDetectorTimeout </span><span class="cov0" title="0">{
                        connectedNodes++
                }</span>
        }
        <span class="cov0" title="0">ds.nodesMutex.RUnlock()
        
        if totalNodes == 0 </span><span class="cov0" title="0">{
                return CheckResult{
                        Status:  "warning",
                        Message: "no other nodes in cluster",
                        Latency: time.Since(start).Milliseconds(),
                        Time:    time.Now(),
                }
        }</span>
        
        <span class="cov0" title="0">connectivity := float64(connectedNodes) / float64(totalNodes)
        if connectivity &gt;= 0.8 </span><span class="cov0" title="0">{
                return CheckResult{
                        Status:  "ok",
                        Message: fmt.Sprintf("%.1f%% nodes connected", connectivity*100),
                        Latency: time.Since(start).Milliseconds(),
                        Time:    time.Now(),
                }
        }</span>
        
        <span class="cov0" title="0">return CheckResult{
                Status:  "error",
                Message: fmt.Sprintf("poor connectivity: %.1f%% nodes connected", connectivity*100),
                Latency: time.Since(start).Milliseconds(),
                Time:    time.Now(),
        }</span>
}

func (ds *DistributedStorageImpl) checkReplicationHealth() CheckResult <span class="cov0" title="0">{
        start := time.Now()
        
        ds.replicationMgr.replicasMutex.RLock()
        totalReplicas := 0
        healthyReplicas := 0
        
        for _, status := range ds.replicationMgr.replicas </span><span class="cov0" title="0">{
                totalReplicas += status.CurrentReplicas
                healthyReplicas += status.HealthyReplicas
        }</span>
        <span class="cov0" title="0">ds.replicationMgr.replicasMutex.RUnlock()
        
        if totalReplicas == 0 </span><span class="cov0" title="0">{
                return CheckResult{
                        Status:  "ok",
                        Message: "no replicated objects",
                        Latency: time.Since(start).Milliseconds(),
                        Time:    time.Now(),
                }
        }</span>
        
        <span class="cov0" title="0">healthRatio := float64(healthyReplicas) / float64(totalReplicas)
        if healthRatio &gt;= 0.9 </span><span class="cov0" title="0">{
                return CheckResult{
                        Status:  "ok",
                        Message: fmt.Sprintf("%.1f%% replicas healthy", healthRatio*100),
                        Latency: time.Since(start).Milliseconds(),
                        Time:    time.Now(),
                }
        }</span>
        
        <span class="cov0" title="0">return CheckResult{
                Status:  "warning",
                Message: fmt.Sprintf("%.1f%% replicas healthy", healthRatio*100),
                Latency: time.Since(start).Milliseconds(),
                Time:    time.Now(),
        }</span>
}

func (ds *DistributedStorageImpl) getReplicationStats() *ReplicationStats <span class="cov0" title="0">{
        ds.replicationMgr.replicasMutex.RLock()
        defer ds.replicationMgr.replicasMutex.RUnlock()
        
        stats := &amp;ReplicationStats{
                ReplicationLag: make(map[string]int64),
                SyncOperations: &amp;SyncStats{},
        }
        
        for _, status := range ds.replicationMgr.replicas </span><span class="cov0" title="0">{
                stats.TotalReplicas += int64(status.CurrentReplicas)
                stats.HealthyReplicas += int64(status.HealthyReplicas)
                stats.OutOfSyncReplicas += int64(status.CurrentReplicas - status.HealthyReplicas)
        }</span>
        
        <span class="cov0" title="0">return stats</span>
}

// Background routines

func (ds *DistributedStorageImpl) heartbeatRoutine() <span class="cov0" title="0">{
        ticker := time.NewTicker(ds.config.HeartbeatInterval)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ds.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        ds.sendHeartbeats()</span>
                }
        }
}

func (ds *DistributedStorageImpl) consensusMonitorRoutine() <span class="cov0" title="0">{
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ds.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        ds.updateConsensusState()</span>
                }
        }
}

func (ds *DistributedStorageImpl) metricsCollectionRoutine() <span class="cov0" title="0">{
        ticker := time.NewTicker(1 * time.Minute)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ds.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        ds.collectDistributedMetrics()</span>
                }
        }
}

func (ds *DistributedStorageImpl) failureDetectorRoutine() <span class="cov0" title="0">{
        ticker := time.NewTicker(ds.config.FailureDetectorTimeout / 2)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ds.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        ds.detectFailedNodes()</span>
                }
        }
}

func (ds *DistributedStorageImpl) sendHeartbeats() <span class="cov0" title="0">{
        // TODO: Implement heartbeat sending to peers
        ds.logger.Debug("sending heartbeats")
}</span>

func (ds *DistributedStorageImpl) updateConsensusState() <span class="cov0" title="0">{
        ds.consensusMutex.Lock()
        defer ds.consensusMutex.Unlock()
        
        ds.consensusState.LastHeartbeat = time.Now()
        ds.consensusState.Term = 1
        ds.consensusState.CommitIndex = 100
        ds.consensusState.LastApplied = 100
        ds.consensusState.LeaderID = ds.nodeID
}</span>

func (ds *DistributedStorageImpl) collectDistributedMetrics() <span class="cov0" title="0">{
        ds.metricsMutex.Lock()
        defer ds.metricsMutex.Unlock()
        
        // Update cluster metrics
        ds.nodesMutex.RLock()
        ds.metrics.ClusterSize = len(ds.nodes) + 1 // Include self
        healthyNodes := 1 // Self is always healthy
        for _, node := range ds.nodes </span><span class="cov0" title="0">{
                if time.Since(node.LastSeen) &lt; ds.config.FailureDetectorTimeout </span><span class="cov0" title="0">{
                        healthyNodes++
                }</span>
        }
        <span class="cov0" title="0">ds.metrics.HealthyNodes = healthyNodes
        ds.nodesMutex.RUnlock()
        
        // Update replication factor
        if ds.metrics.ClusterSize &gt; 0 </span><span class="cov0" title="0">{
                ds.metrics.ReplicationFactor = float64(ds.config.ReplicationFactor)
        }</span>
}

func (ds *DistributedStorageImpl) detectFailedNodes() <span class="cov0" title="0">{
        ds.nodesMutex.Lock()
        defer ds.nodesMutex.Unlock()
        
        cutoff := time.Now().Add(-ds.config.FailureDetectorTimeout)
        for nodeID, node := range ds.nodes </span><span class="cov0" title="0">{
                if node.LastSeen.Before(cutoff) </span><span class="cov0" title="0">{
                        ds.logger.Warn("node appears to have failed", "node_id", nodeID, "last_seen", node.LastSeen)
                        node.Status = "failed"
                }</span>
        }
}

// ReplicationManager methods

func (rm *ReplicationManager) removeReplicationStatus(key string) <span class="cov0" title="0">{
        rm.replicasMutex.Lock()
        defer rm.replicasMutex.Unlock()
        
        delete(rm.replicas, key)
}</span>

// ReplicationWorker methods

func (w *ReplicationWorker) start() <span class="cov0" title="0">{
        w.logger.Info("replication worker started", "worker_id", w.id)
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-w.manager.ctx.Done():<span class="cov0" title="0">
                        w.logger.Info("replication worker stopped", "worker_id", w.id)
                        return</span>
                case task := &lt;-w.manager.workQueue:<span class="cov0" title="0">
                        w.processTask(task)</span>
                }
        }
}

func (w *ReplicationWorker) processTask(task *ReplicationTask) <span class="cov0" title="0">{
        w.logger.Debug("processing replication task", "worker_id", w.id, "type", task.Type, "key", task.Key)
        
        // TODO: Implement actual replication logic
        // This would involve network communication with target nodes
        
        time.Sleep(100 * time.Millisecond) // Simulate work
}</span>

// DistributedLock methods

func (dl *DistributedLock) Release() error <span class="cov0" title="0">{
        dl.mutex.Lock()
        defer dl.mutex.Unlock()
        
        if dl.released </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:    ErrCodeInvalidArgument,
                        Message: "lock already released",
                }
        }</span>
        
        <span class="cov0" title="0">dl.storage.locksMutex.Lock()
        delete(dl.storage.locks, dl.lockID)
        dl.storage.locksMutex.Unlock()
        
        dl.released = true
        return nil</span>
}

func (dl *DistributedLock) Renew(timeout time.Duration) error <span class="cov0" title="0">{
        dl.mutex.Lock()
        defer dl.mutex.Unlock()
        
        if dl.released </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:    ErrCodeInvalidArgument,
                        Message: "cannot renew released lock",
                }
        }</span>
        
        <span class="cov0" title="0">dl.expiration = time.Now().Add(timeout)
        return nil</span>
}

func (dl *DistributedLock) IsHeld() bool <span class="cov0" title="0">{
        dl.mutex.Lock()
        defer dl.mutex.Unlock()
        
        return !dl.released &amp;&amp; time.Now().Before(dl.expiration)
}</span>

func (dl *DistributedLock) GetOwner() string <span class="cov0" title="0">{
        return dl.owner
}</span>

func (dl *DistributedLock) GetExpiration() time.Time <span class="cov0" title="0">{
        dl.mutex.Lock()
        defer dl.mutex.Unlock()
        
        return dl.expiration
}</pre>
		
		<pre class="file" id="file11" style="display: none">package storage

import (
        "context"
        "fmt"
        "io"
        "time"
)

// Storage defines the interface for distributed storage operations
type Storage interface {
        // Core storage operations
        Store(ctx context.Context, key string, data io.Reader, metadata *ObjectMetadata) error
        Retrieve(ctx context.Context, key string) (io.ReadCloser, *ObjectMetadata, error)
        Delete(ctx context.Context, key string) error
        Exists(ctx context.Context, key string) (bool, error)
        
        // Metadata operations
        GetMetadata(ctx context.Context, key string) (*ObjectMetadata, error)
        SetMetadata(ctx context.Context, key string, metadata *ObjectMetadata) error
        UpdateMetadata(ctx context.Context, key string, updates map[string]interface{}) error
        
        // Batch operations
        BatchStore(ctx context.Context, operations []BatchStoreOperation) error
        BatchDelete(ctx context.Context, keys []string) error
        
        // Listing and iteration
        List(ctx context.Context, prefix string, options *ListOptions) (*ListResult, error)
        ListKeys(ctx context.Context, prefix string) ([]string, error)
        
        // Health and monitoring
        HealthCheck(ctx context.Context) (*HealthStatus, error)
        GetStats(ctx context.Context) (*StorageStats, error)
        
        // Lifecycle management
        Start(ctx context.Context) error
        Stop(ctx context.Context) error
        Close() error
}

// DistributedStorage extends Storage with distributed-specific operations
type DistributedStorage interface {
        Storage
        
        // Replication operations
        Replicate(ctx context.Context, key string, targetNodes []string) error
        GetReplicationStatus(ctx context.Context, key string) (*ReplicationStatus, error)
        SetReplicationPolicy(ctx context.Context, key string, policy *ReplicationPolicy) error
        
        // Consensus and coordination
        ProposeWrite(ctx context.Context, key string, data io.Reader, metadata *ObjectMetadata) error
        ProposeDelete(ctx context.Context, key string) error
        GetConsensusState(ctx context.Context) (*ConsensusState, error)
        
        // Node management
        AddNode(ctx context.Context, nodeID string, nodeInfo *NodeInfo) error
        RemoveNode(ctx context.Context, nodeID string) error
        GetNodes(ctx context.Context) ([]*NodeInfo, error)
        
        // Distributed coordination
        AcquireLock(ctx context.Context, lockID string, timeout time.Duration) (Lock, error)
        GetDistributedMetrics(ctx context.Context) (*DistributedMetrics, error)
}

// ModelStorage defines storage operations specific to AI models
type ModelStorage interface {
        Storage
        
        // Model-specific operations
        StoreModel(ctx context.Context, modelID string, modelData io.Reader, config *ModelConfig) error
        RetrieveModel(ctx context.Context, modelID string) (io.ReadCloser, *ModelConfig, error)
        DeleteModel(ctx context.Context, modelID string) error
        
        // Model metadata and versioning
        GetModelVersions(ctx context.Context, modelID string) ([]*ModelVersion, error)
        GetModelConfig(ctx context.Context, modelID string) (*ModelConfig, error)
        SetModelConfig(ctx context.Context, modelID string, config *ModelConfig) error
        
        // Model lifecycle
        ArchiveModel(ctx context.Context, modelID string) error
        RestoreModel(ctx context.Context, modelID string) error
        GetArchivedModels(ctx context.Context) ([]*ArchivedModel, error)
}

// BackupStorage defines backup and recovery operations
type BackupStorage interface {
        // Backup operations
        CreateBackup(ctx context.Context, backupID string, options *BackupOptions) error
        RestoreBackup(ctx context.Context, backupID string, options *RestoreOptions) error
        DeleteBackup(ctx context.Context, backupID string) error
        
        // Backup management
        ListBackups(ctx context.Context) ([]*BackupInfo, error)
        GetBackupInfo(ctx context.Context, backupID string) (*BackupInfo, error)
        VerifyBackup(ctx context.Context, backupID string) (*BackupVerification, error)
        
        // Incremental backup support
        CreateIncrementalBackup(ctx context.Context, backupID string, baseBackupID string, options *BackupOptions) error
        GetBackupChain(ctx context.Context, backupID string) ([]*BackupInfo, error)
}

// Lock represents a distributed lock
type Lock interface {
        Release() error
        Renew(timeout time.Duration) error
        IsHeld() bool
        GetOwner() string
        GetExpiration() time.Time
}

// ObjectMetadata contains metadata for stored objects
type ObjectMetadata struct {
        Key         string                 `json:"key"`
        Size        int64                  `json:"size"`
        ContentType string                 `json:"content_type"`
        Hash        string                 `json:"hash"`
        CreatedAt   time.Time              `json:"created_at"`
        UpdatedAt   time.Time              `json:"updated_at"`
        AccessedAt  time.Time              `json:"accessed_at"`
        Version     string                 `json:"version"`
        Attributes  map[string]interface{} `json:"attributes"`
        
        // Replication metadata
        ReplicationPolicy *ReplicationPolicy `json:"replication_policy,omitempty"`
        ReplicationNodes  []string           `json:"replication_nodes,omitempty"`
        
        // Model-specific metadata
        ModelInfo *ModelMetadata `json:"model_info,omitempty"`
}

// ModelMetadata contains AI model specific metadata
type ModelMetadata struct {
        ModelID     string            `json:"model_id"`
        ModelType   string            `json:"model_type"`
        Format      string            `json:"format"`
        Parameters  map[string]string `json:"parameters"`
        Tags        []string          `json:"tags"`
        Description string            `json:"description"`
        Author      string            `json:"author"`
        License     string            `json:"license"`
}

// BatchStoreOperation represents a batch store operation
type BatchStoreOperation struct {
        Key      string          `json:"key"`
        Data     io.Reader       `json:"-"`
        Metadata *ObjectMetadata `json:"metadata"`
}

// ListOptions contains options for listing operations
type ListOptions struct {
        Limit        int    `json:"limit"`
        Continuation string `json:"continuation"`
        Recursive    bool   `json:"recursive"`
        IncludeSize  bool   `json:"include_size"`
        SortBy       string `json:"sort_by"`
        SortOrder    string `json:"sort_order"`
}

// ListResult contains the result of a list operation
type ListResult struct {
        Items        []*ObjectMetadata `json:"items"`
        Continuation string            `json:"continuation"`
        Total        int64             `json:"total"`
        HasMore      bool              `json:"has_more"`
}

// HealthStatus represents the health status of storage
type HealthStatus struct {
        Status     string                 `json:"status"`
        Healthy    bool                   `json:"healthy"`
        LastCheck  time.Time              `json:"last_check"`
        Checks     map[string]CheckResult `json:"checks"`
        NodeHealth map[string]NodeHealth  `json:"node_health,omitempty"`
}

// CheckResult represents the result of a health check
type CheckResult struct {
        Status  string    `json:"status"`
        Message string    `json:"message"`
        Latency int64     `json:"latency_ms"`
        Time    time.Time `json:"time"`
}

// NodeHealth represents the health of a storage node
type NodeHealth struct {
        NodeID      string    `json:"node_id"`
        Status      string    `json:"status"`
        LastSeen    time.Time `json:"last_seen"`
        Latency     int64     `json:"latency_ms"`
        StorageUsed int64     `json:"storage_used"`
        StorageTotal int64    `json:"storage_total"`
}

// StorageStats contains storage statistics
type StorageStats struct {
        TotalObjects    int64             `json:"total_objects"`
        TotalSize       int64             `json:"total_size"`
        UsedSpace       int64             `json:"used_space"`
        AvailableSpace  int64             `json:"available_space"`
        OperationCounts map[string]int64  `json:"operation_counts"`
        Performance     *PerformanceStats `json:"performance"`
        Replication     *ReplicationStats `json:"replication,omitempty"`
}

// PerformanceStats contains performance metrics
type PerformanceStats struct {
        ReadLatency   *LatencyStats `json:"read_latency"`
        WriteLatency  *LatencyStats `json:"write_latency"`
        DeleteLatency *LatencyStats `json:"delete_latency"`
        Throughput    *Throughput   `json:"throughput"`
}

// LatencyStats contains latency statistics
type LatencyStats struct {
        Min     int64   `json:"min_ms"`
        Max     int64   `json:"max_ms"`
        Mean    float64 `json:"mean_ms"`
        Median  int64   `json:"median_ms"`
        P95     int64   `json:"p95_ms"`
        P99     int64   `json:"p99_ms"`
        Samples int64   `json:"samples"`
}

// Throughput contains throughput metrics
type Throughput struct {
        ReadOpsPerSec   float64 `json:"read_ops_per_sec"`
        WriteOpsPerSec  float64 `json:"write_ops_per_sec"`
        DeleteOpsPerSec float64 `json:"delete_ops_per_sec"`
        ReadBytesPerSec int64   `json:"read_bytes_per_sec"`
        WriteBytesPerSec int64  `json:"write_bytes_per_sec"`
}

// ReplicationPolicy defines how objects should be replicated
type ReplicationPolicy struct {
        MinReplicas      int                    `json:"min_replicas"`
        MaxReplicas      int                    `json:"max_replicas"`
        PreferredNodes   []string               `json:"preferred_nodes"`
        ExcludedNodes    []string               `json:"excluded_nodes"`
        ConsistencyLevel string                 `json:"consistency_level"` // strong, eventual, weak
        Strategy         string                 `json:"strategy"`          // eager, lazy, on_demand
        Priority         int                    `json:"priority"`
        Constraints      map[string]interface{} `json:"constraints"`
}

// ReplicationStatus represents the status of object replication
type ReplicationStatus struct {
        Key              string            `json:"key"`
        Policy           *ReplicationPolicy `json:"policy"`
        CurrentReplicas  int               `json:"current_replicas"`
        HealthyReplicas  int               `json:"healthy_replicas"`
        ReplicaNodes     []string          `json:"replica_nodes"`
        SyncStatus       map[string]string `json:"sync_status"`
        LastSync         time.Time         `json:"last_sync"`
        ConsistencyCheck time.Time         `json:"consistency_check"`
}

// ReplicationStats contains replication statistics
type ReplicationStats struct {
        TotalReplicas     int64             `json:"total_replicas"`
        HealthyReplicas   int64             `json:"healthy_replicas"`
        OutOfSyncReplicas int64             `json:"out_of_sync_replicas"`
        ReplicationLag    map[string]int64  `json:"replication_lag_ms"`
        SyncOperations    *SyncStats        `json:"sync_operations"`
}

// SyncStats contains synchronization statistics
type SyncStats struct {
        SuccessfulSyncs int64 `json:"successful_syncs"`
        FailedSyncs     int64 `json:"failed_syncs"`
        PendingSyncs    int64 `json:"pending_syncs"`
        AverageSyncTime int64 `json:"average_sync_time_ms"`
}

// ConsensusState represents the state of distributed consensus
type ConsensusState struct {
        LeaderID       string            `json:"leader_id"`
        Term           int64             `json:"term"`
        CommitIndex    int64             `json:"commit_index"`
        LastApplied    int64             `json:"last_applied"`
        Nodes          map[string]string `json:"nodes"` // nodeID -&gt; status
        QuorumSize     int               `json:"quorum_size"`
        IsHealthy      bool              `json:"is_healthy"`
        LastHeartbeat  time.Time         `json:"last_heartbeat"`
}

// NodeInfo contains information about a storage node
type NodeInfo struct {
        NodeID       string                 `json:"node_id"`
        Address      string                 `json:"address"`
        Port         int                    `json:"port"`
        Region       string                 `json:"region"`
        Zone         string                 `json:"zone"`
        Capacity     int64                  `json:"capacity"`
        Used         int64                  `json:"used"`
        Available    int64                  `json:"available"`
        Status       string                 `json:"status"`
        Capabilities []string               `json:"capabilities"`
        Metadata     map[string]interface{} `json:"metadata"`
        JoinedAt     time.Time              `json:"joined_at"`
        LastSeen     time.Time              `json:"last_seen"`
}

// DistributedMetrics contains distributed storage metrics
type DistributedMetrics struct {
        ClusterSize       int                    `json:"cluster_size"`
        HealthyNodes      int                    `json:"healthy_nodes"`
        TotalCapacity     int64                  `json:"total_capacity"`
        UsedCapacity      int64                  `json:"used_capacity"`
        ReplicationFactor float64                `json:"replication_factor"`
        DataDistribution  map[string]int64       `json:"data_distribution"`
        NetworkMetrics    *NetworkMetrics        `json:"network_metrics"`
        ConsensusMetrics  *ConsensusMetrics      `json:"consensus_metrics"`
}

// NetworkMetrics contains network-related metrics
type NetworkMetrics struct {
        AverageLatency    int64            `json:"average_latency_ms"`
        TotalBandwidth    int64            `json:"total_bandwidth_bps"`
        UsedBandwidth     int64            `json:"used_bandwidth_bps"`
        NetworkErrors     int64            `json:"network_errors"`
        ConnectionCounts  map[string]int64 `json:"connection_counts"`
}

// ConsensusMetrics contains consensus-related metrics
type ConsensusMetrics struct {
        LeaderElections    int64 `json:"leader_elections"`
        TermsCompleted     int64 `json:"terms_completed"`
        ProposalsSubmitted int64 `json:"proposals_submitted"`
        ProposalsCommitted int64 `json:"proposals_committed"`
        ConsensuLatency    int64 `json:"consensus_latency_ms"`
}

// ModelConfig contains configuration for AI models
type ModelConfig struct {
        ModelID      string                 `json:"model_id"`
        Name         string                 `json:"name"`
        Description  string                 `json:"description"`
        Version      string                 `json:"version"`
        Type         string                 `json:"type"`
        Format       string                 `json:"format"`
        Size         int64                  `json:"size"`
        Hash         string                 `json:"hash"`
        Parameters   map[string]interface{} `json:"parameters"`
        Metadata     map[string]interface{} `json:"metadata"`
        Dependencies []string               `json:"dependencies"`
        CreatedAt    time.Time              `json:"created_at"`
        UpdatedAt    time.Time              `json:"updated_at"`
}

// ModelVersion represents a version of a model
type ModelVersion struct {
        Version   string    `json:"version"`
        Hash      string    `json:"hash"`
        Size      int64     `json:"size"`
        Changes   []string  `json:"changes"`
        CreatedAt time.Time `json:"created_at"`
        IsActive  bool      `json:"is_active"`
}

// ArchivedModel represents an archived model
type ArchivedModel struct {
        ModelID     string    `json:"model_id"`
        ArchiveID   string    `json:"archive_id"`
        ArchivePath string    `json:"archive_path"`
        OriginalSize int64    `json:"original_size"`
        CompressedSize int64  `json:"compressed_size"`
        ArchivedAt  time.Time `json:"archived_at"`
        Reason      string    `json:"reason"`
}

// BackupOptions contains options for backup operations
type BackupOptions struct {
        Compression    string            `json:"compression"`
        Encryption     bool              `json:"encryption"`
        IncludeIndex   bool              `json:"include_index"`
        IncludeMetadata bool             `json:"include_metadata"`
        Filters        []string          `json:"filters"`
        ChunkSize      int64             `json:"chunk_size"`
        Parallel       bool              `json:"parallel"`
        Metadata       map[string]string `json:"metadata"`
}

// RestoreOptions contains options for restore operations
type RestoreOptions struct {
        OverwriteExisting bool              `json:"overwrite_existing"`
        VerifyIntegrity   bool              `json:"verify_integrity"`
        RestoreMetadata   bool              `json:"restore_metadata"`
        RestoreIndex      bool              `json:"restore_index"`
        Filters           []string          `json:"filters"`
        TargetPath        string            `json:"target_path"`
        Parallel          bool              `json:"parallel"`
        Metadata          map[string]string `json:"metadata"`
}

// BackupInfo contains information about a backup
type BackupInfo struct {
        BackupID      string    `json:"backup_id"`
        BaseBackupID  string    `json:"base_backup_id,omitempty"`
        Type          string    `json:"type"` // full, incremental
        Status        string    `json:"status"`
        Size          int64     `json:"size"`
        CompressedSize int64    `json:"compressed_size"`
        ObjectCount   int64     `json:"object_count"`
        CreatedAt     time.Time `json:"created_at"`
        CompletedAt   time.Time `json:"completed_at"`
        ExpiresAt     time.Time `json:"expires_at"`
        Metadata      map[string]string `json:"metadata"`
        Checksums     map[string]string `json:"checksums"`
}

// BackupVerification contains the result of backup verification
type BackupVerification struct {
        BackupID    string            `json:"backup_id"`
        IsValid     bool              `json:"is_valid"`
        Errors      []string          `json:"errors"`
        Warnings    []string          `json:"warnings"`
        CheckedAt   time.Time         `json:"checked_at"`
        Checksums   map[string]string `json:"checksums"`
        ObjectCount int64             `json:"object_count"`
        TotalSize   int64             `json:"total_size"`
}

// StorageError represents storage operation errors
type StorageError struct {
        Code      string `json:"code"`
        Message   string `json:"message"`
        Operation string `json:"operation"`
        Key       string `json:"key,omitempty"`
        Cause     error  `json:"-"`
}

func (e *StorageError) Error() string <span class="cov0" title="0">{
        if e.Cause != nil </span><span class="cov0" title="0">{
                return fmt.Sprintf("%s: %s (caused by: %v)", e.Code, e.Message, e.Cause)
        }</span>
        <span class="cov0" title="0">return fmt.Sprintf("%s: %s", e.Code, e.Message)</span>
}

func (e *StorageError) Unwrap() error <span class="cov0" title="0">{
        return e.Cause
}</span>

// Common error codes
const (
        ErrCodeNotFound         = "NOT_FOUND"
        ErrCodeAlreadyExists    = "ALREADY_EXISTS"
        ErrCodePermissionDenied = "PERMISSION_DENIED"
        ErrCodeQuotaExceeded    = "QUOTA_EXCEEDED"
        ErrCodeInvalidArgument  = "INVALID_ARGUMENT"
        ErrCodeInternal         = "INTERNAL_ERROR"
        ErrCodeUnavailable      = "UNAVAILABLE"
        ErrCodeTimeout          = "TIMEOUT"
        ErrCodeCorrupted        = "CORRUPTED"
        ErrCodeConsistency      = "CONSISTENCY_ERROR"
)</pre>
		
		<pre class="file" id="file12" style="display: none">package storage

import (
        "context"
        "crypto/sha256"
        "encoding/hex"
        "encoding/json"
        "fmt"
        "io"
        "os"
        "path/filepath"
        "sort"
        "strings"
        "sync"
        "time"

        "log/slog"
)

// LocalStorage implements Storage interface for local filesystem storage
type LocalStorage struct {
        basePath    string
        metaPath    string
        logger      *slog.Logger
        
        // Configuration
        maxSize     int64
        compression bool
        encryption  bool
        
        // Caching and performance
        metadataCache map[string]*ObjectMetadata
        cacheMutex    sync.RWMutex
        cacheSize     int
        maxCacheSize  int
        
        // Statistics
        stats       *StorageStats
        statsMutex  sync.RWMutex
        
        // File locks for concurrent access
        fileLocks   map[string]*sync.RWMutex
        locksMutex  sync.RWMutex
        
        // Health monitoring
        lastHealthCheck time.Time
        healthy         bool
        
        // Background tasks
        ctx         context.Context
        cancel      context.CancelFunc
        started     bool
        mu          sync.RWMutex
}

// LocalStorageConfig contains configuration for local storage
type LocalStorageConfig struct {
        BasePath      string `json:"base_path"`
        MaxSize       int64  `json:"max_size"`
        Compression   bool   `json:"compression"`
        Encryption    bool   `json:"encryption"`
        MaxCacheSize  int    `json:"max_cache_size"`
        CleanupAge    time.Duration `json:"cleanup_age"`
        SyncWrites    bool   `json:"sync_writes"`
}

// NewLocalStorage creates a new local storage instance
func NewLocalStorage(config *LocalStorageConfig, logger *slog.Logger) (*LocalStorage, error) <span class="cov3" title="3">{
        if config.BasePath == "" </span><span class="cov0" title="0">{
                return nil, &amp;StorageError{
                        Code:    ErrCodeInvalidArgument,
                        Message: "base path cannot be empty",
                }
        }</span>
        
        // Create base directories
        <span class="cov3" title="3">if err := os.MkdirAll(config.BasePath, 0755); err != nil </span><span class="cov0" title="0">{
                return nil, &amp;StorageError{
                        Code:    ErrCodeInternal,
                        Message: "failed to create base directory",
                        Cause:   err,
                }
        }</span>
        
        <span class="cov3" title="3">metaPath := filepath.Join(config.BasePath, "metadata")
        if err := os.MkdirAll(metaPath, 0755); err != nil </span><span class="cov0" title="0">{
                return nil, &amp;StorageError{
                        Code:    ErrCodeInternal,
                        Message: "failed to create metadata directory",
                        Cause:   err,
                }
        }</span>
        
        <span class="cov3" title="3">ctx, cancel := context.WithCancel(context.Background())
        
        ls := &amp;LocalStorage{
                basePath:      config.BasePath,
                metaPath:      metaPath,
                logger:        logger,
                maxSize:       config.MaxSize,
                compression:   config.Compression,
                encryption:    config.Encryption,
                metadataCache: make(map[string]*ObjectMetadata),
                maxCacheSize:  config.MaxCacheSize,
                fileLocks:     make(map[string]*sync.RWMutex),
                stats: &amp;StorageStats{
                        OperationCounts: make(map[string]int64),
                        Performance: &amp;PerformanceStats{
                                ReadLatency:   &amp;LatencyStats{},
                                WriteLatency:  &amp;LatencyStats{},
                                DeleteLatency: &amp;LatencyStats{},
                                Throughput:    &amp;Throughput{},
                        },
                },
                ctx:     ctx,
                cancel:  cancel,
                healthy: true,
        }
        
        // Load existing metadata into cache
        if err := ls.loadMetadataCache(); err != nil </span><span class="cov0" title="0">{
                logger.Warn("failed to load metadata cache", "error", err)
        }</span>
        
        <span class="cov3" title="3">return ls, nil</span>
}

// Start starts the local storage
func (ls *LocalStorage) Start(ctx context.Context) error <span class="cov2" title="2">{
        ls.mu.Lock()
        defer ls.mu.Unlock()
        
        if ls.started </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:    ErrCodeInternal,
                        Message: "storage already started",
                }
        }</span>
        
        // Start background cleanup routine
        <span class="cov2" title="2">go ls.cleanupRoutine()
        
        // Start health monitoring
        go ls.healthMonitorRoutine()
        
        // Start statistics collection
        go ls.statsCollectionRoutine()
        
        ls.started = true
        ls.logger.Info("local storage started", "base_path", ls.basePath)
        
        return nil</span>
}

// Stop stops the local storage
func (ls *LocalStorage) Stop(ctx context.Context) error <span class="cov2" title="2">{
        ls.mu.Lock()
        defer ls.mu.Unlock()
        
        if !ls.started </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        <span class="cov2" title="2">ls.cancel()
        ls.started = false
        
        // Save metadata cache
        if err := ls.saveMetadataCache(); err != nil </span><span class="cov0" title="0">{
                ls.logger.Error("failed to save metadata cache", "error", err)
        }</span>
        
        <span class="cov2" title="2">ls.logger.Info("local storage stopped")
        return nil</span>
}

// Close closes the local storage
func (ls *LocalStorage) Close() error <span class="cov2" title="2">{
        return ls.Stop(context.Background())
}</span>

// Store stores an object in local storage
func (ls *LocalStorage) Store(ctx context.Context, key string, data io.Reader, metadata *ObjectMetadata) error <span class="cov5" title="6">{
        start := time.Now()
        defer func() </span><span class="cov5" title="6">{
                ls.updateLatencyStats("write", time.Since(start))
                ls.incrementOperationCount("store")
        }</span>()
        
        <span class="cov5" title="6">if err := ls.validateKey(key); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        // Get file lock
        <span class="cov5" title="6">lock := ls.getFileLock(key)
        lock.Lock()
        defer lock.Unlock()
        
        // Create object path
        objPath := ls.getObjectPath(key)
        if err := os.MkdirAll(filepath.Dir(objPath), 0755); err != nil </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:      ErrCodeInternal,
                        Message:   "failed to create object directory",
                        Operation: "store",
                        Key:       key,
                        Cause:     err,
                }
        }</span>
        
        // Create temporary file for atomic write
        <span class="cov5" title="6">tempPath := objPath + ".tmp"
        tempFile, err := os.Create(tempPath)
        if err != nil </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:      ErrCodeInternal,
                        Message:   "failed to create temporary file",
                        Operation: "store",
                        Key:       key,
                        Cause:     err,
                }
        }</span>
        <span class="cov5" title="6">defer os.Remove(tempPath) // Cleanup on error
        
        // Copy data and calculate hash
        hash := sha256.New()
        size, err := io.Copy(io.MultiWriter(tempFile, hash), data)
        if err != nil </span><span class="cov0" title="0">{
                tempFile.Close()
                return &amp;StorageError{
                        Code:      ErrCodeInternal,
                        Message:   "failed to write data",
                        Operation: "store",
                        Key:       key,
                        Cause:     err,
                }
        }</span>
        
        <span class="cov5" title="6">if err := tempFile.Sync(); err != nil </span><span class="cov0" title="0">{
                tempFile.Close()
                return &amp;StorageError{
                        Code:      ErrCodeInternal,
                        Message:   "failed to sync file",
                        Operation: "store",
                        Key:       key,
                        Cause:     err,
                }
        }</span>
        <span class="cov5" title="6">tempFile.Close()
        
        // Check size limits
        if ls.maxSize &gt; 0 &amp;&amp; size &gt; ls.maxSize </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:      ErrCodeQuotaExceeded,
                        Message:   "object size exceeds maximum allowed size",
                        Operation: "store",
                        Key:       key,
                }
        }</span>
        
        // Prepare metadata
        <span class="cov5" title="6">now := time.Now()
        if metadata == nil </span><span class="cov1" title="1">{
                metadata = &amp;ObjectMetadata{}
        }</span>
        <span class="cov5" title="6">metadata.Key = key
        metadata.Size = size
        metadata.Hash = hex.EncodeToString(hash.Sum(nil))
        metadata.CreatedAt = now
        metadata.UpdatedAt = now
        metadata.AccessedAt = now
        
        // Atomic move
        if err := os.Rename(tempPath, objPath); err != nil </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:      ErrCodeInternal,
                        Message:   "failed to move temporary file",
                        Operation: "store",
                        Key:       key,
                        Cause:     err,
                }
        }</span>
        
        // Store metadata
        <span class="cov5" title="6">if err := ls.storeMetadata(key, metadata); err != nil </span><span class="cov0" title="0">{
                // Try to cleanup object file
                os.Remove(objPath)
                return err
        }</span>
        
        // Update cache
        <span class="cov5" title="6">ls.updateMetadataCache(key, metadata)
        
        // Update statistics
        ls.statsMutex.Lock()
        ls.stats.TotalObjects++
        ls.stats.TotalSize += size
        ls.stats.UsedSpace += size
        ls.statsMutex.Unlock()
        
        ls.logger.Debug("object stored", "key", key, "size", size, "hash", metadata.Hash)
        return nil</span>
}

// Retrieve retrieves an object from local storage
func (ls *LocalStorage) Retrieve(ctx context.Context, key string) (io.ReadCloser, *ObjectMetadata, error) <span class="cov2" title="2">{
        start := time.Now()
        defer func() </span><span class="cov2" title="2">{
                ls.updateLatencyStats("read", time.Since(start))
                ls.incrementOperationCount("retrieve")
        }</span>()
        
        <span class="cov2" title="2">if err := ls.validateKey(key); err != nil </span><span class="cov0" title="0">{
                return nil, nil, err
        }</span>
        
        // Get metadata first
        <span class="cov2" title="2">metadata, err := ls.GetMetadata(ctx, key)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, err
        }</span>
        
        // Open object file
        <span class="cov2" title="2">objPath := ls.getObjectPath(key)
        file, err := os.Open(objPath)
        if err != nil </span><span class="cov0" title="0">{
                if os.IsNotExist(err) </span><span class="cov0" title="0">{
                        return nil, nil, &amp;StorageError{
                                Code:      ErrCodeNotFound,
                                Message:   "object not found",
                                Operation: "retrieve",
                                Key:       key,
                        }
                }</span>
                <span class="cov0" title="0">return nil, nil, &amp;StorageError{
                        Code:      ErrCodeInternal,
                        Message:   "failed to open object file",
                        Operation: "retrieve",
                        Key:       key,
                        Cause:     err,
                }</span>
        }
        
        // Update access time
        <span class="cov2" title="2">metadata.AccessedAt = time.Now()
        ls.updateMetadataCache(key, metadata)
        go ls.storeMetadata(key, metadata) // Async update
        
        return file, metadata, nil</span>
}

// Delete deletes an object from local storage
func (ls *LocalStorage) Delete(ctx context.Context, key string) error <span class="cov4" title="4">{
        start := time.Now()
        defer func() </span><span class="cov4" title="4">{
                ls.updateLatencyStats("delete", time.Since(start))
                ls.incrementOperationCount("delete")
        }</span>()
        
        <span class="cov4" title="4">if err := ls.validateKey(key); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        // Get file lock
        <span class="cov4" title="4">lock := ls.getFileLock(key)
        lock.Lock()
        defer lock.Unlock()
        
        // Get metadata for size accounting
        metadata, err := ls.GetMetadata(ctx, key)
        if err != nil </span><span class="cov0" title="0">{
                if isNotFoundError(err) </span><span class="cov0" title="0">{
                        return nil // Already deleted
                }</span>
                <span class="cov0" title="0">return err</span>
        }
        
        // Delete object file
        <span class="cov4" title="4">objPath := ls.getObjectPath(key)
        if err := os.Remove(objPath); err != nil &amp;&amp; !os.IsNotExist(err) </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:      ErrCodeInternal,
                        Message:   "failed to delete object file",
                        Operation: "delete",
                        Key:       key,
                        Cause:     err,
                }
        }</span>
        
        // Delete metadata
        <span class="cov4" title="4">metaPath := ls.getMetadataPath(key)
        if err := os.Remove(metaPath); err != nil &amp;&amp; !os.IsNotExist(err) </span><span class="cov0" title="0">{
                ls.logger.Warn("failed to delete metadata file", "key", key, "error", err)
        }</span>
        
        // Remove from cache
        <span class="cov4" title="4">ls.removeFromMetadataCache(key)
        
        // Update statistics
        ls.statsMutex.Lock()
        ls.stats.TotalObjects--
        ls.stats.TotalSize -= metadata.Size
        ls.stats.UsedSpace -= metadata.Size
        ls.statsMutex.Unlock()
        
        ls.logger.Debug("object deleted", "key", key, "size", metadata.Size)
        return nil</span>
}

// Exists checks if an object exists in local storage
func (ls *LocalStorage) Exists(ctx context.Context, key string) (bool, error) <span class="cov5" title="6">{
        if err := ls.validateKey(key); err != nil </span><span class="cov0" title="0">{
                return false, err
        }</span>
        
        <span class="cov5" title="6">objPath := ls.getObjectPath(key)
        _, err := os.Stat(objPath)
        if err != nil </span><span class="cov2" title="2">{
                if os.IsNotExist(err) </span><span class="cov2" title="2">{
                        return false, nil
                }</span>
                <span class="cov0" title="0">return false, &amp;StorageError{
                        Code:      ErrCodeInternal,
                        Message:   "failed to check object existence",
                        Operation: "exists",
                        Key:       key,
                        Cause:     err,
                }</span>
        }
        
        <span class="cov4" title="4">return true, nil</span>
}

// GetMetadata retrieves metadata for an object
func (ls *LocalStorage) GetMetadata(ctx context.Context, key string) (*ObjectMetadata, error) <span class="cov7" title="13">{
        if err := ls.validateKey(key); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        
        // Check cache first
        <span class="cov7" title="13">if metadata := ls.getFromMetadataCache(key); metadata != nil </span><span class="cov7" title="13">{
                return metadata, nil
        }</span>
        
        // Load from disk
        <span class="cov0" title="0">metaPath := ls.getMetadataPath(key)
        data, err := os.ReadFile(metaPath)
        if err != nil </span><span class="cov0" title="0">{
                if os.IsNotExist(err) </span><span class="cov0" title="0">{
                        return nil, &amp;StorageError{
                                Code:      ErrCodeNotFound,
                                Message:   "metadata not found",
                                Operation: "get_metadata",
                                Key:       key,
                        }
                }</span>
                <span class="cov0" title="0">return nil, &amp;StorageError{
                        Code:      ErrCodeInternal,
                        Message:   "failed to read metadata file",
                        Operation: "get_metadata",
                        Key:       key,
                        Cause:     err,
                }</span>
        }
        
        <span class="cov0" title="0">var metadata ObjectMetadata
        if err := json.Unmarshal(data, &amp;metadata); err != nil </span><span class="cov0" title="0">{
                return nil, &amp;StorageError{
                        Code:      ErrCodeInternal,
                        Message:   "failed to parse metadata",
                        Operation: "get_metadata",
                        Key:       key,
                        Cause:     err,
                }
        }</span>
        
        // Update cache
        <span class="cov0" title="0">ls.updateMetadataCache(key, &amp;metadata)
        
        return &amp;metadata, nil</span>
}

// SetMetadata sets metadata for an object
func (ls *LocalStorage) SetMetadata(ctx context.Context, key string, metadata *ObjectMetadata) error <span class="cov1" title="1">{
        if err := ls.validateKey(key); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        <span class="cov1" title="1">metadata.Key = key
        metadata.UpdatedAt = time.Now()
        
        if err := ls.storeMetadata(key, metadata); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        <span class="cov1" title="1">ls.updateMetadataCache(key, metadata)
        return nil</span>
}

// UpdateMetadata updates specific metadata fields
func (ls *LocalStorage) UpdateMetadata(ctx context.Context, key string, updates map[string]interface{}) error <span class="cov1" title="1">{
        metadata, err := ls.GetMetadata(ctx, key)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        // Apply updates
        <span class="cov1" title="1">if metadata.Attributes == nil </span><span class="cov0" title="0">{
                metadata.Attributes = make(map[string]interface{})
        }</span>
        
        <span class="cov1" title="1">for field, value := range updates </span><span class="cov2" title="2">{
                switch field </span>{
                case "content_type":<span class="cov0" title="0">
                        if v, ok := value.(string); ok </span><span class="cov0" title="0">{
                                metadata.ContentType = v
                        }</span>
                case "version":<span class="cov1" title="1">
                        if v, ok := value.(string); ok </span><span class="cov1" title="1">{
                                metadata.Version = v
                        }</span>
                default:<span class="cov1" title="1">
                        metadata.Attributes[field] = value</span>
                }
        }
        
        <span class="cov1" title="1">return ls.SetMetadata(ctx, key, metadata)</span>
}

// BatchStore performs batch store operations
func (ls *LocalStorage) BatchStore(ctx context.Context, operations []BatchStoreOperation) error <span class="cov1" title="1">{
        var errors []error
        
        for _, op := range operations </span><span class="cov2" title="2">{
                if err := ls.Store(ctx, op.Key, op.Data, op.Metadata); err != nil </span><span class="cov0" title="0">{
                        errors = append(errors, fmt.Errorf("failed to store %s: %w", op.Key, err))
                }</span>
        }
        
        <span class="cov1" title="1">if len(errors) &gt; 0 </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:    ErrCodeInternal,
                        Message: fmt.Sprintf("batch store failed with %d errors", len(errors)),
                }
        }</span>
        
        <span class="cov1" title="1">return nil</span>
}

// BatchDelete performs batch delete operations
func (ls *LocalStorage) BatchDelete(ctx context.Context, keys []string) error <span class="cov1" title="1">{
        var errors []error
        
        for _, key := range keys </span><span class="cov2" title="2">{
                if err := ls.Delete(ctx, key); err != nil </span><span class="cov0" title="0">{
                        errors = append(errors, fmt.Errorf("failed to delete %s: %w", key, err))
                }</span>
        }
        
        <span class="cov1" title="1">if len(errors) &gt; 0 </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:    ErrCodeInternal,
                        Message: fmt.Sprintf("batch delete failed with %d errors", len(errors)),
                }
        }</span>
        
        <span class="cov1" title="1">return nil</span>
}

// List lists objects with optional prefix and pagination
func (ls *LocalStorage) List(ctx context.Context, prefix string, options *ListOptions) (*ListResult, error) <span class="cov2" title="2">{
        if options == nil </span><span class="cov0" title="0">{
                options = &amp;ListOptions{Limit: 1000}
        }</span>
        
        <span class="cov2" title="2">var items []*ObjectMetadata
        
        // Walk the metadata directory
        err := filepath.Walk(ls.metaPath, func(path string, info os.FileInfo, err error) error </span><span class="cov7" title="11">{
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                
                <span class="cov7" title="11">if info.IsDir() </span><span class="cov6" title="7">{
                        return nil
                }</span>
                
                // Extract key from path
                <span class="cov4" title="4">relPath, err := filepath.Rel(ls.metaPath, path)
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                
                <span class="cov4" title="4">key := strings.ReplaceAll(relPath, string(filepath.Separator), "/")
                key = strings.TrimSuffix(key, ".meta")
                
                // Check prefix filter
                if prefix != "" &amp;&amp; !strings.HasPrefix(key, prefix) </span><span class="cov1" title="1">{
                        return nil
                }</span>
                
                // Load metadata
                <span class="cov3" title="3">metadata, err := ls.GetMetadata(ctx, key)
                if err != nil </span><span class="cov0" title="0">{
                        ls.logger.Warn("failed to load metadata during list", "key", key, "error", err)
                        return nil
                }</span>
                
                <span class="cov3" title="3">items = append(items, metadata)
                
                // Check limit
                if options.Limit &gt; 0 &amp;&amp; len(items) &gt;= options.Limit </span><span class="cov0" title="0">{
                        return filepath.SkipDir
                }</span>
                
                <span class="cov3" title="3">return nil</span>
        })
        
        <span class="cov2" title="2">if err != nil </span><span class="cov0" title="0">{
                return nil, &amp;StorageError{
                        Code:      ErrCodeInternal,
                        Message:   "failed to list objects",
                        Operation: "list",
                        Cause:     err,
                }
        }</span>
        
        // Sort results
        <span class="cov2" title="2">if options.SortBy == "name" </span><span class="cov0" title="0">{
                sort.Slice(items, func(i, j int) bool </span><span class="cov0" title="0">{
                        if options.SortOrder == "desc" </span><span class="cov0" title="0">{
                                return items[i].Key &gt; items[j].Key
                        }</span>
                        <span class="cov0" title="0">return items[i].Key &lt; items[j].Key</span>
                })
        } else<span class="cov2" title="2"> if options.SortBy == "size" </span><span class="cov0" title="0">{
                sort.Slice(items, func(i, j int) bool </span><span class="cov0" title="0">{
                        if options.SortOrder == "desc" </span><span class="cov0" title="0">{
                                return items[i].Size &gt; items[j].Size
                        }</span>
                        <span class="cov0" title="0">return items[i].Size &lt; items[j].Size</span>
                })
        } else<span class="cov2" title="2"> if options.SortBy == "modified" </span><span class="cov0" title="0">{
                sort.Slice(items, func(i, j int) bool </span><span class="cov0" title="0">{
                        if options.SortOrder == "desc" </span><span class="cov0" title="0">{
                                return items[i].UpdatedAt.After(items[j].UpdatedAt)
                        }</span>
                        <span class="cov0" title="0">return items[i].UpdatedAt.Before(items[j].UpdatedAt)</span>
                })
        }
        
        <span class="cov2" title="2">return &amp;ListResult{
                Items:   items,
                Total:   int64(len(items)),
                HasMore: false,
        }, nil</span>
}

// ListKeys lists object keys with optional prefix
func (ls *LocalStorage) ListKeys(ctx context.Context, prefix string) ([]string, error) <span class="cov0" title="0">{
        result, err := ls.List(ctx, prefix, &amp;ListOptions{})
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        
        <span class="cov0" title="0">keys := make([]string, len(result.Items))
        for i, item := range result.Items </span><span class="cov0" title="0">{
                keys[i] = item.Key
        }</span>
        
        <span class="cov0" title="0">return keys, nil</span>
}

// HealthCheck performs a health check on local storage
func (ls *LocalStorage) HealthCheck(ctx context.Context) (*HealthStatus, error) <span class="cov1" title="1">{
        checks := make(map[string]CheckResult)
        healthy := true
        
        // Check disk space
        start := time.Now()
        stat, err := ls.getDiskUsage()
        if err != nil </span><span class="cov0" title="0">{
                checks["disk_space"] = CheckResult{
                        Status:  "error",
                        Message: "failed to get disk usage",
                        Latency: time.Since(start).Milliseconds(),
                        Time:    time.Now(),
                }
                healthy = false
        }</span> else<span class="cov1" title="1"> {
                status := "ok"
                message := fmt.Sprintf("%.1f%% used", float64(stat.Used)/float64(stat.Total)*100)
                
                if float64(stat.Used)/float64(stat.Total) &gt; 0.9 </span><span class="cov0" title="0">{
                        status = "warning"
                        message = "disk space running low"
                }</span>
                
                <span class="cov1" title="1">checks["disk_space"] = CheckResult{
                        Status:  status,
                        Message: message,
                        Latency: time.Since(start).Milliseconds(),
                        Time:    time.Now(),
                }
                
                if status != "ok" </span><span class="cov0" title="0">{
                        healthy = false
                }</span>
        }
        
        // Check write performance
        <span class="cov1" title="1">start = time.Now()
        testKey := "health_check_test"
        testData := strings.NewReader("health check test data")
        err = ls.Store(ctx, testKey, testData, nil)
        writeLatency := time.Since(start).Milliseconds()
        
        if err != nil </span><span class="cov0" title="0">{
                checks["write_test"] = CheckResult{
                        Status:  "error",
                        Message: "write test failed",
                        Latency: writeLatency,
                        Time:    time.Now(),
                }
                healthy = false
        }</span> else<span class="cov1" title="1"> {
                // Cleanup test object
                ls.Delete(ctx, testKey)
                
                status := "ok"
                message := "write test passed"
                if writeLatency &gt; 1000 </span><span class="cov0" title="0">{
                        status = "warning"
                        message = "slow write performance"
                }</span>
                
                <span class="cov1" title="1">checks["write_test"] = CheckResult{
                        Status:  status,
                        Message: message,
                        Latency: writeLatency,
                        Time:    time.Now(),
                }</span>
        }
        
        <span class="cov1" title="1">ls.lastHealthCheck = time.Now()
        ls.healthy = healthy
        
        status := "healthy"
        if !healthy </span><span class="cov0" title="0">{
                status = "unhealthy"
        }</span>
        
        <span class="cov1" title="1">return &amp;HealthStatus{
                Status:    status,
                Healthy:   healthy,
                LastCheck: ls.lastHealthCheck,
                Checks:    checks,
        }, nil</span>
}

// GetStats returns storage statistics
func (ls *LocalStorage) GetStats(ctx context.Context) (*StorageStats, error) <span class="cov2" title="2">{
        ls.statsMutex.RLock()
        defer ls.statsMutex.RUnlock()
        
        // Update disk usage
        diskStat, err := ls.getDiskUsage()
        if err != nil </span><span class="cov0" title="0">{
                ls.logger.Warn("failed to get disk usage", "error", err)
        }</span> else<span class="cov2" title="2"> {
                ls.stats.AvailableSpace = diskStat.Available
        }</span>
        
        // Create a copy of stats
        <span class="cov2" title="2">stats := *ls.stats
        stats.OperationCounts = make(map[string]int64)
        for k, v := range ls.stats.OperationCounts </span><span class="cov5" title="6">{
                stats.OperationCounts[k] = v
        }</span>
        
        // Copy performance stats
        <span class="cov2" title="2">if ls.stats.Performance != nil </span><span class="cov2" title="2">{
                perf := *ls.stats.Performance
                if ls.stats.Performance.ReadLatency != nil </span><span class="cov2" title="2">{
                        readLat := *ls.stats.Performance.ReadLatency
                        perf.ReadLatency = &amp;readLat
                }</span>
                <span class="cov2" title="2">if ls.stats.Performance.WriteLatency != nil </span><span class="cov2" title="2">{
                        writeLat := *ls.stats.Performance.WriteLatency
                        perf.WriteLatency = &amp;writeLat
                }</span>
                <span class="cov2" title="2">if ls.stats.Performance.DeleteLatency != nil </span><span class="cov2" title="2">{
                        deleteLat := *ls.stats.Performance.DeleteLatency
                        perf.DeleteLatency = &amp;deleteLat
                }</span>
                <span class="cov2" title="2">if ls.stats.Performance.Throughput != nil </span><span class="cov2" title="2">{
                        throughput := *ls.stats.Performance.Throughput
                        perf.Throughput = &amp;throughput
                }</span>
                <span class="cov2" title="2">stats.Performance = &amp;perf</span>
        }
        
        <span class="cov2" title="2">return &amp;stats, nil</span>
}

// Helper methods

func (ls *LocalStorage) validateKey(key string) error <span class="cov10" title="32">{
        if key == "" </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:    ErrCodeInvalidArgument,
                        Message: "key cannot be empty",
                }
        }</span>
        
        <span class="cov10" title="32">if strings.Contains(key, "..") </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:    ErrCodeInvalidArgument,
                        Message: "key cannot contain '..'",
                }
        }</span>
        
        <span class="cov10" title="32">return nil</span>
}

func (ls *LocalStorage) getObjectPath(key string) string <span class="cov8" title="18">{
        // Create a safe path by replacing path separators
        safePath := strings.ReplaceAll(key, "/", string(filepath.Separator))
        return filepath.Join(ls.basePath, "objects", safePath)
}</span>

func (ls *LocalStorage) getMetadataPath(key string) string <span class="cov7" title="13">{
        safePath := strings.ReplaceAll(key, "/", string(filepath.Separator))
        return filepath.Join(ls.metaPath, safePath+".meta")
}</span>

func (ls *LocalStorage) getFileLock(key string) *sync.RWMutex <span class="cov6" title="10">{
        ls.locksMutex.Lock()
        defer ls.locksMutex.Unlock()
        
        if lock, exists := ls.fileLocks[key]; exists </span><span class="cov4" title="4">{
                return lock
        }</span>
        
        <span class="cov5" title="6">lock := &amp;sync.RWMutex{}
        ls.fileLocks[key] = lock
        return lock</span>
}

func (ls *LocalStorage) storeMetadata(key string, metadata *ObjectMetadata) error <span class="cov6" title="9">{
        metaPath := ls.getMetadataPath(key)
        if err := os.MkdirAll(filepath.Dir(metaPath), 0755); err != nil </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:      ErrCodeInternal,
                        Message:   "failed to create metadata directory",
                        Operation: "store_metadata",
                        Key:       key,
                        Cause:     err,
                }
        }</span>
        
        <span class="cov6" title="9">data, err := json.MarshalIndent(metadata, "", "  ")
        if err != nil </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:      ErrCodeInternal,
                        Message:   "failed to serialize metadata",
                        Operation: "store_metadata",
                        Key:       key,
                        Cause:     err,
                }
        }</span>
        
        <span class="cov6" title="9">tempPath := metaPath + ".tmp"
        if err := os.WriteFile(tempPath, data, 0644); err != nil </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:      ErrCodeInternal,
                        Message:   "failed to write metadata file",
                        Operation: "store_metadata",
                        Key:       key,
                        Cause:     err,
                }
        }</span>
        
        <span class="cov6" title="9">if err := os.Rename(tempPath, metaPath); err != nil </span><span class="cov1" title="1">{
                os.Remove(tempPath)
                return &amp;StorageError{
                        Code:      ErrCodeInternal,
                        Message:   "failed to move metadata file",
                        Operation: "store_metadata",
                        Key:       key,
                        Cause:     err,
                }
        }</span>
        
        <span class="cov6" title="8">return nil</span>
}

// Cache management methods

func (ls *LocalStorage) getFromMetadataCache(key string) *ObjectMetadata <span class="cov7" title="13">{
        ls.cacheMutex.RLock()
        defer ls.cacheMutex.RUnlock()
        
        if metadata, exists := ls.metadataCache[key]; exists </span><span class="cov7" title="13">{
                // Create a copy to avoid race conditions
                copy := *metadata
                return &amp;copy
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

func (ls *LocalStorage) updateMetadataCache(key string, metadata *ObjectMetadata) <span class="cov6" title="9">{
        ls.cacheMutex.Lock()
        defer ls.cacheMutex.Unlock()
        
        // Check cache size and evict if necessary
        if len(ls.metadataCache) &gt;= ls.maxCacheSize </span><span class="cov0" title="0">{
                ls.evictFromCache()
        }</span>
        
        // Create a copy to store in cache
        <span class="cov6" title="9">copy := *metadata
        ls.metadataCache[key] = &amp;copy
        ls.cacheSize++</span>
}

func (ls *LocalStorage) removeFromMetadataCache(key string) <span class="cov4" title="4">{
        ls.cacheMutex.Lock()
        defer ls.cacheMutex.Unlock()
        
        if _, exists := ls.metadataCache[key]; exists </span><span class="cov4" title="4">{
                delete(ls.metadataCache, key)
                ls.cacheSize--
        }</span>
}

func (ls *LocalStorage) evictFromCache() <span class="cov0" title="0">{
        // Simple LRU eviction - remove oldest accessed
        var oldestKey string
        var oldestTime time.Time = time.Now()
        
        for key, metadata := range ls.metadataCache </span><span class="cov0" title="0">{
                if metadata.AccessedAt.Before(oldestTime) </span><span class="cov0" title="0">{
                        oldestTime = metadata.AccessedAt
                        oldestKey = key
                }</span>
        }
        
        <span class="cov0" title="0">if oldestKey != "" </span><span class="cov0" title="0">{
                delete(ls.metadataCache, oldestKey)
                ls.cacheSize--
        }</span>
}

func (ls *LocalStorage) loadMetadataCache() error <span class="cov3" title="3">{
        // Load frequently accessed metadata into cache
        return filepath.Walk(ls.metaPath, func(path string, info os.FileInfo, err error) error </span><span class="cov3" title="3">{
                if err != nil || info.IsDir() </span><span class="cov3" title="3">{
                        return err
                }</span>
                
                <span class="cov0" title="0">if !strings.HasSuffix(path, ".meta") </span><span class="cov0" title="0">{
                        return nil
                }</span>
                
                // Extract key
                <span class="cov0" title="0">relPath, err := filepath.Rel(ls.metaPath, path)
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">key := strings.TrimSuffix(relPath, ".meta")
                key = strings.ReplaceAll(key, string(filepath.Separator), "/")
                
                // Load metadata
                data, err := os.ReadFile(path)
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                
                <span class="cov0" title="0">var metadata ObjectMetadata
                if err := json.Unmarshal(data, &amp;metadata); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                
                // Add to cache if recently accessed
                <span class="cov0" title="0">if time.Since(metadata.AccessedAt) &lt; 24*time.Hour </span><span class="cov0" title="0">{
                        ls.cacheMutex.Lock()
                        if len(ls.metadataCache) &lt; ls.maxCacheSize </span><span class="cov0" title="0">{
                                ls.metadataCache[key] = &amp;metadata
                                ls.cacheSize++
                        }</span>
                        <span class="cov0" title="0">ls.cacheMutex.Unlock()</span>
                }
                
                <span class="cov0" title="0">return nil</span>
        })
}

func (ls *LocalStorage) saveMetadataCache() error <span class="cov2" title="2">{
        // No need to explicitly save as metadata is persisted on writes
        return nil
}</span>

// Statistics and monitoring methods

func (ls *LocalStorage) updateLatencyStats(operation string, latency time.Duration) <span class="cov7" title="12">{
        ls.statsMutex.Lock()
        defer ls.statsMutex.Unlock()
        
        latencyMs := latency.Milliseconds()
        
        var stats *LatencyStats
        switch operation </span>{
        case "read":<span class="cov2" title="2">
                stats = ls.stats.Performance.ReadLatency</span>
        case "write":<span class="cov5" title="6">
                stats = ls.stats.Performance.WriteLatency</span>
        case "delete":<span class="cov4" title="4">
                stats = ls.stats.Performance.DeleteLatency</span>
        default:<span class="cov0" title="0">
                return</span>
        }
        
        // Update statistics
        <span class="cov7" title="12">if stats.Samples == 0 </span><span class="cov6" title="7">{
                stats.Min = latencyMs
                stats.Max = latencyMs
                stats.Mean = float64(latencyMs)
                stats.Median = latencyMs
        }</span> else<span class="cov5" title="5"> {
                if latencyMs &lt; stats.Min </span><span class="cov3" title="3">{
                        stats.Min = latencyMs
                }</span>
                <span class="cov5" title="5">if latencyMs &gt; stats.Max </span><span class="cov0" title="0">{
                        stats.Max = latencyMs
                }</span>
                
                // Update mean
                <span class="cov5" title="5">stats.Mean = (stats.Mean*float64(stats.Samples) + float64(latencyMs)) / float64(stats.Samples+1)</span>
        }
        
        <span class="cov7" title="12">stats.Samples++</span>
}

func (ls *LocalStorage) incrementOperationCount(operation string) <span class="cov7" title="12">{
        ls.statsMutex.Lock()
        defer ls.statsMutex.Unlock()
        
        ls.stats.OperationCounts[operation]++
}</span>

// Background routines

func (ls *LocalStorage) cleanupRoutine() <span class="cov2" title="2">{
        ticker := time.NewTicker(1 * time.Hour)
        defer ticker.Stop()
        
        for </span><span class="cov2" title="2">{
                select </span>{
                case &lt;-ls.ctx.Done():<span class="cov2" title="2">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        ls.performCleanup()</span>
                }
        }
}

func (ls *LocalStorage) healthMonitorRoutine() <span class="cov2" title="2">{
        ticker := time.NewTicker(5 * time.Minute)
        defer ticker.Stop()
        
        for </span><span class="cov2" title="2">{
                select </span>{
                case &lt;-ls.ctx.Done():<span class="cov2" title="2">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        ls.HealthCheck(ls.ctx)</span>
                }
        }
}

func (ls *LocalStorage) statsCollectionRoutine() <span class="cov2" title="2">{
        ticker := time.NewTicker(1 * time.Minute)
        defer ticker.Stop()
        
        for </span><span class="cov2" title="2">{
                select </span>{
                case &lt;-ls.ctx.Done():<span class="cov2" title="2">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        ls.collectStats()</span>
                }
        }
}

func (ls *LocalStorage) performCleanup() <span class="cov0" title="0">{
        // Clean up temporary files
        err := filepath.Walk(ls.basePath, func(path string, info os.FileInfo, err error) error </span><span class="cov0" title="0">{
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                
                <span class="cov0" title="0">if strings.HasSuffix(path, ".tmp") &amp;&amp; time.Since(info.ModTime()) &gt; time.Hour </span><span class="cov0" title="0">{
                        os.Remove(path)
                }</span>
                
                <span class="cov0" title="0">return nil</span>
        })
        
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                ls.logger.Error("cleanup failed", "error", err)
        }</span>
}

func (ls *LocalStorage) collectStats() <span class="cov0" title="0">{
        // Update throughput stats based on operation counts
        // This is a simplified implementation
        ls.statsMutex.Lock()
        defer ls.statsMutex.Unlock()
        
        // Calculate ops per second (simplified)
        if ls.stats.Performance != nil &amp;&amp; ls.stats.Performance.Throughput != nil </span><span class="cov0" title="0">{
                totalOps := int64(0)
                for _, count := range ls.stats.OperationCounts </span><span class="cov0" title="0">{
                        totalOps += count
                }</span>
                
                // Simple calculation - in practice this would be more sophisticated
                <span class="cov0" title="0">ls.stats.Performance.Throughput.ReadOpsPerSec = float64(ls.stats.OperationCounts["retrieve"]) / 60.0
                ls.stats.Performance.Throughput.WriteOpsPerSec = float64(ls.stats.OperationCounts["store"]) / 60.0
                ls.stats.Performance.Throughput.DeleteOpsPerSec = float64(ls.stats.OperationCounts["delete"]) / 60.0</span>
        }
}

// Disk usage calculation (platform-specific implementations would be needed)
type diskStat struct {
        Total     int64
        Used      int64
        Available int64
}

func (ls *LocalStorage) getDiskUsage() (*diskStat, error) <span class="cov3" title="3">{
        // This is a simplified implementation
        // In practice, this would use platform-specific syscalls
        return &amp;diskStat{
                Total:     100 * 1024 * 1024 * 1024, // 100GB
                Used:      ls.stats.UsedSpace,
                Available: (100 * 1024 * 1024 * 1024) - ls.stats.UsedSpace,
        }, nil
}</span>

// Helper function to check if error is not found
func isNotFoundError(err error) bool <span class="cov0" title="0">{
        if storageErr, ok := err.(*StorageError); ok </span><span class="cov0" title="0">{
                return storageErr.Code == ErrCodeNotFound
        }</span>
        <span class="cov0" title="0">return false</span>
}</pre>
		
		<pre class="file" id="file13" style="display: none">package storage

import (
        "context"
        "encoding/json"
        "fmt"
        "log/slog"
        "os"
        "path/filepath"
        "sort"
        "strings"
        "sync"
        "time"

        "github.com/syndtr/goleveldb/leveldb"
        "github.com/syndtr/goleveldb/leveldb/util"
)

// MetadataManager manages metadata storage and operations
type MetadataManager struct {
        logger *slog.Logger
        
        // Storage backends
        levelDB    *leveldb.DB
        fileSystem *FileSystemMetadata
        
        // Configuration
        config *MetadataConfig
        
        // Caching
        cache      map[string]*CachedMetadata
        cacheMutex sync.RWMutex
        cacheSize  int
        maxCache   int
        
        // Indexing
        indexes    map[string]*MetadataIndex
        indexMutex sync.RWMutex
        
        // Statistics
        stats      *MetadataStats
        statsMutex sync.RWMutex
        
        // Background tasks
        ctx     context.Context
        cancel  context.CancelFunc
        started bool
        mu      sync.RWMutex
}

// MetadataConfig contains configuration for metadata management
type MetadataConfig struct {
        Backend       string        `json:"backend"`        // leveldb, filesystem, memory
        DataDir       string        `json:"data_dir"`
        IndexingMode  string        `json:"indexing_mode"`  // eager, lazy, disabled
        CacheSize     int           `json:"cache_size"`
        SyncInterval  time.Duration `json:"sync_interval"`
        CompactInterval time.Duration `json:"compact_interval"`
        EnableSearch  bool          `json:"enable_search"`
        EnableVersioning bool       `json:"enable_versioning"`
}

// FileSystemMetadata implements filesystem-based metadata storage
type FileSystemMetadata struct {
        basePath string
        logger   *slog.Logger
}

// CachedMetadata represents cached metadata with additional information
type CachedMetadata struct {
        Metadata   *ObjectMetadata `json:"metadata"`
        CachedAt   time.Time       `json:"cached_at"`
        AccessCount int            `json:"access_count"`
        LastAccess time.Time       `json:"last_access"`
}

// MetadataIndex represents an index for fast metadata queries
type MetadataIndex struct {
        Name      string                     `json:"name"`
        Type      string                     `json:"type"` // btree, hash, text
        Fields    []string                   `json:"fields"`
        Values    map[string][]string        `json:"values"` // value -&gt; keys
        CreatedAt time.Time                  `json:"created_at"`
        UpdatedAt time.Time                  `json:"updated_at"`
        Stats     *IndexStats                `json:"stats"`
}

// IndexStats contains statistics about an index
type IndexStats struct {
        TotalEntries  int64     `json:"total_entries"`
        UniqueValues  int64     `json:"unique_values"`
        LastUpdated   time.Time `json:"last_updated"`
        UpdateCount   int64     `json:"update_count"`
        QueryCount    int64     `json:"query_count"`
        AverageDepth  float64   `json:"average_depth"`
}

// MetadataStats contains statistics about metadata operations
type MetadataStats struct {
        TotalObjects     int64             `json:"total_objects"`
        TotalSize        int64             `json:"total_size"`
        CacheHitRate     float64           `json:"cache_hit_rate"`
        CacheHits        int64             `json:"cache_hits"`
        CacheMisses      int64             `json:"cache_misses"`
        IndexQueries     int64             `json:"index_queries"`
        OperationCounts  map[string]int64  `json:"operation_counts"`
        Performance      *MetadataPerformance `json:"performance"`
        LastCompaction   time.Time         `json:"last_compaction"`
        LastSync         time.Time         `json:"last_sync"`
}

// MetadataPerformance contains performance metrics
type MetadataPerformance struct {
        GetLatency    *LatencyStats `json:"get_latency"`
        SetLatency    *LatencyStats `json:"set_latency"`
        SearchLatency *LatencyStats `json:"search_latency"`
        IndexLatency  *LatencyStats `json:"index_latency"`
}

// MetadataQuery represents a metadata query
type MetadataQuery struct {
        Fields     map[string]interface{} `json:"fields"`
        Conditions []*QueryCondition      `json:"conditions"`
        Sort       *SortOptions           `json:"sort"`
        Limit      int                    `json:"limit"`
        Offset     int                    `json:"offset"`
        FullText   string                 `json:"full_text"`
}

// QueryCondition represents a query condition
type QueryCondition struct {
        Field    string      `json:"field"`
        Operator string      `json:"operator"` // eq, ne, gt, lt, gte, lte, in, like, regex
        Value    interface{} `json:"value"`
        LogicalOp string     `json:"logical_op"` // and, or, not
}

// SortOptions represents sorting options
type SortOptions struct {
        Field string `json:"field"`
        Order string `json:"order"` // asc, desc
}

// MetadataQueryResult represents the result of a metadata query
type MetadataQueryResult struct {
        Objects      []*ObjectMetadata `json:"objects"`
        Total        int64             `json:"total"`
        QueryTime    time.Duration     `json:"query_time"`
        IndexUsed    string            `json:"index_used"`
        Explanation  string            `json:"explanation"`
}

// NewMetadataManager creates a new metadata manager
func NewMetadataManager(config *MetadataConfig, logger *slog.Logger) (*MetadataManager, error) <span class="cov2" title="2">{
        ctx, cancel := context.WithCancel(context.Background())
        
        mm := &amp;MetadataManager{
                logger:     logger,
                config:     config,
                cache:      make(map[string]*CachedMetadata),
                maxCache:   config.CacheSize,
                indexes:    make(map[string]*MetadataIndex),
                stats: &amp;MetadataStats{
                        OperationCounts: make(map[string]int64),
                        Performance: &amp;MetadataPerformance{
                                GetLatency:    &amp;LatencyStats{},
                                SetLatency:    &amp;LatencyStats{},
                                SearchLatency: &amp;LatencyStats{},
                                IndexLatency:  &amp;LatencyStats{},
                        },
                },
                ctx:    ctx,
                cancel: cancel,
        }
        
        // Initialize storage backend
        if err := mm.initializeBackend(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to initialize metadata backend: %w", err)
        }</span>
        
        // Create default indexes
        <span class="cov2" title="2">if config.IndexingMode != "disabled" </span><span class="cov2" title="2">{
                mm.createDefaultIndexes()
        }</span>
        
        <span class="cov2" title="2">return mm, nil</span>
}

// Start starts the metadata manager
func (mm *MetadataManager) Start(ctx context.Context) error <span class="cov2" title="2">{
        mm.mu.Lock()
        defer mm.mu.Unlock()
        
        if mm.started </span><span class="cov0" title="0">{
                return fmt.Errorf("metadata manager already started")
        }</span>
        
        // Start background routines
        <span class="cov2" title="2">go mm.syncRoutine()
        go mm.compactionRoutine()
        go mm.cacheMaintenanceRoutine()
        go mm.statsCollectionRoutine()
        
        mm.started = true
        mm.logger.Info("metadata manager started", "backend", mm.config.Backend)
        
        return nil</span>
}

// Stop stops the metadata manager
func (mm *MetadataManager) Stop(ctx context.Context) error <span class="cov2" title="2">{
        mm.mu.Lock()
        defer mm.mu.Unlock()
        
        if !mm.started </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        <span class="cov2" title="2">mm.cancel()
        
        // Close storage backends
        if mm.levelDB != nil </span><span class="cov0" title="0">{
                mm.levelDB.Close()
        }</span>
        
        <span class="cov2" title="2">mm.started = false
        mm.logger.Info("metadata manager stopped")
        
        return nil</span>
}

// Store stores metadata for an object
func (mm *MetadataManager) Store(ctx context.Context, key string, metadata *ObjectMetadata) error <span class="cov4" title="3">{
        start := time.Now()
        defer func() </span><span class="cov4" title="3">{
                mm.updateLatencyStats("set", time.Since(start))
                mm.incrementOperationCount("store")
        }</span>()
        
        // Prepare metadata
        <span class="cov4" title="3">metadata.Key = key
        metadata.UpdatedAt = time.Now()
        if metadata.CreatedAt.IsZero() </span><span class="cov0" title="0">{
                metadata.CreatedAt = time.Now()
        }</span>
        
        // Store in backend
        <span class="cov4" title="3">if err := mm.storeInBackend(key, metadata); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        // Update cache
        <span class="cov4" title="3">mm.updateCache(key, metadata)
        
        // Update indexes
        if mm.config.IndexingMode == "eager" </span><span class="cov4" title="3">{
                mm.updateIndexes(key, metadata)
        }</span>
        
        // Update statistics
        <span class="cov4" title="3">mm.statsMutex.Lock()
        mm.stats.TotalObjects++
        if metadata.Size &gt; 0 </span><span class="cov4" title="3">{
                mm.stats.TotalSize += metadata.Size
        }</span>
        <span class="cov4" title="3">mm.statsMutex.Unlock()
        
        return nil</span>
}

// Get retrieves metadata for an object
func (mm *MetadataManager) Get(ctx context.Context, key string) (*ObjectMetadata, error) <span class="cov6" title="6">{
        start := time.Now()
        defer func() </span><span class="cov6" title="6">{
                mm.updateLatencyStats("get", time.Since(start))
                mm.incrementOperationCount("get")
        }</span>()
        
        // Check cache first
        <span class="cov6" title="6">if cached := mm.getFromCache(key); cached != nil </span><span class="cov5" title="5">{
                mm.incrementCacheHits()
                return cached.Metadata, nil
        }</span>
        
        <span class="cov1" title="1">mm.incrementCacheMisses()
        
        // Load from backend
        metadata, err := mm.loadFromBackend(key)
        if err != nil </span><span class="cov1" title="1">{
                return nil, err
        }</span>
        
        // Update cache
        <span class="cov0" title="0">mm.updateCache(key, metadata)
        
        return metadata, nil</span>
}

// Update updates specific metadata fields
func (mm *MetadataManager) Update(ctx context.Context, key string, updates map[string]interface{}) error <span class="cov1" title="1">{
        // Get current metadata
        metadata, err := mm.Get(ctx, key)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        // Apply updates
        <span class="cov1" title="1">if metadata.Attributes == nil </span><span class="cov0" title="0">{
                metadata.Attributes = make(map[string]interface{})
        }</span>
        
        <span class="cov1" title="1">for field, value := range updates </span><span class="cov2" title="2">{
                switch field </span>{
                case "content_type":<span class="cov0" title="0">
                        if v, ok := value.(string); ok </span><span class="cov0" title="0">{
                                metadata.ContentType = v
                        }</span>
                case "version":<span class="cov1" title="1">
                        if v, ok := value.(string); ok </span><span class="cov1" title="1">{
                                metadata.Version = v
                        }</span>
                case "size":<span class="cov0" title="0">
                        if v, ok := value.(int64); ok </span><span class="cov0" title="0">{
                                metadata.Size = v
                        }</span>
                case "hash":<span class="cov0" title="0">
                        if v, ok := value.(string); ok </span><span class="cov0" title="0">{
                                metadata.Hash = v
                        }</span>
                default:<span class="cov1" title="1">
                        metadata.Attributes[field] = value</span>
                }
        }
        
        <span class="cov1" title="1">return mm.Store(ctx, key, metadata)</span>
}

// Delete deletes metadata for an object
func (mm *MetadataManager) Delete(ctx context.Context, key string) error <span class="cov1" title="1">{
        start := time.Now()
        defer func() </span><span class="cov1" title="1">{
                mm.updateLatencyStats("delete", time.Since(start))
                mm.incrementOperationCount("delete")
        }</span>()
        
        // Get metadata for size accounting
        <span class="cov1" title="1">metadata, err := mm.Get(ctx, key)
        if err != nil &amp;&amp; !isNotFoundError(err) </span><span class="cov0" title="0">{
                return err
        }</span>
        
        // Delete from backend
        <span class="cov1" title="1">if err := mm.deleteFromBackend(key); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        // Remove from cache
        <span class="cov1" title="1">mm.removeFromCache(key)
        
        // Remove from indexes
        if mm.config.IndexingMode != "disabled" </span><span class="cov1" title="1">{
                mm.removeFromIndexes(key, metadata)
        }</span>
        
        // Update statistics
        <span class="cov1" title="1">if metadata != nil </span><span class="cov1" title="1">{
                mm.statsMutex.Lock()
                mm.stats.TotalObjects--
                if metadata.Size &gt; 0 </span><span class="cov1" title="1">{
                        mm.stats.TotalSize -= metadata.Size
                }</span>
                <span class="cov1" title="1">mm.statsMutex.Unlock()</span>
        }
        
        <span class="cov1" title="1">return nil</span>
}

// List lists metadata with optional filtering
func (mm *MetadataManager) List(ctx context.Context, prefix string, options *ListOptions) ([]*ObjectMetadata, error) <span class="cov1" title="1">{
        start := time.Now()
        defer func() </span><span class="cov1" title="1">{
                mm.updateLatencyStats("list", time.Since(start))
                mm.incrementOperationCount("list")
        }</span>()
        
        <span class="cov1" title="1">return mm.listFromBackend(prefix, options)</span>
}

// Search performs advanced metadata search
func (mm *MetadataManager) Search(ctx context.Context, query *MetadataQuery) (*MetadataQueryResult, error) <span class="cov2" title="2">{
        start := time.Now()
        defer func() </span><span class="cov2" title="2">{
                mm.updateLatencyStats("search", time.Since(start))
                mm.incrementOperationCount("search")
        }</span>()
        
        <span class="cov2" title="2">if !mm.config.EnableSearch </span><span class="cov0" title="0">{
                return nil, &amp;StorageError{
                        Code:    ErrCodeUnavailable,
                        Message: "search not enabled",
                }
        }</span>
        
        // Determine best index to use
        <span class="cov2" title="2">indexName := mm.selectBestIndex(query)
        
        var results []*ObjectMetadata
        var err error
        
        if indexName != "" </span><span class="cov1" title="1">{
                results, err = mm.searchWithIndex(ctx, query, indexName)
        }</span> else<span class="cov1" title="1"> {
                results, err = mm.searchWithoutIndex(ctx, query)
        }</span>
        
        <span class="cov2" title="2">if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        
        // Apply sorting and pagination
        <span class="cov2" title="2">results = mm.applySortingAndPagination(results, query)
        
        return &amp;MetadataQueryResult{
                Objects:     results,
                Total:       int64(len(results)),
                QueryTime:   time.Since(start),
                IndexUsed:   indexName,
                Explanation: mm.explainQuery(query, indexName),
        }, nil</span>
}

// CreateIndex creates a new metadata index
func (mm *MetadataManager) CreateIndex(ctx context.Context, name string, fields []string, indexType string) error <span class="cov7" title="11">{
        start := time.Now()
        defer func() </span><span class="cov7" title="11">{
                mm.updateLatencyStats("index", time.Since(start))
                mm.incrementOperationCount("create_index")
        }</span>()
        
        <span class="cov7" title="11">mm.indexMutex.Lock()
        defer mm.indexMutex.Unlock()
        
        if _, exists := mm.indexes[name]; exists </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:    ErrCodeAlreadyExists,
                        Message: "index already exists",
                }
        }</span>
        
        <span class="cov7" title="11">index := &amp;MetadataIndex{
                Name:      name,
                Type:      indexType,
                Fields:    fields,
                Values:    make(map[string][]string),
                CreatedAt: time.Now(),
                UpdatedAt: time.Now(),
                Stats:     &amp;IndexStats{},
        }
        
        mm.indexes[name] = index
        
        // Build index from existing metadata
        go mm.buildIndex(ctx, index)
        
        mm.logger.Info("metadata index created", "name", name, "fields", fields, "type", indexType)
        
        return nil</span>
}

// DropIndex drops a metadata index
func (mm *MetadataManager) DropIndex(ctx context.Context, name string) error <span class="cov0" title="0">{
        mm.indexMutex.Lock()
        defer mm.indexMutex.Unlock()
        
        if _, exists := mm.indexes[name]; !exists </span><span class="cov0" title="0">{
                return &amp;StorageError{
                        Code:    ErrCodeNotFound,
                        Message: "index not found",
                }
        }</span>
        
        <span class="cov0" title="0">delete(mm.indexes, name)
        
        mm.logger.Info("metadata index dropped", "name", name)
        
        return nil</span>
}

// GetIndexes returns all metadata indexes
func (mm *MetadataManager) GetIndexes(ctx context.Context) ([]*MetadataIndex, error) <span class="cov1" title="1">{
        mm.indexMutex.RLock()
        defer mm.indexMutex.RUnlock()
        
        indexes := make([]*MetadataIndex, 0, len(mm.indexes))
        for _, index := range mm.indexes </span><span class="cov6" title="6">{
                // Create a copy
                indexCopy := *index
                indexCopy.Values = make(map[string][]string)
                for k, v := range index.Values </span><span class="cov6" title="6">{
                        indexCopy.Values[k] = append([]string{}, v...)
                }</span>
                <span class="cov6" title="6">indexes = append(indexes, &amp;indexCopy)</span>
        }
        
        <span class="cov1" title="1">return indexes, nil</span>
}

// GetStats returns metadata statistics
func (mm *MetadataManager) GetStats(ctx context.Context) (*MetadataStats, error) <span class="cov2" title="2">{
        mm.statsMutex.RLock()
        defer mm.statsMutex.RUnlock()
        
        // Update cache hit rate
        totalRequests := mm.stats.CacheHits + mm.stats.CacheMisses
        if totalRequests &gt; 0 </span><span class="cov1" title="1">{
                mm.stats.CacheHitRate = float64(mm.stats.CacheHits) / float64(totalRequests)
        }</span>
        
        // Create a copy
        <span class="cov2" title="2">stats := *mm.stats
        stats.OperationCounts = make(map[string]int64)
        for k, v := range mm.stats.OperationCounts </span><span class="cov6" title="8">{
                stats.OperationCounts[k] = v
        }</span>
        
        <span class="cov2" title="2">return &amp;stats, nil</span>
}

// Backend initialization

func (mm *MetadataManager) initializeBackend() error <span class="cov2" title="2">{
        switch mm.config.Backend </span>{
        case "leveldb":<span class="cov0" title="0">
                return mm.initializeLevelDB()</span>
        case "filesystem":<span class="cov2" title="2">
                return mm.initializeFileSystem()</span>
        case "memory":<span class="cov0" title="0">
                return nil</span> // Memory backend is the default cache
        default:<span class="cov0" title="0">
                return fmt.Errorf("unsupported metadata backend: %s", mm.config.Backend)</span>
        }
}

func (mm *MetadataManager) initializeLevelDB() error <span class="cov0" title="0">{
        dbPath := filepath.Join(mm.config.DataDir, "metadata.db")
        if err := os.MkdirAll(filepath.Dir(dbPath), 0755); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        <span class="cov0" title="0">db, err := leveldb.OpenFile(dbPath, nil)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        <span class="cov0" title="0">mm.levelDB = db
        return nil</span>
}

func (mm *MetadataManager) initializeFileSystem() error <span class="cov2" title="2">{
        metaPath := filepath.Join(mm.config.DataDir, "metadata")
        if err := os.MkdirAll(metaPath, 0755); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        <span class="cov2" title="2">mm.fileSystem = &amp;FileSystemMetadata{
                basePath: metaPath,
                logger:   mm.logger,
        }
        
        return nil</span>
}

// Backend operations

func (mm *MetadataManager) storeInBackend(key string, metadata *ObjectMetadata) error <span class="cov4" title="3">{
        data, err := json.Marshal(metadata)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        <span class="cov4" title="3">switch mm.config.Backend </span>{
        case "leveldb":<span class="cov0" title="0">
                return mm.levelDB.Put([]byte(key), data, nil)</span>
        case "filesystem":<span class="cov4" title="3">
                return mm.fileSystem.store(key, data)</span>
        case "memory":<span class="cov0" title="0">
                return nil</span> // Only stored in cache
        default:<span class="cov0" title="0">
                return fmt.Errorf("unsupported backend: %s", mm.config.Backend)</span>
        }
}

func (mm *MetadataManager) loadFromBackend(key string) (*ObjectMetadata, error) <span class="cov1" title="1">{
        var data []byte
        var err error
        
        switch mm.config.Backend </span>{
        case "leveldb":<span class="cov0" title="0">
                data, err = mm.levelDB.Get([]byte(key), nil)
                if err == leveldb.ErrNotFound </span><span class="cov0" title="0">{
                        return nil, &amp;StorageError{
                                Code:    ErrCodeNotFound,
                                Message: "metadata not found",
                        }
                }</span>
        case "filesystem":<span class="cov1" title="1">
                data, err = mm.fileSystem.load(key)</span>
        case "memory":<span class="cov0" title="0">
                return nil, &amp;StorageError{
                        Code:    ErrCodeNotFound,
                        Message: "metadata not found in memory",
                }</span>
        default:<span class="cov0" title="0">
                return nil, fmt.Errorf("unsupported backend: %s", mm.config.Backend)</span>
        }
        
        <span class="cov1" title="1">if err != nil </span><span class="cov1" title="1">{
                return nil, err
        }</span>
        
        <span class="cov0" title="0">var metadata ObjectMetadata
        if err := json.Unmarshal(data, &amp;metadata); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        
        <span class="cov0" title="0">return &amp;metadata, nil</span>
}

func (mm *MetadataManager) deleteFromBackend(key string) error <span class="cov1" title="1">{
        switch mm.config.Backend </span>{
        case "leveldb":<span class="cov0" title="0">
                return mm.levelDB.Delete([]byte(key), nil)</span>
        case "filesystem":<span class="cov1" title="1">
                return mm.fileSystem.delete(key)</span>
        case "memory":<span class="cov0" title="0">
                return nil</span> // Only deleted from cache
        default:<span class="cov0" title="0">
                return fmt.Errorf("unsupported backend: %s", mm.config.Backend)</span>
        }
}

func (mm *MetadataManager) listFromBackend(prefix string, options *ListOptions) ([]*ObjectMetadata, error) <span class="cov8" title="13">{
        var results []*ObjectMetadata
        
        switch mm.config.Backend </span>{
        case "leveldb":<span class="cov0" title="0">
                iter := mm.levelDB.NewIterator(util.BytesPrefix([]byte(prefix)), nil)
                defer iter.Release()
                
                for iter.Next() </span><span class="cov0" title="0">{
                        var metadata ObjectMetadata
                        if err := json.Unmarshal(iter.Value(), &amp;metadata); err != nil </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov0" title="0">results = append(results, &amp;metadata)
                        
                        if options != nil &amp;&amp; options.Limit &gt; 0 &amp;&amp; len(results) &gt;= options.Limit </span><span class="cov0" title="0">{
                                break</span>
                        }
                }
                
                <span class="cov0" title="0">return results, iter.Error()</span>
                
        case "filesystem":<span class="cov8" title="13">
                return mm.fileSystem.list(prefix, options)</span>
                
        case "memory":<span class="cov0" title="0">
                // List from cache
                mm.cacheMutex.RLock()
                defer mm.cacheMutex.RUnlock()
                
                for key, cached := range mm.cache </span><span class="cov0" title="0">{
                        if strings.HasPrefix(key, prefix) </span><span class="cov0" title="0">{
                                results = append(results, cached.Metadata)
                                if options != nil &amp;&amp; options.Limit &gt; 0 &amp;&amp; len(results) &gt;= options.Limit </span><span class="cov0" title="0">{
                                        break</span>
                                }
                        }
                }
                
                <span class="cov0" title="0">return results, nil</span>
                
        default:<span class="cov0" title="0">
                return nil, fmt.Errorf("unsupported backend: %s", mm.config.Backend)</span>
        }
}

// Cache management

func (mm *MetadataManager) getFromCache(key string) *CachedMetadata <span class="cov6" title="6">{
        mm.cacheMutex.RLock()
        defer mm.cacheMutex.RUnlock()
        
        if cached, exists := mm.cache[key]; exists </span><span class="cov5" title="5">{
                cached.LastAccess = time.Now()
                cached.AccessCount++
                return cached
        }</span>
        
        <span class="cov1" title="1">return nil</span>
}

func (mm *MetadataManager) updateCache(key string, metadata *ObjectMetadata) <span class="cov4" title="3">{
        mm.cacheMutex.Lock()
        defer mm.cacheMutex.Unlock()
        
        // Check cache size
        if len(mm.cache) &gt;= mm.maxCache </span><span class="cov0" title="0">{
                mm.evictFromCache()
        }</span>
        
        <span class="cov4" title="3">mm.cache[key] = &amp;CachedMetadata{
                Metadata:    metadata,
                CachedAt:    time.Now(),
                AccessCount: 1,
                LastAccess:  time.Now(),
        }
        mm.cacheSize++</span>
}

func (mm *MetadataManager) removeFromCache(key string) <span class="cov1" title="1">{
        mm.cacheMutex.Lock()
        defer mm.cacheMutex.Unlock()
        
        if _, exists := mm.cache[key]; exists </span><span class="cov1" title="1">{
                delete(mm.cache, key)
                mm.cacheSize--
        }</span>
}

func (mm *MetadataManager) evictFromCache() <span class="cov0" title="0">{
        // LRU eviction
        var oldestKey string
        var oldestTime time.Time = time.Now()
        
        for key, cached := range mm.cache </span><span class="cov0" title="0">{
                if cached.LastAccess.Before(oldestTime) </span><span class="cov0" title="0">{
                        oldestTime = cached.LastAccess
                        oldestKey = key
                }</span>
        }
        
        <span class="cov0" title="0">if oldestKey != "" </span><span class="cov0" title="0">{
                delete(mm.cache, oldestKey)
                mm.cacheSize--
        }</span>
}

// Index management

func (mm *MetadataManager) createDefaultIndexes() <span class="cov2" title="2">{
        // Create indexes for common fields
        commonIndexes := map[string][]string{
                "size_index":         {"size"},
                "type_index":         {"content_type"},
                "created_index":      {"created_at"},
                "updated_index":      {"updated_at"},
                "hash_index":         {"hash"},
        }
        
        for name, fields := range commonIndexes </span><span class="cov7" title="10">{
                if err := mm.CreateIndex(context.Background(), name, fields, "btree"); err != nil </span><span class="cov0" title="0">{
                        mm.logger.Warn("failed to create default index", "name", name, "error", err)
                }</span>
        }
}

func (mm *MetadataManager) updateIndexes(key string, metadata *ObjectMetadata) <span class="cov4" title="3">{
        mm.indexMutex.Lock()
        defer mm.indexMutex.Unlock()
        
        for _, index := range mm.indexes </span><span class="cov8" title="15">{
                mm.updateIndex(index, key, metadata)
        }</span>
}

func (mm *MetadataManager) updateIndex(index *MetadataIndex, key string, metadata *ObjectMetadata) <span class="cov8" title="17">{
        for _, field := range index.Fields </span><span class="cov8" title="17">{
                value := mm.extractFieldValue(metadata, field)
                if value != "" </span><span class="cov8" title="17">{
                        if keys, exists := index.Values[value]; exists </span><span class="cov6" title="6">{
                                // Check if key already exists
                                found := false
                                for _, k := range keys </span><span class="cov6" title="6">{
                                        if k == key </span><span class="cov6" title="6">{
                                                found = true
                                                break</span>
                                        }
                                }
                                <span class="cov6" title="6">if !found </span><span class="cov0" title="0">{
                                        index.Values[value] = append(keys, key)
                                }</span>
                        } else<span class="cov7" title="11"> {
                                index.Values[value] = []string{key}
                        }</span>
                }
        }
        
        <span class="cov8" title="17">index.UpdatedAt = time.Now()
        index.Stats.UpdateCount++</span>
}

func (mm *MetadataManager) removeFromIndexes(key string, metadata *ObjectMetadata) <span class="cov1" title="1">{
        if metadata == nil </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov1" title="1">mm.indexMutex.Lock()
        defer mm.indexMutex.Unlock()
        
        for _, index := range mm.indexes </span><span class="cov6" title="6">{
                mm.removeFromIndex(index, key, metadata)
        }</span>
}

func (mm *MetadataManager) removeFromIndex(index *MetadataIndex, key string, metadata *ObjectMetadata) <span class="cov6" title="6">{
        for _, field := range index.Fields </span><span class="cov6" title="6">{
                value := mm.extractFieldValue(metadata, field)
                if value != "" </span><span class="cov6" title="6">{
                        if keys, exists := index.Values[value]; exists </span><span class="cov6" title="6">{
                                // Remove key from slice
                                var newKeys []string
                                for _, k := range keys </span><span class="cov6" title="6">{
                                        if k != key </span><span class="cov0" title="0">{
                                                newKeys = append(newKeys, k)
                                        }</span>
                                }
                                
                                <span class="cov6" title="6">if len(newKeys) == 0 </span><span class="cov6" title="6">{
                                        delete(index.Values, value)
                                }</span> else<span class="cov0" title="0"> {
                                        index.Values[value] = newKeys
                                }</span>
                        }
                }
        }
        
        <span class="cov6" title="6">index.UpdatedAt = time.Now()</span>
}

func (mm *MetadataManager) buildIndex(ctx context.Context, index *MetadataIndex) <span class="cov7" title="11">{
        mm.logger.Info("building metadata index", "name", index.Name)
        
        // Get all metadata from backend
        allMetadata, err := mm.listFromBackend("", nil)
        if err != nil </span><span class="cov0" title="0">{
                mm.logger.Error("failed to load metadata for index building", "error", err)
                return
        }</span>
        
        // Build index
        <span class="cov7" title="11">for _, metadata := range allMetadata </span><span class="cov2" title="2">{
                mm.updateIndex(index, metadata.Key, metadata)
        }</span>
        
        <span class="cov7" title="11">index.Stats.TotalEntries = int64(len(allMetadata))
        index.Stats.UniqueValues = int64(len(index.Values))
        index.Stats.LastUpdated = time.Now()
        
        mm.logger.Info("metadata index built", "name", index.Name, "entries", index.Stats.TotalEntries)</span>
}

// Search implementation

func (mm *MetadataManager) selectBestIndex(query *MetadataQuery) string <span class="cov2" title="2">{
        mm.indexMutex.RLock()
        defer mm.indexMutex.RUnlock()
        
        var bestIndex string
        var bestScore int
        
        for name, index := range mm.indexes </span><span class="cov7" title="11">{
                score := mm.calculateIndexScore(index, query)
                if score &gt; bestScore </span><span class="cov1" title="1">{
                        bestScore = score
                        bestIndex = name
                }</span>
        }
        
        <span class="cov2" title="2">return bestIndex</span>
}

func (mm *MetadataManager) calculateIndexScore(index *MetadataIndex, query *MetadataQuery) int <span class="cov7" title="11">{
        score := 0
        
        // Check if index fields match query conditions
        for _, condition := range query.Conditions </span><span class="cov7" title="11">{
                for _, field := range index.Fields </span><span class="cov7" title="11">{
                        if field == condition.Field </span><span class="cov2" title="2">{
                                score += 10
                                
                                // Bonus for exact match operators
                                if condition.Operator == "eq" </span><span class="cov2" title="2">{
                                        score += 5
                                }</span>
                        }
                }
        }
        
        // Check sorting field
        <span class="cov7" title="11">if query.Sort != nil </span><span class="cov0" title="0">{
                for _, field := range index.Fields </span><span class="cov0" title="0">{
                        if field == query.Sort.Field </span><span class="cov0" title="0">{
                                score += 3
                        }</span>
                }
        }
        
        <span class="cov7" title="11">return score</span>
}

func (mm *MetadataManager) searchWithIndex(ctx context.Context, query *MetadataQuery, indexName string) ([]*ObjectMetadata, error) <span class="cov1" title="1">{
        mm.indexMutex.RLock()
        index, exists := mm.indexes[indexName]
        mm.indexMutex.RUnlock()
        
        if !exists </span><span class="cov0" title="0">{
                return mm.searchWithoutIndex(ctx, query)
        }</span>
        
        <span class="cov1" title="1">var candidateKeys []string
        
        // Find candidate keys using index
        for _, condition := range query.Conditions </span><span class="cov1" title="1">{
                if mm.isFieldIndexed(index, condition.Field) </span><span class="cov1" title="1">{
                        keys := mm.getKeysFromIndex(index, condition)
                        if candidateKeys == nil </span><span class="cov1" title="1">{
                                candidateKeys = keys
                        }</span> else<span class="cov0" title="0"> {
                                candidateKeys = mm.intersectKeys(candidateKeys, keys)
                        }</span>
                }
        }
        
        // Load metadata for candidate keys
        <span class="cov1" title="1">var results []*ObjectMetadata
        for _, key := range candidateKeys </span><span class="cov1" title="1">{
                metadata, err := mm.Get(ctx, key)
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }
                
                // Apply additional filtering
                <span class="cov1" title="1">if mm.matchesQuery(metadata, query) </span><span class="cov1" title="1">{
                        results = append(results, metadata)
                }</span>
        }
        
        <span class="cov1" title="1">index.Stats.QueryCount++
        
        return results, nil</span>
}

func (mm *MetadataManager) searchWithoutIndex(ctx context.Context, query *MetadataQuery) ([]*ObjectMetadata, error) <span class="cov1" title="1">{
        // Full scan
        allMetadata, err := mm.listFromBackend("", nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        
        <span class="cov1" title="1">var results []*ObjectMetadata
        for _, metadata := range allMetadata </span><span class="cov1" title="1">{
                if mm.matchesQuery(metadata, query) </span><span class="cov1" title="1">{
                        results = append(results, metadata)
                }</span>
        }
        
        <span class="cov1" title="1">return results, nil</span>
}

func (mm *MetadataManager) applySortingAndPagination(results []*ObjectMetadata, query *MetadataQuery) []*ObjectMetadata <span class="cov2" title="2">{
        // Apply sorting
        if query.Sort != nil </span><span class="cov0" title="0">{
                sort.Slice(results, func(i, j int) bool </span><span class="cov0" title="0">{
                        return mm.compareMetadata(results[i], results[j], query.Sort)
                }</span>)
        }
        
        // Apply pagination
        <span class="cov2" title="2">start := query.Offset
        if start &lt; 0 </span><span class="cov0" title="0">{
                start = 0
        }</span>
        <span class="cov2" title="2">if start &gt;= len(results) </span><span class="cov0" title="0">{
                return []*ObjectMetadata{}
        }</span>
        
        <span class="cov2" title="2">end := start + query.Limit
        if query.Limit &lt;= 0 || end &gt; len(results) </span><span class="cov2" title="2">{
                end = len(results)
        }</span>
        
        <span class="cov2" title="2">return results[start:end]</span>
}

// Helper methods

func (mm *MetadataManager) extractFieldValue(metadata *ObjectMetadata, field string) string <span class="cov10" title="25">{
        switch field </span>{
        case "key":<span class="cov0" title="0">
                return metadata.Key</span>
        case "size":<span class="cov5" title="5">
                return fmt.Sprintf("%d", metadata.Size)</span>
        case "content_type":<span class="cov6" title="7">
                return metadata.ContentType</span>
        case "hash":<span class="cov4" title="4">
                return metadata.Hash</span>
        case "version":<span class="cov0" title="0">
                return metadata.Version</span>
        case "created_at":<span class="cov4" title="4">
                return metadata.CreatedAt.Format(time.RFC3339)</span>
        case "updated_at":<span class="cov4" title="4">
                return metadata.UpdatedAt.Format(time.RFC3339)</span>
        case "accessed_at":<span class="cov0" title="0">
                return metadata.AccessedAt.Format(time.RFC3339)</span>
        default:<span class="cov1" title="1">
                if metadata.Attributes != nil </span><span class="cov1" title="1">{
                        if value, exists := metadata.Attributes[field]; exists </span><span class="cov1" title="1">{
                                return fmt.Sprintf("%v", value)
                        }</span>
                }
                <span class="cov0" title="0">return ""</span>
        }
}

func (mm *MetadataManager) isFieldIndexed(index *MetadataIndex, field string) bool <span class="cov1" title="1">{
        for _, indexField := range index.Fields </span><span class="cov1" title="1">{
                if indexField == field </span><span class="cov1" title="1">{
                        return true
                }</span>
        }
        <span class="cov0" title="0">return false</span>
}

func (mm *MetadataManager) getKeysFromIndex(index *MetadataIndex, condition *QueryCondition) []string <span class="cov1" title="1">{
        value := fmt.Sprintf("%v", condition.Value)
        
        switch condition.Operator </span>{
        case "eq":<span class="cov1" title="1">
                if keys, exists := index.Values[value]; exists </span><span class="cov1" title="1">{
                        return keys
                }</span>
                <span class="cov0" title="0">return []string{}</span>
        case "ne":<span class="cov0" title="0">
                var allKeys []string
                for v, keys := range index.Values </span><span class="cov0" title="0">{
                        if v != value </span><span class="cov0" title="0">{
                                allKeys = append(allKeys, keys...)
                        }</span>
                }
                <span class="cov0" title="0">return allKeys</span>
        default:<span class="cov0" title="0">
                // For other operators, return all keys for full evaluation
                var allKeys []string
                for _, keys := range index.Values </span><span class="cov0" title="0">{
                        allKeys = append(allKeys, keys...)
                }</span>
                <span class="cov0" title="0">return allKeys</span>
        }
}

func (mm *MetadataManager) intersectKeys(keys1, keys2 []string) []string <span class="cov0" title="0">{
        keyMap := make(map[string]bool)
        for _, key := range keys1 </span><span class="cov0" title="0">{
                keyMap[key] = true
        }</span>
        
        <span class="cov0" title="0">var result []string
        for _, key := range keys2 </span><span class="cov0" title="0">{
                if keyMap[key] </span><span class="cov0" title="0">{
                        result = append(result, key)
                }</span>
        }
        
        <span class="cov0" title="0">return result</span>
}

func (mm *MetadataManager) matchesQuery(metadata *ObjectMetadata, query *MetadataQuery) bool <span class="cov2" title="2">{
        for _, condition := range query.Conditions </span><span class="cov2" title="2">{
                if !mm.matchesCondition(metadata, condition) </span><span class="cov0" title="0">{
                        return false
                }</span>
        }
        
        // TODO: Implement full-text search
        <span class="cov2" title="2">if query.FullText != "" </span><span class="cov0" title="0">{
                // Simplified full-text search
                searchText := strings.ToLower(query.FullText)
                if !strings.Contains(strings.ToLower(metadata.Key), searchText) &amp;&amp;
                   !strings.Contains(strings.ToLower(metadata.ContentType), searchText) </span><span class="cov0" title="0">{
                        return false
                }</span>
        }
        
        <span class="cov2" title="2">return true</span>
}

func (mm *MetadataManager) matchesCondition(metadata *ObjectMetadata, condition *QueryCondition) bool <span class="cov2" title="2">{
        fieldValue := mm.extractFieldValue(metadata, condition.Field)
        conditionValue := fmt.Sprintf("%v", condition.Value)
        
        switch condition.Operator </span>{
        case "eq":<span class="cov2" title="2">
                return fieldValue == conditionValue</span>
        case "ne":<span class="cov0" title="0">
                return fieldValue != conditionValue</span>
        case "like":<span class="cov0" title="0">
                return strings.Contains(strings.ToLower(fieldValue), strings.ToLower(conditionValue))</span>
        case "gt", "gte", "lt", "lte":<span class="cov0" title="0">
                // Numeric comparison (simplified)
                return mm.compareValues(fieldValue, conditionValue, condition.Operator)</span>
        case "in":<span class="cov0" title="0">
                // TODO: Implement IN operator
                return false</span>
        default:<span class="cov0" title="0">
                return false</span>
        }
}

func (mm *MetadataManager) compareValues(value1, value2, operator string) bool <span class="cov0" title="0">{
        // Simplified comparison (would need proper type handling)
        switch operator </span>{
        case "gt":<span class="cov0" title="0">
                return value1 &gt; value2</span>
        case "gte":<span class="cov0" title="0">
                return value1 &gt;= value2</span>
        case "lt":<span class="cov0" title="0">
                return value1 &lt; value2</span>
        case "lte":<span class="cov0" title="0">
                return value1 &lt;= value2</span>
        default:<span class="cov0" title="0">
                return false</span>
        }
}

func (mm *MetadataManager) compareMetadata(m1, m2 *ObjectMetadata, sort *SortOptions) bool <span class="cov0" title="0">{
        value1 := mm.extractFieldValue(m1, sort.Field)
        value2 := mm.extractFieldValue(m2, sort.Field)
        
        if sort.Order == "desc" </span><span class="cov0" title="0">{
                return value1 &gt; value2
        }</span>
        <span class="cov0" title="0">return value1 &lt; value2</span>
}

func (mm *MetadataManager) explainQuery(query *MetadataQuery, indexUsed string) string <span class="cov2" title="2">{
        if indexUsed != "" </span><span class="cov1" title="1">{
                return fmt.Sprintf("Used index: %s", indexUsed)
        }</span>
        <span class="cov1" title="1">return "Full table scan"</span>
}

// Statistics methods

func (mm *MetadataManager) updateLatencyStats(operation string, latency time.Duration) <span class="cov9" title="24">{
        mm.statsMutex.Lock()
        defer mm.statsMutex.Unlock()
        
        latencyMs := latency.Milliseconds()
        
        var stats *LatencyStats
        switch operation </span>{
        case "get":<span class="cov6" title="6">
                stats = mm.stats.Performance.GetLatency</span>
        case "set":<span class="cov4" title="3">
                stats = mm.stats.Performance.SetLatency</span>
        case "search":<span class="cov2" title="2">
                stats = mm.stats.Performance.SearchLatency</span>
        case "index":<span class="cov7" title="11">
                stats = mm.stats.Performance.IndexLatency</span>
        default:<span class="cov2" title="2">
                return</span>
        }
        
        <span class="cov9" title="22">if stats.Samples == 0 </span><span class="cov6" title="7">{
                stats.Min = latencyMs
                stats.Max = latencyMs
                stats.Mean = float64(latencyMs)
        }</span> else<span class="cov8" title="15"> {
                if latencyMs &lt; stats.Min </span><span class="cov1" title="1">{
                        stats.Min = latencyMs
                }</span>
                <span class="cov8" title="15">if latencyMs &gt; stats.Max </span><span class="cov0" title="0">{
                        stats.Max = latencyMs
                }</span>
                <span class="cov8" title="15">stats.Mean = (stats.Mean*float64(stats.Samples) + float64(latencyMs)) / float64(stats.Samples+1)</span>
        }
        
        <span class="cov9" title="22">stats.Samples++</span>
}

func (mm *MetadataManager) incrementOperationCount(operation string) <span class="cov9" title="24">{
        mm.statsMutex.Lock()
        defer mm.statsMutex.Unlock()
        
        mm.stats.OperationCounts[operation]++
}</span>

func (mm *MetadataManager) incrementCacheHits() <span class="cov5" title="5">{
        mm.statsMutex.Lock()
        defer mm.statsMutex.Unlock()
        
        mm.stats.CacheHits++
}</span>

func (mm *MetadataManager) incrementCacheMisses() <span class="cov1" title="1">{
        mm.statsMutex.Lock()
        defer mm.statsMutex.Unlock()
        
        mm.stats.CacheMisses++
}</span>

// Background routines

func (mm *MetadataManager) syncRoutine() <span class="cov2" title="2">{
        if mm.config.SyncInterval &lt;= 0 </span><span class="cov1" title="1">{
                return
        }</span>
        
        <span class="cov1" title="1">ticker := time.NewTicker(mm.config.SyncInterval)
        defer ticker.Stop()
        
        for </span><span class="cov1" title="1">{
                select </span>{
                case &lt;-mm.ctx.Done():<span class="cov1" title="1">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        mm.performSync()</span>
                }
        }
}

func (mm *MetadataManager) compactionRoutine() <span class="cov2" title="2">{
        if mm.config.CompactInterval &lt;= 0 </span><span class="cov1" title="1">{
                return
        }</span>
        
        <span class="cov1" title="1">ticker := time.NewTicker(mm.config.CompactInterval)
        defer ticker.Stop()
        
        for </span><span class="cov1" title="1">{
                select </span>{
                case &lt;-mm.ctx.Done():<span class="cov1" title="1">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        mm.performCompaction()</span>
                }
        }
}

func (mm *MetadataManager) cacheMaintenanceRoutine() <span class="cov2" title="2">{
        ticker := time.NewTicker(5 * time.Minute)
        defer ticker.Stop()
        
        for </span><span class="cov2" title="2">{
                select </span>{
                case &lt;-mm.ctx.Done():<span class="cov2" title="2">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        mm.performCacheMaintenance()</span>
                }
        }
}

func (mm *MetadataManager) statsCollectionRoutine() <span class="cov2" title="2">{
        ticker := time.NewTicker(1 * time.Minute)
        defer ticker.Stop()
        
        for </span><span class="cov2" title="2">{
                select </span>{
                case &lt;-mm.ctx.Done():<span class="cov2" title="2">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        mm.collectStats()</span>
                }
        }
}

func (mm *MetadataManager) performSync() <span class="cov0" title="0">{
        if mm.levelDB != nil </span>{<span class="cov0" title="0">
                // Force sync to disk
                // LevelDB doesn't have explicit sync, but compaction helps
        }</span>
        
        <span class="cov0" title="0">mm.statsMutex.Lock()
        mm.stats.LastSync = time.Now()
        mm.statsMutex.Unlock()</span>
}

func (mm *MetadataManager) performCompaction() <span class="cov0" title="0">{
        if mm.levelDB != nil </span><span class="cov0" title="0">{
                // Compact database
                mm.levelDB.CompactRange(util.Range{})
        }</span>
        
        <span class="cov0" title="0">mm.statsMutex.Lock()
        mm.stats.LastCompaction = time.Now()
        mm.statsMutex.Unlock()</span>
}

func (mm *MetadataManager) performCacheMaintenance() <span class="cov0" title="0">{
        mm.cacheMutex.Lock()
        defer mm.cacheMutex.Unlock()
        
        // Remove stale cache entries
        cutoff := time.Now().Add(-1 * time.Hour)
        for key, cached := range mm.cache </span><span class="cov0" title="0">{
                if cached.LastAccess.Before(cutoff) &amp;&amp; cached.AccessCount &lt; 5 </span><span class="cov0" title="0">{
                        delete(mm.cache, key)
                        mm.cacheSize--
                }</span>
        }
}

func (mm *MetadataManager) collectStats() <span class="cov0" title="0">{
        // Update cache statistics
        mm.cacheMutex.RLock()
        cacheSize := len(mm.cache)
        mm.cacheMutex.RUnlock()
        
        mm.logger.Debug("metadata stats", "cache_size", cacheSize, "total_objects", mm.stats.TotalObjects)
}</span>

// FileSystemMetadata implementation

func (fsm *FileSystemMetadata) store(key string, data []byte) error <span class="cov4" title="3">{
        safePath := strings.ReplaceAll(key, "/", string(filepath.Separator))
        metaPath := filepath.Join(fsm.basePath, safePath+".meta")
        
        if err := os.MkdirAll(filepath.Dir(metaPath), 0755); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        <span class="cov4" title="3">return os.WriteFile(metaPath, data, 0644)</span>
}

func (fsm *FileSystemMetadata) load(key string) ([]byte, error) <span class="cov1" title="1">{
        safePath := strings.ReplaceAll(key, "/", string(filepath.Separator))
        metaPath := filepath.Join(fsm.basePath, safePath+".meta")
        
        data, err := os.ReadFile(metaPath)
        if err != nil </span><span class="cov1" title="1">{
                if os.IsNotExist(err) </span><span class="cov1" title="1">{
                        return nil, &amp;StorageError{
                                Code:    ErrCodeNotFound,
                                Message: "metadata not found",
                        }
                }</span>
                <span class="cov0" title="0">return nil, err</span>
        }
        
        <span class="cov0" title="0">return data, nil</span>
}

func (fsm *FileSystemMetadata) delete(key string) error <span class="cov1" title="1">{
        safePath := strings.ReplaceAll(key, "/", string(filepath.Separator))
        metaPath := filepath.Join(fsm.basePath, safePath+".meta")
        
        err := os.Remove(metaPath)
        if err != nil &amp;&amp; !os.IsNotExist(err) </span><span class="cov0" title="0">{
                return err
        }</span>
        
        <span class="cov1" title="1">return nil</span>
}

func (fsm *FileSystemMetadata) list(prefix string, options *ListOptions) ([]*ObjectMetadata, error) <span class="cov8" title="13">{
        var results []*ObjectMetadata
        
        err := filepath.Walk(fsm.basePath, func(path string, info os.FileInfo, err error) error </span><span class="cov10" title="25">{
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                
                <span class="cov10" title="25">if info.IsDir() || !strings.HasSuffix(path, ".meta") </span><span class="cov9" title="21">{
                        return nil
                }</span>
                
                // Extract key
                <span class="cov4" title="4">relPath, err := filepath.Rel(fsm.basePath, path)
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                
                <span class="cov4" title="4">key := strings.TrimSuffix(relPath, ".meta")
                key = strings.ReplaceAll(key, string(filepath.Separator), "/")
                
                if prefix != "" &amp;&amp; !strings.HasPrefix(key, prefix) </span><span class="cov0" title="0">{
                        return nil
                }</span>
                
                // Load metadata
                <span class="cov4" title="4">data, err := os.ReadFile(path)
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                
                <span class="cov4" title="4">var metadata ObjectMetadata
                if err := json.Unmarshal(data, &amp;metadata); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                
                <span class="cov4" title="4">results = append(results, &amp;metadata)
                
                if options != nil &amp;&amp; options.Limit &gt; 0 &amp;&amp; len(results) &gt;= options.Limit </span><span class="cov0" title="0">{
                        return filepath.SkipDir
                }</span>
                
                <span class="cov4" title="4">return nil</span>
        })
        
        <span class="cov8" title="13">return results, err</span>
}</pre>
		
		<pre class="file" id="file14" style="display: none">package storage

import (
        "context"
        "fmt"
        "log/slog"
        "math/rand"
        "sort"
        "sync"
        "time"
)

// ReplicationEngine manages data replication across storage nodes
type ReplicationEngine struct {
        logger *slog.Logger
        
        // Storage and node management
        localStorage Storage
        nodeManager  *NodeManager
        
        // Replication coordination
        coordinator *ReplicationCoordinator
        
        // Replication strategies
        strategies map[string]ReplicationStrategy
        
        // Configuration
        config *ReplicationConfig
        
        // Monitoring and health
        health      *ReplicationHealth
        healthMutex sync.RWMutex
        
        // Background tasks
        ctx     context.Context
        cancel  context.CancelFunc
        started bool
        mu      sync.RWMutex
}

// ReplicationConfig contains configuration for replication
type ReplicationConfig struct {
        DefaultStrategy      string        `json:"default_strategy"`
        MinReplicas         int           `json:"min_replicas"`
        MaxReplicas         int           `json:"max_replicas"`
        ReplicationFactor   int           `json:"replication_factor"`
        ConsistencyLevel    string        `json:"consistency_level"`
        SyncTimeout         time.Duration `json:"sync_timeout"`
        HealthCheckInterval time.Duration `json:"health_check_interval"`
        MaxConcurrentSyncs  int           `json:"max_concurrent_syncs"`
        RetryAttempts       int           `json:"retry_attempts"`
        RetryDelay          time.Duration `json:"retry_delay"`
        QuorumSize          int           `json:"quorum_size"`
        EnableAsyncRepl     bool          `json:"enable_async_replication"`
        EnableCompression   bool          `json:"enable_compression"`
        BandwidthLimit      int64         `json:"bandwidth_limit_bps"`
}

// NodeManager manages storage nodes in the cluster
type NodeManager struct {
        logger *slog.Logger
        
        // Node registry
        nodes      map[string]*StorageNode
        nodesMutex sync.RWMutex
        
        // Node selection and ranking
        selector *NodeSelector
        
        // Health monitoring
        healthChecker *NodeHealthChecker
        
        // Configuration
        config *NodeManagerConfig
}

// NodeManagerConfig contains configuration for node management
type NodeManagerConfig struct {
        HeartbeatInterval   time.Duration `json:"heartbeat_interval"`
        FailureTimeout      time.Duration `json:"failure_timeout"`
        MaxFailures         int           `json:"max_failures"`
        EnableLoadBalancing bool          `json:"enable_load_balancing"`
        PreferLocalReplicas bool          `json:"prefer_local_replicas"`
}

// StorageNode represents a storage node in the cluster
type StorageNode struct {
        ID           string                 `json:"id"`
        Address      string                 `json:"address"`
        Port         int                    `json:"port"`
        Region       string                 `json:"region"`
        Zone         string                 `json:"zone"`
        Datacenter   string                 `json:"datacenter"`
        Capabilities []string               `json:"capabilities"`
        Capacity     *NodeCapacity          `json:"capacity"`
        Health       *NodeHealthStatus      `json:"health"`
        Metadata     map[string]interface{} `json:"metadata"`
        
        // Runtime state
        Status       string    `json:"status"`
        LastSeen     time.Time `json:"last_seen"`
        JoinedAt     time.Time `json:"joined_at"`
        FailureCount int       `json:"failure_count"`
        
        // Performance metrics
        Latency      time.Duration `json:"latency"`
        Bandwidth    int64         `json:"bandwidth"`
        LoadFactor   float64       `json:"load_factor"`
        
        // Connection state
        Connected    bool      `json:"connected"`
        LastPing     time.Time `json:"last_ping"`
        
        mutex sync.RWMutex
}

// NodeCapacity represents node storage capacity
type NodeCapacity struct {
        TotalBytes     int64   `json:"total_bytes"`
        UsedBytes      int64   `json:"used_bytes"`
        AvailableBytes int64   `json:"available_bytes"`
        UsagePercent   float64 `json:"usage_percent"`
        ObjectCount    int64   `json:"object_count"`
}

// NodeHealthStatus represents node health information
type NodeHealthStatus struct {
        Status         string            `json:"status"` // healthy, degraded, unhealthy, down
        LastCheck      time.Time         `json:"last_check"`
        Checks         map[string]bool   `json:"checks"`
        Errors         []string          `json:"errors"`
        Warnings       []string          `json:"warnings"`
        ResponseTime   time.Duration     `json:"response_time"`
        SuccessRate    float64           `json:"success_rate"`
        TotalRequests  int64             `json:"total_requests"`
        FailedRequests int64             `json:"failed_requests"`
}

// ReplicationCoordinator coordinates replication operations
type ReplicationCoordinator struct {
        engine *ReplicationEngine
        logger *slog.Logger
        
        // Operation queues
        replicationQueue chan *ReplicationOperation
        syncQueue        chan *SyncOperation
        
        // Worker pools
        replWorkers []*ReplicationEngineWorker
        syncWorkers []*SyncWorker
        
        // Operation tracking
        operations      map[string]*ReplicationOperation
        operationsMutex sync.RWMutex
        
        ctx    context.Context
        cancel context.CancelFunc
}

// ReplicationOperation represents a replication operation
type ReplicationOperation struct {
        ID            string              `json:"id"`
        Type          string              `json:"type"` // replicate, sync, remove, verify
        Key           string              `json:"key"`
        SourceNode    string              `json:"source_node"`
        TargetNodes   []string            `json:"target_nodes"`
        Strategy      string              `json:"strategy"`
        Priority      int                 `json:"priority"`
        Status        string              `json:"status"`
        Progress      float64             `json:"progress"`
        BytesTotal    int64               `json:"bytes_total"`
        BytesReplicated int64             `json:"bytes_replicated"`
        StartTime     time.Time           `json:"start_time"`
        EndTime       time.Time           `json:"end_time"`
        Error         string              `json:"error,omitempty"`
        RetryCount    int                 `json:"retry_count"`
        Metadata      map[string]interface{} `json:"metadata"`
        
        // Channels for coordination
        ResultChan chan error `json:"-"`
        CancelChan chan struct{} `json:"-"`
}

// SyncOperation represents a data synchronization operation
type SyncOperation struct {
        ID          string    `json:"id"`
        Key         string    `json:"key"`
        SourceNode  string    `json:"source_node"`
        TargetNode  string    `json:"target_node"`
        SyncType    string    `json:"sync_type"` // full, incremental, checksum
        Status      string    `json:"status"`
        StartTime   time.Time `json:"start_time"`
        EndTime     time.Time `json:"end_time"`
        Error       string    `json:"error,omitempty"`
        Checksum    string    `json:"checksum"`
        BytesTransferred int64 `json:"bytes_transferred"`
}

// ReplicationStrategy defines how data should be replicated
type ReplicationStrategy interface {
        GetName() string
        SelectTargetNodes(sourceNode string, nodes []*StorageNode, policy *ReplicationPolicy) ([]*StorageNode, error)
        GetReplicationOrder(sourceNode string, targetNodes []*StorageNode) []*StorageNode
        ShouldReplicate(key string, metadata *ObjectMetadata, policy *ReplicationPolicy) bool
        GetConsistencyLevel() string
}

// EagerReplicationStrategy implements eager replication
type EagerReplicationStrategy struct {
        config *ReplicationConfig
}

// LazyReplicationStrategy implements lazy replication
type LazyReplicationStrategy struct {
        config *ReplicationConfig
}

// GeographicReplicationStrategy implements geographic replication
type GeographicReplicationStrategy struct {
        config         *ReplicationConfig
        regionPriority map[string]int
}

// ReplicationEngineWorker handles replication tasks
type ReplicationEngineWorker struct {
        id          int
        coordinator *ReplicationCoordinator
        logger      *slog.Logger
        
        ctx    context.Context
        cancel context.CancelFunc
}

// SyncWorker handles synchronization tasks
type SyncWorker struct {
        id          int
        coordinator *ReplicationCoordinator
        logger      *slog.Logger
        
        ctx    context.Context
        cancel context.CancelFunc
}

// NodeSelector selects optimal nodes for replication
type NodeSelector struct {
        manager *NodeManager
        logger  *slog.Logger
        
        // Selection strategies
        strategies map[string]SelectionStrategy
}

// SelectionStrategy defines node selection algorithms
type SelectionStrategy interface {
        SelectNodes(availableNodes []*StorageNode, count int, constraints map[string]interface{}) ([]*StorageNode, error)
}

// LoadBalancedSelection implements load-balanced node selection
type LoadBalancedSelection struct{}

// GeographicSelection implements geographic-aware node selection
type GeographicSelection struct {
        preferredRegions []string
}

// CapacityBasedSelection implements capacity-based node selection
type CapacityBasedSelection struct{}

// NodeHealthChecker monitors node health
type NodeHealthChecker struct {
        manager *NodeManager
        logger  *slog.Logger
        
        // Health check configuration
        interval time.Duration
        timeout  time.Duration
        
        ctx    context.Context
        cancel context.CancelFunc
}

// ReplicationHealth tracks overall replication health
type ReplicationHealth struct {
        OverallStatus     string                 `json:"overall_status"`
        HealthyNodes      int                    `json:"healthy_nodes"`
        TotalNodes        int                    `json:"total_nodes"`
        ActiveOperations  int                    `json:"active_operations"`
        FailedOperations  int                    `json:"failed_operations"`
        ReplicationLag    time.Duration          `json:"replication_lag"`
        ConsistencyScore  float64                `json:"consistency_score"`
        ThroughputBPS     int64                  `json:"throughput_bps"`
        ErrorRate         float64                `json:"error_rate"`
        LastHealthCheck   time.Time              `json:"last_health_check"`
        RegionHealth      map[string]RegionHealth `json:"region_health"`
}

// RegionHealth tracks health per region
type RegionHealth struct {
        Region        string  `json:"region"`
        HealthyNodes  int     `json:"healthy_nodes"`
        TotalNodes    int     `json:"total_nodes"`
        AverageLatency time.Duration `json:"average_latency"`
        Status        string  `json:"status"`
}

// NewReplicationEngine creates a new replication engine
func NewReplicationEngine(
        localStorage Storage,
        config *ReplicationConfig,
        logger *slog.Logger,
) (*ReplicationEngine, error) <span class="cov1" title="1">{
        ctx, cancel := context.WithCancel(context.Background())
        
        // Create node manager
        nodeManager, err := NewNodeManager(&amp;NodeManagerConfig{
                HeartbeatInterval:   30 * time.Second,
                FailureTimeout:      2 * time.Minute,
                MaxFailures:         3,
                EnableLoadBalancing: true,
                PreferLocalReplicas: true,
        }, logger)
        if err != nil </span><span class="cov0" title="0">{
                cancel()
                return nil, fmt.Errorf("failed to create node manager: %w", err)
        }</span>
        
        <span class="cov1" title="1">re := &amp;ReplicationEngine{
                logger:      logger,
                localStorage: localStorage,
                nodeManager: nodeManager,
                strategies:  make(map[string]ReplicationStrategy),
                config:      config,
                health: &amp;ReplicationHealth{
                        RegionHealth: make(map[string]RegionHealth),
                },
                ctx:    ctx,
                cancel: cancel,
        }
        
        // Create coordinator
        re.coordinator = &amp;ReplicationCoordinator{
                engine:           re,
                logger:           logger,
                replicationQueue: make(chan *ReplicationOperation, 1000),
                syncQueue:        make(chan *SyncOperation, 1000),
                operations:       make(map[string]*ReplicationOperation),
                ctx:              ctx,
                cancel:           cancel,
        }
        
        // Register default strategies
        re.registerDefaultStrategies()
        
        return re, nil</span>
}

// Start starts the replication engine
func (re *ReplicationEngine) Start(ctx context.Context) error <span class="cov1" title="1">{
        re.mu.Lock()
        defer re.mu.Unlock()
        
        if re.started </span><span class="cov0" title="0">{
                return fmt.Errorf("replication engine already started")
        }</span>
        
        // Start node manager
        <span class="cov1" title="1">if err := re.nodeManager.Start(ctx); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start node manager: %w", err)
        }</span>
        
        // Start coordinator
        <span class="cov1" title="1">if err := re.coordinator.Start(ctx); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start coordinator: %w", err)
        }</span>
        
        // Start background routines
        <span class="cov1" title="1">go re.healthMonitorRoutine()
        go re.maintenanceRoutine()
        
        re.started = true
        re.logger.Info("replication engine started")
        
        return nil</span>
}

// Stop stops the replication engine
func (re *ReplicationEngine) Stop(ctx context.Context) error <span class="cov1" title="1">{
        re.mu.Lock()
        defer re.mu.Unlock()
        
        if !re.started </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        <span class="cov1" title="1">re.cancel()
        
        // Stop coordinator
        if err := re.coordinator.Stop(ctx); err != nil </span><span class="cov0" title="0">{
                re.logger.Error("failed to stop coordinator", "error", err)
        }</span>
        
        // Stop node manager
        <span class="cov1" title="1">if err := re.nodeManager.Stop(ctx); err != nil </span><span class="cov0" title="0">{
                re.logger.Error("failed to stop node manager", "error", err)
        }</span>
        
        <span class="cov1" title="1">re.started = false
        re.logger.Info("replication engine stopped")
        
        return nil</span>
}

// Replicate replicates an object according to policy
func (re *ReplicationEngine) Replicate(ctx context.Context, key string, policy *ReplicationPolicy) error <span class="cov1" title="1">{
        metadata, err := re.localStorage.GetMetadata(ctx, key)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get metadata: %w", err)
        }</span>
        
        // Get replication strategy
        <span class="cov1" title="1">strategy, exists := re.strategies[policy.Strategy]
        if !exists </span><span class="cov0" title="0">{
                strategy = re.strategies[re.config.DefaultStrategy]
        }</span>
        
        // Check if replication is needed
        <span class="cov1" title="1">if !strategy.ShouldReplicate(key, metadata, policy) </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        // Get available nodes
        <span class="cov1" title="1">nodes := re.nodeManager.GetHealthyNodes()
        
        // Select target nodes
        targetNodes, err := strategy.SelectTargetNodes("local", nodes, policy)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to select target nodes: %w", err)
        }</span>
        
        <span class="cov1" title="1">if len(targetNodes) == 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("no suitable target nodes available")
        }</span>
        
        // Create replication operation
        <span class="cov1" title="1">operation := &amp;ReplicationOperation{
                ID:          generateOperationID(),
                Type:        "replicate",
                Key:         key,
                SourceNode:  "local",
                TargetNodes: extractNodeIDs(targetNodes),
                Strategy:    strategy.GetName(),
                Priority:    policy.Priority,
                Status:      "pending",
                Progress:    0.0,
                BytesTotal:  metadata.Size,
                StartTime:   time.Now(),
                ResultChan:  make(chan error, 1),
                CancelChan:  make(chan struct{}),
                Metadata:    make(map[string]interface{}),
        }
        
        // Submit operation
        select </span>{
        case re.coordinator.replicationQueue &lt;- operation:<span class="cov1" title="1"></span>
        case &lt;-ctx.Done():<span class="cov0" title="0">
                return ctx.Err()</span>
        case &lt;-time.After(5 * time.Second):<span class="cov0" title="0">
                return fmt.Errorf("replication queue full")</span>
        }
        
        // Wait for result based on consistency level
        <span class="cov1" title="1">if policy.ConsistencyLevel == "strong" </span><span class="cov1" title="1">{
                select </span>{
                case err := &lt;-operation.ResultChan:<span class="cov1" title="1">
                        return err</span>
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return ctx.Err()</span>
                }
        }
        
        <span class="cov0" title="0">return nil</span>
}

// GetReplicationStatus gets the status of a key's replication
func (re *ReplicationEngine) GetReplicationStatus(ctx context.Context, key string) (*ReplicationStatus, error) <span class="cov1" title="1">{
        // Query all nodes for replica information
        nodes := re.nodeManager.GetHealthyNodes()
        
        status := &amp;ReplicationStatus{
                Key:             key,
                CurrentReplicas: 0,
                HealthyReplicas: 0,
                ReplicaNodes:    []string{},
                SyncStatus:      make(map[string]string),
                LastSync:        time.Now(),
        }
        
        // Check local copy
        if exists, err := re.localStorage.Exists(ctx, key); err == nil &amp;&amp; exists </span><span class="cov1" title="1">{
                status.CurrentReplicas++
                status.HealthyReplicas++
                status.ReplicaNodes = append(status.ReplicaNodes, "local")
                status.SyncStatus["local"] = "healthy"
        }</span>
        
        // Check remote replicas
        <span class="cov1" title="1">for _, node := range nodes </span><span class="cov4" title="2">{
                // TODO: Implement remote existence check
                re.logger.Debug("checking replica on node", "key", key, "node", node.ID)
        }</span>
        
        <span class="cov1" title="1">return status, nil</span>
}

// SynchronizeReplicas synchronizes all replicas of a key
func (re *ReplicationEngine) SynchronizeReplicas(ctx context.Context, key string) error <span class="cov0" title="0">{
        status, err := re.GetReplicationStatus(ctx, key)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        <span class="cov0" title="0">if len(status.ReplicaNodes) &lt;= 1 </span><span class="cov0" title="0">{
                return nil // No replicas to sync
        }</span>
        
        // Create sync operations
        <span class="cov0" title="0">sourceNode := status.ReplicaNodes[0] // Use first healthy replica as source
        
        for _, targetNode := range status.ReplicaNodes[1:] </span><span class="cov0" title="0">{
                syncOp := &amp;SyncOperation{
                        ID:         generateOperationID(),
                        Key:        key,
                        SourceNode: sourceNode,
                        TargetNode: targetNode,
                        SyncType:   "checksum",
                        Status:     "pending",
                        StartTime:  time.Now(),
                }
                
                select </span>{
                case re.coordinator.syncQueue &lt;- syncOp:<span class="cov0" title="0"></span>
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return ctx.Err()</span>
                default:<span class="cov0" title="0">
                        re.logger.Warn("sync queue full", "key", key)</span>
                }
        }
        
        <span class="cov0" title="0">return nil</span>
}

// GetHealth returns replication health status
func (re *ReplicationEngine) GetHealth(ctx context.Context) (*ReplicationHealth, error) <span class="cov1" title="1">{
        re.healthMutex.RLock()
        defer re.healthMutex.RUnlock()
        
        // Create a copy
        health := *re.health
        health.RegionHealth = make(map[string]RegionHealth)
        for k, v := range re.health.RegionHealth </span><span class="cov0" title="0">{
                health.RegionHealth[k] = v
        }</span>
        
        <span class="cov1" title="1">return &amp;health, nil</span>
}

// Node management methods

// AddNode adds a node to the cluster
func (re *ReplicationEngine) AddNode(ctx context.Context, node *StorageNode) error <span class="cov4" title="2">{
        return re.nodeManager.AddNode(ctx, node)
}</span>

// RemoveNode removes a node from the cluster
func (re *ReplicationEngine) RemoveNode(ctx context.Context, nodeID string) error <span class="cov1" title="1">{
        return re.nodeManager.RemoveNode(ctx, nodeID)
}</span>

// GetNodes returns all nodes in the cluster
func (re *ReplicationEngine) GetNodes(ctx context.Context) ([]*StorageNode, error) <span class="cov4" title="2">{
        return re.nodeManager.GetAllNodes(), nil
}</span>

// Private methods

func (re *ReplicationEngine) registerDefaultStrategies() <span class="cov1" title="1">{
        re.strategies["eager"] = &amp;EagerReplicationStrategy{config: re.config}
        re.strategies["lazy"] = &amp;LazyReplicationStrategy{config: re.config}
        re.strategies["geographic"] = &amp;GeographicReplicationStrategy{
                config:         re.config,
                regionPriority: make(map[string]int),
        }
}</span>

func (re *ReplicationEngine) healthMonitorRoutine() <span class="cov1" title="1">{
        ticker := time.NewTicker(re.config.HealthCheckInterval)
        defer ticker.Stop()
        
        for </span><span class="cov1" title="1">{
                select </span>{
                case &lt;-re.ctx.Done():<span class="cov1" title="1">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        re.updateHealth()</span>
                }
        }
}

func (re *ReplicationEngine) maintenanceRoutine() <span class="cov1" title="1">{
        ticker := time.NewTicker(1 * time.Hour)
        defer ticker.Stop()
        
        for </span><span class="cov1" title="1">{
                select </span>{
                case &lt;-re.ctx.Done():<span class="cov1" title="1">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        re.performMaintenance()</span>
                }
        }
}

func (re *ReplicationEngine) updateHealth() <span class="cov0" title="0">{
        re.healthMutex.Lock()
        defer re.healthMutex.Unlock()
        
        nodes := re.nodeManager.GetAllNodes()
        healthyNodes := 0
        totalNodes := len(nodes)
        
        regionStats := make(map[string]*RegionHealth)
        
        for _, node := range nodes </span><span class="cov0" title="0">{
                if node.Health.Status == "healthy" </span><span class="cov0" title="0">{
                        healthyNodes++
                }</span>
                
                // Update region stats
                <span class="cov0" title="0">region := node.Region
                if region == "" </span><span class="cov0" title="0">{
                        region = "default"
                }</span>
                
                <span class="cov0" title="0">if regionStats[region] == nil </span><span class="cov0" title="0">{
                        regionStats[region] = &amp;RegionHealth{
                                Region: region,
                                Status: "healthy",
                        }
                }</span>
                
                <span class="cov0" title="0">regionStats[region].TotalNodes++
                if node.Health.Status == "healthy" </span><span class="cov0" title="0">{
                        regionStats[region].HealthyNodes++
                }</span>
        }
        
        // Update overall health
        <span class="cov0" title="0">re.health.HealthyNodes = healthyNodes
        re.health.TotalNodes = totalNodes
        re.health.LastHealthCheck = time.Now()
        
        if float64(healthyNodes)/float64(totalNodes) &gt;= 0.8 </span><span class="cov0" title="0">{
                re.health.OverallStatus = "healthy"
        }</span> else<span class="cov0" title="0"> if float64(healthyNodes)/float64(totalNodes) &gt;= 0.5 </span><span class="cov0" title="0">{
                re.health.OverallStatus = "degraded"
        }</span> else<span class="cov0" title="0"> {
                re.health.OverallStatus = "unhealthy"
        }</span>
        
        // Update region health
        <span class="cov0" title="0">for region, stats := range regionStats </span><span class="cov0" title="0">{
                if float64(stats.HealthyNodes)/float64(stats.TotalNodes) &gt;= 0.8 </span><span class="cov0" title="0">{
                        stats.Status = "healthy"
                }</span> else<span class="cov0" title="0"> {
                        stats.Status = "degraded"
                }</span>
                <span class="cov0" title="0">re.health.RegionHealth[region] = *stats</span>
        }
}

func (re *ReplicationEngine) performMaintenance() <span class="cov0" title="0">{
        re.logger.Info("performing replication maintenance")
        
        // Clean up completed operations
        re.coordinator.cleanupOperations()
        
        // Check for under-replicated objects
        re.checkUnderReplicatedObjects()
        
        // Rebalance replicas if needed
        re.rebalanceReplicas()
}</span>

func (re *ReplicationEngine) checkUnderReplicatedObjects() <span class="cov0" title="0">{
        // TODO: Implement under-replication detection
        re.logger.Debug("checking for under-replicated objects")
}</span>

func (re *ReplicationEngine) rebalanceReplicas() <span class="cov0" title="0">{
        // TODO: Implement replica rebalancing
        re.logger.Debug("rebalancing replicas")
}</span>

// NodeManager implementation

func NewNodeManager(config *NodeManagerConfig, logger *slog.Logger) (*NodeManager, error) <span class="cov1" title="1">{
        nm := &amp;NodeManager{
                logger: logger,
                nodes:  make(map[string]*StorageNode),
                config: config,
        }
        
        // Create node selector
        nm.selector = &amp;NodeSelector{
                manager:    nm,
                logger:     logger,
                strategies: make(map[string]SelectionStrategy),
        }
        
        // Register selection strategies
        nm.selector.strategies["load_balanced"] = &amp;LoadBalancedSelection{}
        nm.selector.strategies["geographic"] = &amp;GeographicSelection{}
        nm.selector.strategies["capacity_based"] = &amp;CapacityBasedSelection{}
        
        // Create health checker
        nm.healthChecker = &amp;NodeHealthChecker{
                manager:  nm,
                logger:   logger,
                interval: config.HeartbeatInterval,
                timeout:  config.FailureTimeout,
        }
        
        return nm, nil
}</span>

func (nm *NodeManager) Start(ctx context.Context) error <span class="cov1" title="1">{
        // Start health checker
        return nm.healthChecker.Start(ctx)
}</span>

func (nm *NodeManager) Stop(ctx context.Context) error <span class="cov1" title="1">{
        // Stop health checker
        return nm.healthChecker.Stop(ctx)
}</span>

func (nm *NodeManager) AddNode(ctx context.Context, node *StorageNode) error <span class="cov4" title="2">{
        nm.nodesMutex.Lock()
        defer nm.nodesMutex.Unlock()
        
        node.JoinedAt = time.Now()
        node.LastSeen = time.Now()
        node.Status = "joining"
        node.Connected = true
        
        nm.nodes[node.ID] = node
        
        nm.logger.Info("node added", "node_id", node.ID, "address", node.Address)
        
        return nil
}</span>

func (nm *NodeManager) RemoveNode(ctx context.Context, nodeID string) error <span class="cov1" title="1">{
        nm.nodesMutex.Lock()
        defer nm.nodesMutex.Unlock()
        
        if node, exists := nm.nodes[nodeID]; exists </span><span class="cov1" title="1">{
                node.Status = "leaving"
                node.Connected = false
                delete(nm.nodes, nodeID)
                
                nm.logger.Info("node removed", "node_id", nodeID)
        }</span>
        
        <span class="cov1" title="1">return nil</span>
}

func (nm *NodeManager) GetAllNodes() []*StorageNode <span class="cov7" title="4">{
        nm.nodesMutex.RLock()
        defer nm.nodesMutex.RUnlock()
        
        nodes := make([]*StorageNode, 0, len(nm.nodes))
        for _, node := range nm.nodes </span><span class="cov10" title="7">{
                // Create a copy
                nodeCopy := *node
                nodes = append(nodes, &amp;nodeCopy)
        }</span>
        
        <span class="cov7" title="4">return nodes</span>
}

func (nm *NodeManager) GetHealthyNodes() []*StorageNode <span class="cov4" title="2">{
        allNodes := nm.GetAllNodes()
        var healthyNodes []*StorageNode
        
        for _, node := range allNodes </span><span class="cov7" title="4">{
                if node.Health.Status == "healthy" &amp;&amp; node.Connected </span><span class="cov7" title="4">{
                        healthyNodes = append(healthyNodes, node)
                }</span>
        }
        
        <span class="cov4" title="2">return healthyNodes</span>
}

func (nm *NodeManager) SelectNodes(strategy string, count int, constraints map[string]interface{}) ([]*StorageNode, error) <span class="cov0" title="0">{
        return nm.selector.SelectNodes(strategy, count, constraints)
}</span>

// NodeSelector implementation

func (ns *NodeSelector) SelectNodes(strategy string, count int, constraints map[string]interface{}) ([]*StorageNode, error) <span class="cov0" title="0">{
        availableNodes := ns.manager.GetHealthyNodes()
        
        if len(availableNodes) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no healthy nodes available")
        }</span>
        
        <span class="cov0" title="0">selectionStrategy, exists := ns.strategies[strategy]
        if !exists </span><span class="cov0" title="0">{
                selectionStrategy = ns.strategies["load_balanced"]
        }</span>
        
        <span class="cov0" title="0">return selectionStrategy.SelectNodes(availableNodes, count, constraints)</span>
}

// ReplicationCoordinator implementation

func (rc *ReplicationCoordinator) Start(ctx context.Context) error <span class="cov1" title="1">{
        // Start replication workers
        workerCount := rc.engine.config.MaxConcurrentSyncs
        if workerCount &lt;= 0 </span><span class="cov0" title="0">{
                workerCount = 10
        }</span>
        
        <span class="cov1" title="1">rc.replWorkers = make([]*ReplicationEngineWorker, workerCount)
        for i := 0; i &lt; workerCount; i++ </span><span class="cov8" title="5">{
                worker := &amp;ReplicationEngineWorker{
                        id:          i,
                        coordinator: rc,
                        logger:      rc.logger,
                        ctx:         ctx,
                }
                rc.replWorkers[i] = worker
                go worker.start()
        }</span>
        
        // Start sync workers
        <span class="cov1" title="1">rc.syncWorkers = make([]*SyncWorker, workerCount/2)
        for i := 0; i &lt; workerCount/2; i++ </span><span class="cov4" title="2">{
                worker := &amp;SyncWorker{
                        id:          i,
                        coordinator: rc,
                        logger:      rc.logger,
                        ctx:         ctx,
                }
                rc.syncWorkers[i] = worker
                go worker.start()
        }</span>
        
        <span class="cov1" title="1">return nil</span>
}

func (rc *ReplicationCoordinator) Stop(ctx context.Context) error <span class="cov1" title="1">{
        rc.cancel()
        return nil
}</span>

func (rc *ReplicationCoordinator) cleanupOperations() <span class="cov0" title="0">{
        rc.operationsMutex.Lock()
        defer rc.operationsMutex.Unlock()
        
        cutoff := time.Now().Add(-1 * time.Hour)
        for id, op := range rc.operations </span><span class="cov0" title="0">{
                if op.EndTime.Before(cutoff) &amp;&amp; (op.Status == "completed" || op.Status == "failed") </span><span class="cov0" title="0">{
                        delete(rc.operations, id)
                }</span>
        }
}

// ReplicationEngineWorker implementation

func (rw *ReplicationEngineWorker) start() <span class="cov8" title="5">{
        rw.logger.Info("replication worker started", "worker_id", rw.id)
        
        for </span><span class="cov9" title="6">{
                select </span>{
                case &lt;-rw.ctx.Done():<span class="cov0" title="0">
                        rw.logger.Info("replication worker stopped", "worker_id", rw.id)
                        return</span>
                case operation := &lt;-rw.coordinator.replicationQueue:<span class="cov1" title="1">
                        rw.processReplication(operation)</span>
                }
        }
}

func (rw *ReplicationEngineWorker) processReplication(operation *ReplicationOperation) <span class="cov1" title="1">{
        rw.logger.Info("processing replication", "worker_id", rw.id, "operation_id", operation.ID, "key", operation.Key)
        
        operation.Status = "in_progress"
        
        // Track operation
        rw.coordinator.operationsMutex.Lock()
        rw.coordinator.operations[operation.ID] = operation
        rw.coordinator.operationsMutex.Unlock()
        
        // Simulate replication work
        err := rw.performReplication(operation)
        
        // Update operation status
        if err != nil </span><span class="cov0" title="0">{
                operation.Status = "failed"
                operation.Error = err.Error()
                rw.logger.Error("replication failed", "worker_id", rw.id, "operation_id", operation.ID, "error", err)
        }</span> else<span class="cov1" title="1"> {
                operation.Status = "completed"
                operation.Progress = 100.0
                rw.logger.Info("replication completed", "worker_id", rw.id, "operation_id", operation.ID)
        }</span>
        
        <span class="cov1" title="1">operation.EndTime = time.Now()
        
        // Send result
        select </span>{
        case operation.ResultChan &lt;- err:<span class="cov1" title="1"></span>
        default:<span class="cov0" title="0"></span>
        }
}

func (rw *ReplicationEngineWorker) performReplication(operation *ReplicationOperation) error <span class="cov1" title="1">{
        // TODO: Implement actual replication logic
        // This would involve:
        // 1. Reading data from source
        // 2. Transferring to target nodes
        // 3. Verifying transfer integrity
        // 4. Updating progress
        
        // Simulate work
        time.Sleep(100 * time.Millisecond)
        
        return nil
}</span>

// SyncWorker implementation

func (sw *SyncWorker) start() <span class="cov4" title="2">{
        sw.logger.Info("sync worker started", "worker_id", sw.id)
        
        for </span><span class="cov4" title="2">{
                select </span>{
                case &lt;-sw.ctx.Done():<span class="cov0" title="0">
                        sw.logger.Info("sync worker stopped", "worker_id", sw.id)
                        return</span>
                case operation := &lt;-sw.coordinator.syncQueue:<span class="cov0" title="0">
                        sw.processSync(operation)</span>
                }
        }
}

func (sw *SyncWorker) processSync(operation *SyncOperation) <span class="cov0" title="0">{
        sw.logger.Info("processing sync", "worker_id", sw.id, "operation_id", operation.ID, "key", operation.Key)
        
        operation.Status = "in_progress"
        
        // TODO: Implement actual sync logic
        time.Sleep(50 * time.Millisecond)
        
        operation.Status = "completed"
        operation.EndTime = time.Now()
}</span>

// Strategy implementations

func (ers *EagerReplicationStrategy) GetName() string <span class="cov1" title="1">{
        return "eager"
}</span>

func (ers *EagerReplicationStrategy) SelectTargetNodes(sourceNode string, nodes []*StorageNode, policy *ReplicationPolicy) ([]*StorageNode, error) <span class="cov1" title="1">{
        if len(nodes) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no nodes available")
        }</span>
        
        // Sort nodes by health and capacity
        <span class="cov1" title="1">sortedNodes := make([]*StorageNode, len(nodes))
        copy(sortedNodes, nodes)
        
        sort.Slice(sortedNodes, func(i, j int) bool </span><span class="cov1" title="1">{
                scoreI := ers.calculateNodeScore(sortedNodes[i])
                scoreJ := ers.calculateNodeScore(sortedNodes[j])
                return scoreI &gt; scoreJ
        }</span>)
        
        // Select top nodes up to MinReplicas
        <span class="cov1" title="1">count := policy.MinReplicas
        if count &gt; len(sortedNodes) </span><span class="cov0" title="0">{
                count = len(sortedNodes)
        }</span>
        
        <span class="cov1" title="1">return sortedNodes[:count], nil</span>
}

func (ers *EagerReplicationStrategy) GetReplicationOrder(sourceNode string, targetNodes []*StorageNode) []*StorageNode <span class="cov0" title="0">{
        // For eager replication, replicate to all nodes in parallel
        return targetNodes
}</span>

func (ers *EagerReplicationStrategy) ShouldReplicate(key string, metadata *ObjectMetadata, policy *ReplicationPolicy) bool <span class="cov1" title="1">{
        // Always replicate in eager strategy
        return true
}</span>

func (ers *EagerReplicationStrategy) GetConsistencyLevel() string <span class="cov0" title="0">{
        return "strong"
}</span>

func (ers *EagerReplicationStrategy) calculateNodeScore(node *StorageNode) float64 <span class="cov4" title="2">{
        score := 0.0
        
        // Health score
        if node.Health.Status == "healthy" </span><span class="cov4" title="2">{
                score += 100.0
        }</span> else<span class="cov0" title="0"> if node.Health.Status == "degraded" </span><span class="cov0" title="0">{
                score += 50.0
        }</span>
        
        // Capacity score
        <span class="cov4" title="2">if node.Capacity != nil </span><span class="cov4" title="2">{
                availableRatio := float64(node.Capacity.AvailableBytes) / float64(node.Capacity.TotalBytes)
                score += availableRatio * 50.0
        }</span>
        
        // Load factor score
        <span class="cov4" title="2">score += (1.0 - node.LoadFactor) * 30.0
        
        return score</span>
}

// GeographicReplicationStrategy implementation

func (grs *GeographicReplicationStrategy) GetName() string <span class="cov0" title="0">{
        return "geographic"
}</span>

func (grs *GeographicReplicationStrategy) SelectTargetNodes(sourceNode string, nodes []*StorageNode, policy *ReplicationPolicy) ([]*StorageNode, error) <span class="cov0" title="0">{
        // Group nodes by region
        regionNodes := make(map[string][]*StorageNode)
        for _, node := range nodes </span><span class="cov0" title="0">{
                region := node.Region
                if region == "" </span><span class="cov0" title="0">{
                        region = "default"
                }</span>
                <span class="cov0" title="0">regionNodes[region] = append(regionNodes[region], node)</span>
        }
        
        <span class="cov0" title="0">var selectedNodes []*StorageNode
        targetCount := policy.MinReplicas
        
        // Select nodes from different regions for geographic distribution
        for _, regionNodeList := range regionNodes </span><span class="cov0" title="0">{
                if len(selectedNodes) &gt;= targetCount </span><span class="cov0" title="0">{
                        break</span>
                }
                
                // Select best node from this region
                <span class="cov0" title="0">if len(regionNodeList) &gt; 0 </span><span class="cov0" title="0">{
                        // Sort by health and capacity
                        sort.Slice(regionNodeList, func(i, j int) bool </span><span class="cov0" title="0">{
                                scoreI := grs.calculateNodeScore(regionNodeList[i])
                                scoreJ := grs.calculateNodeScore(regionNodeList[j])
                                return scoreI &gt; scoreJ
                        }</span>)
                        
                        <span class="cov0" title="0">selectedNodes = append(selectedNodes, regionNodeList[0])</span>
                }
        }
        
        <span class="cov0" title="0">return selectedNodes, nil</span>
}

func (grs *GeographicReplicationStrategy) GetReplicationOrder(sourceNode string, targetNodes []*StorageNode) []*StorageNode <span class="cov0" title="0">{
        return targetNodes
}</span>

func (grs *GeographicReplicationStrategy) ShouldReplicate(key string, metadata *ObjectMetadata, policy *ReplicationPolicy) bool <span class="cov0" title="0">{
        return true
}</span>

func (grs *GeographicReplicationStrategy) GetConsistencyLevel() string <span class="cov0" title="0">{
        return "eventual"
}</span>

func (grs *GeographicReplicationStrategy) calculateNodeScore(node *StorageNode) float64 <span class="cov0" title="0">{
        score := 0.0
        
        // Health score
        if node.Health.Status == "healthy" </span><span class="cov0" title="0">{
                score += 100.0
        }</span> else<span class="cov0" title="0"> if node.Health.Status == "degraded" </span><span class="cov0" title="0">{
                score += 50.0
        }</span>
        
        // Regional priority
        <span class="cov0" title="0">if priority, exists := grs.regionPriority[node.Region]; exists </span><span class="cov0" title="0">{
                score += float64(priority * 10)
        }</span>
        
        <span class="cov0" title="0">return score</span>
}

// LazyReplicationStrategy implementation

func (lrs *LazyReplicationStrategy) GetName() string <span class="cov0" title="0">{
        return "lazy"
}</span>

func (lrs *LazyReplicationStrategy) SelectTargetNodes(sourceNode string, nodes []*StorageNode, policy *ReplicationPolicy) ([]*StorageNode, error) <span class="cov0" title="0">{
        // For lazy replication, select fewer nodes initially
        count := policy.MinReplicas / 2
        if count == 0 </span><span class="cov0" title="0">{
                count = 1
        }</span>
        
        <span class="cov0" title="0">if len(nodes) &lt; count </span><span class="cov0" title="0">{
                count = len(nodes)
        }</span>
        
        // Simple random selection for demonstration
        <span class="cov0" title="0">selectedNodes := make([]*StorageNode, count)
        for i := 0; i &lt; count; i++ </span><span class="cov0" title="0">{
                selectedNodes[i] = nodes[rand.Intn(len(nodes))]
        }</span>
        
        <span class="cov0" title="0">return selectedNodes, nil</span>
}

func (lrs *LazyReplicationStrategy) GetReplicationOrder(sourceNode string, targetNodes []*StorageNode) []*StorageNode <span class="cov0" title="0">{
        return targetNodes
}</span>

func (lrs *LazyReplicationStrategy) ShouldReplicate(key string, metadata *ObjectMetadata, policy *ReplicationPolicy) bool <span class="cov0" title="0">{
        // Replicate based on access patterns or other criteria
        return time.Since(metadata.CreatedAt) &gt; time.Hour
}</span>

func (lrs *LazyReplicationStrategy) GetConsistencyLevel() string <span class="cov0" title="0">{
        return "eventual"
}</span>

// Selection strategy implementations

func (lbs *LoadBalancedSelection) SelectNodes(availableNodes []*StorageNode, count int, constraints map[string]interface{}) ([]*StorageNode, error) <span class="cov0" title="0">{
        if len(availableNodes) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no nodes available")
        }</span>
        
        // Sort by load factor (ascending)
        <span class="cov0" title="0">sortedNodes := make([]*StorageNode, len(availableNodes))
        copy(sortedNodes, availableNodes)
        
        sort.Slice(sortedNodes, func(i, j int) bool </span><span class="cov0" title="0">{
                return sortedNodes[i].LoadFactor &lt; sortedNodes[j].LoadFactor
        }</span>)
        
        <span class="cov0" title="0">if count &gt; len(sortedNodes) </span><span class="cov0" title="0">{
                count = len(sortedNodes)
        }</span>
        
        <span class="cov0" title="0">return sortedNodes[:count], nil</span>
}

func (gs *GeographicSelection) SelectNodes(availableNodes []*StorageNode, count int, constraints map[string]interface{}) ([]*StorageNode, error) <span class="cov0" title="0">{
        // TODO: Implement geographic selection based on regions/zones
        return availableNodes[:min(count, len(availableNodes))], nil
}</span>

func (cbs *CapacityBasedSelection) SelectNodes(availableNodes []*StorageNode, count int, constraints map[string]interface{}) ([]*StorageNode, error) <span class="cov0" title="0">{
        // Sort by available capacity (descending)
        sortedNodes := make([]*StorageNode, len(availableNodes))
        copy(sortedNodes, availableNodes)
        
        sort.Slice(sortedNodes, func(i, j int) bool </span><span class="cov0" title="0">{
                if sortedNodes[i].Capacity == nil || sortedNodes[j].Capacity == nil </span><span class="cov0" title="0">{
                        return false
                }</span>
                <span class="cov0" title="0">return sortedNodes[i].Capacity.AvailableBytes &gt; sortedNodes[j].Capacity.AvailableBytes</span>
        })
        
        <span class="cov0" title="0">if count &gt; len(sortedNodes) </span><span class="cov0" title="0">{
                count = len(sortedNodes)
        }</span>
        
        <span class="cov0" title="0">return sortedNodes[:count], nil</span>
}

// NodeHealthChecker implementation

func (nhc *NodeHealthChecker) Start(ctx context.Context) error <span class="cov1" title="1">{
        nhc.ctx, nhc.cancel = context.WithCancel(ctx)
        
        go nhc.healthCheckRoutine()
        
        nhc.logger.Info("node health checker started")
        return nil
}</span>

func (nhc *NodeHealthChecker) Stop(ctx context.Context) error <span class="cov1" title="1">{
        if nhc.cancel != nil </span><span class="cov1" title="1">{
                nhc.cancel()
        }</span>
        
        <span class="cov1" title="1">nhc.logger.Info("node health checker stopped")
        return nil</span>
}

func (nhc *NodeHealthChecker) healthCheckRoutine() <span class="cov1" title="1">{
        ticker := time.NewTicker(nhc.interval)
        defer ticker.Stop()
        
        for </span><span class="cov1" title="1">{
                select </span>{
                case &lt;-nhc.ctx.Done():<span class="cov1" title="1">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        nhc.checkAllNodes()</span>
                }
        }
}

func (nhc *NodeHealthChecker) checkAllNodes() <span class="cov0" title="0">{
        nodes := nhc.manager.GetAllNodes()
        
        for _, node := range nodes </span><span class="cov0" title="0">{
                go nhc.checkNode(node)
        }</span>
}

func (nhc *NodeHealthChecker) checkNode(node *StorageNode) <span class="cov0" title="0">{
        start := time.Now()
        
        // TODO: Implement actual health checks
        // This would involve network calls to the node
        
        // Simulate health check
        healthy := true
        if time.Since(node.LastSeen) &gt; nhc.timeout </span><span class="cov0" title="0">{
                healthy = false
        }</span>
        
        <span class="cov0" title="0">node.mutex.Lock()
        defer node.mutex.Unlock()
        
        node.Health.LastCheck = time.Now()
        node.Health.ResponseTime = time.Since(start)
        
        if healthy </span><span class="cov0" title="0">{
                node.Health.Status = "healthy"
                node.Connected = true
                node.LastSeen = time.Now()
                node.FailureCount = 0
        }</span> else<span class="cov0" title="0"> {
                node.FailureCount++
                if node.FailureCount &gt;= nhc.manager.config.MaxFailures </span><span class="cov0" title="0">{
                        node.Health.Status = "unhealthy"
                        node.Connected = false
                }</span> else<span class="cov0" title="0"> {
                        node.Health.Status = "degraded"
                }</span>
        }
}

// Utility functions

func generateOperationID() string <span class="cov1" title="1">{
        return fmt.Sprintf("op_%d_%d", time.Now().UnixNano(), rand.Intn(10000))
}</span>

func extractNodeIDs(nodes []*StorageNode) []string <span class="cov1" title="1">{
        ids := make([]string, len(nodes))
        for i, node := range nodes </span><span class="cov4" title="2">{
                ids[i] = node.ID
        }</span>
        <span class="cov1" title="1">return ids</span>
}

func min(a, b int) int <span class="cov0" title="0">{
        if a &lt; b </span><span class="cov0" title="0">{
                return a
        }</span>
        <span class="cov0" title="0">return b</span>
}</pre>
		
		<pre class="file" id="file15" style="display: none">package api

import (
        "context"
        "fmt"
        "log/slog"
        "net/http"
        "os"
        "strings"

        "github.com/gin-gonic/gin"
        "github.com/ollama/ollama-distributed/pkg/integration"
        "github.com/ollama/ollama-distributed/pkg/models"
        "github.com/ollama/ollama-distributed/pkg/scheduler"
)

// ServerWrapper wraps the original server to implement integration.Server interface
type ServerWrapper struct {
        originalServer interface{}
}

func (sw *ServerWrapper) GenerateRoutes(registry *integration.Registry) (http.Handler, error) <span class="cov0" title="0">{
        // Return a basic handler for compatibility
        return http.DefaultServeMux, nil
}</span>

func (sw *ServerWrapper) Start(ctx context.Context) error <span class="cov0" title="0">{
        // If the original server has a Start method, call it
        if starter, ok := sw.originalServer.(interface{ Start(context.Context) error }); ok </span><span class="cov0" title="0">{
                return starter.Start(ctx)
        }</span>
        <span class="cov0" title="0">return nil</span>
}

func (sw *ServerWrapper) Stop(ctx context.Context) error <span class="cov0" title="0">{
        // If the original server has a Stop method, call it
        if stopper, ok := sw.originalServer.(interface{ Stop(context.Context) error }); ok </span><span class="cov0" title="0">{
                return stopper.Stop(ctx)
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DistributedServerWrapper wraps the original Ollama server with distributed capabilities
type DistributedServerWrapper struct {
        // Original server components (using interface for compatibility)
        originalServer interface{}
        
        // Distributed components
        distributedRoutes *DistributedRoutes
        scheduler         *scheduler.Engine
        modelDistribution *models.Manager
        
        // Configuration
        distributedEnabled bool
        fallbackEnabled    bool
        localAddr          string
}

// NewDistributedServerWrapper creates a new wrapper for the original server
func NewDistributedServerWrapper(originalServer interface{}, scheduler *scheduler.Engine, modelDist *models.Manager, localAddr string) (*DistributedServerWrapper, error) <span class="cov0" title="0">{
        // Create distributed routes
        distributedRoutes, err := NewDistributedRoutes(scheduler, modelDist, localAddr)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create distributed routes: %w", err)
        }</span>
        
        // Create server wrapper for fallback
        <span class="cov0" title="0">serverWrapper := &amp;ServerWrapper{originalServer: originalServer}
        distributedRoutes.SetOriginalServer(serverWrapper)
        
        return &amp;DistributedServerWrapper{
                originalServer:     originalServer,
                distributedRoutes:  distributedRoutes,
                scheduler:          scheduler,
                modelDistribution:  modelDist,
                distributedEnabled: true,
                fallbackEnabled:    true,
                localAddr:          localAddr,
        }, nil</span>
}

// GenerateRoutesWithDistributed generates routes with distributed capabilities
func (dsw *DistributedServerWrapper) GenerateRoutesWithDistributed(rc *integration.Registry) (http.Handler, error) <span class="cov0" title="0">{
        // Create a stub handler for original routes (would integrate with actual ollama server)
        originalHandler := http.NewServeMux()
        originalHandler.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) </span><span class="cov0" title="0">{
                w.WriteHeader(http.StatusNotImplemented)
                w.Write([]byte("Original ollama server integration not available in stub mode"))
        }</span>)
        
        // Create a new router with distributed capabilities
        <span class="cov0" title="0">router := gin.New()
        router.Use(gin.Logger())
        router.Use(gin.Recovery())
        
        // Add distributed middleware
        router.Use(dsw.distributedMiddleware())
        
        // Setup distributed routes
        dsw.distributedRoutes.SetupRoutes(router)
        
        // Add fallback handler for any routes not handled by distributed system
        router.NoRoute(func(c *gin.Context) </span><span class="cov0" title="0">{
                // If distributed mode is disabled or fallback is needed, use original handler
                if !dsw.distributedEnabled || dsw.shouldFallback(c) </span><span class="cov0" title="0">{
                        // Serve using original handler
                        originalHandler.ServeHTTP(c.Writer, c.Request)
                }</span> else<span class="cov0" title="0"> {
                        // Return 404 for unknown distributed routes
                        c.JSON(http.StatusNotFound, gin.H{"error": "endpoint not found"})
                }</span>
        })
        
        <span class="cov0" title="0">return router, nil</span>
}

// distributedMiddleware adds distributed-specific middleware
func (dsw *DistributedServerWrapper) distributedMiddleware() gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                // Add distributed headers
                c.Header("X-Ollama-Distributed-Wrapper", "true")
                c.Header("X-Ollama-Distributed-Enabled", fmt.Sprintf("%v", dsw.distributedEnabled))
                c.Header("X-Ollama-Fallback-Enabled", fmt.Sprintf("%v", dsw.fallbackEnabled))
                
                // Check if we should enable distributed mode for this request
                if dsw.shouldUseDistributed(c) </span><span class="cov0" title="0">{
                        c.Header("X-Ollama-Route-Mode", "distributed")
                }</span> else<span class="cov0" title="0"> {
                        c.Header("X-Ollama-Route-Mode", "local")
                }</span>
                
                <span class="cov0" title="0">c.Next()</span>
        }
}

// shouldUseDistributed determines if a request should use distributed routing
func (dsw *DistributedServerWrapper) shouldUseDistributed(c *gin.Context) bool <span class="cov0" title="0">{
        // Check if distributed mode is enabled
        if !dsw.distributedEnabled </span><span class="cov0" title="0">{
                return false
        }</span>
        
        // Check for override headers
        <span class="cov0" title="0">if c.GetHeader("X-Ollama-Force-Local") == "true" </span><span class="cov0" title="0">{
                return false
        }</span>
        
        <span class="cov0" title="0">if c.GetHeader("X-Ollama-Force-Distributed") == "true" </span><span class="cov0" title="0">{
                return true
        }</span>
        
        // Check request path
        <span class="cov0" title="0">path := c.Request.URL.Path
        
        // Always use distributed for inference endpoints
        if strings.HasPrefix(path, "/api/generate") ||
                strings.HasPrefix(path, "/api/chat") ||
                strings.HasPrefix(path, "/api/embed") ||
                strings.HasPrefix(path, "/v1/chat/completions") ||
                strings.HasPrefix(path, "/v1/completions") ||
                strings.HasPrefix(path, "/v1/embeddings") </span><span class="cov0" title="0">{
                return true
        }</span>
        
        // Use distributed for model management if model is distributed
        <span class="cov0" title="0">if strings.HasPrefix(path, "/api/show") ||
                strings.HasPrefix(path, "/api/tags") ||
                strings.HasPrefix(path, "/api/pull") </span><span class="cov0" title="0">{
                return true
        }</span>
        
        // Default to local for other endpoints
        <span class="cov0" title="0">return false</span>
}

// shouldFallback determines if a request should fallback to local
func (dsw *DistributedServerWrapper) shouldFallback(c *gin.Context) bool <span class="cov0" title="0">{
        // Check if fallback is enabled
        if !dsw.fallbackEnabled </span><span class="cov0" title="0">{
                return false
        }</span>
        
        // Check for fallback indicators in headers
        <span class="cov0" title="0">if c.GetHeader("X-Ollama-Distributed-Error") != "" </span><span class="cov0" title="0">{
                return true
        }</span>
        
        // Check cluster health
        <span class="cov0" title="0">if dsw.scheduler.GetClusterSize() &lt; 2 </span><span class="cov0" title="0">{
                return true
        }</span>
        
        // Check if any nodes are available
        <span class="cov0" title="0">if dsw.scheduler.GetActiveNodes() == 0 </span><span class="cov0" title="0">{
                return true
        }</span>
        
        <span class="cov0" title="0">return false</span>
}

// Start starts the distributed server wrapper
func (dsw *DistributedServerWrapper) Start(ctx context.Context) error <span class="cov0" title="0">{
        slog.Info("Starting distributed server wrapper")
        
        // Start distributed routes
        if err := dsw.distributedRoutes.Start(ctx); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start distributed routes: %w", err)
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// Shutdown gracefully shuts down the distributed server wrapper
func (dsw *DistributedServerWrapper) Shutdown(ctx context.Context) error <span class="cov0" title="0">{
        slog.Info("Shutting down distributed server wrapper")
        
        // Shutdown distributed routes
        if err := dsw.distributedRoutes.Shutdown(ctx); err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to shutdown distributed routes", "error", err)
                return err
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// GetDistributedRoutes returns the distributed routes handler
func (dsw *DistributedServerWrapper) GetDistributedRoutes() *DistributedRoutes <span class="cov0" title="0">{
        return dsw.distributedRoutes
}</span>

// SetDistributedEnabled enables or disables distributed mode
func (dsw *DistributedServerWrapper) SetDistributedEnabled(enabled bool) <span class="cov0" title="0">{
        dsw.distributedEnabled = enabled
}</span>

// SetFallbackEnabled enables or disables fallback mode
func (dsw *DistributedServerWrapper) SetFallbackEnabled(enabled bool) <span class="cov0" title="0">{
        dsw.fallbackEnabled = enabled
}</span>

// IsDistributedEnabled returns whether distributed mode is enabled
func (dsw *DistributedServerWrapper) IsDistributedEnabled() bool <span class="cov0" title="0">{
        return dsw.distributedEnabled
}</span>

// IsFallbackEnabled returns whether fallback mode is enabled
func (dsw *DistributedServerWrapper) IsFallbackEnabled() bool <span class="cov0" title="0">{
        return dsw.fallbackEnabled
}</span>

// GetStats returns wrapper statistics
func (dsw *DistributedServerWrapper) GetStats() map[string]interface{} <span class="cov0" title="0">{
        return map[string]interface{}{
                "distributed_enabled": dsw.distributedEnabled,
                "fallback_enabled":    dsw.fallbackEnabled,
                "local_addr":          dsw.localAddr,
                "cluster_size":        dsw.scheduler.GetClusterSize(),
                "active_nodes":        dsw.scheduler.GetActiveNodes(),
                "distributed_routes":  dsw.distributedRoutes.GetIntegrationLayer().GetStats(),
        }
}</span>

// DistributedServerCompatibility provides compatibility functions for integration
type DistributedServerCompatibility struct {
        wrapper *DistributedServerWrapper
}

// NewDistributedServerCompatibility creates a new compatibility layer
func NewDistributedServerCompatibility(wrapper *DistributedServerWrapper) *DistributedServerCompatibility <span class="cov0" title="0">{
        return &amp;DistributedServerCompatibility{
                wrapper: wrapper,
        }
}</span>

// WrapGenerateRoutes wraps the original GenerateRoutes function with distributed capabilities
func (dsc *DistributedServerCompatibility) WrapGenerateRoutes(originalServer interface{}) func(*integration.Registry) (http.Handler, error) <span class="cov0" title="0">{
        return func(rc *integration.Registry) (http.Handler, error) </span><span class="cov0" title="0">{
                // Check if distributed mode is enabled
                if os.Getenv("OLLAMA_DISTRIBUTED") == "false" </span><span class="cov0" title="0">{
                        // Return stub handler for original server
                        handler := http.NewServeMux()
                        handler.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) </span><span class="cov0" title="0">{
                                w.WriteHeader(http.StatusOK)
                                w.Write([]byte("Original ollama server (stub mode)"))
                        }</span>)
                        <span class="cov0" title="0">return handler, nil</span>
                }
                
                // Use distributed wrapper
                <span class="cov0" title="0">return dsc.wrapper.GenerateRoutesWithDistributed(rc)</span>
        }
}

// GetDistributedHandlers returns distributed-specific handlers
func (dsc *DistributedServerCompatibility) GetDistributedHandlers() map[string]gin.HandlerFunc <span class="cov0" title="0">{
        distributedRoutes := dsc.wrapper.GetDistributedRoutes()
        
        return map[string]gin.HandlerFunc{
                "generate":    distributedRoutes.handleGenerate,
                "chat":        distributedRoutes.handleChat,
                "embed":       distributedRoutes.handleEmbed,
                "embeddings":  distributedRoutes.handleEmbeddings,
                "pull":        distributedRoutes.handlePull,
                "show":        distributedRoutes.handleShow,
                "tags":        distributedRoutes.handleTags,
                "ps":          distributedRoutes.handlePs,
                "version":     distributedRoutes.handleVersion,
                "health":      distributedRoutes.handleHealth,
                "metrics":     distributedRoutes.handleMetrics,
        }
}</span>

// InjectDistributedHandlers injects distributed handlers into existing routes
func (dsc *DistributedServerCompatibility) InjectDistributedHandlers(router *gin.Engine) <span class="cov0" title="0">{
        handlers := dsc.GetDistributedHandlers()
        
        // Replace existing handlers with distributed versions
        api := router.Group("/api")
        </span><span class="cov0" title="0">{
                api.POST("/generate", handlers["generate"])
                api.POST("/chat", handlers["chat"])
                api.POST("/embed", handlers["embed"])
                api.POST("/embeddings", handlers["embeddings"])
                api.POST("/pull", handlers["pull"])
                api.POST("/show", handlers["show"])
                api.GET("/tags", handlers["tags"])
                api.GET("/ps", handlers["ps"])
                api.GET("/version", handlers["version"])
        }</span>
        
        // Add health and metrics
        <span class="cov0" title="0">router.GET("/health", handlers["health"])
        router.GET("/metrics", handlers["metrics"])</span>
}

// CreateDistributedMiddleware creates middleware for distributed functionality
func (dsc *DistributedServerCompatibility) CreateDistributedMiddleware() gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                // Check if request should be handled by distributed system
                if dsc.wrapper.shouldUseDistributed(c) </span><span class="cov0" title="0">{
                        // Mark as distributed
                        c.Set("distributed", true)
                        c.Header("X-Ollama-Distributed-Request", "true")
                        
                        // Check if fallback is needed
                        if dsc.wrapper.shouldFallback(c) </span><span class="cov0" title="0">{
                                c.Header("X-Ollama-Fallback-Available", "true")
                        }</span>
                } else<span class="cov0" title="0"> {
                        // Mark as local
                        c.Set("distributed", false)
                        c.Header("X-Ollama-Distributed-Request", "false")
                }</span>
                
                <span class="cov0" title="0">c.Next()</span>
        }
}

// GetDistributedStatus returns the status of distributed components
func (dsc *DistributedServerCompatibility) GetDistributedStatus() map[string]interface{} <span class="cov0" title="0">{
        return map[string]interface{}{
                "wrapper_enabled":     dsc.wrapper.IsDistributedEnabled(),
                "fallback_enabled":    dsc.wrapper.IsFallbackEnabled(),
                "cluster_size":        dsc.wrapper.scheduler.GetClusterSize(),
                "active_nodes":        dsc.wrapper.scheduler.GetActiveNodes(),
                "scheduler_healthy":   dsc.wrapper.scheduler.IsHealthy(),
                "routes_initialized":  dsc.wrapper.distributedRoutes != nil,
                "integration_stats":   dsc.wrapper.distributedRoutes.GetIntegrationLayer().GetStats(),
        }
}</span>

// EnableDistributedMode enables distributed mode with configuration
func (dsc *DistributedServerCompatibility) EnableDistributedMode(config map[string]interface{}) error <span class="cov0" title="0">{
        // Enable distributed mode
        dsc.wrapper.SetDistributedEnabled(true)
        
        // Configure based on provided config
        if fallback, ok := config["fallback"].(bool); ok </span><span class="cov0" title="0">{
                dsc.wrapper.SetFallbackEnabled(fallback)
        }</span>
        
        // Start distributed components if not already started
        <span class="cov0" title="0">ctx := context.Background()
        if err := dsc.wrapper.Start(ctx); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start distributed mode: %w", err)
        }</span>
        
        <span class="cov0" title="0">slog.Info("Distributed mode enabled", "config", config)
        return nil</span>
}

// DisableDistributedMode disables distributed mode
func (dsc *DistributedServerCompatibility) DisableDistributedMode() error <span class="cov0" title="0">{
        // Disable distributed mode
        dsc.wrapper.SetDistributedEnabled(false)
        
        // Shutdown distributed components
        ctx := context.Background()
        if err := dsc.wrapper.Shutdown(ctx); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to shutdown distributed mode: %w", err)
        }</span>
        
        <span class="cov0" title="0">slog.Info("Distributed mode disabled")
        return nil</span>
}

// GetIntegrationLayer returns the integration layer for external use
func (dsc *DistributedServerCompatibility) GetIntegrationLayer() *IntegrationLayer <span class="cov0" title="0">{
        return dsc.wrapper.GetDistributedRoutes().GetIntegrationLayer()
}</span>

// GetDistributedRunner returns the distributed runner for external use
func (dsc *DistributedServerCompatibility) GetDistributedRunner() *DistributedRunner <span class="cov0" title="0">{
        return dsc.wrapper.GetDistributedRoutes().GetDistributedRunner()
}</span>

// RegisterDistributedEndpoints registers additional distributed endpoints
func (dsc *DistributedServerCompatibility) RegisterDistributedEndpoints(router *gin.Engine) <span class="cov0" title="0">{
        // Distributed status endpoint
        router.GET("/distributed/status", func(c *gin.Context) </span><span class="cov0" title="0">{
                c.JSON(http.StatusOK, dsc.GetDistributedStatus())
        }</span>)
        
        // Distributed control endpoints
        <span class="cov0" title="0">admin := router.Group("/distributed/admin")
        </span><span class="cov0" title="0">{
                admin.POST("/enable", func(c *gin.Context) </span><span class="cov0" title="0">{
                        var config map[string]interface{}
                        if err := c.ShouldBindJSON(&amp;config); err != nil </span><span class="cov0" title="0">{
                                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                                return
                        }</span>
                        
                        <span class="cov0" title="0">if err := dsc.EnableDistributedMode(config); err != nil </span><span class="cov0" title="0">{
                                c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                                return
                        }</span>
                        
                        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{"message": "Distributed mode enabled"})</span>
                })
                
                <span class="cov0" title="0">admin.POST("/disable", func(c *gin.Context) </span><span class="cov0" title="0">{
                        if err := dsc.DisableDistributedMode(); err != nil </span><span class="cov0" title="0">{
                                c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                                return
                        }</span>
                        
                        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{"message": "Distributed mode disabled"})</span>
                })
        }
}</pre>
		
		<pre class="file" id="file16" style="display: none">package api

import (
        "bytes"
        "context"
        "fmt"
        "io"
        "log/slog"
        "net/http"
        "net/url"
        "sync"
        "time"

        "github.com/gin-gonic/gin"
        ollamaapi "github.com/ollama/ollama/api"
)

// FallbackManager manages fallback mechanisms for distributed requests
type FallbackManager struct {
        // Local Ollama instance details
        localURL     *url.URL
        localClient  *http.Client
        localHealthy bool
        
        // Fallback configuration
        fallbackEnabled     bool
        fallbackTimeout     time.Duration
        healthCheckInterval time.Duration
        maxRetries          int
        
        // Health monitoring
        healthMu           sync.RWMutex
        lastHealthCheck    time.Time
        consecutiveFailures int
        
        // Fallback statistics
        statsMu         sync.RWMutex
        fallbackCount   int64
        successCount    int64
        failureCount    int64
        averageLatency  time.Duration
}

// NewFallbackManager creates a new fallback manager
func NewFallbackManager(localAddr string) (*FallbackManager, error) <span class="cov0" title="0">{
        localURL, err := url.Parse(localAddr)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("invalid local URL: %w", err)
        }</span>
        
        <span class="cov0" title="0">client := &amp;http.Client{
                Timeout: 30 * time.Second,
        }
        
        fm := &amp;FallbackManager{
                localURL:            localURL,
                localClient:         client,
                localHealthy:        true,
                fallbackEnabled:     true,
                fallbackTimeout:     30 * time.Second,
                healthCheckInterval: 30 * time.Second,
                maxRetries:          3,
        }
        
        // Start health monitoring
        go fm.startHealthMonitoring()
        
        return fm, nil</span>
}

// startHealthMonitoring starts continuous health monitoring of local instance
func (fm *FallbackManager) startHealthMonitoring() <span class="cov0" title="0">{
        ticker := time.NewTicker(fm.healthCheckInterval)
        defer ticker.Stop()
        
        for range ticker.C </span><span class="cov0" title="0">{
                fm.checkLocalHealth()
        }</span>
}

// checkLocalHealth checks the health of the local Ollama instance
func (fm *FallbackManager) checkLocalHealth() <span class="cov0" title="0">{
        fm.healthMu.Lock()
        defer fm.healthMu.Unlock()
        
        fm.lastHealthCheck = time.Now()
        
        // Create health check request
        healthURL := fmt.Sprintf("%s/api/version", fm.localURL.String())
        
        ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
        defer cancel()
        
        req, err := http.NewRequestWithContext(ctx, "GET", healthURL, nil)
        if err != nil </span><span class="cov0" title="0">{
                fm.recordHealthFailure()
                return
        }</span>
        
        <span class="cov0" title="0">resp, err := fm.localClient.Do(req)
        if err != nil </span><span class="cov0" title="0">{
                fm.recordHealthFailure()
                return
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()
        
        if resp.StatusCode == http.StatusOK </span><span class="cov0" title="0">{
                fm.recordHealthSuccess()
        }</span> else<span class="cov0" title="0"> {
                fm.recordHealthFailure()
        }</span>
}

// recordHealthSuccess records a successful health check
func (fm *FallbackManager) recordHealthSuccess() <span class="cov0" title="0">{
        fm.consecutiveFailures = 0
        if !fm.localHealthy </span><span class="cov0" title="0">{
                fm.localHealthy = true
                slog.Info("Local Ollama instance is healthy again")
        }</span>
}

// recordHealthFailure records a failed health check
func (fm *FallbackManager) recordHealthFailure() <span class="cov0" title="0">{
        fm.consecutiveFailures++
        if fm.consecutiveFailures &gt;= 3 &amp;&amp; fm.localHealthy </span><span class="cov0" title="0">{
                fm.localHealthy = false
                slog.Warn("Local Ollama instance is unhealthy", "failures", fm.consecutiveFailures)
        }</span>
}

// IsLocalHealthy returns whether the local instance is healthy
func (fm *FallbackManager) IsLocalHealthy() bool <span class="cov0" title="0">{
        fm.healthMu.RLock()
        defer fm.healthMu.RUnlock()
        return fm.localHealthy
}</span>

// ShouldFallback determines if a request should fallback to local
func (fm *FallbackManager) ShouldFallback(reason string) bool <span class="cov0" title="0">{
        if !fm.fallbackEnabled </span><span class="cov0" title="0">{
                return false
        }</span>
        
        // Always fallback if local is unhealthy and we have no other options
        <span class="cov0" title="0">if !fm.IsLocalHealthy() &amp;&amp; reason != "local-unhealthy" </span><span class="cov0" title="0">{
                return false
        }</span>
        
        // Check specific fallback reasons
        <span class="cov0" title="0">switch reason </span>{
        case "scheduler-error":<span class="cov0" title="0">
                return true</span>
        case "execution-error":<span class="cov0" title="0">
                return true</span>
        case "timeout":<span class="cov0" title="0">
                return true</span>
        case "no-nodes":<span class="cov0" title="0">
                return true</span>
        case "model-not-found":<span class="cov0" title="0">
                return true</span>
        case "distributed-error":<span class="cov0" title="0">
                return true</span>
        default:<span class="cov0" title="0">
                return false</span>
        }
}

// ExecuteFallback executes a fallback request to local Ollama
func (fm *FallbackManager) ExecuteFallback(c *gin.Context, reason string) error <span class="cov0" title="0">{
        if !fm.ShouldFallback(reason) </span><span class="cov0" title="0">{
                return fmt.Errorf("fallback not allowed for reason: %s", reason)
        }</span>
        
        <span class="cov0" title="0">startTime := time.Now()
        
        // Increment fallback count
        fm.statsMu.Lock()
        fm.fallbackCount++
        fm.statsMu.Unlock()
        
        // Log fallback
        slog.Info("Executing fallback to local", "reason", reason, "path", c.Request.URL.Path)
        
        // Add fallback headers
        c.Header("X-Ollama-Fallback", "true")
        c.Header("X-Ollama-Fallback-Reason", reason)
        c.Header("X-Ollama-Fallback-Time", startTime.Format(time.RFC3339))
        
        // Execute fallback request
        err := fm.executeLocalRequest(c)
        
        // Update statistics
        latency := time.Since(startTime)
        fm.updateStats(err == nil, latency)
        
        return err</span>
}

// executeLocalRequest executes a request against the local Ollama instance
func (fm *FallbackManager) executeLocalRequest(c *gin.Context) error <span class="cov0" title="0">{
        // Read request body
        var body []byte
        var err error
        
        if c.Request.Body != nil </span><span class="cov0" title="0">{
                body, err = io.ReadAll(c.Request.Body)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to read request body: %w", err)
                }</span>
                // Reset body for potential retries
                <span class="cov0" title="0">c.Request.Body = io.NopCloser(bytes.NewBuffer(body))</span>
        }
        
        // Construct local URL
        <span class="cov0" title="0">localURL := fmt.Sprintf("%s%s", fm.localURL.String(), c.Request.URL.Path)
        if c.Request.URL.RawQuery != "" </span><span class="cov0" title="0">{
                localURL += "?" + c.Request.URL.RawQuery
        }</span>
        
        // Create request with timeout
        <span class="cov0" title="0">ctx, cancel := context.WithTimeout(c.Request.Context(), fm.fallbackTimeout)
        defer cancel()
        
        req, err := http.NewRequestWithContext(ctx, c.Request.Method, localURL, bytes.NewBuffer(body))
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create request: %w", err)
        }</span>
        
        // Copy headers
        <span class="cov0" title="0">for key, values := range c.Request.Header </span><span class="cov0" title="0">{
                for _, value := range values </span><span class="cov0" title="0">{
                        req.Header.Add(key, value)
                }</span>
        }
        
        // Execute request with retries
        <span class="cov0" title="0">var resp *http.Response
        var lastErr error
        
        for attempt := 0; attempt &lt; fm.maxRetries; attempt++ </span><span class="cov0" title="0">{
                if attempt &gt; 0 </span><span class="cov0" title="0">{
                        slog.Debug("Retrying fallback request", "attempt", attempt+1, "maxRetries", fm.maxRetries)
                        time.Sleep(time.Duration(attempt) * time.Second)
                }</span>
                
                <span class="cov0" title="0">resp, lastErr = fm.localClient.Do(req)
                if lastErr == nil </span><span class="cov0" title="0">{
                        break</span>
                }
                
                // Reset request body for retry
                <span class="cov0" title="0">if body != nil </span><span class="cov0" title="0">{
                        req.Body = io.NopCloser(bytes.NewBuffer(body))
                }</span>
        }
        
        <span class="cov0" title="0">if lastErr != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("fallback request failed after %d attempts: %w", fm.maxRetries, lastErr)
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()
        
        // Copy response headers
        for key, values := range resp.Header </span><span class="cov0" title="0">{
                for _, value := range values </span><span class="cov0" title="0">{
                        c.Header(key, value)
                }</span>
        }
        
        // Set status code
        <span class="cov0" title="0">c.Status(resp.StatusCode)
        
        // Stream response body
        _, err = io.Copy(c.Writer, resp.Body)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to copy response body: %w", err)
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// FallbackToLocal provides a convenience method for fallback
func (fm *FallbackManager) FallbackToLocal(c *gin.Context, reason string) <span class="cov0" title="0">{
        if err := fm.ExecuteFallback(c, reason); err != nil </span><span class="cov0" title="0">{
                slog.Error("Fallback execution failed", "error", err, "reason", reason)
                c.JSON(http.StatusInternalServerError, gin.H{
                        "error": "Fallback to local failed",
                        "reason": reason,
                        "details": err.Error(),
                })
        }</span>
}

// HandleDistributedError handles errors from distributed execution
func (fm *FallbackManager) HandleDistributedError(c *gin.Context, err error, operation string) <span class="cov0" title="0">{
        // Determine fallback reason based on error
        reason := "distributed-error"
        
        if err != nil </span><span class="cov0" title="0">{
                switch </span>{
                case bytes.Contains([]byte(err.Error()), []byte("timeout")):<span class="cov0" title="0">
                        reason = "timeout"</span>
                case bytes.Contains([]byte(err.Error()), []byte("no nodes")):<span class="cov0" title="0">
                        reason = "no-nodes"</span>
                case bytes.Contains([]byte(err.Error()), []byte("model not found")):<span class="cov0" title="0">
                        reason = "model-not-found"</span>
                case bytes.Contains([]byte(err.Error()), []byte("scheduler")):<span class="cov0" title="0">
                        reason = "scheduler-error"</span>
                }
        }
        
        // Log error
        <span class="cov0" title="0">slog.Error("Distributed operation failed", "error", err, "operation", operation, "reason", reason)
        
        // Add error headers
        c.Header("X-Ollama-Distributed-Error", err.Error())
        c.Header("X-Ollama-Error-Operation", operation)
        
        // Try fallback
        if fm.ShouldFallback(reason) </span><span class="cov0" title="0">{
                fm.FallbackToLocal(c, reason)
        }</span> else<span class="cov0" title="0"> {
                c.JSON(http.StatusInternalServerError, gin.H{
                        "error": "Distributed operation failed",
                        "operation": operation,
                        "reason": reason,
                        "details": err.Error(),
                        "fallback_available": false,
                })
        }</span>
}

// updateStats updates fallback statistics
func (fm *FallbackManager) updateStats(success bool, latency time.Duration) <span class="cov0" title="0">{
        fm.statsMu.Lock()
        defer fm.statsMu.Unlock()
        
        if success </span><span class="cov0" title="0">{
                fm.successCount++
        }</span> else<span class="cov0" title="0"> {
                fm.failureCount++
        }</span>
        
        // Update average latency
        <span class="cov0" title="0">totalRequests := fm.successCount + fm.failureCount
        if totalRequests == 1 </span><span class="cov0" title="0">{
                fm.averageLatency = latency
        }</span> else<span class="cov0" title="0"> {
                fm.averageLatency = (fm.averageLatency*time.Duration(totalRequests-1) + latency) / time.Duration(totalRequests)
        }</span>
}

// GetStats returns fallback statistics
func (fm *FallbackManager) GetStats() map[string]interface{} <span class="cov0" title="0">{
        fm.statsMu.RLock()
        defer fm.statsMu.RUnlock()
        
        fm.healthMu.RLock()
        defer fm.healthMu.RUnlock()
        
        successRate := float64(0)
        totalRequests := fm.successCount + fm.failureCount
        if totalRequests &gt; 0 </span><span class="cov0" title="0">{
                successRate = float64(fm.successCount) / float64(totalRequests) * 100
        }</span>
        
        <span class="cov0" title="0">return map[string]interface{}{
                "enabled":               fm.fallbackEnabled,
                "local_healthy":         fm.localHealthy,
                "local_url":             fm.localURL.String(),
                "fallback_count":        fm.fallbackCount,
                "success_count":         fm.successCount,
                "failure_count":         fm.failureCount,
                "success_rate":          successRate,
                "average_latency":       fm.averageLatency.String(),
                "consecutive_failures":  fm.consecutiveFailures,
                "last_health_check":     fm.lastHealthCheck.Format(time.RFC3339),
                "health_check_interval": fm.healthCheckInterval.String(),
                "timeout":               fm.fallbackTimeout.String(),
                "max_retries":           fm.maxRetries,
        }</span>
}

// SetEnabled enables or disables fallback
func (fm *FallbackManager) SetEnabled(enabled bool) <span class="cov0" title="0">{
        fm.fallbackEnabled = enabled
        slog.Info("Fallback mode changed", "enabled", enabled)
}</span>

// SetTimeout sets the fallback timeout
func (fm *FallbackManager) SetTimeout(timeout time.Duration) <span class="cov0" title="0">{
        fm.fallbackTimeout = timeout
}</span>

// SetMaxRetries sets the maximum number of retries
func (fm *FallbackManager) SetMaxRetries(retries int) <span class="cov0" title="0">{
        fm.maxRetries = retries
}</span>

// SetHealthCheckInterval sets the health check interval
func (fm *FallbackManager) SetHealthCheckInterval(interval time.Duration) <span class="cov0" title="0">{
        fm.healthCheckInterval = interval
}</span>

// Reset resets fallback statistics
func (fm *FallbackManager) Reset() <span class="cov0" title="0">{
        fm.statsMu.Lock()
        defer fm.statsMu.Unlock()
        
        fm.fallbackCount = 0
        fm.successCount = 0
        fm.failureCount = 0
        fm.averageLatency = 0
        
        slog.Info("Fallback statistics reset")
}</span>

// StandaloneMode represents standalone mode configuration
type StandaloneMode struct {
        enabled      bool
        reason       string
        enabledAt    time.Time
        fallbackMgr  *FallbackManager
}

// NewStandaloneMode creates a new standalone mode manager
func NewStandaloneMode(fallbackMgr *FallbackManager) *StandaloneMode <span class="cov0" title="0">{
        return &amp;StandaloneMode{
                enabled:     false,
                fallbackMgr: fallbackMgr,
        }
}</span>

// Enable enables standalone mode
func (sm *StandaloneMode) Enable(reason string) <span class="cov0" title="0">{
        sm.enabled = true
        sm.reason = reason
        sm.enabledAt = time.Now()
        
        slog.Info("Standalone mode enabled", "reason", reason)
}</span>

// Disable disables standalone mode
func (sm *StandaloneMode) Disable() <span class="cov0" title="0">{
        sm.enabled = false
        sm.reason = ""
        
        slog.Info("Standalone mode disabled")
}</span>

// IsEnabled returns whether standalone mode is enabled
func (sm *StandaloneMode) IsEnabled() bool <span class="cov0" title="0">{
        return sm.enabled
}</span>

// GetReason returns the reason for standalone mode
func (sm *StandaloneMode) GetReason() string <span class="cov0" title="0">{
        return sm.reason
}</span>

// HandleRequest handles a request in standalone mode
func (sm *StandaloneMode) HandleRequest(c *gin.Context) <span class="cov0" title="0">{
        if !sm.enabled </span><span class="cov0" title="0">{
                c.JSON(http.StatusServiceUnavailable, gin.H{
                        "error": "Standalone mode is not enabled",
                })
                return
        }</span>
        
        // Add standalone headers
        <span class="cov0" title="0">c.Header("X-Ollama-Standalone", "true")
        c.Header("X-Ollama-Standalone-Reason", sm.reason)
        c.Header("X-Ollama-Standalone-Since", sm.enabledAt.Format(time.RFC3339))
        
        // Execute request using fallback manager
        if err := sm.fallbackMgr.ExecuteFallback(c, "standalone-mode"); err != nil </span><span class="cov0" title="0">{
                slog.Error("Standalone request failed", "error", err)
                c.JSON(http.StatusInternalServerError, gin.H{
                        "error": "Standalone request failed",
                        "details": err.Error(),
                })
        }</span>
}

// GetStats returns standalone mode statistics
func (sm *StandaloneMode) GetStats() map[string]interface{} <span class="cov0" title="0">{
        return map[string]interface{}{
                "enabled":    sm.enabled,
                "reason":     sm.reason,
                "enabled_at": sm.enabledAt.Format(time.RFC3339),
                "duration":   time.Since(sm.enabledAt).String(),
        }
}</span>

// FallbackChain represents a chain of fallback mechanisms
type FallbackChain struct {
        fallbacks []FallbackHandler
}

// FallbackHandler represents a fallback handler
type FallbackHandler interface {
        CanHandle(reason string) bool
        Handle(c *gin.Context, reason string) error
        GetName() string
}

// NewFallbackChain creates a new fallback chain
func NewFallbackChain() *FallbackChain <span class="cov0" title="0">{
        return &amp;FallbackChain{
                fallbacks: make([]FallbackHandler, 0),
        }
}</span>

// AddFallback adds a fallback handler to the chain
func (fc *FallbackChain) AddFallback(handler FallbackHandler) <span class="cov0" title="0">{
        fc.fallbacks = append(fc.fallbacks, handler)
}</span>

// Execute executes the fallback chain
func (fc *FallbackChain) Execute(c *gin.Context, reason string) error <span class="cov0" title="0">{
        for _, handler := range fc.fallbacks </span><span class="cov0" title="0">{
                if handler.CanHandle(reason) </span><span class="cov0" title="0">{
                        slog.Debug("Executing fallback handler", "handler", handler.GetName(), "reason", reason)
                        return handler.Handle(c, reason)
                }</span>
        }
        
        <span class="cov0" title="0">return fmt.Errorf("no fallback handler available for reason: %s", reason)</span>
}

// LocalFallbackHandler implements fallback to local Ollama
type LocalFallbackHandler struct {
        fallbackMgr *FallbackManager
}

// NewLocalFallbackHandler creates a new local fallback handler
func NewLocalFallbackHandler(fallbackMgr *FallbackManager) *LocalFallbackHandler <span class="cov0" title="0">{
        return &amp;LocalFallbackHandler{
                fallbackMgr: fallbackMgr,
        }
}</span>

// CanHandle checks if this handler can handle the given reason
func (lfh *LocalFallbackHandler) CanHandle(reason string) bool <span class="cov0" title="0">{
        return lfh.fallbackMgr.ShouldFallback(reason)
}</span>

// Handle handles the fallback request
func (lfh *LocalFallbackHandler) Handle(c *gin.Context, reason string) error <span class="cov0" title="0">{
        return lfh.fallbackMgr.ExecuteFallback(c, reason)
}</span>

// GetName returns the handler name
func (lfh *LocalFallbackHandler) GetName() string <span class="cov0" title="0">{
        return "local-fallback"
}</span>

// CachedResponseHandler implements fallback to cached responses
type CachedResponseHandler struct {
        cache map[string]*ollamaapi.GenerateResponse
        mu    sync.RWMutex
}

// NewCachedResponseHandler creates a new cached response handler
func NewCachedResponseHandler() *CachedResponseHandler <span class="cov0" title="0">{
        return &amp;CachedResponseHandler{
                cache: make(map[string]*ollamaapi.GenerateResponse),
        }
}</span>

// CanHandle checks if this handler can handle the given reason
func (crh *CachedResponseHandler) CanHandle(reason string) bool <span class="cov0" title="0">{
        // Only handle timeout and temporary errors
        return reason == "timeout" || reason == "temporary-error"
}</span>

// Handle handles the fallback request
func (crh *CachedResponseHandler) Handle(c *gin.Context, reason string) error <span class="cov0" title="0">{
        // Try to find cached response
        key := crh.generateCacheKey(c)
        
        crh.mu.RLock()
        cached, exists := crh.cache[key]
        crh.mu.RUnlock()
        
        if !exists </span><span class="cov0" title="0">{
                return fmt.Errorf("no cached response available")
        }</span>
        
        // Return cached response
        <span class="cov0" title="0">c.Header("X-Ollama-Cached-Response", "true")
        c.Header("X-Ollama-Cache-Key", key)
        c.JSON(http.StatusOK, cached)
        
        return nil</span>
}

// GetName returns the handler name
func (crh *CachedResponseHandler) GetName() string <span class="cov0" title="0">{
        return "cached-response"
}</span>

// generateCacheKey generates a cache key for the request
func (crh *CachedResponseHandler) generateCacheKey(c *gin.Context) string <span class="cov0" title="0">{
        // Simple cache key based on path and method
        return fmt.Sprintf("%s:%s", c.Request.Method, c.Request.URL.Path)
}</span>

// CacheResponse caches a response
func (crh *CachedResponseHandler) CacheResponse(key string, response *ollamaapi.GenerateResponse) <span class="cov0" title="0">{
        crh.mu.Lock()
        defer crh.mu.Unlock()
        
        crh.cache[key] = response
}</span>

// ClearCache clears the cache
func (crh *CachedResponseHandler) ClearCache() <span class="cov0" title="0">{
        crh.mu.Lock()
        defer crh.mu.Unlock()
        
        crh.cache = make(map[string]*ollamaapi.GenerateResponse)
}</pre>
		
		<pre class="file" id="file17" style="display: none">package api

import (
        "bytes"
        "encoding/json"
        "fmt"
        "io"
        "net/http"
        "net/http/httputil"
        "net/url"
        "strings"
        "sync"
        "time"

        "github.com/gin-gonic/gin"
        ollamaapi "github.com/ollama/ollama/api"
        "github.com/ollama/ollama-distributed/pkg/models"
        "github.com/ollama/ollama-distributed/pkg/scheduler"
)

// IntegrationLayer provides transparent API layer for distributed Ollama
type IntegrationLayer struct {
        scheduler    *scheduler.Engine
        localProxy   *httputil.ReverseProxy
        localURL     *url.URL
        
        // Distributed mode settings
        distributedMode bool
        fallbackMode    bool
        
        // Request tracking
        requestTracker *RequestTracker
        
        // Model distribution
        modelDistribution *models.Manager
}

// RequestTracker tracks ongoing requests for failover
type RequestTracker struct {
        mu       sync.RWMutex
        requests map[string]*TrackedRequest
}

type TrackedRequest struct {
        ID       string
        Started  time.Time
        NodeID   string
        Model    string
        Retries  int
        Response chan *scheduler.Response
}

// NewIntegrationLayer creates a new API integration layer
func NewIntegrationLayer(scheduler *scheduler.Engine, localAddr string, modelDist *models.Manager) (*IntegrationLayer, error) <span class="cov0" title="0">{
        localURL, err := url.Parse(localAddr)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("invalid local Ollama URL: %w", err)
        }</span>
        
        <span class="cov0" title="0">proxy := httputil.NewSingleHostReverseProxy(localURL)
        
        // Customize proxy to handle errors and add distributed headers
        proxy.ErrorHandler = func(w http.ResponseWriter, r *http.Request, err error) </span><span class="cov0" title="0">{
                w.Header().Set("X-Ollama-Distributed-Error", "local-proxy-failed")
                w.WriteHeader(http.StatusBadGateway)
                json.NewEncoder(w).Encode(gin.H{"error": "Local Ollama instance unavailable"})
        }</span>
        
        <span class="cov0" title="0">return &amp;IntegrationLayer{
                scheduler:         scheduler,
                localProxy:        proxy,
                localURL:          localURL,
                distributedMode:   true,
                fallbackMode:      true,
                requestTracker:    &amp;RequestTracker{requests: make(map[string]*TrackedRequest)},
                modelDistribution: modelDist,
        }, nil</span>
}

// HandleRequest processes API requests with transparent distributed routing
func (il *IntegrationLayer) HandleRequest(c *gin.Context) <span class="cov0" title="0">{
        path := c.Request.URL.Path
        
        // Add distributed headers
        c.Header("X-Ollama-Distributed", "true")
        c.Header("X-Ollama-Mode", il.getMode())
        
        // Route based on endpoint
        switch </span>{
        case strings.HasPrefix(path, "/api/generate"):<span class="cov0" title="0">
                il.handleGenerate(c)</span>
        case strings.HasPrefix(path, "/api/chat"):<span class="cov0" title="0">
                il.handleChat(c)</span>
        case strings.HasPrefix(path, "/api/embed"):<span class="cov0" title="0">
                il.handleEmbed(c)</span>
        case strings.HasPrefix(path, "/api/embeddings"):<span class="cov0" title="0">
                il.handleEmbeddings(c)</span>
        case strings.HasPrefix(path, "/api/pull"):<span class="cov0" title="0">
                il.handlePull(c)</span>
        case strings.HasPrefix(path, "/api/push"):<span class="cov0" title="0">
                il.handlePush(c)</span>
        case strings.HasPrefix(path, "/api/show"):<span class="cov0" title="0">
                il.handleShow(c)</span>
        case strings.HasPrefix(path, "/api/tags"):<span class="cov0" title="0">
                il.handleTags(c)</span>
        case strings.HasPrefix(path, "/api/delete"):<span class="cov0" title="0">
                il.handleDelete(c)</span>
        case strings.HasPrefix(path, "/api/copy"):<span class="cov0" title="0">
                il.handleCopy(c)</span>
        case strings.HasPrefix(path, "/api/ps"):<span class="cov0" title="0">
                il.handlePs(c)</span>
        case strings.HasPrefix(path, "/api/create"):<span class="cov0" title="0">
                il.handleCreate(c)</span>
        case strings.HasPrefix(path, "/api/version"):<span class="cov0" title="0">
                il.handleVersion(c)</span>
        case strings.HasPrefix(path, "/v1/"):<span class="cov0" title="0">
                // OpenAI compatibility - handle distributed
                il.handleOpenAI(c)</span>
        default:<span class="cov0" title="0">
                // Unknown endpoint - fallback to local
                il.proxyToLocal(c)</span>
        }
}

// Generate endpoint with distributed routing
func (il *IntegrationLayer) handleGenerate(c *gin.Context) <span class="cov0" title="0">{
        var req ollamaapi.GenerateRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        // Check if model should be distributed
        <span class="cov0" title="0">if !il.shouldDistribute(req.Model) </span><span class="cov0" title="0">{
                il.proxyToLocal(c)
                return
        }</span>
        
        // Create distributed request
        <span class="cov0" title="0">distribReq := &amp;scheduler.Request{
                ID:         fmt.Sprintf("gen_%d", time.Now().UnixNano()),
                ModelName:  req.Model,
                Type:       "generate",
                Priority:   1,
                Timeout:    30 * time.Second,
                ResponseCh: make(chan *scheduler.Response, 1),
                Payload: map[string]interface{}{
                        "prompt":  req.Prompt,
                        "stream":  req.Stream,
                        "options": req.Options,
                },
        }
        
        // Track request
        il.requestTracker.TrackRequest(distribReq)
        defer il.requestTracker.UntrackRequest(distribReq.ID)
        
        // Schedule on distributed cluster
        if err := il.scheduler.Schedule(distribReq); err != nil </span><span class="cov0" title="0">{
                if il.fallbackMode </span><span class="cov0" title="0">{
                        c.Header("X-Ollama-Fallback", "scheduler-error")
                        il.proxyToLocal(c)
                        return
                }</span>
                <span class="cov0" title="0">c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                return</span>
        }
        
        // Wait for response
        <span class="cov0" title="0">select </span>{
        case response := &lt;-distribReq.ResponseCh:<span class="cov0" title="0">
                if response.Success </span><span class="cov0" title="0">{
                        c.Header("X-Ollama-Node", response.NodeID)
                        c.JSON(http.StatusOK, response.Data)
                }</span> else<span class="cov0" title="0"> {
                        if il.fallbackMode </span><span class="cov0" title="0">{
                                c.Header("X-Ollama-Fallback", "execution-error")
                                il.proxyToLocal(c)
                                return
                        }</span>
                        <span class="cov0" title="0">c.JSON(http.StatusInternalServerError, gin.H{"error": response.Error})</span>
                }
        case &lt;-time.After(30 * time.Second):<span class="cov0" title="0">
                if il.fallbackMode </span><span class="cov0" title="0">{
                        c.Header("X-Ollama-Fallback", "timeout")
                        il.proxyToLocal(c)
                        return
                }</span>
                <span class="cov0" title="0">c.JSON(http.StatusRequestTimeout, gin.H{"error": "Request timeout"})</span>
        }
}

// Chat endpoint with distributed routing
func (il *IntegrationLayer) handleChat(c *gin.Context) <span class="cov0" title="0">{
        var req ollamaapi.ChatRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        // Check if model should be distributed
        <span class="cov0" title="0">if !il.shouldDistribute(req.Model) </span><span class="cov0" title="0">{
                il.proxyToLocal(c)
                return
        }</span>
        
        // Create distributed request
        <span class="cov0" title="0">distribReq := &amp;scheduler.Request{
                ID:         fmt.Sprintf("chat_%d", time.Now().UnixNano()),
                ModelName:  req.Model,
                Type:       "chat",
                Priority:   1,
                Timeout:    30 * time.Second,
                ResponseCh: make(chan *scheduler.Response, 1),
                Payload: map[string]interface{}{
                        "messages": req.Messages,
                        "stream":   req.Stream,
                        "options":  req.Options,
                },
        }
        
        // Track and schedule
        il.requestTracker.TrackRequest(distribReq)
        defer il.requestTracker.UntrackRequest(distribReq.ID)
        
        if err := il.scheduler.Schedule(distribReq); err != nil </span><span class="cov0" title="0">{
                if il.fallbackMode </span><span class="cov0" title="0">{
                        c.Header("X-Ollama-Fallback", "scheduler-error")
                        il.proxyToLocal(c)
                        return
                }</span>
                <span class="cov0" title="0">c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                return</span>
        }
        
        // Wait for response
        <span class="cov0" title="0">select </span>{
        case response := &lt;-distribReq.ResponseCh:<span class="cov0" title="0">
                if response.Success </span><span class="cov0" title="0">{
                        c.Header("X-Ollama-Node", response.NodeID)
                        c.JSON(http.StatusOK, response.Data)
                }</span> else<span class="cov0" title="0"> {
                        if il.fallbackMode </span><span class="cov0" title="0">{
                                c.Header("X-Ollama-Fallback", "execution-error")
                                il.proxyToLocal(c)
                                return
                        }</span>
                        <span class="cov0" title="0">c.JSON(http.StatusInternalServerError, gin.H{"error": response.Error})</span>
                }
        case &lt;-time.After(30 * time.Second):<span class="cov0" title="0">
                if il.fallbackMode </span><span class="cov0" title="0">{
                        c.Header("X-Ollama-Fallback", "timeout")
                        il.proxyToLocal(c)
                }</span>
                <span class="cov0" title="0">c.JSON(http.StatusRequestTimeout, gin.H{"error": "Request timeout"})</span>
        }
}

// Embed endpoint with distributed routing
func (il *IntegrationLayer) handleEmbed(c *gin.Context) <span class="cov0" title="0">{
        var req ollamaapi.EmbedRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        <span class="cov0" title="0">if !il.shouldDistribute(req.Model) </span><span class="cov0" title="0">{
                il.proxyToLocal(c)
                return
        }</span>
        
        // Create distributed request
        <span class="cov0" title="0">distribReq := &amp;scheduler.Request{
                ID:         fmt.Sprintf("embed_%d", time.Now().UnixNano()),
                ModelName:  req.Model,
                Type:       "embed",
                Priority:   1,
                Timeout:    30 * time.Second,
                ResponseCh: make(chan *scheduler.Response, 1),
                Payload: map[string]interface{}{
                        "input":    req.Input,
                        "truncate": req.Truncate,
                        "options":  req.Options,
                },
        }
        
        il.requestTracker.TrackRequest(distribReq)
        defer il.requestTracker.UntrackRequest(distribReq.ID)
        
        if err := il.scheduler.Schedule(distribReq); err != nil </span><span class="cov0" title="0">{
                if il.fallbackMode </span><span class="cov0" title="0">{
                        c.Header("X-Ollama-Fallback", "scheduler-error")
                        il.proxyToLocal(c)
                        return
                }</span>
                <span class="cov0" title="0">c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                return</span>
        }
        
        <span class="cov0" title="0">select </span>{
        case response := &lt;-distribReq.ResponseCh:<span class="cov0" title="0">
                if response.Success </span><span class="cov0" title="0">{
                        c.Header("X-Ollama-Node", response.NodeID)
                        c.JSON(http.StatusOK, response.Data)
                }</span> else<span class="cov0" title="0"> {
                        if il.fallbackMode </span><span class="cov0" title="0">{
                                c.Header("X-Ollama-Fallback", "execution-error")
                                il.proxyToLocal(c)
                                return
                        }</span>
                        <span class="cov0" title="0">c.JSON(http.StatusInternalServerError, gin.H{"error": response.Error})</span>
                }
        case &lt;-time.After(30 * time.Second):<span class="cov0" title="0">
                if il.fallbackMode </span><span class="cov0" title="0">{
                        c.Header("X-Ollama-Fallback", "timeout")
                        il.proxyToLocal(c)
                }</span>
                <span class="cov0" title="0">c.JSON(http.StatusRequestTimeout, gin.H{"error": "Request timeout"})</span>
        }
}

// Embeddings endpoint (compatibility)
func (il *IntegrationLayer) handleEmbeddings(c *gin.Context) <span class="cov0" title="0">{
        // Convert to EmbedRequest format and handle
        var req ollamaapi.EmbeddingRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        // Convert to EmbedRequest
        <span class="cov0" title="0">embedReq := ollamaapi.EmbedRequest{
                Model:     req.Model,
                Input:     req.Prompt,
                Options:   req.Options,
                KeepAlive: req.KeepAlive,
        }
        
        // Replace request body
        body, _ := json.Marshal(embedReq)
        c.Request.Body = io.NopCloser(bytes.NewBuffer(body))
        
        il.handleEmbed(c)</span>
}

// Pull endpoint with distributed model management
func (il *IntegrationLayer) handlePull(c *gin.Context) <span class="cov0" title="0">{
        var req ollamaapi.PullRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        // Check if model should be distributed
        <span class="cov0" title="0">if il.modelDistribution.ShouldDistribute(req.Model) </span><span class="cov0" title="0">{
                // Handle distributed pull
                il.handleDistributedPull(c, req)
        }</span> else<span class="cov0" title="0"> {
                // Proxy to local
                il.proxyToLocal(c)
        }</span>
}

// Push endpoint - proxy to local by default
func (il *IntegrationLayer) handlePush(c *gin.Context) <span class="cov0" title="0">{
        // Push operations are typically done locally
        il.proxyToLocal(c)
}</span>

// Show endpoint with distributed model info
func (il *IntegrationLayer) handleShow(c *gin.Context) <span class="cov0" title="0">{
        var req ollamaapi.ShowRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        // Check if model is distributed
        <span class="cov0" title="0">if il.modelDistribution.IsDistributed(req.Model) </span><span class="cov0" title="0">{
                // Get info from distributed cluster
                info := il.modelDistribution.GetModelInfo(req.Model)
                if info == nil </span><span class="cov0" title="0">{
                        if il.fallbackMode </span><span class="cov0" title="0">{
                                c.Header("X-Ollama-Fallback", "distributed-info-error")
                                il.proxyToLocal(c)
                                return
                        }</span>
                        <span class="cov0" title="0">c.JSON(http.StatusInternalServerError, gin.H{"error": "Model info not found"})
                        return</span>
                }
                
                <span class="cov0" title="0">c.Header("X-Ollama-Distributed-Model", "true")
                c.JSON(http.StatusOK, info)</span>
        } else<span class="cov0" title="0"> {
                il.proxyToLocal(c)
        }</span>
}

// Tags endpoint with distributed model listing
func (il *IntegrationLayer) handleTags(c *gin.Context) <span class="cov0" title="0">{
        // Get local models
        localModels, err := il.getLocalModels()
        if err != nil &amp;&amp; !il.fallbackMode </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                return
        }</span>
        
        // Get distributed models
        <span class="cov0" title="0">distributedModels := il.modelDistribution.GetDistributedModels()
        if distributedModels == nil &amp;&amp; !il.fallbackMode </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to get distributed models"})
                return
        }</span>
        
        // Convert distributed models to ListModelResponse and merge
        <span class="cov0" title="0">var convertedDistributed []ollamaapi.ListModelResponse
        for _, model := range distributedModels </span><span class="cov0" title="0">{
                if modelMap, ok := model.(map[string]interface{}); ok </span><span class="cov0" title="0">{
                        response := ollamaapi.ListModelResponse{
                                Name:  getString(modelMap, "name"),
                                Model: getString(modelMap, "name"),
                                Size:  getInt64(modelMap, "size"),
                        }
                        convertedDistributed = append(convertedDistributed, response)
                }</span>
        }
        
        // Merge models
        <span class="cov0" title="0">allModels := append(localModels, convertedDistributed...)
        
        c.Header("X-Ollama-Total-Models", fmt.Sprintf("%d", len(allModels)))
        c.Header("X-Ollama-Local-Models", fmt.Sprintf("%d", len(localModels)))
        c.Header("X-Ollama-Distributed-Models", fmt.Sprintf("%d", len(distributedModels)))
        
        c.JSON(http.StatusOK, ollamaapi.ListResponse{Models: allModels})</span>
}

// Delete endpoint with distributed model cleanup
func (il *IntegrationLayer) handleDelete(c *gin.Context) <span class="cov0" title="0">{
        var req ollamaapi.DeleteRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        // Check if model is distributed
        <span class="cov0" title="0">if il.modelDistribution.IsDistributed(req.Model) </span><span class="cov0" title="0">{
                // Delete from distributed cluster
                if err := il.modelDistribution.DeleteModel(req.Model); err != nil </span><span class="cov0" title="0">{
                        c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                        return
                }</span>
                <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{"message": "Model deleted from distributed cluster"})</span>
        } else<span class="cov0" title="0"> {
                // Delete locally
                il.proxyToLocal(c)
        }</span>
}

// Copy endpoint - proxy to local
func (il *IntegrationLayer) handleCopy(c *gin.Context) <span class="cov0" title="0">{
        il.proxyToLocal(c)
}</span>

// PS endpoint with distributed process info
func (il *IntegrationLayer) handlePs(c *gin.Context) <span class="cov0" title="0">{
        // Get local processes
        localProcs, err := il.getLocalProcesses()
        if err != nil &amp;&amp; !il.fallbackMode </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                return
        }</span>
        
        // Get distributed processes
        <span class="cov0" title="0">distributedProcs, err := il.getDistributedProcesses()
        if err != nil &amp;&amp; !il.fallbackMode </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                return
        }</span>
        
        // Merge processes
        <span class="cov0" title="0">allProcs := append(localProcs, distributedProcs...)
        
        c.Header("X-Ollama-Total-Processes", fmt.Sprintf("%d", len(allProcs)))
        c.Header("X-Ollama-Local-Processes", fmt.Sprintf("%d", len(localProcs)))
        c.Header("X-Ollama-Distributed-Processes", fmt.Sprintf("%d", len(distributedProcs)))
        
        c.JSON(http.StatusOK, ollamaapi.ProcessResponse{Models: allProcs})</span>
}

// Create endpoint - proxy to local
func (il *IntegrationLayer) handleCreate(c *gin.Context) <span class="cov0" title="0">{
        il.proxyToLocal(c)
}</span>

// Version endpoint with distributed info
func (il *IntegrationLayer) handleVersion(c *gin.Context) <span class="cov0" title="0">{
        // Get local version first
        localVersion, err := il.getLocalVersion()
        if err != nil </span><span class="cov0" title="0">{
                localVersion = map[string]interface{}{"version": "unknown"}
        }</span>
        
        // Add distributed info
        <span class="cov0" title="0">version := map[string]interface{}{
                "version":            localVersion["version"],
                "distributed":        true,
                "distributed_mode":   il.distributedMode,
                "fallback_mode":      il.fallbackMode,
                "cluster_size":       il.scheduler.GetClusterSize(),
                "active_nodes":       il.scheduler.GetActiveNodes(),
                "distributed_models": il.modelDistribution.GetDistributedModelCount(),
        }
        
        c.JSON(http.StatusOK, version)</span>
}

// OpenAI compatibility endpoints
func (il *IntegrationLayer) handleOpenAI(c *gin.Context) <span class="cov0" title="0">{
        // For OpenAI compatibility, we need to handle:
        // - /v1/chat/completions -&gt; chat
        // - /v1/completions -&gt; generate
        // - /v1/embeddings -&gt; embed
        // - /v1/models -&gt; tags
        
        path := c.Request.URL.Path
        switch </span>{
        case strings.HasSuffix(path, "/chat/completions"):<span class="cov0" title="0">
                il.handleOpenAIChat(c)</span>
        case strings.HasSuffix(path, "/completions"):<span class="cov0" title="0">
                il.handleOpenAICompletion(c)</span>
        case strings.HasSuffix(path, "/embeddings"):<span class="cov0" title="0">
                il.handleOpenAIEmbeddings(c)</span>
        case strings.HasSuffix(path, "/models"):<span class="cov0" title="0">
                il.handleOpenAIModels(c)</span>
        default:<span class="cov0" title="0">
                il.proxyToLocal(c)</span>
        }
}

// Helper methods

func (il *IntegrationLayer) shouldDistribute(model string) bool <span class="cov0" title="0">{
        return il.distributedMode &amp;&amp; il.modelDistribution.ShouldDistribute(model)
}</span>

func (il *IntegrationLayer) getMode() string <span class="cov0" title="0">{
        if il.distributedMode </span><span class="cov0" title="0">{
                if il.fallbackMode </span><span class="cov0" title="0">{
                        return "distributed-with-fallback"
                }</span>
                <span class="cov0" title="0">return "distributed"</span>
        }
        <span class="cov0" title="0">return "local"</span>
}

func (il *IntegrationLayer) proxyToLocal(c *gin.Context) <span class="cov0" title="0">{
        c.Header("X-Ollama-Proxy", "local")
        il.localProxy.ServeHTTP(c.Writer, c.Request)
}</span>

// Request tracking methods

func (rt *RequestTracker) TrackRequest(req *scheduler.Request) <span class="cov0" title="0">{
        rt.mu.Lock()
        defer rt.mu.Unlock()
        
        rt.requests[req.ID] = &amp;TrackedRequest{
                ID:       req.ID,
                Started:  time.Now(),
                Model:    req.ModelName,
                Retries:  0,
                Response: req.ResponseCh,
        }
}</span>

func (rt *RequestTracker) UntrackRequest(id string) <span class="cov0" title="0">{
        rt.mu.Lock()
        defer rt.mu.Unlock()
        
        delete(rt.requests, id)
}</span>

func (rt *RequestTracker) GetActiveRequests() map[string]*TrackedRequest <span class="cov0" title="0">{
        rt.mu.RLock()
        defer rt.mu.RUnlock()
        
        result := make(map[string]*TrackedRequest)
        for k, v := range rt.requests </span><span class="cov0" title="0">{
                result[k] = v
        }</span>
        <span class="cov0" title="0">return result</span>
}

// Helper functions for type conversion
func getString(m map[string]interface{}, key string) string <span class="cov0" title="0">{
        if v, ok := m[key]; ok </span><span class="cov0" title="0">{
                if s, ok := v.(string); ok </span><span class="cov0" title="0">{
                        return s
                }</span>
        }
        <span class="cov0" title="0">return ""</span>
}

func getInt64(m map[string]interface{}, key string) int64 <span class="cov0" title="0">{
        if v, ok := m[key]; ok </span><span class="cov0" title="0">{
                if i, ok := v.(int64); ok </span><span class="cov0" title="0">{
                        return i
                }</span>
                <span class="cov0" title="0">if f, ok := v.(float64); ok </span><span class="cov0" title="0">{
                        return int64(f)
                }</span>
                <span class="cov0" title="0">if i, ok := v.(int); ok </span><span class="cov0" title="0">{
                        return int64(i)
                }</span>
        }
        <span class="cov0" title="0">return 0</span>
}

// Placeholder methods for implementation

func (il *IntegrationLayer) handleDistributedPull(c *gin.Context, req ollamaapi.PullRequest) <span class="cov0" title="0">{
        // First check if model already exists in distributed cluster
        if il.modelDistribution.IsDistributed(req.Model) </span><span class="cov0" title="0">{
                c.JSON(http.StatusOK, gin.H{"status": "Model already available in distributed cluster"})
                return
        }</span>

        // Start distributed pull process
        <span class="cov0" title="0">pullCh := make(chan bool, 1)
        go func() </span><span class="cov0" title="0">{
                // Try to find model on network first
                if modelInfo := il.modelDistribution.GetModelInfo(req.Model); modelInfo != nil </span><span class="cov0" title="0">{
                        // Model exists on network, download from peer
                        if err := il.modelDistribution.DownloadFromPeer(req.Model, "default-peer"); err != nil </span><span class="cov0" title="0">{
                                pullCh &lt;- false
                                return
                        }</span>
                        <span class="cov0" title="0">pullCh &lt;- true
                        return</span>
                }

                // Model not on network, pull locally and replicate
                <span class="cov0" title="0">if err := il.pullModelLocally(req); err != nil </span><span class="cov0" title="0">{
                        pullCh &lt;- false
                        return
                }</span>

                // Register model for distribution
                <span class="cov0" title="0">if err := il.modelDistribution.RegisterModel(req.Model, "/tmp/models/"+req.Model); err != nil </span><span class="cov0" title="0">{
                        pullCh &lt;- false
                        return
                }</span>

                <span class="cov0" title="0">pullCh &lt;- true</span>
        }()

        // Wait for pull to complete or timeout
        <span class="cov0" title="0">select </span>{
        case success := &lt;-pullCh:<span class="cov0" title="0">
                if success </span><span class="cov0" title="0">{
                        c.Header("X-Ollama-Distributed-Pull", "true")
                        c.JSON(http.StatusOK, gin.H{"status": "success", "model": req.Model})
                }</span> else<span class="cov0" title="0"> {
                        c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to pull model"})
                }</span>
        case &lt;-time.After(5 * time.Minute):<span class="cov0" title="0">
                c.JSON(http.StatusRequestTimeout, gin.H{"error": "Pull timeout"})</span>
        }
}

func (il *IntegrationLayer) getLocalModels() ([]ollamaapi.ListModelResponse, error) <span class="cov0" title="0">{
        // Create request to local Ollama instance
        req, err := http.NewRequest("GET", il.localURL.String()+"/api/tags", nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create request: %w", err)
        }</span>

        // Make request to local instance
        <span class="cov0" title="0">client := &amp;http.Client{Timeout: 10 * time.Second}
        resp, err := client.Do(req)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to get local models: %w", err)
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()

        if resp.StatusCode != http.StatusOK </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("local Ollama returned status %d", resp.StatusCode)
        }</span>

        // Parse response
        <span class="cov0" title="0">var listResponse ollamaapi.ListResponse
        if err := json.NewDecoder(resp.Body).Decode(&amp;listResponse); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to decode response: %w", err)
        }</span>

        <span class="cov0" title="0">return listResponse.Models, nil</span>
}

func (il *IntegrationLayer) getLocalProcesses() ([]ollamaapi.ProcessModelResponse, error) <span class="cov0" title="0">{
        // Create request to local Ollama instance
        req, err := http.NewRequest("GET", il.localURL.String()+"/api/ps", nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create request: %w", err)
        }</span>

        // Make request to local instance
        <span class="cov0" title="0">client := &amp;http.Client{Timeout: 10 * time.Second}
        resp, err := client.Do(req)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to get local processes: %w", err)
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()

        if resp.StatusCode != http.StatusOK </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("local Ollama returned status %d", resp.StatusCode)
        }</span>

        // Parse response
        <span class="cov0" title="0">var processResponse ollamaapi.ProcessResponse
        if err := json.NewDecoder(resp.Body).Decode(&amp;processResponse); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to decode response: %w", err)
        }</span>

        <span class="cov0" title="0">return processResponse.Models, nil</span>
}

func (il *IntegrationLayer) getDistributedProcesses() ([]ollamaapi.ProcessModelResponse, error) <span class="cov0" title="0">{
        // Get active requests from scheduler
        activeRequests := il.requestTracker.GetActiveRequests()

        // Convert to process responses
        var processes []ollamaapi.ProcessModelResponse
        for _, req := range activeRequests </span><span class="cov0" title="0">{
                process := ollamaapi.ProcessModelResponse{
                        Model: req.Model,
                        Name:  req.Model,
                        ExpiresAt: req.Started.Add(30 * time.Minute), // Default expiry
                        SizeVRAM: 0, // TODO: Get actual VRAM usage
                        Size: 0,     // TODO: Get actual size
                }
                processes = append(processes, process)
        }</span>

        // Also get processes from distributed nodes via scheduler
        <span class="cov0" title="0">if il.scheduler != nil </span><span class="cov0" title="0">{
                nodes := il.scheduler.GetAvailableNodes()
                for _, node := range nodes </span><span class="cov0" title="0">{
                        // Query each node for its processes
                        nodeProcesses, err := il.getNodeProcesses(node.ID)
                        if err != nil </span><span class="cov0" title="0">{
                                // Log error but continue with other nodes
                                continue</span>
                        }
                        <span class="cov0" title="0">processes = append(processes, nodeProcesses...)</span>
                }
        }

        <span class="cov0" title="0">return processes, nil</span>
}

func (il *IntegrationLayer) getLocalVersion() (map[string]interface{}, error) <span class="cov0" title="0">{
        // Create request to local Ollama instance
        req, err := http.NewRequest("GET", il.localURL.String()+"/api/version", nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create request: %w", err)
        }</span>

        // Make request to local instance
        <span class="cov0" title="0">client := &amp;http.Client{Timeout: 5 * time.Second}
        resp, err := client.Do(req)
        if err != nil </span><span class="cov0" title="0">{
                return map[string]interface{}{"version": "unknown"}, nil
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()

        if resp.StatusCode != http.StatusOK </span><span class="cov0" title="0">{
                return map[string]interface{}{"version": "unknown"}, nil
        }</span>

        // Parse response
        <span class="cov0" title="0">var versionResponse map[string]interface{}
        if err := json.NewDecoder(resp.Body).Decode(&amp;versionResponse); err != nil </span><span class="cov0" title="0">{
                return map[string]interface{}{"version": "unknown"}, nil
        }</span>

        <span class="cov0" title="0">return versionResponse, nil</span>
}

func (il *IntegrationLayer) handleOpenAIChat(c *gin.Context) <span class="cov0" title="0">{
        // Parse OpenAI chat completion request
        var openAIReq struct {
                Model    string `json:"model"`
                Messages []struct {
                        Role    string `json:"role"`
                        Content string `json:"content"`
                } `json:"messages"`
                Stream bool `json:"stream"`
        }

        if err := c.ShouldBindJSON(&amp;openAIReq); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>

        // Convert to Ollama chat request
        <span class="cov0" title="0">ollamaReq := ollamaapi.ChatRequest{
                Model: openAIReq.Model,
                Stream: &amp;openAIReq.Stream,
        }

        // Convert messages
        for _, msg := range openAIReq.Messages </span><span class="cov0" title="0">{
                ollamaReq.Messages = append(ollamaReq.Messages, ollamaapi.Message{
                        Role:    msg.Role,
                        Content: msg.Content,
                })
        }</span>

        // Replace request body with Ollama format
        <span class="cov0" title="0">body, _ := json.Marshal(ollamaReq)
        c.Request.Body = io.NopCloser(bytes.NewBuffer(body))
        c.Request.ContentLength = int64(len(body))

        // Handle as regular chat request
        il.handleChat(c)</span>
}

func (il *IntegrationLayer) handleOpenAICompletion(c *gin.Context) <span class="cov0" title="0">{
        // Parse OpenAI completion request
        var openAIReq struct {
                Model  string `json:"model"`
                Prompt string `json:"prompt"`
                Stream bool   `json:"stream"`
        }

        if err := c.ShouldBindJSON(&amp;openAIReq); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>

        // Convert to Ollama generate request
        <span class="cov0" title="0">ollamaReq := ollamaapi.GenerateRequest{
                Model:  openAIReq.Model,
                Prompt: openAIReq.Prompt,
                Stream: &amp;openAIReq.Stream,
        }

        // Replace request body with Ollama format
        body, _ := json.Marshal(ollamaReq)
        c.Request.Body = io.NopCloser(bytes.NewBuffer(body))
        c.Request.ContentLength = int64(len(body))

        // Handle as regular generate request
        il.handleGenerate(c)</span>
}

func (il *IntegrationLayer) handleOpenAIEmbeddings(c *gin.Context) <span class="cov0" title="0">{
        // Parse OpenAI embeddings request
        var openAIReq struct {
                Model string `json:"model"`
                Input string `json:"input"`
        }

        if err := c.ShouldBindJSON(&amp;openAIReq); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>

        // Convert to Ollama embed request
        <span class="cov0" title="0">ollamaReq := ollamaapi.EmbedRequest{
                Model: openAIReq.Model,
                Input: openAIReq.Input,
        }

        // Replace request body with Ollama format
        body, _ := json.Marshal(ollamaReq)
        c.Request.Body = io.NopCloser(bytes.NewBuffer(body))
        c.Request.ContentLength = int64(len(body))

        // Handle as regular embed request
        il.handleEmbed(c)</span>
}

func (il *IntegrationLayer) handleOpenAIModels(c *gin.Context) <span class="cov0" title="0">{
        // Get models using existing tags handler logic
        localModels, err := il.getLocalModels()
        if err != nil &amp;&amp; !il.fallbackMode </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                return
        }</span>

        <span class="cov0" title="0">distributedModels := il.modelDistribution.GetDistributedModels()
        if distributedModels == nil &amp;&amp; !il.fallbackMode </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to get distributed models"})
                return
        }</span>

        // Convert to OpenAI format
        <span class="cov0" title="0">var openAIModels []map[string]interface{}

        // Add local models
        for _, model := range localModels </span><span class="cov0" title="0">{
                openAIModels = append(openAIModels, map[string]interface{}{
                        "id":      model.Name,
                        "object":  "model",
                        "created": model.ModifiedAt.Unix(),
                        "owned_by": "ollama",
                })
        }</span>

        // Add distributed models
        <span class="cov0" title="0">for _, model := range distributedModels </span><span class="cov0" title="0">{
                if modelMap, ok := model.(map[string]interface{}); ok </span><span class="cov0" title="0">{
                        openAIModels = append(openAIModels, map[string]interface{}{
                                "id":      getString(modelMap, "name"),
                                "object":  "model",
                                "created": time.Now().Unix(), // Use current time since we don't have ModifiedAt
                                "owned_by": "ollama-distributed",
                        })
                }</span>
        }

        // Return OpenAI-compatible response
        <span class="cov0" title="0">c.Header("X-Ollama-OpenAI-Compatible", "true")
        c.JSON(http.StatusOK, map[string]interface{}{
                "object": "list",
                "data":   openAIModels,
        })</span>
}

// SetDistributedMode enables/disables distributed mode
func (il *IntegrationLayer) SetDistributedMode(enabled bool) <span class="cov0" title="0">{
        il.distributedMode = enabled
}</span>

// SetFallbackMode enables/disables fallback to local
func (il *IntegrationLayer) SetFallbackMode(enabled bool) <span class="cov0" title="0">{
        il.fallbackMode = enabled
}</span>

// GetStats returns integration layer statistics
func (il *IntegrationLayer) GetStats() map[string]interface{} <span class="cov0" title="0">{
        return map[string]interface{}{
                "distributed_mode": il.distributedMode,
                "fallback_mode":    il.fallbackMode,
                "active_requests":  len(il.requestTracker.GetActiveRequests()),
                "local_url":        il.localURL.String(),
        }
}</span>

// pullModelLocally pulls a model using the local Ollama instance
func (il *IntegrationLayer) pullModelLocally(req ollamaapi.PullRequest) error <span class="cov0" title="0">{
        // Create request to local Ollama instance
        body, err := json.Marshal(req)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal request: %w", err)
        }</span>

        <span class="cov0" title="0">httpReq, err := http.NewRequest("POST", il.localURL.String()+"/api/pull", bytes.NewBuffer(body))
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create request: %w", err)
        }</span>
        <span class="cov0" title="0">httpReq.Header.Set("Content-Type", "application/json")

        // Make request to local instance
        client := &amp;http.Client{Timeout: 10 * time.Minute}
        resp, err := client.Do(httpReq)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to pull model locally: %w", err)
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()

        if resp.StatusCode != http.StatusOK </span><span class="cov0" title="0">{
                return fmt.Errorf("local pull failed with status %d", resp.StatusCode)
        }</span>

        <span class="cov0" title="0">return nil</span>
}

// getNodeProcesses gets processes from a specific node
func (il *IntegrationLayer) getNodeProcesses(nodeID string) ([]ollamaapi.ProcessModelResponse, error) <span class="cov0" title="0">{
        // TODO: Implement P2P communication to get processes from specific node
        // For now, return empty slice
        return []ollamaapi.ProcessModelResponse{}, nil
}</pre>
		
		<pre class="file" id="file18" style="display: none">package api

import (
        "context"
        "fmt"
        "log/slog"
        "net/http"
        "os"
        "time"

        "github.com/gin-gonic/gin"
        "github.com/ollama/ollama-distributed/pkg/integration"
        "github.com/ollama/ollama-distributed/pkg/models"
        "github.com/ollama/ollama-distributed/pkg/scheduler"
)

// DistributedRoutes provides distributed routing capability for Ollama
type DistributedRoutes struct {
        scheduler         *scheduler.Engine
        integrationLayer  *IntegrationLayer
        distributedRunner *DistributedRunner
        modelDistribution *models.Manager
        
        // Original server for fallback
        originalServer integration.Server
        
        // Configuration
        distributedMode bool
        fallbackMode    bool
        localAddr       string
}

// NewDistributedRoutes creates a new distributed routes handler
func NewDistributedRoutes(scheduler *scheduler.Engine, modelDist *models.Manager, localAddr string) (*DistributedRoutes, error) <span class="cov0" title="0">{
        // Create integration layer
        integrationLayer, err := NewIntegrationLayer(scheduler, localAddr, modelDist)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create integration layer: %w", err)
        }</span>
        
        // Create distributed runner
        <span class="cov0" title="0">distributedRunner := NewDistributedRunner(scheduler, integrationLayer)
        
        return &amp;DistributedRoutes{
                scheduler:         scheduler,
                integrationLayer:  integrationLayer,
                distributedRunner: distributedRunner,
                modelDistribution: modelDist,
                distributedMode:   true,
                fallbackMode:      true,
                localAddr:         localAddr,
        }, nil</span>
}

// Start starts the distributed routes system
func (dr *DistributedRoutes) Start(ctx context.Context) error <span class="cov0" title="0">{
        // Start distributed runner
        if err := dr.distributedRunner.Start(ctx); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start distributed runner: %w", err)
        }</span>
        
        <span class="cov0" title="0">slog.Info("Distributed routes started", "localAddr", dr.localAddr)
        return nil</span>
}

// SetupRoutes sets up routes with distributed capabilities
func (dr *DistributedRoutes) SetupRoutes(router *gin.Engine) <span class="cov0" title="0">{
        // Add distributed middleware
        router.Use(dr.distributedMiddleware())
        
        // API routes with distributed handling
        api := router.Group("/api")
        </span><span class="cov0" title="0">{
                // Inference endpoints
                api.POST("/generate", dr.handleGenerate)
                api.POST("/chat", dr.handleChat)
                api.POST("/embed", dr.handleEmbed)
                api.POST("/embeddings", dr.handleEmbeddings)
                
                // Model management
                api.POST("/pull", dr.handlePull)
                api.POST("/push", dr.handlePush)
                api.POST("/show", dr.handleShow)
                api.GET("/tags", dr.handleTags)
                api.DELETE("/delete", dr.handleDelete)
                api.POST("/copy", dr.handleCopy)
                api.POST("/create", dr.handleCreate)
                
                // System endpoints
                api.GET("/ps", dr.handlePs)
                api.GET("/version", dr.handleVersion)
                
                // Distributed-specific endpoints
                api.GET("/distributed/status", dr.handleDistributedStatus)
                api.GET("/distributed/nodes", dr.handleDistributedNodes)
                api.GET("/distributed/models", dr.handleDistributedModels)
                api.POST("/distributed/rebalance", dr.handleRebalance)
                api.POST("/distributed/migrate", dr.handleMigrate)
        }</span>
        
        // OpenAI compatibility endpoints
        <span class="cov0" title="0">v1 := router.Group("/v1")
        </span><span class="cov0" title="0">{
                v1.POST("/chat/completions", dr.handleOpenAIChat)
                v1.POST("/completions", dr.handleOpenAICompletion)
                v1.POST("/embeddings", dr.handleOpenAIEmbeddings)
                v1.GET("/models", dr.handleOpenAIModels)
                v1.GET("/models/:model", dr.handleOpenAIModel)
        }</span>
        
        // Health and metrics
        <span class="cov0" title="0">router.GET("/health", dr.handleHealth)
        router.GET("/metrics", dr.handleMetrics)
        
        // Distributed admin endpoints
        admin := router.Group("/admin")
        </span><span class="cov0" title="0">{
                admin.Use(dr.adminAuthMiddleware())
                admin.POST("/mode", dr.handleSetMode)
                admin.POST("/fallback", dr.handleSetFallback)
                admin.POST("/rebalance", dr.handleForceRebalance)
                admin.GET("/stats", dr.handleStats)
        }</span>
}

// Middleware

func (dr *DistributedRoutes) distributedMiddleware() gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                // Add distributed headers
                c.Header("X-Ollama-Distributed", "true")
                c.Header("X-Ollama-Version", "distributed")
                c.Header("X-Ollama-Cluster-Size", fmt.Sprintf("%d", dr.scheduler.GetClusterSize()))
                c.Header("X-Ollama-Mode", dr.getMode())
                
                // Add request ID for tracing
                requestID := fmt.Sprintf("req_%d", time.Now().UnixNano())
                c.Header("X-Request-ID", requestID)
                c.Set("requestID", requestID)
                
                // Continue processing
                c.Next()
        }</span>
}

func (dr *DistributedRoutes) adminAuthMiddleware() gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                // Simple token-based auth for admin endpoints
                token := c.GetHeader("Authorization")
                if token == "" || token != "Bearer "+os.Getenv("OLLAMA_ADMIN_TOKEN") </span><span class="cov0" title="0">{
                        c.JSON(http.StatusUnauthorized, gin.H{"error": "unauthorized"})
                        c.Abort()
                        return
                }</span>
                <span class="cov0" title="0">c.Next()</span>
        }
}

// Core API handlers

func (dr *DistributedRoutes) handleGenerate(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

func (dr *DistributedRoutes) handleChat(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

func (dr *DistributedRoutes) handleEmbed(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

func (dr *DistributedRoutes) handleEmbeddings(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

func (dr *DistributedRoutes) handlePull(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

func (dr *DistributedRoutes) handlePush(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

func (dr *DistributedRoutes) handleShow(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

func (dr *DistributedRoutes) handleTags(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

func (dr *DistributedRoutes) handleDelete(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

func (dr *DistributedRoutes) handleCopy(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

func (dr *DistributedRoutes) handleCreate(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

func (dr *DistributedRoutes) handlePs(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

func (dr *DistributedRoutes) handleVersion(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

// OpenAI compatibility handlers

func (dr *DistributedRoutes) handleOpenAIChat(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

func (dr *DistributedRoutes) handleOpenAICompletion(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

func (dr *DistributedRoutes) handleOpenAIEmbeddings(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

func (dr *DistributedRoutes) handleOpenAIModels(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

func (dr *DistributedRoutes) handleOpenAIModel(c *gin.Context) <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                dr.integrationLayer.HandleRequest(c)
        }</span> else<span class="cov0" title="0"> {
                dr.fallbackToOriginal(c)
        }</span>
}

// Distributed-specific handlers

func (dr *DistributedRoutes) handleDistributedStatus(c *gin.Context) <span class="cov0" title="0">{
        status := map[string]interface{}{
                "distributed_mode": dr.distributedMode,
                "fallback_mode":    dr.fallbackMode,
                "cluster_size":     dr.scheduler.GetClusterSize(),
                "active_nodes":     dr.scheduler.GetActiveNodes(),
                "scheduler_stats":  dr.scheduler.GetStats(),
                "runner_stats":     dr.distributedRunner.GetStats(),
                "integration_stats": dr.integrationLayer.GetStats(),
        }
        
        c.JSON(http.StatusOK, status)
}</span>

func (dr *DistributedRoutes) handleDistributedNodes(c *gin.Context) <span class="cov0" title="0">{
        nodes := dr.scheduler.GetNodes()
        c.JSON(http.StatusOK, gin.H{"nodes": nodes})
}</span>

func (dr *DistributedRoutes) handleDistributedModels(c *gin.Context) <span class="cov0" title="0">{
        models := dr.modelDistribution.GetDistributedModels()
        c.JSON(http.StatusOK, gin.H{"models": models})
}</span>

func (dr *DistributedRoutes) handleRebalance(c *gin.Context) <span class="cov0" title="0">{
        if err := dr.modelDistribution.Rebalance(); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                return
        }</span>
        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{"message": "Rebalance initiated"})</span>
}

func (dr *DistributedRoutes) handleMigrate(c *gin.Context) <span class="cov0" title="0">{
        var req struct {
                ModelName string `json:"model_name"`
                FromNode  string `json:"from_node"`
                ToNode    string `json:"to_node"`
        }
        
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        <span class="cov0" title="0">if err := dr.modelDistribution.MigrateModel(req.ModelName, req.ToNode); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                return
        }</span>
        
        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{"message": "Migration initiated"})</span>
}

// System handlers

func (dr *DistributedRoutes) handleHealth(c *gin.Context) <span class="cov0" title="0">{
        health := map[string]interface{}{
                "status":       "healthy",
                "timestamp":    time.Now().Unix(),
                "distributed":  dr.distributedMode,
                "cluster_size": dr.scheduler.GetClusterSize(),
                "services": map[string]interface{}{
                        "scheduler":   dr.scheduler.IsHealthy(),
                        "runner":      len(dr.distributedRunner.GetActiveRunners()) &gt; 0,
                        "integration": dr.integrationLayer != nil,
                },
        }
        
        c.JSON(http.StatusOK, health)
}</span>

func (dr *DistributedRoutes) handleMetrics(c *gin.Context) <span class="cov0" title="0">{
        metrics := map[string]interface{}{
                "scheduler":   dr.scheduler.GetStats(),
                "runner":      dr.distributedRunner.GetStats(),
                "integration": dr.integrationLayer.GetStats(),
                "models":      dr.modelDistribution.GetStats(),
        }
        
        c.JSON(http.StatusOK, metrics)
}</span>

// Admin handlers

func (dr *DistributedRoutes) handleSetMode(c *gin.Context) <span class="cov0" title="0">{
        var req struct {
                Mode string `json:"mode"`
        }
        
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        <span class="cov0" title="0">switch req.Mode </span>{
        case "distributed":<span class="cov0" title="0">
                dr.distributedMode = true
                dr.integrationLayer.SetDistributedMode(true)</span>
        case "local":<span class="cov0" title="0">
                dr.distributedMode = false
                dr.integrationLayer.SetDistributedMode(false)</span>
        default:<span class="cov0" title="0">
                c.JSON(http.StatusBadRequest, gin.H{"error": "invalid mode"})
                return</span>
        }
        
        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{"message": fmt.Sprintf("Mode set to %s", req.Mode)})</span>
}

func (dr *DistributedRoutes) handleSetFallback(c *gin.Context) <span class="cov0" title="0">{
        var req struct {
                Enabled bool `json:"enabled"`
        }
        
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        <span class="cov0" title="0">dr.fallbackMode = req.Enabled
        dr.integrationLayer.SetFallbackMode(req.Enabled)
        
        c.JSON(http.StatusOK, gin.H{"message": fmt.Sprintf("Fallback mode set to %v", req.Enabled)})</span>
}

func (dr *DistributedRoutes) handleForceRebalance(c *gin.Context) <span class="cov0" title="0">{
        if err := dr.modelDistribution.ForceRebalance(); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                return
        }</span>
        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{"message": "Force rebalance initiated"})</span>
}

func (dr *DistributedRoutes) handleStats(c *gin.Context) <span class="cov0" title="0">{
        stats := map[string]interface{}{
                "mode":             dr.getMode(),
                "uptime":           time.Since(time.Now()).String(),
                "cluster_size":     dr.scheduler.GetClusterSize(),
                "active_nodes":     dr.scheduler.GetActiveNodes(),
                "total_models":     dr.modelDistribution.GetTotalModels(),
                "distributed_models": dr.modelDistribution.GetDistributedModelCount(),
                "active_runners":   len(dr.distributedRunner.GetActiveRunners()),
                "scheduler_stats":  dr.scheduler.GetStats(),
                "runner_stats":     dr.distributedRunner.GetStats(),
                "integration_stats": dr.integrationLayer.GetStats(),
        }
        
        c.JSON(http.StatusOK, stats)
}</span>

// Helper methods

func (dr *DistributedRoutes) getMode() string <span class="cov0" title="0">{
        if dr.distributedMode </span><span class="cov0" title="0">{
                if dr.fallbackMode </span><span class="cov0" title="0">{
                        return "distributed-with-fallback"
                }</span>
                <span class="cov0" title="0">return "distributed"</span>
        }
        <span class="cov0" title="0">return "local"</span>
}

func (dr *DistributedRoutes) fallbackToOriginal(c *gin.Context) <span class="cov0" title="0">{
        if dr.originalServer != nil </span><span class="cov0" title="0">{
                // TODO: Implement fallback to original server
                c.Header("X-Ollama-Fallback", "original-server")
        }</span>
        
        // For now, proxy to local
        <span class="cov0" title="0">dr.integrationLayer.proxyToLocal(c)</span>
}

// SetOriginalServer sets the original server for fallback
func (dr *DistributedRoutes) SetOriginalServer(server integration.Server) <span class="cov0" title="0">{
        dr.originalServer = server
}</span>

// GetIntegrationLayer returns the integration layer
func (dr *DistributedRoutes) GetIntegrationLayer() *IntegrationLayer <span class="cov0" title="0">{
        return dr.integrationLayer
}</span>

// GetDistributedRunner returns the distributed runner
func (dr *DistributedRoutes) GetDistributedRunner() *DistributedRunner <span class="cov0" title="0">{
        return dr.distributedRunner
}</span>

// IsDistributedMode returns whether distributed mode is enabled
func (dr *DistributedRoutes) IsDistributedMode() bool <span class="cov0" title="0">{
        return dr.distributedMode
}</span>

// IsFallbackMode returns whether fallback mode is enabled
func (dr *DistributedRoutes) IsFallbackMode() bool <span class="cov0" title="0">{
        return dr.fallbackMode
}</span>

// Shutdown gracefully shuts down the distributed routes
func (dr *DistributedRoutes) Shutdown(ctx context.Context) error <span class="cov0" title="0">{
        slog.Info("Shutting down distributed routes")
        
        // Shutdown distributed runner
        if err := dr.distributedRunner.Shutdown(ctx); err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to shutdown distributed runner", "error", err)
                return err
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}</pre>
		
		<pre class="file" id="file19" style="display: none">package api

import (
        "context"
        "fmt"
        "log/slog"
        "net/http"
        "os"
        "strings"

        "github.com/gin-gonic/gin"
        "github.com/ollama/ollama-distributed/pkg/integration"
        "github.com/ollama/ollama-distributed/pkg/models"
        "github.com/ollama/ollama-distributed/pkg/scheduler"
)

// RouteIntegration provides seamless integration with existing Ollama routes
type RouteIntegration struct {
        distributedWrapper *DistributedServerWrapper
        compatibility      *DistributedServerCompatibility
        fallbackManager    *FallbackManager
        standalone         *StandaloneMode
        
        // Integration state
        enabled     bool
        initialized bool
}

// NewRouteIntegration creates a new route integration
func NewRouteIntegration(scheduler *scheduler.Engine, modelDist *models.Manager, localAddr string) (*RouteIntegration, error) <span class="cov0" title="0">{
        // Create fallback manager
        fallbackMgr, err := NewFallbackManager(localAddr)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create fallback manager: %w", err)
        }</span>
        
        // Create standalone mode
        <span class="cov0" title="0">standalone := NewStandaloneMode(fallbackMgr)
        
        return &amp;RouteIntegration{
                fallbackManager: fallbackMgr,
                standalone:      standalone,
                enabled:         os.Getenv("OLLAMA_DISTRIBUTED") != "false",
                initialized:     false,
        }, nil</span>
}

// Initialize initializes the route integration with an existing server
func (ri *RouteIntegration) Initialize(originalServer interface{}, scheduler *scheduler.Engine, modelDist *models.Manager, localAddr string) error <span class="cov0" title="0">{
        if ri.initialized </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        // Create distributed wrapper
        <span class="cov0" title="0">wrapper, err := NewDistributedServerWrapper(originalServer, scheduler, modelDist, localAddr)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create distributed wrapper: %w", err)
        }</span>
        
        // Create compatibility layer
        <span class="cov0" title="0">compatibility := NewDistributedServerCompatibility(wrapper)
        
        ri.distributedWrapper = wrapper
        ri.compatibility = compatibility
        ri.initialized = true
        
        slog.Info("Route integration initialized", "enabled", ri.enabled)
        return nil</span>
}

// WrapGenerateRoutes wraps the original GenerateRoutes function
func (ri *RouteIntegration) WrapGenerateRoutes(originalServer interface{}, scheduler *scheduler.Engine, modelDist *models.Manager, localAddr string) func(*integration.Registry) (http.Handler, error) <span class="cov0" title="0">{
        return func(rc *integration.Registry) (http.Handler, error) </span><span class="cov0" title="0">{
                // Initialize if not done
                if !ri.initialized </span><span class="cov0" title="0">{
                        if err := ri.Initialize(originalServer, scheduler, modelDist, localAddr); err != nil </span><span class="cov0" title="0">{
                                slog.Error("Failed to initialize route integration", "error", err)
                                // Fall back to original
                                if generator, ok := originalServer.(interface{ GenerateRoutes(*integration.Registry) (http.Handler, error) }); ok </span><span class="cov0" title="0">{
                                        return generator.GenerateRoutes(rc)
                                }</span>
                                <span class="cov0" title="0">return http.DefaultServeMux, fmt.Errorf("original server doesn't support GenerateRoutes")</span>
                        }
                }
                
                // Check if distributed mode is enabled
                <span class="cov0" title="0">if !ri.enabled </span><span class="cov0" title="0">{
                        slog.Info("Distributed mode disabled, using original routes")
                        if generator, ok := originalServer.(interface{ GenerateRoutes(*integration.Registry) (http.Handler, error) }); ok </span><span class="cov0" title="0">{
                                return generator.GenerateRoutes(rc)
                        }</span>
                        <span class="cov0" title="0">return http.DefaultServeMux, fmt.Errorf("original server doesn't support GenerateRoutes")</span>
                }
                
                // Check if we should use standalone mode
                <span class="cov0" title="0">if ri.shouldUseStandaloneMode() </span><span class="cov0" title="0">{
                        slog.Info("Using standalone mode")
                        return ri.generateStandaloneRoutes(rc)
                }</span>
                
                // Use distributed routes
                <span class="cov0" title="0">slog.Info("Using distributed routes")
                return ri.distributedWrapper.GenerateRoutesWithDistributed(rc)</span>
        }
}

// shouldUseStandaloneMode determines if standalone mode should be used
func (ri *RouteIntegration) shouldUseStandaloneMode() bool <span class="cov0" title="0">{
        // Check if explicitly enabled
        if os.Getenv("OLLAMA_STANDALONE") == "true" </span><span class="cov0" title="0">{
                ri.standalone.Enable("environment-variable")
                return true
        }</span>
        
        // Check if no distributed components are available
        <span class="cov0" title="0">if ri.distributedWrapper == nil </span><span class="cov0" title="0">{
                ri.standalone.Enable("no-distributed-components")
                return true
        }</span>
        
        // Check if local instance is unhealthy
        <span class="cov0" title="0">if !ri.fallbackManager.IsLocalHealthy() </span><span class="cov0" title="0">{
                ri.standalone.Enable("local-unhealthy")
                return true
        }</span>
        
        <span class="cov0" title="0">return ri.standalone.IsEnabled()</span>
}

// generateStandaloneRoutes generates routes for standalone mode
func (ri *RouteIntegration) generateStandaloneRoutes(rc *integration.Registry) (http.Handler, error) <span class="cov0" title="0">{
        router := gin.New()
        router.Use(gin.Logger())
        router.Use(gin.Recovery())
        
        // Add standalone middleware
        router.Use(ri.standaloneMiddleware())
        
        // All routes go through standalone handler
        router.Any("/*path", ri.standalone.HandleRequest)
        
        return router, nil
}</span>

// standaloneMiddleware adds standalone-specific middleware
func (ri *RouteIntegration) standaloneMiddleware() gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                c.Header("X-Ollama-Mode", "standalone")
                c.Header("X-Ollama-Standalone", "true")
                c.Header("X-Ollama-Standalone-Reason", ri.standalone.GetReason())
                c.Next()
        }</span>
}

// CreateIntegratedRouter creates a router with integrated distributed capabilities
func (ri *RouteIntegration) CreateIntegratedRouter(originalServer interface{}, rc *integration.Registry) (*gin.Engine, error) <span class="cov0" title="0">{
        router := gin.New()
        router.Use(gin.Logger())
        router.Use(gin.Recovery())
        
        // Add integration middleware
        router.Use(ri.integrationMiddleware())
        
        // Get original routes
        var originalHandler http.Handler
        var err error
        if generator, ok := originalServer.(interface{ GenerateRoutes(*integration.Registry) (http.Handler, error) }); ok </span><span class="cov0" title="0">{
                originalHandler, err = generator.GenerateRoutes(rc)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to get original routes: %w", err)
                }</span>
        } else<span class="cov0" title="0"> {
                originalHandler = http.DefaultServeMux
        }</span>
        
        // Add distributed routes if enabled
        <span class="cov0" title="0">if ri.enabled &amp;&amp; ri.compatibility != nil </span><span class="cov0" title="0">{
                // Inject distributed handlers
                ri.compatibility.InjectDistributedHandlers(router)
                
                // Register distributed endpoints
                ri.compatibility.RegisterDistributedEndpoints(router)
        }</span>
        
        // Add fallback handler
        <span class="cov0" title="0">router.NoRoute(func(c *gin.Context) </span><span class="cov0" title="0">{
                // Check if we should use distributed
                if ri.shouldUseDistributed(c) </span><span class="cov0" title="0">{
                        // Try distributed first
                        if ri.compatibility != nil </span><span class="cov0" title="0">{
                                handlers := ri.compatibility.GetDistributedHandlers()
                                if handler, exists := handlers[ri.getHandlerName(c.Request.URL.Path)]; exists </span><span class="cov0" title="0">{
                                        handler(c)
                                        return
                                }</span>
                        }
                }
                
                // Fall back to original
                <span class="cov0" title="0">originalHandler.ServeHTTP(c.Writer, c.Request)</span>
        })
        
        <span class="cov0" title="0">return router, nil</span>
}

// integrationMiddleware adds integration-specific middleware
func (ri *RouteIntegration) integrationMiddleware() gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                c.Header("X-Ollama-Integration", "true")
                c.Header("X-Ollama-Integration-Enabled", fmt.Sprintf("%v", ri.enabled))
                c.Header("X-Ollama-Integration-Initialized", fmt.Sprintf("%v", ri.initialized))
                
                // Add health status
                if ri.fallbackManager != nil </span><span class="cov0" title="0">{
                        c.Header("X-Ollama-Local-Healthy", fmt.Sprintf("%v", ri.fallbackManager.IsLocalHealthy()))
                }</span>
                
                <span class="cov0" title="0">c.Next()</span>
        }
}

// shouldUseDistributed determines if a request should use distributed routing
func (ri *RouteIntegration) shouldUseDistributed(c *gin.Context) bool <span class="cov0" title="0">{
        if !ri.enabled || ri.compatibility == nil </span><span class="cov0" title="0">{
                return false
        }</span>
        
        // Check path
        <span class="cov0" title="0">path := c.Request.URL.Path
        
        // Use distributed for inference endpoints
        if strings.Contains(path, "/generate") ||
                strings.Contains(path, "/chat") ||
                strings.Contains(path, "/embed") ||
                strings.Contains(path, "/completions") </span><span class="cov0" title="0">{
                return true
        }</span>
        
        // Use distributed for model management
        <span class="cov0" title="0">if strings.Contains(path, "/show") ||
                strings.Contains(path, "/tags") ||
                strings.Contains(path, "/pull") </span><span class="cov0" title="0">{
                return true
        }</span>
        
        <span class="cov0" title="0">return false</span>
}

// getHandlerName extracts handler name from path
func (ri *RouteIntegration) getHandlerName(path string) string <span class="cov0" title="0">{
        parts := strings.Split(path, "/")
        if len(parts) &gt;= 3 </span><span class="cov0" title="0">{
                return parts[len(parts)-1]
        }</span>
        <span class="cov0" title="0">return ""</span>
}

// EnableDistributedMode enables distributed mode
func (ri *RouteIntegration) EnableDistributedMode() error <span class="cov0" title="0">{
        ri.enabled = true
        
        if ri.compatibility != nil </span><span class="cov0" title="0">{
                config := map[string]interface{}{
                        "fallback": true,
                }
                return ri.compatibility.EnableDistributedMode(config)
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// DisableDistributedMode disables distributed mode
func (ri *RouteIntegration) DisableDistributedMode() error <span class="cov0" title="0">{
        ri.enabled = false
        
        if ri.compatibility != nil </span><span class="cov0" title="0">{
                return ri.compatibility.DisableDistributedMode()
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// EnableStandaloneMode enables standalone mode
func (ri *RouteIntegration) EnableStandaloneMode(reason string) <span class="cov0" title="0">{
        ri.standalone.Enable(reason)
}</span>

// DisableStandaloneMode disables standalone mode
func (ri *RouteIntegration) DisableStandaloneMode() <span class="cov0" title="0">{
        ri.standalone.Disable()
}</span>

// IsDistributedMode returns whether distributed mode is enabled
func (ri *RouteIntegration) IsDistributedMode() bool <span class="cov0" title="0">{
        return ri.enabled
}</span>

// IsStandaloneMode returns whether standalone mode is enabled
func (ri *RouteIntegration) IsStandaloneMode() bool <span class="cov0" title="0">{
        return ri.standalone.IsEnabled()
}</span>

// GetStatus returns integration status
func (ri *RouteIntegration) GetStatus() map[string]interface{} <span class="cov0" title="0">{
        status := map[string]interface{}{
                "enabled":     ri.enabled,
                "initialized": ri.initialized,
                "mode":        ri.getMode(),
        }
        
        if ri.fallbackManager != nil </span><span class="cov0" title="0">{
                status["fallback"] = ri.fallbackManager.GetStats()
        }</span>
        
        <span class="cov0" title="0">if ri.standalone != nil </span><span class="cov0" title="0">{
                status["standalone"] = ri.standalone.GetStats()
        }</span>
        
        <span class="cov0" title="0">if ri.compatibility != nil </span><span class="cov0" title="0">{
                status["distributed"] = ri.compatibility.GetDistributedStatus()
        }</span>
        
        <span class="cov0" title="0">return status</span>
}

// getMode returns the current mode
func (ri *RouteIntegration) getMode() string <span class="cov0" title="0">{
        if ri.standalone.IsEnabled() </span><span class="cov0" title="0">{
                return "standalone"
        }</span>
        
        <span class="cov0" title="0">if ri.enabled </span><span class="cov0" title="0">{
                return "distributed"
        }</span>
        
        <span class="cov0" title="0">return "local"</span>
}

// Start starts the route integration
func (ri *RouteIntegration) Start(ctx context.Context) error <span class="cov0" title="0">{
        if ri.distributedWrapper != nil </span><span class="cov0" title="0">{
                return ri.distributedWrapper.Start(ctx)
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// Shutdown shuts down the route integration
func (ri *RouteIntegration) Shutdown(ctx context.Context) error <span class="cov0" title="0">{
        if ri.distributedWrapper != nil </span><span class="cov0" title="0">{
                return ri.distributedWrapper.Shutdown(ctx)
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// GetFallbackManager returns the fallback manager
func (ri *RouteIntegration) GetFallbackManager() *FallbackManager <span class="cov0" title="0">{
        return ri.fallbackManager
}</span>

// GetDistributedWrapper returns the distributed wrapper
func (ri *RouteIntegration) GetDistributedWrapper() *DistributedServerWrapper <span class="cov0" title="0">{
        return ri.distributedWrapper
}</span>

// GetCompatibility returns the compatibility layer
func (ri *RouteIntegration) GetCompatibility() *DistributedServerCompatibility <span class="cov0" title="0">{
        return ri.compatibility
}</span>

// Global integration instance
var globalIntegration *RouteIntegration

// InitializeGlobalIntegration initializes the global integration
func InitializeGlobalIntegration(scheduler *scheduler.Engine, modelDist *models.Manager, localAddr string) error <span class="cov0" title="0">{
        integration, err := NewRouteIntegration(scheduler, modelDist, localAddr)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create global integration: %w", err)
        }</span>
        
        <span class="cov0" title="0">globalIntegration = integration
        return nil</span>
}

// GetGlobalIntegration returns the global integration
func GetGlobalIntegration() *RouteIntegration <span class="cov0" title="0">{
        return globalIntegration
}</span>

// WrapServerGenerateRoutes wraps the server's GenerateRoutes method
func WrapServerGenerateRoutes(originalServer interface{}, scheduler *scheduler.Engine, modelDist *models.Manager, localAddr string) func(*integration.Registry) (http.Handler, error) <span class="cov0" title="0">{
        // Initialize global integration if not done
        if globalIntegration == nil </span><span class="cov0" title="0">{
                if err := InitializeGlobalIntegration(scheduler, modelDist, localAddr); err != nil </span><span class="cov0" title="0">{
                        slog.Error("Failed to initialize global integration", "error", err)
                        // Return original function if it supports GenerateRoutes
                        if generator, ok := originalServer.(interface{ GenerateRoutes(*integration.Registry) (http.Handler, error) }); ok </span><span class="cov0" title="0">{
                                return generator.GenerateRoutes
                        }</span>
                        // Return fallback function
                        <span class="cov0" title="0">return func(*integration.Registry) (http.Handler, error) </span><span class="cov0" title="0">{
                                return http.DefaultServeMux, fmt.Errorf("original server doesn't support GenerateRoutes")
                        }</span>
                }
        }
        
        // Return wrapped function
        <span class="cov0" title="0">return globalIntegration.WrapGenerateRoutes(originalServer, scheduler, modelDist, localAddr)</span>
}

// Helper functions for external integration

// EnableDistributed enables distributed mode globally
func EnableDistributed() error <span class="cov0" title="0">{
        if globalIntegration == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("global integration not initialized")
        }</span>
        <span class="cov0" title="0">return globalIntegration.EnableDistributedMode()</span>
}

// DisableDistributed disables distributed mode globally
func DisableDistributed() error <span class="cov0" title="0">{
        if globalIntegration == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("global integration not initialized")
        }</span>
        <span class="cov0" title="0">return globalIntegration.DisableDistributedMode()</span>
}

// EnableStandalone enables standalone mode globally
func EnableStandalone(reason string) <span class="cov0" title="0">{
        if globalIntegration != nil </span><span class="cov0" title="0">{
                globalIntegration.EnableStandaloneMode(reason)
        }</span>
}

// DisableStandalone disables standalone mode globally
func DisableStandalone() <span class="cov0" title="0">{
        if globalIntegration != nil </span><span class="cov0" title="0">{
                globalIntegration.DisableStandaloneMode()
        }</span>
}

// GetIntegrationStatus returns global integration status
func GetIntegrationStatus() map[string]interface{} <span class="cov0" title="0">{
        if globalIntegration == nil </span><span class="cov0" title="0">{
                return map[string]interface{}{
                        "initialized": false,
                        "error":       "global integration not initialized",
                }
        }</span>
        <span class="cov0" title="0">return globalIntegration.GetStatus()</span>
}</pre>
		
		<pre class="file" id="file20" style="display: none">package api

import (
        "context"
        "fmt"
        "net/http"
        "sync"
        "time"

        "github.com/gin-gonic/gin"
        ollamaapi "github.com/ollama/ollama/api"
        "github.com/ollama/ollama-distributed/pkg/scheduler"
)

// Stub types for missing llm package
type CompletionRequest struct {
        Model  string `json:"model"`
        Prompt string `json:"prompt"`
        Stream bool   `json:"stream,omitempty"`
}

type CompletionResponse struct {
        Text     string `json:"text"`
        Finished bool   `json:"finished"`
        Error    string `json:"error,omitempty"`
}

// DistributedRunner extends the existing runner functionality for distributed execution
type DistributedRunner struct {
        scheduler       *scheduler.Engine
        integrationLayer *IntegrationLayer
        
        // Runner state
        mu              sync.RWMutex
        activeRunners   map[string]*RunnerInstance
        runnerPool      chan *RunnerInstance
        maxRunners      int
        
        // Metrics
        requestCount    int64
        successCount    int64
        failureCount    int64
        averageLatency  time.Duration
}

// RunnerInstance represents a runner instance on a specific node
type RunnerInstance struct {
        ID          string
        NodeID      string
        ModelName   string
        Status      string
        Created     time.Time
        LastUsed    time.Time
        RequestChan chan *RunnerRequest
        ResponseChan chan *RunnerResponse
}

// RunnerRequest represents a request to a runner
type RunnerRequest struct {
        ID       string
        Type     string
        Context  context.Context
        Payload  interface{}
        Response chan *RunnerResponse
}

// RunnerResponse represents a response from a runner
type RunnerResponse struct {
        ID      string
        Success bool
        Data    interface{}
        Error   string
        NodeID  string
        Latency time.Duration
}

// NewDistributedRunner creates a new distributed runner
func NewDistributedRunner(scheduler *scheduler.Engine, integrationLayer *IntegrationLayer) *DistributedRunner <span class="cov0" title="0">{
        return &amp;DistributedRunner{
                scheduler:        scheduler,
                integrationLayer: integrationLayer,
                activeRunners:    make(map[string]*RunnerInstance),
                runnerPool:       make(chan *RunnerInstance, 100),
                maxRunners:       10,
        }
}</span>

// Start starts the distributed runner
func (dr *DistributedRunner) Start(ctx context.Context) error <span class="cov0" title="0">{
        // Start runner pool manager
        go dr.manageRunnerPool(ctx)
        
        // Start metrics collection
        go dr.collectMetrics(ctx)
        
        return nil
}</span>

// ExecuteRequest executes a request using distributed runners
func (dr *DistributedRunner) ExecuteRequest(req *RunnerRequest) (*RunnerResponse, error) <span class="cov0" title="0">{
        startTime := time.Now()
        
        // Get or create runner instance
        runner, err := dr.getRunner(req.Type)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to get runner: %w", err)
        }</span>
        
        // Send request to runner
        <span class="cov0" title="0">select </span>{
        case runner.RequestChan &lt;- req:<span class="cov0" title="0"></span>
                // Request sent successfully
        case &lt;-time.After(5 * time.Second):<span class="cov0" title="0">
                return nil, fmt.Errorf("runner request timeout")</span>
        }
        
        // Wait for response
        <span class="cov0" title="0">select </span>{
        case resp := &lt;-req.Response:<span class="cov0" title="0">
                resp.Latency = time.Since(startTime)
                dr.updateMetrics(resp)
                return resp, nil</span>
        case &lt;-time.After(30 * time.Second):<span class="cov0" title="0">
                return nil, fmt.Errorf("runner response timeout")</span>
        }
}

// HandleGeneration handles generation requests
func (dr *DistributedRunner) HandleGeneration(c *gin.Context) <span class="cov0" title="0">{
        var req ollamaapi.GenerateRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        // Create runner request
        <span class="cov0" title="0">runnerReq := &amp;RunnerRequest{
                ID:       fmt.Sprintf("gen_%d", time.Now().UnixNano()),
                Type:     "generate",
                Context:  c.Request.Context(),
                Payload:  req,
                Response: make(chan *RunnerResponse, 1),
        }
        
        // Execute request
        resp, err := dr.ExecuteRequest(runnerReq)
        if err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                return
        }</span>
        
        <span class="cov0" title="0">if resp.Success </span><span class="cov0" title="0">{
                c.Header("X-Ollama-Node", resp.NodeID)
                c.Header("X-Ollama-Latency", resp.Latency.String())
                c.JSON(http.StatusOK, resp.Data)
        }</span> else<span class="cov0" title="0"> {
                c.JSON(http.StatusInternalServerError, gin.H{"error": resp.Error})
        }</span>
}

// HandleChat handles chat requests
func (dr *DistributedRunner) HandleChat(c *gin.Context) <span class="cov0" title="0">{
        var req ollamaapi.ChatRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        // Create runner request
        <span class="cov0" title="0">runnerReq := &amp;RunnerRequest{
                ID:       fmt.Sprintf("chat_%d", time.Now().UnixNano()),
                Type:     "chat",
                Context:  c.Request.Context(),
                Payload:  req,
                Response: make(chan *RunnerResponse, 1),
        }
        
        // Execute request
        resp, err := dr.ExecuteRequest(runnerReq)
        if err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                return
        }</span>
        
        <span class="cov0" title="0">if resp.Success </span><span class="cov0" title="0">{
                c.Header("X-Ollama-Node", resp.NodeID)
                c.Header("X-Ollama-Latency", resp.Latency.String())
                c.JSON(http.StatusOK, resp.Data)
        }</span> else<span class="cov0" title="0"> {
                c.JSON(http.StatusInternalServerError, gin.H{"error": resp.Error})
        }</span>
}

// HandleEmbedding handles embedding requests
func (dr *DistributedRunner) HandleEmbedding(c *gin.Context) <span class="cov0" title="0">{
        var req ollamaapi.EmbedRequest
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        // Create runner request
        <span class="cov0" title="0">runnerReq := &amp;RunnerRequest{
                ID:       fmt.Sprintf("embed_%d", time.Now().UnixNano()),
                Type:     "embed",
                Context:  c.Request.Context(),
                Payload:  req,
                Response: make(chan *RunnerResponse, 1),
        }
        
        // Execute request
        resp, err := dr.ExecuteRequest(runnerReq)
        if err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                return
        }</span>
        
        <span class="cov0" title="0">if resp.Success </span><span class="cov0" title="0">{
                c.Header("X-Ollama-Node", resp.NodeID)
                c.Header("X-Ollama-Latency", resp.Latency.String())
                c.JSON(http.StatusOK, resp.Data)
        }</span> else<span class="cov0" title="0"> {
                c.JSON(http.StatusInternalServerError, gin.H{"error": resp.Error})
        }</span>
}

// getRunner gets or creates a runner instance
func (dr *DistributedRunner) getRunner(requestType string) (*RunnerInstance, error) <span class="cov0" title="0">{
        dr.mu.Lock()
        defer dr.mu.Unlock()
        
        // Try to get from pool
        select </span>{
        case runner := &lt;-dr.runnerPool:<span class="cov0" title="0">
                runner.LastUsed = time.Now()
                return runner, nil</span>
        default:<span class="cov0" title="0">
                // Create new runner if pool is empty
                if len(dr.activeRunners) &lt; dr.maxRunners </span><span class="cov0" title="0">{
                        return dr.createRunner(requestType)
                }</span>
                <span class="cov0" title="0">return nil, fmt.Errorf("max runners reached")</span>
        }
}

// createRunner creates a new runner instance
func (dr *DistributedRunner) createRunner(requestType string) (*RunnerInstance, error) <span class="cov0" title="0">{
        // Get available node from scheduler
        nodes := dr.scheduler.GetAvailableNodes()
        if len(nodes) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no available nodes")
        }</span>
        
        // Select best node (for now, just use first)
        <span class="cov0" title="0">nodeID := nodes[0].ID
        
        runner := &amp;RunnerInstance{
                ID:           fmt.Sprintf("runner_%d", time.Now().UnixNano()),
                NodeID:       nodeID,
                ModelName:    "auto", // Will be set based on request
                Status:       "active",
                Created:      time.Now(),
                LastUsed:     time.Now(),
                RequestChan:  make(chan *RunnerRequest, 10),
                ResponseChan: make(chan *RunnerResponse, 10),
        }
        
        // Start runner goroutine
        go dr.runRunner(runner)
        
        dr.activeRunners[runner.ID] = runner
        
        return runner, nil</span>
}

// runRunner runs a runner instance
func (dr *DistributedRunner) runRunner(runner *RunnerInstance) <span class="cov0" title="0">{
        defer func() </span><span class="cov0" title="0">{
                dr.mu.Lock()
                delete(dr.activeRunners, runner.ID)
                dr.mu.Unlock()
        }</span>()
        
        <span class="cov0" title="0">for </span><span class="cov0" title="0">{
                select </span>{
                case req := &lt;-runner.RequestChan:<span class="cov0" title="0">
                        // Process request
                        resp := dr.processRequest(runner, req)
                        
                        // Send response
                        select </span>{
                        case req.Response &lt;- resp:<span class="cov0" title="0"></span>
                                // Response sent
                        case &lt;-time.After(5 * time.Second):<span class="cov0" title="0"></span>
                                // Response timeout
                        }
                        
                case &lt;-time.After(30 * time.Second):<span class="cov0" title="0">
                        // Runner idle timeout
                        return</span>
                }
        }
}

// processRequest processes a request on a runner
func (dr *DistributedRunner) processRequest(runner *RunnerInstance, req *RunnerRequest) *RunnerResponse <span class="cov0" title="0">{
        startTime := time.Now()
        
        // Create scheduler request
        // Convert interface{} payload to map[string]interface{}
        var payload map[string]interface{}
        if req.Payload != nil </span><span class="cov0" title="0">{
                if p, ok := req.Payload.(map[string]interface{}); ok </span><span class="cov0" title="0">{
                        payload = p
                }</span> else<span class="cov0" title="0"> {
                        // If payload is not a map, wrap it
                        payload = map[string]interface{}{
                                "data": req.Payload,
                        }
                }</span>
        }
        
        <span class="cov0" title="0">schedReq := &amp;scheduler.Request{
                ID:         req.ID,
                Type:       req.Type,
                Priority:   1,
                Timeout:    30 * time.Second,
                ResponseCh: make(chan *scheduler.Response, 1),
                Payload:    payload,
        }
        
        // Schedule request
        if err := dr.scheduler.Schedule(schedReq); err != nil </span><span class="cov0" title="0">{
                return &amp;RunnerResponse{
                        ID:      req.ID,
                        Success: false,
                        Error:   err.Error(),
                        NodeID:  runner.NodeID,
                        Latency: time.Since(startTime),
                }
        }</span>
        
        // Wait for response
        <span class="cov0" title="0">select </span>{
        case schedResp := &lt;-schedReq.ResponseCh:<span class="cov0" title="0">
                return &amp;RunnerResponse{
                        ID:      req.ID,
                        Success: schedResp.Success,
                        Data:    schedResp.Data,
                        Error:   schedResp.Error,
                        NodeID:  schedResp.NodeID,
                        Latency: time.Since(startTime),
                }</span>
        case &lt;-time.After(30 * time.Second):<span class="cov0" title="0">
                return &amp;RunnerResponse{
                        ID:      req.ID,
                        Success: false,
                        Error:   "scheduler timeout",
                        NodeID:  runner.NodeID,
                        Latency: time.Since(startTime),
                }</span>
        }
}

// manageRunnerPool manages the runner pool
func (dr *DistributedRunner) manageRunnerPool(ctx context.Context) <span class="cov0" title="0">{
        ticker := time.NewTicker(10 * time.Second)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        dr.cleanupRunners()</span>
                }
        }
}

// cleanupRunners cleans up inactive runners
func (dr *DistributedRunner) cleanupRunners() <span class="cov0" title="0">{
        dr.mu.Lock()
        defer dr.mu.Unlock()
        
        now := time.Now()
        for id, runner := range dr.activeRunners </span><span class="cov0" title="0">{
                if now.Sub(runner.LastUsed) &gt; 5*time.Minute </span><span class="cov0" title="0">{
                        delete(dr.activeRunners, id)
                }</span>
        }
}

// collectMetrics collects performance metrics
func (dr *DistributedRunner) collectMetrics(ctx context.Context) <span class="cov0" title="0">{
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        dr.calculateMetrics()</span>
                }
        }
}

// calculateMetrics calculates performance metrics
func (dr *DistributedRunner) calculateMetrics() {<span class="cov0" title="0">
        // TODO: Implement metrics calculation
        // This would calculate average latency, throughput, etc.
}</span>

// updateMetrics updates metrics with response data
func (dr *DistributedRunner) updateMetrics(resp *RunnerResponse) <span class="cov0" title="0">{
        dr.mu.Lock()
        defer dr.mu.Unlock()
        
        dr.requestCount++
        if resp.Success </span><span class="cov0" title="0">{
                dr.successCount++
        }</span> else<span class="cov0" title="0"> {
                dr.failureCount++
        }</span>
        
        // Update average latency (simple moving average)
        <span class="cov0" title="0">if dr.requestCount == 1 </span><span class="cov0" title="0">{
                dr.averageLatency = resp.Latency
        }</span> else<span class="cov0" title="0"> {
                dr.averageLatency = (dr.averageLatency*time.Duration(dr.requestCount-1) + resp.Latency) / time.Duration(dr.requestCount)
        }</span>
}

// GetStats returns runner statistics
func (dr *DistributedRunner) GetStats() map[string]interface{} <span class="cov0" title="0">{
        dr.mu.RLock()
        defer dr.mu.RUnlock()
        
        successRate := float64(0)
        if dr.requestCount &gt; 0 </span><span class="cov0" title="0">{
                successRate = float64(dr.successCount) / float64(dr.requestCount) * 100
        }</span>
        
        <span class="cov0" title="0">return map[string]interface{}{
                "active_runners":   len(dr.activeRunners),
                "max_runners":      dr.maxRunners,
                "request_count":    dr.requestCount,
                "success_count":    dr.successCount,
                "failure_count":    dr.failureCount,
                "success_rate":     successRate,
                "average_latency":  dr.averageLatency.String(),
                "pool_size":        len(dr.runnerPool),
        }</span>
}

// GetActiveRunners returns information about active runners
func (dr *DistributedRunner) GetActiveRunners() map[string]*RunnerInstance <span class="cov0" title="0">{
        dr.mu.RLock()
        defer dr.mu.RUnlock()
        
        result := make(map[string]*RunnerInstance)
        for k, v := range dr.activeRunners </span><span class="cov0" title="0">{
                result[k] = v
        }</span>
        <span class="cov0" title="0">return result</span>
}

// SetMaxRunners sets the maximum number of runners
func (dr *DistributedRunner) SetMaxRunners(max int) <span class="cov0" title="0">{
        dr.mu.Lock()
        defer dr.mu.Unlock()
        
        dr.maxRunners = max
}</span>

// Shutdown gracefully shuts down the distributed runner
func (dr *DistributedRunner) Shutdown(ctx context.Context) error <span class="cov0" title="0">{
        dr.mu.Lock()
        defer dr.mu.Unlock()
        
        // Close all active runners
        for _, runner := range dr.activeRunners </span><span class="cov0" title="0">{
                close(runner.RequestChan)
                close(runner.ResponseChan)
        }</span>
        
        // Clear runners
        <span class="cov0" title="0">dr.activeRunners = make(map[string]*RunnerInstance)
        
        return nil</span>
}

// DistributedRunnerAdapter adapts the distributed runner to work with existing Ollama server
type DistributedRunnerAdapter struct {
        runner *DistributedRunner
}

// NewDistributedRunnerAdapter creates a new adapter
func NewDistributedRunnerAdapter(runner *DistributedRunner) *DistributedRunnerAdapter <span class="cov0" title="0">{
        return &amp;DistributedRunnerAdapter{
                runner: runner,
        }
}</span>

// Completion implements the LlamaServer interface for compatibility
func (dra *DistributedRunnerAdapter) Completion(ctx context.Context, req CompletionRequest, fn func(CompletionResponse)) error <span class="cov0" title="0">{
        // Convert to RunnerRequest
        runnerReq := &amp;RunnerRequest{
                ID:       fmt.Sprintf("comp_%d", time.Now().UnixNano()),
                Type:     "completion",
                Context:  ctx,
                Payload:  req,
                Response: make(chan *RunnerResponse, 1),
        }
        
        // Execute request
        resp, err := dra.runner.ExecuteRequest(runnerReq)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        <span class="cov0" title="0">if !resp.Success </span><span class="cov0" title="0">{
                return fmt.Errorf("completion failed: %s", resp.Error)
        }</span>
        
        // Convert response back to CompletionResponse
        <span class="cov0" title="0">if completionResp, ok := resp.Data.(CompletionResponse); ok </span><span class="cov0" title="0">{
                fn(completionResp)
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// Embedding implements the LlamaServer interface for compatibility
func (dra *DistributedRunnerAdapter) Embedding(ctx context.Context, prompt string) ([]float32, error) <span class="cov0" title="0">{
        // Convert to RunnerRequest
        runnerReq := &amp;RunnerRequest{
                ID:       fmt.Sprintf("embed_%d", time.Now().UnixNano()),
                Type:     "embedding",
                Context:  ctx,
                Payload:  prompt,
                Response: make(chan *RunnerResponse, 1),
        }
        
        // Execute request
        resp, err := dra.runner.ExecuteRequest(runnerReq)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        
        <span class="cov0" title="0">if !resp.Success </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("embedding failed: %s", resp.Error)
        }</span>
        
        // Convert response back to embedding
        <span class="cov0" title="0">if embedding, ok := resp.Data.([]float32); ok </span><span class="cov0" title="0">{
                return embedding, nil
        }</span>
        
        <span class="cov0" title="0">return nil, fmt.Errorf("invalid embedding response")</span>
}

// Tokenize implements the LlamaServer interface for compatibility
func (dra *DistributedRunnerAdapter) Tokenize(ctx context.Context, content string) ([]int, error) <span class="cov0" title="0">{
        // Convert to RunnerRequest
        runnerReq := &amp;RunnerRequest{
                ID:       fmt.Sprintf("tokenize_%d", time.Now().UnixNano()),
                Type:     "tokenize",
                Context:  ctx,
                Payload:  content,
                Response: make(chan *RunnerResponse, 1),
        }
        
        // Execute request
        resp, err := dra.runner.ExecuteRequest(runnerReq)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        
        <span class="cov0" title="0">if !resp.Success </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("tokenization failed: %s", resp.Error)
        }</span>
        
        // Convert response back to tokens
        <span class="cov0" title="0">if tokens, ok := resp.Data.([]int); ok </span><span class="cov0" title="0">{
                return tokens, nil
        }</span>
        
        <span class="cov0" title="0">return nil, fmt.Errorf("invalid tokenization response")</span>
}

// Detokenize implements the LlamaServer interface for compatibility
func (dra *DistributedRunnerAdapter) Detokenize(ctx context.Context, tokens []int) (string, error) <span class="cov0" title="0">{
        // Convert to RunnerRequest
        runnerReq := &amp;RunnerRequest{
                ID:       fmt.Sprintf("detokenize_%d", time.Now().UnixNano()),
                Type:     "detokenize",
                Context:  ctx,
                Payload:  tokens,
                Response: make(chan *RunnerResponse, 1),
        }
        
        // Execute request
        resp, err := dra.runner.ExecuteRequest(runnerReq)
        if err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>
        
        <span class="cov0" title="0">if !resp.Success </span><span class="cov0" title="0">{
                return "", fmt.Errorf("detokenization failed: %s", resp.Error)
        }</span>
        
        // Convert response back to string
        <span class="cov0" title="0">if text, ok := resp.Data.(string); ok </span><span class="cov0" title="0">{
                return text, nil
        }</span>
        
        <span class="cov0" title="0">return "", fmt.Errorf("invalid detokenization response")</span>
}

// Close implements the LlamaServer interface for compatibility
func (dra *DistributedRunnerAdapter) Close() error <span class="cov0" title="0">{
        return dra.runner.Shutdown(context.Background())
}</pre>
		
		<pre class="file" id="file21" style="display: none">package api

import (
        "context"
        "encoding/json"
        "fmt"
        "net/http"
        "strings"
        "time"

        "github.com/gin-gonic/gin"
        "github.com/golang-jwt/jwt/v5"
        "github.com/gorilla/websocket"
        "github.com/ollama/ollama-distributed/internal/config"
        "github.com/ollama/ollama-distributed/pkg/consensus"
        "github.com/ollama/ollama-distributed/pkg/p2p"
        "github.com/ollama/ollama-distributed/pkg/scheduler"
)

// Server represents the API server
type Server struct {
        config    *config.APIConfig
        p2p       *p2p.Node
        consensus *consensus.Engine
        scheduler *scheduler.Engine
        
        router   *gin.Engine
        server   *http.Server
        upgrader websocket.Upgrader
        
        // WebSocket connections
        wsConnections map[string]*websocket.Conn
        wsHub         *WSHub
}

// WSHub manages WebSocket connections
type WSHub struct {
        clients    map[*websocket.Conn]bool
        broadcast  chan []byte
        register   chan *websocket.Conn
        unregister chan *websocket.Conn
}

// NewServer creates a new API server
func NewServer(config *config.APIConfig, p2pNode *p2p.Node, consensusEngine *consensus.Engine, schedulerEngine *scheduler.Engine) (*Server, error) <span class="cov0" title="0">{
        server := &amp;Server{
                config:        config,
                p2p:           p2pNode,
                consensus:     consensusEngine,
                scheduler:     schedulerEngine,
                wsConnections: make(map[string]*websocket.Conn),
                upgrader: websocket.Upgrader{
                        CheckOrigin: func(r *http.Request) bool </span><span class="cov0" title="0">{
                                // Check if origin is in allowed list
                        allowedOrigins := []string{"http://localhost:8080", "https://localhost:8080"}
                        origin := r.Header.Get("Origin")
                        for _, allowed := range allowedOrigins </span><span class="cov0" title="0">{
                                if origin == allowed </span><span class="cov0" title="0">{
                                        return true
                                }</span>
                        }
                        <span class="cov0" title="0">return false</span>
                        },
                },
                wsHub: &amp;WSHub{
                        clients:    make(map[*websocket.Conn]bool),
                        broadcast:  make(chan []byte),
                        register:   make(chan *websocket.Conn),
                        unregister: make(chan *websocket.Conn),
                },
        }
        
        <span class="cov0" title="0">server.setupRoutes()
        
        return server, nil</span>
}

// setupRoutes sets up the API routes
func (s *Server) setupRoutes() <span class="cov0" title="0">{
        if gin.Mode() == gin.ReleaseMode </span><span class="cov0" title="0">{
                gin.SetMode(gin.ReleaseMode)
        }</span>
        
        <span class="cov0" title="0">s.router = gin.New()
        s.router.Use(gin.Logger())
        s.router.Use(gin.Recovery())
        s.router.Use(s.rateLimitMiddleware())
        s.router.Use(s.inputValidationMiddleware())
        
        // CORS middleware with security-first configuration
        s.router.Use(func(c *gin.Context) </span><span class="cov0" title="0">{
                // Get origin from config CORS settings
                allowedOrigins := s.config.Cors.AllowedOrigins
                if len(allowedOrigins) == 0 || (len(allowedOrigins) == 1 &amp;&amp; allowedOrigins[0] == "*") </span><span class="cov0" title="0">{
                        // Default to secure localhost for development if wildcard is configured
                        allowedOrigins = []string{"http://localhost:8080", "https://localhost:8080"}
                }</span>
                
                <span class="cov0" title="0">origin := c.Request.Header.Get("Origin")
                allowed := false
                for _, allowedOrigin := range allowedOrigins </span><span class="cov0" title="0">{
                        if origin == allowedOrigin </span><span class="cov0" title="0">{
                                allowed = true
                                break</span>
                        }
                }
                
                <span class="cov0" title="0">if allowed </span><span class="cov0" title="0">{
                        c.Header("Access-Control-Allow-Origin", origin)
                }</span> else<span class="cov0" title="0"> {
                        c.Header("Access-Control-Allow-Origin", "")
                }</span>
                
                <span class="cov0" title="0">c.Header("Access-Control-Allow-Methods", strings.Join(s.config.Cors.AllowedMethods, ", "))
                c.Header("Access-Control-Allow-Headers", strings.Join(s.config.Cors.AllowedHeaders, ", "))
                if s.config.Cors.AllowCredentials </span><span class="cov0" title="0">{
                        c.Header("Access-Control-Allow-Credentials", "true")
                }</span>
                <span class="cov0" title="0">c.Header("Access-Control-Max-Age", fmt.Sprintf("%d", s.config.Cors.MaxAge))
                
                if c.Request.Method == "OPTIONS" </span><span class="cov0" title="0">{
                        c.AbortWithStatus(204)
                        return
                }</span>
                
                <span class="cov0" title="0">c.Next()</span>
        })
        
        // API routes with authentication
        <span class="cov0" title="0">api := s.router.Group("/api/v1")
        api.Use(s.authMiddleware())
        </span><span class="cov0" title="0">{
                // Node management
                api.GET("/nodes", s.getNodes)
                api.GET("/nodes/:id", s.getNode)
                api.POST("/nodes/:id/drain", s.drainNode)
                api.POST("/nodes/:id/undrain", s.undrainNode)
                
                // Model management
                api.GET("/models", s.getModels)
                api.GET("/models/:name", s.getModel)
                api.POST("/models/:name/download", s.downloadModel)
                api.DELETE("/models/:name", s.deleteModel)
                
                // Distribution management
                api.POST("/distribution/auto-configure", s.handleAutoDistribution)
                
                // Cluster management
                api.GET("/cluster/status", s.getClusterStatus)
                api.GET("/cluster/leader", s.getLeader)
                api.POST("/cluster/join", s.joinCluster)
                api.POST("/cluster/leave", s.leaveCluster)
                
                // Inference
                api.POST("/generate", s.generate)
                api.POST("/chat", s.chat)
                api.POST("/embeddings", s.embeddings)
                
                // Monitoring
                api.GET("/metrics", s.getMetrics)
                api.GET("/health", s.healthCheck)
                api.GET("/transfers", s.getTransfers)
                api.GET("/transfers/:id", s.getTransfer)
                
                // WebSocket endpoint
                api.GET("/ws", s.handleWebSocket)
        }</span>
        
        // Serve static files for web UI
        <span class="cov0" title="0">s.router.Static("/static", "./web/static")
        s.router.StaticFile("/", "./web/index.html")
        s.router.StaticFile("/favicon.ico", "./web/favicon.ico")
        
        // Catch-all for SPA routing
        s.router.NoRoute(func(c *gin.Context) </span><span class="cov0" title="0">{
                c.File("./web/index.html")
        }</span>)
}

// Start starts the API server
func (s *Server) Start() error <span class="cov0" title="0">{
        s.server = &amp;http.Server{
                Addr:    s.config.Listen,
                Handler: s.router,
        }
        
        // Start WebSocket hub
        go s.wsHub.run()
        
        // Start metrics broadcasting
        s.StartMetricsBroadcasting()
        
        // Start server
        go func() </span><span class="cov0" title="0">{
                if err := s.server.ListenAndServe(); err != nil &amp;&amp; err != http.ErrServerClosed </span><span class="cov0" title="0">{
                        fmt.Printf("Failed to start server: %v\n", err)
                }</span>
        }()
        
        <span class="cov0" title="0">fmt.Printf("API server started on %s\n", s.config.Listen)
        return nil</span>
}

// Shutdown gracefully shuts down the API server
func (s *Server) Shutdown(ctx context.Context) error <span class="cov0" title="0">{
        return s.server.Shutdown(ctx)
}</span>

// Node management handlers

func (s *Server) getNodes(c *gin.Context) <span class="cov0" title="0">{
        nodes := s.scheduler.GetNodes()
        c.JSON(http.StatusOK, gin.H{"nodes": nodes})
}</span>

func (s *Server) getNode(c *gin.Context) <span class="cov0" title="0">{
        nodeID := c.Param("id")
        
        nodes := s.scheduler.GetNodes()
        if node, exists := nodes[nodeID]; exists </span><span class="cov0" title="0">{
                c.JSON(http.StatusOK, gin.H{"node": node})
        }</span> else<span class="cov0" title="0"> {
                c.JSON(http.StatusNotFound, gin.H{"error": "Node not found"})
        }</span>
}

func (s *Server) drainNode(c *gin.Context) <span class="cov0" title="0">{
        nodeID := c.Param("id")
        
        // TODO: Implement node draining
        c.JSON(http.StatusOK, gin.H{"message": fmt.Sprintf("Node %s is being drained", nodeID)})
}</span>

func (s *Server) undrainNode(c *gin.Context) <span class="cov0" title="0">{
        nodeID := c.Param("id")
        
        // TODO: Implement node undraining
        c.JSON(http.StatusOK, gin.H{"message": fmt.Sprintf("Node %s is no longer draining", nodeID)})
}</span>

// Model management handlers

func (s *Server) getModels(c *gin.Context) <span class="cov0" title="0">{
        // Get models from scheduler
        models := s.scheduler.GetAllModels()
        c.JSON(http.StatusOK, gin.H{"models": models})
}</span>

func (s *Server) getModel(c *gin.Context) <span class="cov0" title="0">{
        modelName := c.Param("name")
        
        // Get specific model from scheduler
        if model, exists := s.scheduler.GetModel(modelName); exists </span><span class="cov0" title="0">{
                c.JSON(http.StatusOK, gin.H{"model": model})
        }</span> else<span class="cov0" title="0"> {
                c.JSON(http.StatusNotFound, gin.H{"error": "Model not found"})
        }</span>
}

func (s *Server) downloadModel(c *gin.Context) <span class="cov0" title="0">{
        modelName := c.Param("name")
        
        // Initiate model download via scheduler
        nodes := s.scheduler.GetAvailableNodes()
        if len(nodes) == 0 </span><span class="cov0" title="0">{
                c.JSON(http.StatusServiceUnavailable, gin.H{"error": "No available nodes for model download"})
                return
        }</span>
        
        // Select the best node for download (first available for now)
        <span class="cov0" title="0">targetNode := nodes[0]
        
        // Register the model as being downloaded
        err := s.scheduler.RegisterModel(modelName, 0, "", targetNode.ID)
        if err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": fmt.Sprintf("Failed to register model: %v", err)})
                return
        }</span>
        
        // TODO: Implement actual model download to node
        // For now, just simulate the download process
        <span class="cov0" title="0">go func() </span><span class="cov0" title="0">{
                time.Sleep(2 * time.Second) // Simulate download time
                // Update model status in scheduler
                s.scheduler.RegisterModel(modelName, 1024*1024*100, "simulated_checksum", targetNode.ID)
        }</span>()
        
        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{
                "message": fmt.Sprintf("Started downloading model %s to node %s", modelName, targetNode.ID),
                "target_node": targetNode.ID,
        })</span>
}

func (s *Server) deleteModel(c *gin.Context) <span class="cov0" title="0">{
        modelName := c.Param("name")
        
        // Get model info from scheduler
        model, exists := s.scheduler.GetModel(modelName)
        if !exists </span><span class="cov0" title="0">{
                c.JSON(http.StatusNotFound, gin.H{"error": "Model not found"})
                return
        }</span>
        
        // Delete model from scheduler registry
        <span class="cov0" title="0">err := s.scheduler.DeleteModel(modelName)
        if err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                return
        }</span>
        
        // TODO: Send deletion commands to nodes that have the model
        // For now, just remove from registry
        
        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{
                "message": fmt.Sprintf("Deleted model %s from %d nodes", modelName, len(model.Locations)),
                "nodes_affected": model.Locations,
        })</span>
}

// Cluster management handlers

func (s *Server) getClusterStatus(c *gin.Context) <span class="cov0" title="0">{
        status := gin.H{
                "node_id":   s.p2p.ID().String(),
                "is_leader": s.consensus.IsLeader(),
                "leader":    s.consensus.Leader(),
                "peers":     len(s.p2p.ConnectedPeers()),
                "status":    "healthy",
        }
        
        c.JSON(http.StatusOK, status)
}</span>

func (s *Server) getLeader(c *gin.Context) <span class="cov0" title="0">{
        leader := s.consensus.Leader()
        c.JSON(http.StatusOK, gin.H{"leader": leader})
}</span>

func (s *Server) joinCluster(c *gin.Context) <span class="cov0" title="0">{
        var req struct {
                NodeID  string `json:"node_id"`
                Address string `json:"address"`
        }
        
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        <span class="cov0" title="0">if err := s.consensus.AddVoter(req.NodeID, req.Address); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                return
        }</span>
        
        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{"message": "Node joined cluster"})</span>
}

func (s *Server) leaveCluster(c *gin.Context) <span class="cov0" title="0">{
        var req struct {
                NodeID string `json:"node_id"`
        }
        
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        <span class="cov0" title="0">if err := s.consensus.RemoveServer(req.NodeID); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                return
        }</span>
        
        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{"message": "Node left cluster"})</span>
}

// Inference handlers

func (s *Server) generate(c *gin.Context) <span class="cov0" title="0">{
        var req struct {
                Model  string `json:"model"`
                Prompt string `json:"prompt"`
                Stream bool   `json:"stream,omitempty"`
        }
        
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        // Create scheduler request
        <span class="cov0" title="0">schedReq := &amp;scheduler.Request{
                ID:         fmt.Sprintf("req_%d", time.Now().UnixNano()),
                ModelName:  req.Model,
                Priority:   1,
                Timeout:    30 * time.Second,
                ResponseCh: make(chan *scheduler.Response, 1),
        }
        
        // Schedule the request
        if err := s.scheduler.Schedule(schedReq); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
                return
        }</span>
        
        // Wait for response
        <span class="cov0" title="0">select </span>{
        case response := &lt;-schedReq.ResponseCh:<span class="cov0" title="0">
                if response.Success </span><span class="cov0" title="0">{
                        c.JSON(http.StatusOK, gin.H{
                                "response": "Generated response would be here",
                                "model":    req.Model,
                                "node_id":  response.NodeID,
                        })
                }</span> else<span class="cov0" title="0"> {
                        c.JSON(http.StatusInternalServerError, gin.H{"error": response.Error})
                }</span>
        case &lt;-time.After(30 * time.Second):<span class="cov0" title="0">
                c.JSON(http.StatusRequestTimeout, gin.H{"error": "Request timeout"})</span>
        }
}

func (s *Server) chat(c *gin.Context) <span class="cov0" title="0">{
        var req struct {
                Model    string                   `json:"model"`
                Messages []map[string]interface{} `json:"messages"`
                Stream   bool                     `json:"stream,omitempty"`
        }
        
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        // TODO: Implement chat completion
        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{
                "message": gin.H{
                        "role":    "assistant",
                        "content": "This is a placeholder response from the distributed Ollama system",
                },
        })</span>
}

func (s *Server) embeddings(c *gin.Context) <span class="cov0" title="0">{
        var req struct {
                Model string `json:"model"`
                Input string `json:"input"`
        }
        
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        // TODO: Implement embeddings
        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{
                "embeddings": []float64{0.1, 0.2, 0.3, 0.4, 0.5},
        })</span>
}

// Monitoring handlers

func (s *Server) getMetrics(c *gin.Context) <span class="cov0" title="0">{
        // Get real metrics from scheduler
        modelsCount := s.scheduler.GetModelCount()
        nodesCount := len(s.scheduler.GetNodes())
        onlineNodes := s.scheduler.GetOnlineNodeCount()
        
        metrics := gin.H{
                "node_id":           s.p2p.ID().String(),
                "connected_peers":   len(s.p2p.ConnectedPeers()),
                "is_leader":         s.consensus.IsLeader(),
                "requests_processed": 0, // TODO: Add request counter to scheduler
                "models_loaded":     modelsCount,
                "nodes_total":       nodesCount,
                "nodes_online":      onlineNodes,
                "uptime":            time.Since(time.Now()).String(),
                "cpu_usage":         15.5,  // Mock data
                "memory_usage":      23.8,  // Mock data
                "network_usage":     45.2,  // Mock data
                "requests_per_second": 12,   // Mock data
                "average_latency":   125,   // Mock data
                "active_connections": 8,    // Mock data
                "error_rate":        0.2,   // Mock data
        }
        
        c.JSON(http.StatusOK, metrics)
}</span>

func (s *Server) healthCheck(c *gin.Context) <span class="cov0" title="0">{
        health := gin.H{
                "status":    "healthy",
                "timestamp": time.Now().Unix(),
                "node_id":   s.p2p.ID().String(),
                "services": gin.H{
                        "p2p":       "healthy",
                        "consensus": "healthy",
                        "scheduler": "healthy",
                },
        }
        
        c.JSON(http.StatusOK, health)
}</span>

func (s *Server) getTransfers(c *gin.Context) <span class="cov0" title="0">{
        // Get transfer information from scheduler
        // For now, return mock transfer data based on models
        models := s.scheduler.GetAllModels()
        
        transfers := []map[string]interface{}{}
        for modelName, model := range models </span><span class="cov0" title="0">{
                for _, nodeID := range model.Locations </span><span class="cov0" title="0">{
                        transfers = append(transfers, map[string]interface{}{
                                "id": fmt.Sprintf("%s-%s", modelName, nodeID[:8]),
                                "model_name": modelName,
                                "type": "download",
                                "status": "completed",
                                "progress": 100.0,
                                "speed": 0.0,
                                "eta": 0,
                                "peer_id": nodeID,
                                "completed_at": model.LastAccessed,
                        })
                }</span>
        }
        
        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{"transfers": transfers})</span>
}

func (s *Server) getTransfer(c *gin.Context) <span class="cov0" title="0">{
        transferID := c.Param("id")
        
        // TODO: Get specific transfer
        c.JSON(http.StatusOK, gin.H{"transfer": gin.H{"id": transferID}})
}</span>

// Distribution management handlers

func (s *Server) handleAutoDistribution(c *gin.Context) <span class="cov0" title="0">{
        var req struct {
                Enabled bool `json:"enabled"`
        }
        
        if err := c.ShouldBindJSON(&amp;req); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
                return
        }</span>
        
        // Store auto-distribution setting in consensus
        <span class="cov0" title="0">if err := s.consensus.Apply("auto_distribution_enabled", req.Enabled, nil); err != nil </span><span class="cov0" title="0">{
                c.JSON(http.StatusInternalServerError, gin.H{"error": fmt.Sprintf("Failed to update auto-distribution setting: %v", err)})
                return
        }</span>
        
        // If enabling auto-distribution, trigger redistribution
        <span class="cov0" title="0">if req.Enabled </span><span class="cov0" title="0">{
                go s.triggerModelRedistribution()
        }</span>
        
        <span class="cov0" title="0">c.JSON(http.StatusOK, gin.H{
                "message": fmt.Sprintf("Auto-distribution %s", map[bool]string{true: "enabled", false: "disabled"}[req.Enabled]),
                "enabled": req.Enabled,
        })</span>
}

// triggerModelRedistribution triggers redistribution of models across nodes
func (s *Server) triggerModelRedistribution() <span class="cov0" title="0">{
        // Get all available nodes
        nodes := s.scheduler.GetAvailableNodes()
        if len(nodes) &lt; 2 </span><span class="cov0" title="0">{
                return // Need at least 2 nodes for redistribution
        }</span>
        
        // Get all models
        <span class="cov0" title="0">models := s.scheduler.GetAllModels()
        
        // Redistribute models for better load balancing
        for modelName, model := range models </span><span class="cov0" title="0">{
                // If model is only on one node, try to replicate it
                if len(model.Locations) == 1 </span><span class="cov0" title="0">{
                        // Find a node that doesn't have this model
                        for _, node := range nodes </span><span class="cov0" title="0">{
                                if !contains(model.Locations, node.ID) </span><span class="cov0" title="0">{
                                        // Replicate model to this node
                                        go s.replicateModel(modelName, node.ID)
                                        break</span>
                                }
                        }
                }
        }
}

// replicateModel replicates a model to a specific node
func (s *Server) replicateModel(modelName, nodeID string) <span class="cov0" title="0">{
        // TODO: Implement actual model replication logic
        // This would involve P2P transfer of the model file
        
        // For now, just simulate the replication
        time.Sleep(5 * time.Second) // Simulate replication time
        
        // Register the model on the new node
        s.scheduler.RegisterModel(modelName, 0, "", nodeID)
        
        // Broadcast update via WebSocket
        if s.wsHub != nil </span><span class="cov0" title="0">{
                s.wsHub.Broadcast(map[string]interface{}{
                        "type": "model_replicated",
                        "model": modelName,
                        "node": nodeID,
                })
        }</span>
}

// WebSocket handler

func (s *Server) handleWebSocket(c *gin.Context) <span class="cov0" title="0">{
        conn, err := s.upgrader.Upgrade(c.Writer, c.Request, nil)
        if err != nil </span><span class="cov0" title="0">{
                fmt.Printf("WebSocket upgrade error: %v\n", err)
                return
        }</span>
        
        <span class="cov0" title="0">s.wsHub.register &lt;- conn
        
        // Handle messages
        go s.handleWSConnection(conn)</span>
}

func (s *Server) handleWSConnection(conn *websocket.Conn) <span class="cov0" title="0">{
        defer func() </span><span class="cov0" title="0">{
                s.wsHub.unregister &lt;- conn
                conn.Close()
        }</span>()
        
        // Send initial metrics when client connects
        <span class="cov0" title="0">go s.sendInitialMetrics(conn)
        
        for </span><span class="cov0" title="0">{
                var msg map[string]interface{}
                if err := conn.ReadJSON(&amp;msg); err != nil </span><span class="cov0" title="0">{
                        break</span>
                }
                
                // Handle different message types
                <span class="cov0" title="0">switch msg["type"] </span>{
                case "subscribe":<span class="cov0" title="0">
                        // Handle subscription to specific events
                        if channel, ok := msg["channel"].(string); ok </span><span class="cov0" title="0">{
                                s.subscribeToChannel(conn, channel)
                        }</span>
                case "unsubscribe":<span class="cov0" title="0">
                        // Handle unsubscription from events
                        if channel, ok := msg["channel"].(string); ok </span><span class="cov0" title="0">{
                                s.unsubscribeFromChannel(conn, channel)
                        }</span>
                case "ping":<span class="cov0" title="0">
                        // Handle ping
                        conn.WriteJSON(map[string]interface{}{"type": "pong"})</span>
                }
        }
}

// WebSocket Hub methods

func (h *WSHub) run() <span class="cov0" title="0">{
        // Use a cleanup ticker to prevent memory leaks
        cleanupTicker := time.NewTicker(5 * time.Minute)
        defer cleanupTicker.Stop()

        for </span><span class="cov0" title="0">{
                select </span>{
                case conn := &lt;-h.register:<span class="cov0" title="0">
                        h.clients[conn] = true</span>
                        
                case conn := &lt;-h.unregister:<span class="cov0" title="0">
                        if _, ok := h.clients[conn]; ok </span><span class="cov0" title="0">{
                                delete(h.clients, conn)
                                // Ensure connection is properly closed
                                if err := conn.Close(); err != nil </span><span class="cov0" title="0">{
                                        fmt.Printf("Error closing WebSocket connection: %v\n", err)
                                }</span>
                        }
                        
                case message := &lt;-h.broadcast:<span class="cov0" title="0">
                        // Create a list of connections to remove to avoid concurrent map access
                        var toRemove []*websocket.Conn
                        for conn := range h.clients </span><span class="cov0" title="0">{
                                if err := conn.WriteMessage(websocket.TextMessage, message); err != nil </span><span class="cov0" title="0">{
                                        toRemove = append(toRemove, conn)
                                }</span>
                        }
                        // Remove failed connections
                        <span class="cov0" title="0">for _, conn := range toRemove </span><span class="cov0" title="0">{
                                delete(h.clients, conn)
                                conn.Close()
                        }</span>
                        
                case &lt;-cleanupTicker.C:<span class="cov0" title="0">
                        // Periodic cleanup of stale connections
                        h.cleanupStaleConnections()</span>
                }
        }
}

// cleanupStaleConnections removes connections that haven't been active
func (h *WSHub) cleanupStaleConnections() <span class="cov0" title="0">{
        var toRemove []*websocket.Conn
        
        for conn := range h.clients </span><span class="cov0" title="0">{
                // Send ping to check if connection is alive
                if err := conn.WriteMessage(websocket.PingMessage, []byte{}); err != nil </span><span class="cov0" title="0">{
                        toRemove = append(toRemove, conn)
                }</span>
        }
        
        // Remove dead connections
        <span class="cov0" title="0">for _, conn := range toRemove </span><span class="cov0" title="0">{
                delete(h.clients, conn)
                conn.Close()
        }</span>
}

func (h *WSHub) Broadcast(message interface{}) <span class="cov0" title="0">{
        data, err := json.Marshal(message)
        if err != nil </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">select </span>{
        case h.broadcast &lt;- data:<span class="cov0" title="0"></span>
        default:<span class="cov0" title="0"></span>
                // Channel full, drop message
        }
}

// WebSocket helper methods

func (s *Server) sendInitialMetrics(conn *websocket.Conn) <span class="cov0" title="0">{
        // Send initial cluster status
        clusterStatus := map[string]interface{}{
                "type": "cluster_status",
                "data": map[string]interface{}{
                        "node_id":   s.p2p.ID().String(),
                        "is_leader": s.consensus.IsLeader(),
                        "leader":    s.consensus.Leader(),
                        "peers":     len(s.p2p.ConnectedPeers()),
                        "status":    "healthy",
                },
        }
        conn.WriteJSON(clusterStatus)
        
        // Send initial metrics
        metrics := s.getSystemMetrics()
        metricsMsg := map[string]interface{}{
                "type": "metrics",
                "data": metrics,
        }
        conn.WriteJSON(metricsMsg)
}</span>

func (s *Server) subscribeToChannel(conn *websocket.Conn, channel string) <span class="cov0" title="0">{
        // Implementation for channel subscriptions
        // For now, just acknowledge the subscription
        response := map[string]interface{}{
                "type":    "subscription_ack",
                "channel": channel,
                "status":  "subscribed",
        }
        conn.WriteJSON(response)
}</span>

func (s *Server) unsubscribeFromChannel(conn *websocket.Conn, channel string) <span class="cov0" title="0">{
        // Implementation for channel unsubscriptions
        response := map[string]interface{}{
                "type":    "unsubscription_ack",
                "channel": channel,
                "status":  "unsubscribed",
        }
        conn.WriteJSON(response)
}</span>

func (s *Server) getSystemMetrics() map[string]interface{} <span class="cov0" title="0">{
        stats := s.scheduler.GetStats()
        nodes := s.scheduler.GetNodes()
        
        // Calculate CPU, memory, and network usage
        cpuUsage := 25.0 + float64(len(nodes)*3) // Mock CPU based on nodes
        memoryUsage := 40.0 + float64(s.scheduler.GetModelCount()*2) // Mock memory based on models
        networkUsage := 15.0 + float64(len(s.p2p.ConnectedPeers())*5) // Mock network based on peers
        
        return map[string]interface{}{
                "cpu":     cpuUsage,
                "memory":  memoryUsage,
                "network": networkUsage,
                "nodes":   len(nodes),
                "models":  s.scheduler.GetModelCount(),
                "peers":   len(s.p2p.ConnectedPeers()),
                "stats":   stats,
        }
}</span>

// StartMetricsBroadcasting starts broadcasting metrics to WebSocket clients
func (s *Server) StartMetricsBroadcasting() <span class="cov0" title="0">{
        go func() </span><span class="cov0" title="0">{
                ticker := time.NewTicker(5 * time.Second)
                defer ticker.Stop()
                
                for </span><span class="cov0" title="0">{
                        select </span>{
                        case &lt;-ticker.C:<span class="cov0" title="0">
                                // Broadcast metrics to all connected clients
                                metrics := s.getSystemMetrics()
                                metricsMsg := map[string]interface{}{
                                        "type": "metrics",
                                        "data": metrics,
                                }
                                s.wsHub.Broadcast(metricsMsg)</span>
                        }
                }
        }()
}

// BroadcastModelEvent broadcasts model-related events
func (s *Server) BroadcastModelEvent(eventType string, modelName string, data map[string]interface{}) <span class="cov0" title="0">{
        event := map[string]interface{}{
                "type": "model_event",
                "event_type": eventType,
                "model_name": modelName,
                "data": data,
                "timestamp": time.Now().Unix(),
        }
        s.wsHub.Broadcast(event)
}</span>

// BroadcastNodeEvent broadcasts node-related events
func (s *Server) BroadcastNodeEvent(eventType string, nodeID string, data map[string]interface{}) <span class="cov0" title="0">{
        event := map[string]interface{}{
                "type": "node_event",
                "event_type": eventType,
                "node_id": nodeID,
                "data": data,
                "timestamp": time.Now().Unix(),
        }
        s.wsHub.Broadcast(event)
}</span>

// BroadcastAlert broadcasts alert messages
func (s *Server) BroadcastAlert(level string, message string) <span class="cov0" title="0">{
        alert := map[string]interface{}{
                "type": "alert",
                "level": level,
                "message": message,
                "timestamp": time.Now().Unix(),
        }
        s.wsHub.Broadcast(alert)
}</span>

// Helper functions

// contains checks if a slice contains a string
func contains(slice []string, item string) bool <span class="cov0" title="0">{
        for _, s := range slice </span><span class="cov0" title="0">{
                if s == item </span><span class="cov0" title="0">{
                        return true
                }</span>
        }
        <span class="cov0" title="0">return false</span>
}

// Security middleware implementations

// authMiddleware provides JWT-based authentication
func (s *Server) authMiddleware() gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                // Skip auth for health check and options
                if c.Request.URL.Path == "/api/v1/health" || c.Request.Method == "OPTIONS" </span><span class="cov0" title="0">{
                        c.Next()
                        return
                }</span>

                <span class="cov0" title="0">authHeader := c.GetHeader("Authorization")
                if authHeader == "" </span><span class="cov0" title="0">{
                        c.JSON(http.StatusUnauthorized, gin.H{"error": "Authorization header required"})
                        c.Abort()
                        return
                }</span>

                // Extract Bearer token
                <span class="cov0" title="0">parts := strings.SplitN(authHeader, " ", 2)
                if len(parts) != 2 || parts[0] != "Bearer" </span><span class="cov0" title="0">{
                        c.JSON(http.StatusUnauthorized, gin.H{"error": "Invalid authorization header format"})
                        c.Abort()
                        return
                }</span>

                <span class="cov0" title="0">tokenString := parts[1]
                
                // TODO: Get secret from config
                secretKey := []byte("your-secret-key") // This should come from config
                
                // Parse and validate token
                token, err := jwt.Parse(tokenString, func(token *jwt.Token) (interface{}, error) </span><span class="cov0" title="0">{
                        if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("unexpected signing method: %v", token.Header["alg"])
                        }</span>
                        <span class="cov0" title="0">return secretKey, nil</span>
                })

                <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                        c.JSON(http.StatusUnauthorized, gin.H{"error": "Invalid token"})
                        c.Abort()
                        return
                }</span>

                <span class="cov0" title="0">if claims, ok := token.Claims.(jwt.MapClaims); ok &amp;&amp; token.Valid </span><span class="cov0" title="0">{
                        c.Set("user_id", claims["user_id"])
                        c.Set("username", claims["username"])
                        c.Next()
                }</span> else<span class="cov0" title="0"> {
                        c.JSON(http.StatusUnauthorized, gin.H{"error": "Invalid token claims"})
                        c.Abort()
                        return
                }</span>
        }
}

// rateLimitMiddleware provides rate limiting
func (s *Server) rateLimitMiddleware() gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                // TODO: Implement proper rate limiting with redis or in-memory store
                // For now, just add headers
                c.Header("X-RateLimit-Limit", fmt.Sprintf("%d", s.config.RateLimit.RPS))
                c.Header("X-RateLimit-Remaining", "999") // Mock value
                c.Header("X-RateLimit-Reset", fmt.Sprintf("%d", time.Now().Add(time.Minute).Unix()))
                c.Next()
        }</span>
}

// inputValidationMiddleware provides input validation and sanitization
func (s *Server) inputValidationMiddleware() gin.HandlerFunc <span class="cov0" title="0">{
        return func(c *gin.Context) </span><span class="cov0" title="0">{
                // Validate content type for POST/PUT requests
                if c.Request.Method == "POST" || c.Request.Method == "PUT" </span><span class="cov0" title="0">{
                        contentType := c.GetHeader("Content-Type")
                        if contentType != "" &amp;&amp; !strings.Contains(contentType, "application/json") &amp;&amp; 
                           !strings.Contains(contentType, "application/x-www-form-urlencoded") &amp;&amp;
                           !strings.Contains(contentType, "multipart/form-data") </span><span class="cov0" title="0">{
                                c.JSON(http.StatusBadRequest, gin.H{"error": "Unsupported content type"})
                                c.Abort()
                                return
                        }</span>
                }

                // Validate request size
                <span class="cov0" title="0">if c.Request.ContentLength &gt; s.config.MaxBodySize </span><span class="cov0" title="0">{
                        c.JSON(http.StatusRequestEntityTooLarge, gin.H{"error": "Request body too large"})
                        c.Abort()
                        return
                }</span>

                // Add security headers
                <span class="cov0" title="0">c.Header("X-Content-Type-Options", "nosniff")
                c.Header("X-Frame-Options", "DENY")
                c.Header("X-XSS-Protection", "1; mode=block")
                c.Header("Referrer-Policy", "strict-origin-when-cross-origin")
                c.Header("Content-Security-Policy", "default-src 'self'")

                c.Next()</span>
        }
}</pre>
		
		<pre class="file" id="file22" style="display: none">package config

import (
        "time"
        "crypto/rand"
        "github.com/libp2p/go-libp2p/core/crypto"
        "github.com/libp2p/go-libp2p/core/peer"
        "github.com/multiformats/go-multiaddr"
)

// NodeConfig holds all configuration for a P2P node
type NodeConfig struct {
        // Network Settings
        Listen              []string            `yaml:"listen"`
        AnnounceAddresses   []string            `yaml:"announce_addresses"`
        NoAnnounceAddresses []string            `yaml:"no_announce_addresses"`
        
        // Security
        PrivateKey          string              `yaml:"private_key"`
        EnableTLS           bool                `yaml:"enable_tls"`
        EnableNoise         bool                `yaml:"enable_noise"`
        
        // NAT Traversal
        EnableNATService    bool                `yaml:"enable_nat_service"`
        EnableHolePunching  bool                `yaml:"enable_hole_punching"`
        EnableAutoRelay     bool                `yaml:"enable_auto_relay"`
        StaticRelays        []string            `yaml:"static_relays"`
        ForceReachability   string              `yaml:"force_reachability"` // public/private
        
        // DHT Settings
        EnableDHT           bool                `yaml:"enable_dht"`
        DHTMode             string              `yaml:"dht_mode"` // client/server/auto
        BootstrapPeers      []string            `yaml:"bootstrap_peers"`
        
        // Connection Management
        ConnMgrLow          int                 `yaml:"conn_mgr_low"`
        ConnMgrHigh         int                 `yaml:"conn_mgr_high"`
        ConnMgrGrace        time.Duration       `yaml:"conn_mgr_grace"`
        
        // Resource Management
        MaxMemory           int64               `yaml:"max_memory"`
        MaxCPU              float64             `yaml:"max_cpu"`
        MaxGPU              int                 `yaml:"max_gpu"`
        
        // Ollamacron Specific
        NodeType            string              `yaml:"node_type"` // edge/standard/super
        ModelCapabilities   []string            `yaml:"model_capabilities"`
        ResourceTags        map[string]string   `yaml:"resource_tags"`
        
        // Discovery Settings
        RendezvousString    string              `yaml:"rendezvous_string"`
        AutoDiscovery       bool                `yaml:"auto_discovery"`
}

// DefaultConfig returns a default configuration for a P2P node
func DefaultConfig() *NodeConfig <span class="cov0" title="0">{
        return &amp;NodeConfig{
                Listen: []string{
                        "/ip4/0.0.0.0/tcp/0",
                        "/ip6/::/tcp/0",
                        "/ip4/0.0.0.0/udp/0/quic",
                        "/ip6/::/udp/0/quic",
                },
                EnableTLS:           true,
                EnableNoise:         true,
                EnableNATService:    true,
                EnableHolePunching:  true,
                EnableAutoRelay:     true,
                EnableDHT:           true,
                DHTMode:             "auto",
                ConnMgrLow:          50,
                ConnMgrHigh:         200,
                ConnMgrGrace:        time.Minute,
                NodeType:            "standard",
                ModelCapabilities:   []string{},
                ResourceTags:        make(map[string]string),
                RendezvousString:    "ollama-distributed",
                AutoDiscovery:       true,
        }
}</span>

// GenerateKey generates a new cryptographic identity for the node
func (c *NodeConfig) GenerateKey() error <span class="cov0" title="0">{
        priv, _, err := crypto.GenerateKeyPairWithReader(crypto.RSA, 2048, rand.Reader)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        <span class="cov0" title="0">keyBytes, err := crypto.MarshalPrivateKey(priv)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        <span class="cov0" title="0">c.PrivateKey = crypto.ConfigEncodeKey(keyBytes)
        return nil</span>
}

// GetPrivateKey retrieves the private key from configuration
func (c *NodeConfig) GetPrivateKey() (crypto.PrivKey, error) <span class="cov0" title="0">{
        if c.PrivateKey == "" </span><span class="cov0" title="0">{
                return nil, nil
        }</span>
        
        <span class="cov0" title="0">keyBytes, err := crypto.ConfigDecodeKey(c.PrivateKey)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        
        <span class="cov0" title="0">return crypto.UnmarshalPrivateKey(keyBytes)</span>
}

// ParseBootstrapPeers parses bootstrap peer addresses
func (c *NodeConfig) ParseBootstrapPeers() ([]peer.AddrInfo, error) <span class="cov0" title="0">{
        var peers []peer.AddrInfo
        
        for _, addr := range c.BootstrapPeers </span><span class="cov0" title="0">{
                maddr, err := multiaddr.NewMultiaddr(addr)
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }
                
                <span class="cov0" title="0">peerInfo, err := peer.AddrInfoFromP2pAddr(maddr)
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }
                
                <span class="cov0" title="0">peers = append(peers, *peerInfo)</span>
        }
        
        <span class="cov0" title="0">return peers, nil</span>
}

// ParseStaticRelays parses static relay addresses
func (c *NodeConfig) ParseStaticRelays() ([]peer.AddrInfo, error) <span class="cov0" title="0">{
        var relays []peer.AddrInfo
        
        for _, addr := range c.StaticRelays </span><span class="cov0" title="0">{
                maddr, err := multiaddr.NewMultiaddr(addr)
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }
                
                <span class="cov0" title="0">peerInfo, err := peer.AddrInfoFromP2pAddr(maddr)
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }
                
                <span class="cov0" title="0">relays = append(relays, *peerInfo)</span>
        }
        
        <span class="cov0" title="0">return relays, nil</span>
}

// DiscoveryConfig interface implementation
func (c *NodeConfig) GetBootstrapPeers() []string <span class="cov0" title="0">{
        return c.BootstrapPeers
}</span>

func (c *NodeConfig) GetRendezvousString() string <span class="cov0" title="0">{
        return c.RendezvousString
}</span>

func (c *NodeConfig) IsAutoDiscoveryEnabled() bool <span class="cov0" title="0">{
        return c.AutoDiscovery
}</span>

// NodeCapabilities represents the capabilities of a P2P node
type NodeCapabilities struct {
        // Compute resources
        CPUCores       int              `json:"cpu_cores"`
        Memory         int64            `json:"memory"`
        Storage        int64            `json:"storage"`
        GPUs           []*GPUInfo       `json:"gpus"`
        
        // AI capabilities
        SupportedModels []string         `json:"supported_models"`
        ModelFormats    []string         `json:"model_formats"`
        Quantizations   []string         `json:"quantizations"`
        
        // Network capabilities
        Bandwidth      int64            `json:"bandwidth"`
        Latency        time.Duration    `json:"latency"`
        Reliability    float64          `json:"reliability"`
        PricePerToken  float64          `json:"price_per_token"`
        
        // Node state
        Available      bool             `json:"available"`
        LoadFactor     float64          `json:"load_factor"`
        Priority       int              `json:"priority"`
        LastSeen       time.Time        `json:"last_seen"`
        
        // Version information
        Version        string           `json:"version"`
        ProtocolVersion string          `json:"protocol_version"`
        Features       []string         `json:"features"`
}

// GPUInfo represents information about a GPU
type GPUInfo struct {
        ID          string            `json:"id"`
        Name        string            `json:"name"`
        Memory      int64             `json:"memory"`
        Compute     string            `json:"compute"`
        Available   bool              `json:"available"`
        Utilization float64           `json:"utilization"`
        Properties  map[string]string `json:"properties"`
}

// ResourceMetrics contains real-time resource usage metrics
type ResourceMetrics struct {
        CPUUsage    float64 `json:"cpu_usage" yaml:"cpu_usage"`         // CPU usage percentage (0-100)
        MemoryUsage int64   `json:"memory_usage" yaml:"memory_usage"`   // Memory usage in bytes
        DiskUsage   int64   `json:"disk_usage" yaml:"disk_usage"`       // Disk usage in bytes
        NetworkRx   int64   `json:"network_rx" yaml:"network_rx"`       // Network received bytes/sec
        NetworkTx   int64   `json:"network_tx" yaml:"network_tx"`       // Network transmitted bytes/sec
        
        // GPU metrics
        GPUUsage     []float64 `json:"gpu_usage" yaml:"gpu_usage"`         // GPU usage percentage per GPU
        GPUMemory    []int64   `json:"gpu_memory" yaml:"gpu_memory"`       // GPU memory usage per GPU
        GPUTemp      []float64 `json:"gpu_temp" yaml:"gpu_temp"`           // GPU temperature per GPU
        
        // Performance metrics
        RequestsPerSec  float64 `json:"requests_per_sec" yaml:"requests_per_sec"`
        AvgLatency      time.Duration `json:"avg_latency" yaml:"avg_latency"`
        ErrorRate       float64 `json:"error_rate" yaml:"error_rate"`
        
        Timestamp time.Time `json:"timestamp" yaml:"timestamp"`
}</pre>
		
		<pre class="file" id="file23" style="display: none">package consensus

import (
        "context"
        "encoding/json"
        "fmt"
        "io"
        "net"
        "os"
        "path/filepath"
        "sync"
        "sync/atomic"
        "time"

        "github.com/hashicorp/raft"
        raftboltdb "github.com/hashicorp/raft-boltdb"
        "github.com/ollama/ollama-distributed/internal/config"
        "github.com/ollama/ollama-distributed/pkg/p2p"
)

// Engine represents the consensus engine using Raft
type Engine struct {
        config *config.ConsensusConfig
        p2p    *p2p.Node
        
        raft     *raft.Raft
        fsm      *FSM
        store    *raftboltdb.BoltStore
        snapshots raft.SnapshotStore
        transport *raft.NetworkTransport
        
        // Leadership tracking (atomic for thread safety)
        isLeader     int64 // Use atomic operations
        leaderCh     chan bool
        
        // State management
        state   map[string]interface{}
        stateMu sync.RWMutex
        
        // Event channels
        applyCh chan *ApplyEvent
        
        started bool
        mu      sync.RWMutex
}

// ApplyEvent represents a state change event
type ApplyEvent struct {
        Type      string                 `json:"type"`
        Key       string                 `json:"key"`
        Value     interface{}            `json:"value"`
        Timestamp time.Time              `json:"timestamp"`
        Metadata  map[string]interface{} `json:"metadata"`
}

// FSM implements the Raft finite state machine
type FSM struct {
        state   map[string]interface{}
        stateMu sync.RWMutex
        applyCh chan *ApplyEvent
}

// NewEngine creates a new consensus engine
func NewEngine(config *config.ConsensusConfig, p2pNode *p2p.Node) (*Engine, error) <span class="cov0" title="0">{
        engine := &amp;Engine{
                config:    config,
                p2p:       p2pNode,
                state:     make(map[string]interface{}),
                leaderCh:  make(chan bool, 1),
                applyCh:   make(chan *ApplyEvent, 1000),
        }
        
        // Create FSM
        engine.fsm = &amp;FSM{
                state:   make(map[string]interface{}),
                applyCh: engine.applyCh,
        }
        
        if err := engine.initRaft(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to initialize Raft: %w", err)
        }</span>
        
        <span class="cov0" title="0">return engine, nil</span>
}

// initRaft initializes the Raft consensus system
func (e *Engine) initRaft() error <span class="cov0" title="0">{
        // Create data directory
        if err := os.MkdirAll(e.config.DataDir, 0755); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create data directory: %w", err)
        }</span>
        
        // Create Raft configuration
        <span class="cov0" title="0">raftConfig := raft.DefaultConfig()
        raftConfig.LocalID = raft.ServerID(e.p2p.ID().String())
        raftConfig.LogLevel = e.config.LogLevel
        raftConfig.HeartbeatTimeout = e.config.HeartbeatTimeout
        raftConfig.ElectionTimeout = e.config.ElectionTimeout
        raftConfig.CommitTimeout = e.config.CommitTimeout
        raftConfig.MaxAppendEntries = e.config.MaxAppendEntries
        raftConfig.SnapshotInterval = e.config.SnapshotInterval
        raftConfig.SnapshotThreshold = e.config.SnapshotThreshold
        
        // Create log store
        logStore, err := raftboltdb.NewBoltStore(filepath.Join(e.config.DataDir, "raft-log.db"))
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create log store: %w", err)
        }</span>
        <span class="cov0" title="0">e.store = logStore
        
        // Create stable store
        stableStore, err := raftboltdb.NewBoltStore(filepath.Join(e.config.DataDir, "raft-stable.db"))
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create stable store: %w", err)
        }</span>
        
        // Create snapshot store
        <span class="cov0" title="0">snapshots, err := raft.NewFileSnapshotStore(e.config.DataDir, 3, os.Stderr)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create snapshot store: %w", err)
        }</span>
        <span class="cov0" title="0">e.snapshots = snapshots
        
        // Create transport
        addr, err := net.ResolveTCPAddr("tcp", e.config.BindAddr)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to resolve bind address: %w", err)
        }</span>
        
        <span class="cov0" title="0">transport, err := raft.NewTCPTransport(e.config.BindAddr, addr, 3, 10*time.Second, os.Stderr)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create transport: %w", err)
        }</span>
        <span class="cov0" title="0">e.transport = transport
        
        // Create Raft instance
        ra, err := raft.NewRaft(raftConfig, e.fsm, logStore, stableStore, snapshots, transport)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create Raft instance: %w", err)
        }</span>
        <span class="cov0" title="0">e.raft = ra
        
        // Start leadership monitoring
        go e.monitorLeadership()
        
        return nil</span>
}

// monitorLeadership monitors leadership changes
func (e *Engine) monitorLeadership() <span class="cov0" title="0">{
        for </span><span class="cov0" title="0">{
                select </span>{
                case isLeader := &lt;-e.raft.LeaderCh():<span class="cov0" title="0">
                        // Use atomic operations to prevent race conditions
                        var leaderVal int64
                        if isLeader </span><span class="cov0" title="0">{
                                leaderVal = 1
                        }</span>
                        <span class="cov0" title="0">atomic.StoreInt64(&amp;e.isLeader, leaderVal)
                        
                        // Notify leadership change
                        select </span>{
                        case e.leaderCh &lt;- isLeader:<span class="cov0" title="0"></span>
                        default:<span class="cov0" title="0"></span>
                        }
                }
        }
}

// Start starts the consensus engine
func (e *Engine) Start() error <span class="cov0" title="0">{
        e.mu.Lock()
        defer e.mu.Unlock()
        
        if e.started </span><span class="cov0" title="0">{
                return fmt.Errorf("consensus engine already started")
        }</span>
        
        // Bootstrap if configured
        <span class="cov0" title="0">if e.config.Bootstrap </span><span class="cov0" title="0">{
                configuration := raft.Configuration{
                        Servers: []raft.Server{
                                {
                                        ID:      raft.ServerID(e.p2p.ID().String()),
                                        Address: e.transport.LocalAddr(),
                                },
                        },
                }
                
                e.raft.BootstrapCluster(configuration)
        }</span>
        
        // Start event processing
        <span class="cov0" title="0">go e.processEvents()
        
        e.started = true
        return nil</span>
}

// processEvents processes apply events
func (e *Engine) processEvents() <span class="cov0" title="0">{
        for event := range e.applyCh </span><span class="cov0" title="0">{
                // Update local state
                e.stateMu.Lock()
                e.state[event.Key] = event.Value
                e.stateMu.Unlock()
                
                // TODO: Notify subscribers
        }</span>
}

// Apply applies a state change through Raft consensus
func (e *Engine) Apply(key string, value interface{}, metadata map[string]interface{}) error <span class="cov0" title="0">{
        if !e.IsLeader() </span><span class="cov0" title="0">{
                return fmt.Errorf("not leader, cannot apply changes")
        }</span>
        
        <span class="cov0" title="0">event := &amp;ApplyEvent{
                Type:      "set",
                Key:       key,
                Value:     value,
                Timestamp: time.Now(),
                Metadata:  metadata,
        }
        
        data, err := json.Marshal(event)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal event: %w", err)
        }</span>
        
        <span class="cov0" title="0">future := e.raft.Apply(data, 10*time.Second)
        if err := future.Error(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to apply change: %w", err)
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// Get gets a value from the state
func (e *Engine) Get(key string) (interface{}, bool) <span class="cov0" title="0">{
        e.stateMu.RLock()
        defer e.stateMu.RUnlock()
        
        value, exists := e.state[key]
        return value, exists
}</span>

// GetAll gets all state values
func (e *Engine) GetAll() map[string]interface{} <span class="cov0" title="0">{
        e.stateMu.RLock()
        defer e.stateMu.RUnlock()
        
        state := make(map[string]interface{})
        for k, v := range e.state </span><span class="cov0" title="0">{
                state[k] = v
        }</span>
        
        <span class="cov0" title="0">return state</span>
}

// Delete deletes a key from the state
func (e *Engine) Delete(key string) error <span class="cov0" title="0">{
        if !e.IsLeader() </span><span class="cov0" title="0">{
                return fmt.Errorf("not leader, cannot delete")
        }</span>
        
        <span class="cov0" title="0">event := &amp;ApplyEvent{
                Type:      "delete",
                Key:       key,
                Timestamp: time.Now(),
        }
        
        data, err := json.Marshal(event)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal event: %w", err)
        }</span>
        
        <span class="cov0" title="0">future := e.raft.Apply(data, 10*time.Second)
        if err := future.Error(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to apply delete: %w", err)
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// IsLeader returns true if this node is the leader
func (e *Engine) IsLeader() bool <span class="cov0" title="0">{
        return atomic.LoadInt64(&amp;e.isLeader) == 1
}</span>

// Leader returns the current leader address
func (e *Engine) Leader() string <span class="cov0" title="0">{
        return string(e.raft.Leader())
}</span>

// AddVoter adds a voting member to the cluster
func (e *Engine) AddVoter(id string, address string) error <span class="cov0" title="0">{
        if !e.IsLeader() </span><span class="cov0" title="0">{
                return fmt.Errorf("not leader, cannot add voter")
        }</span>
        
        <span class="cov0" title="0">future := e.raft.AddVoter(raft.ServerID(id), raft.ServerAddress(address), 0, 10*time.Second)
        return future.Error()</span>
}

// RemoveServer removes a server from the cluster
func (e *Engine) RemoveServer(id string) error <span class="cov0" title="0">{
        if !e.IsLeader() </span><span class="cov0" title="0">{
                return fmt.Errorf("not leader, cannot remove server")
        }</span>
        
        <span class="cov0" title="0">future := e.raft.RemoveServer(raft.ServerID(id), 0, 10*time.Second)
        return future.Error()</span>
}

// GetConfiguration returns the current cluster configuration
func (e *Engine) GetConfiguration() (*raft.Configuration, error) <span class="cov0" title="0">{
        future := e.raft.GetConfiguration()
        if err := future.Error(); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        
        <span class="cov0" title="0">config := future.Configuration()
        return &amp;config, nil</span>
}

// LeadershipChanges returns a channel that receives leadership changes
func (e *Engine) LeadershipChanges() &lt;-chan bool <span class="cov0" title="0">{
        return e.leaderCh
}</span>

// Stats returns Raft statistics
func (e *Engine) Stats() map[string]string <span class="cov0" title="0">{
        return e.raft.Stats()
}</span>

// Shutdown gracefully shuts down the consensus engine
func (e *Engine) Shutdown(ctx context.Context) error <span class="cov0" title="0">{
        e.mu.Lock()
        defer e.mu.Unlock()
        
        if !e.started </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        // Close apply channel
        <span class="cov0" title="0">close(e.applyCh)
        
        // Shutdown Raft
        if e.raft != nil </span><span class="cov0" title="0">{
                future := e.raft.Shutdown()
                if err := future.Error(); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to shutdown Raft: %w", err)
                }</span>
        }
        
        // Close stores
        <span class="cov0" title="0">if e.store != nil </span><span class="cov0" title="0">{
                e.store.Close()
        }</span>
        
        // Close transport
        <span class="cov0" title="0">if e.transport != nil </span><span class="cov0" title="0">{
                e.transport.Close()
        }</span>
        
        <span class="cov0" title="0">e.started = false
        return nil</span>
}

// FSM Methods

// Apply applies a log entry to the FSM
func (f *FSM) Apply(log *raft.Log) interface{} <span class="cov0" title="0">{
        var event ApplyEvent
        if err := json.Unmarshal(log.Data, &amp;event); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to unmarshal event: %w", err)
        }</span>
        
        // Use atomic operations to prevent race conditions
        <span class="cov0" title="0">f.stateMu.Lock()
        defer f.stateMu.Unlock()
        
        // Validate event before applying
        if err := f.validateEvent(&amp;event); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("invalid event: %w", err)
        }</span>
        
        // Apply state changes atomically
        <span class="cov0" title="0">switch event.Type </span>{
        case "set":<span class="cov0" title="0">
                f.state[event.Key] = event.Value</span>
        case "delete":<span class="cov0" title="0">
                delete(f.state, event.Key)</span>
        case "update":<span class="cov0" title="0">
                // Handle updates atomically
                if _, exists := f.state[event.Key]; exists </span><span class="cov0" title="0">{
                        f.state[event.Key] = event.Value
                }</span> else<span class="cov0" title="0"> {
                        return fmt.Errorf("cannot update non-existent key: %s", event.Key)
                }</span>
        default:<span class="cov0" title="0">
                return fmt.Errorf("unknown event type: %s", event.Type)</span>
        }
        
        // Send to apply channel with timeout to prevent blocking
        // Use goroutine to prevent blocking the FSM apply operation
        <span class="cov0" title="0">go func() </span><span class="cov0" title="0">{
                select </span>{
                case f.applyCh &lt;- &amp;event:<span class="cov0" title="0"></span>
                        // Successfully sent
                case &lt;-time.After(1 * time.Second):<span class="cov0" title="0">
                        // Log warning but continue - don't fail the consensus operation
                        fmt.Printf("Warning: apply channel full, dropping event notification for key %s\n", event.Key)</span>
                }
        }()
        
        <span class="cov0" title="0">return nil</span>
}

// validateEvent validates an event before applying it
func (f *FSM) validateEvent(event *ApplyEvent) error <span class="cov0" title="0">{
        if event.Key == "" </span><span class="cov0" title="0">{
                return fmt.Errorf("event key cannot be empty")
        }</span>
        
        <span class="cov0" title="0">if event.Type == "" </span><span class="cov0" title="0">{
                return fmt.Errorf("event type cannot be empty")
        }</span>
        
        // Validate timestamp is not too old
        <span class="cov0" title="0">if time.Since(event.Timestamp) &gt; 5*time.Minute </span><span class="cov0" title="0">{
                return fmt.Errorf("event timestamp too old")
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// Snapshot creates a snapshot of the FSM state
func (f *FSM) Snapshot() (raft.FSMSnapshot, error) <span class="cov0" title="0">{
        f.stateMu.RLock()
        defer f.stateMu.RUnlock()
        
        // Clone state
        state := make(map[string]interface{})
        for k, v := range f.state </span><span class="cov0" title="0">{
                state[k] = v
        }</span>
        
        <span class="cov0" title="0">return &amp;fsmSnapshot{state: state}, nil</span>
}

// Restore restores the FSM from a snapshot
func (f *FSM) Restore(snapshot io.ReadCloser) error <span class="cov0" title="0">{
        defer snapshot.Close()
        
        var state map[string]interface{}
        if err := json.NewDecoder(snapshot).Decode(&amp;state); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to decode snapshot: %w", err)
        }</span>
        
        <span class="cov0" title="0">f.stateMu.Lock()
        defer f.stateMu.Unlock()
        
        f.state = state
        return nil</span>
}

// fsmSnapshot implements the raft.FSMSnapshot interface
type fsmSnapshot struct {
        state map[string]interface{}
}

// Persist persists the snapshot to the given sink
func (s *fsmSnapshot) Persist(sink raft.SnapshotSink) error <span class="cov0" title="0">{
        err := json.NewEncoder(sink).Encode(s.state)
        if err != nil </span><span class="cov0" title="0">{
                sink.Cancel()
                return fmt.Errorf("failed to encode snapshot: %w", err)
        }</span>
        
        <span class="cov0" title="0">return sink.Close()</span>
}

// Release releases the snapshot resources
func (s *fsmSnapshot) Release() {<span class="cov0" title="0">
        // Nothing to release
}</pre>
		
		<pre class="file" id="file24" style="display: none">package integration

import (
        "context"
        "fmt"
        "net/http"
)

// Registry stub to replace github.com/ollama/ollama/server/internal/client/ollama.Registry
type Registry struct {
        // Stub implementation for compatibility
        models map[string]interface{}
}

// NewRegistry creates a new registry stub
func NewRegistry() *Registry <span class="cov0" title="0">{
        return &amp;Registry{
                models: make(map[string]interface{}),
        }
}</span>

// RegisterModel registers a model in the stub registry
func (r *Registry) RegisterModel(name string, model interface{}) <span class="cov0" title="0">{
        r.models[name] = model
}</span>

// GetModel retrieves a model from the stub registry
func (r *Registry) GetModel(name string) (interface{}, bool) <span class="cov0" title="0">{
        model, exists := r.models[name]
        return model, exists
}</span>

// ListModels returns all registered models
func (r *Registry) ListModels() map[string]interface{} <span class="cov0" title="0">{
        return r.models
}</span>

// ClientInterface provides methods that would be available from ollama client
type ClientInterface interface {
        Generate(ctx context.Context, request GenerateRequest) (*GenerateResponse, error)
        Chat(ctx context.Context, request ChatRequest) (*ChatResponse, error)
        Embed(ctx context.Context, request EmbedRequest) (*EmbedResponse, error)
        List(ctx context.Context) (*ListResponse, error)
        Show(ctx context.Context, request ShowRequest) (*ShowResponse, error)
        Pull(ctx context.Context, request PullRequest) error
        Delete(ctx context.Context, request DeleteRequest) error
        Version(ctx context.Context) (*VersionResponse, error)
}

// Client stub implementation
type Client struct {
        baseURL string
        client  *http.Client
}

// NewClient creates a new ollama client stub
func NewClient(baseURL string) *Client <span class="cov0" title="0">{
        return &amp;Client{
                baseURL: baseURL,
                client:  &amp;http.Client{},
        }
}</span>

// Request/Response types for ollama API

type GenerateRequest struct {
        Model  string `json:"model"`
        Prompt string `json:"prompt"`
        Stream bool   `json:"stream,omitempty"`
}

type GenerateResponse struct {
        Model    string `json:"model"`
        Response string `json:"response"`
        Done     bool   `json:"done"`
}

type ChatRequest struct {
        Model    string        `json:"model"`
        Messages []ChatMessage `json:"messages"`
        Stream   bool          `json:"stream,omitempty"`
}

type ChatMessage struct {
        Role    string `json:"role"`
        Content string `json:"content"`
}

type ChatResponse struct {
        Model   string      `json:"model"`
        Message ChatMessage `json:"message"`
        Done    bool        `json:"done"`
}

type EmbedRequest struct {
        Model string `json:"model"`
        Input string `json:"input"`
}

type EmbedResponse struct {
        Embedding []float64 `json:"embedding"`
}

type ListResponse struct {
        Models []ModelInfo `json:"models"`
}

type ModelInfo struct {
        Name       string `json:"name"`
        Size       int64  `json:"size"`
        Digest     string `json:"digest"`
        ModifiedAt string `json:"modified_at"`
}

type ShowRequest struct {
        Name string `json:"name"`
}

type ShowResponse struct {
        License    string                 `json:"license"`
        Modelfile  string                 `json:"modelfile"`
        Parameters map[string]interface{} `json:"parameters"`
        Template   string                 `json:"template"`
        Details    map[string]interface{} `json:"details"`
}

type PullRequest struct {
        Name   string `json:"name"`
        Stream bool   `json:"stream,omitempty"`
}

type DeleteRequest struct {
        Name string `json:"name"`
}

type VersionResponse struct {
        Version string `json:"version"`
}

// Stub implementations of client methods

func (c *Client) Generate(ctx context.Context, request GenerateRequest) (*GenerateResponse, error) <span class="cov0" title="0">{
        // Stub implementation - would make HTTP request to ollama server
        return &amp;GenerateResponse{
                Model:    request.Model,
                Response: fmt.Sprintf("Generated response for: %s", request.Prompt),
                Done:     true,
        }, nil
}</span>

func (c *Client) Chat(ctx context.Context, request ChatRequest) (*ChatResponse, error) <span class="cov0" title="0">{
        // Stub implementation
        lastMessage := request.Messages[len(request.Messages)-1]
        return &amp;ChatResponse{
                Model: request.Model,
                Message: ChatMessage{
                        Role:    "assistant",
                        Content: fmt.Sprintf("Chat response to: %s", lastMessage.Content),
                },
                Done: true,
        }, nil
}</span>

func (c *Client) Embed(ctx context.Context, request EmbedRequest) (*EmbedResponse, error) <span class="cov0" title="0">{
        // Stub implementation - return dummy embedding
        embedding := make([]float64, 768) // Standard embedding size
        for i := range embedding </span><span class="cov0" title="0">{
                embedding[i] = 0.1 * float64(i%10)
        }</span>
        
        <span class="cov0" title="0">return &amp;EmbedResponse{
                Embedding: embedding,
        }, nil</span>
}

func (c *Client) List(ctx context.Context) (*ListResponse, error) <span class="cov0" title="0">{
        // Stub implementation
        return &amp;ListResponse{
                Models: []ModelInfo{
                        {
                                Name:       "llama2:7b",
                                Size:       3825819519,
                                Digest:     "abc123",
                                ModifiedAt: "2024-01-01T00:00:00Z",
                        },
                },
        }, nil
}</span>

func (c *Client) Show(ctx context.Context, request ShowRequest) (*ShowResponse, error) <span class="cov0" title="0">{
        // Stub implementation
        return &amp;ShowResponse{
                License:    "MIT",
                Modelfile:  fmt.Sprintf("FROM %s", request.Name),
                Parameters: map[string]interface{}{"temperature": 0.7},
                Template:   "{{ .System }} {{ .Prompt }}",
                Details:    map[string]interface{}{"family": "llama"},
        }, nil
}</span>

func (c *Client) Pull(ctx context.Context, request PullRequest) error <span class="cov0" title="0">{
        // Stub implementation
        return nil
}</span>

func (c *Client) Delete(ctx context.Context, request DeleteRequest) error <span class="cov0" title="0">{
        // Stub implementation
        return nil
}</span>

func (c *Client) Version(ctx context.Context) (*VersionResponse, error) <span class="cov0" title="0">{
        // Stub implementation
        return &amp;VersionResponse{
                Version: "0.1.0-distributed",
        }, nil
}</span>

// Server interface stub to replace ollama server interface
type Server interface {
        GenerateRoutes(registry *Registry) (http.Handler, error)
        Start(ctx context.Context) error
        Stop(ctx context.Context) error
}

// ServerStub provides a stub implementation of the Server interface
type ServerStub struct {
        client *Client
}

// NewServerStub creates a new server stub
func NewServerStub(baseURL string) *ServerStub <span class="cov0" title="0">{
        return &amp;ServerStub{
                client: NewClient(baseURL),
        }
}</span>

func (s *ServerStub) GenerateRoutes(registry *Registry) (http.Handler, error) <span class="cov0" title="0">{
        // Stub implementation
        return http.DefaultServeMux, nil
}</span>

func (s *ServerStub) Start(ctx context.Context) error <span class="cov0" title="0">{
        // Stub implementation
        return nil
}</span>

func (s *ServerStub) Stop(ctx context.Context) error <span class="cov0" title="0">{
        // Stub implementation
        return nil
}</span>

// Additional stub types and functions that might be needed

type ModelManifest struct {
        SchemaVersion int                    `json:"schemaVersion"`
        MediaType     string                 `json:"mediaType"`
        Config        ModelConfig            `json:"config"`
        Layers        []ModelLayer           `json:"layers"`
        Annotations   map[string]interface{} `json:"annotations,omitempty"`
}

type ModelConfig struct {
        MediaType string                 `json:"mediaType"`
        Digest    string                 `json:"digest"`
        Size      int64                  `json:"size"`
        Data      map[string]interface{} `json:"data,omitempty"`
}

type ModelLayer struct {
        MediaType   string                 `json:"mediaType"`
        Digest      string                 `json:"digest"`
        Size        int64                  `json:"size"`
        Annotations map[string]interface{} `json:"annotations,omitempty"`
}

// Progress tracking for long-running operations
type ProgressCallback func(status string, current, total int64)

// Additional utility functions
func ParseModelName(name string) (registry, namespace, model, tag string) <span class="cov0" title="0">{
        // Stub implementation for model name parsing
        return "", "", name, "latest"
}</span>

func ValidateModelName(name string) error <span class="cov0" title="0">{
        if name == "" </span><span class="cov0" title="0">{
                return fmt.Errorf("model name cannot be empty")
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// Health check function
func (c *Client) Health(ctx context.Context) error <span class="cov0" title="0">{
        // Stub implementation
        return nil
}</span>

// Error types
type APIError struct {
        Code    int    `json:"code"`
        Message string `json:"message"`
}

func (e APIError) Error() string <span class="cov0" title="0">{
        return fmt.Sprintf("API error %d: %s", e.Code, e.Message)
}</span>

// Constants
const (
        DefaultBaseURL = "http://localhost:11434"
        DefaultTimeout = 30 // seconds
)</pre>
		
		<pre class="file" id="file25" style="display: none">package models

import (
        "crypto/sha256"
        "encoding/hex"
        "fmt"
        "io"
        "log/slog"
        "os"
        "path/filepath"
        "sync"
        "time"
)

// ContentAddressedStore implements a content-addressed storage system for models
type ContentAddressedStore struct {
        storeDir    string
        logger      *slog.Logger
        
        // Object tracking
        objects     map[string]*StoredObject
        objectsMutex sync.RWMutex
        
        // Reference counting
        refCounts   map[string]int
        refMutex    sync.RWMutex
        
        // Storage configuration
        maxObjects  int
        maxSize     int64
        
        // Cleanup settings
        cleanupInterval time.Duration
        maxAge         time.Duration
        
        // Statistics
        stats       *StoreStats
        statsMutex  sync.RWMutex
}

// StoredObject represents an object in the content-addressed store
type StoredObject struct {
        Hash      string            `json:"hash"`
        Size      int64             `json:"size"`
        Path      string            `json:"path"`
        RefCount  int               `json:"ref_count"`
        CreatedAt time.Time         `json:"created_at"`
        AccessedAt time.Time        `json:"accessed_at"`
        Metadata  map[string]string `json:"metadata"`
}

// StoreStats contains statistics about the store
type StoreStats struct {
        TotalObjects    int64 `json:"total_objects"`
        TotalSize       int64 `json:"total_size"`
        TotalReferences int64 `json:"total_references"`
        HitCount        int64 `json:"hit_count"`
        MissCount       int64 `json:"miss_count"`
        LastCleanup     time.Time `json:"last_cleanup"`
}

// NewContentAddressedStore creates a new content-addressed store
func NewContentAddressedStore(storeDir string, logger *slog.Logger) (*ContentAddressedStore, error) <span class="cov0" title="0">{
        if err := os.MkdirAll(storeDir, 0755); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create store directory: %w", err)
        }</span>
        
        <span class="cov0" title="0">cas := &amp;ContentAddressedStore{
                storeDir:        storeDir,
                logger:          logger,
                objects:         make(map[string]*StoredObject),
                refCounts:       make(map[string]int),
                maxObjects:      10000,
                maxSize:         100 * 1024 * 1024 * 1024, // 100GB
                cleanupInterval: time.Hour,
                maxAge:          24 * time.Hour * 7, // 1 week
                stats:           &amp;StoreStats{},
        }
        
        // Load existing objects
        if err := cas.loadObjects(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to load objects: %w", err)
        }</span>
        
        // Start cleanup routine
        <span class="cov0" title="0">go cas.cleanupRoutine()
        
        return cas, nil</span>
}

// Store stores data in the content-addressed store
func (cas *ContentAddressedStore) Store(hash string, sourcePath string) error <span class="cov0" title="0">{
        cas.logger.Info("storing object", "hash", hash, "source", sourcePath)
        
        // Check if object already exists
        cas.objectsMutex.RLock()
        if obj, exists := cas.objects[hash]; exists </span><span class="cov0" title="0">{
                cas.objectsMutex.RUnlock()
                
                // Update access time and increment reference count
                obj.AccessedAt = time.Now()
                cas.incrementReference(hash)
                
                cas.statsMutex.Lock()
                cas.stats.HitCount++
                cas.statsMutex.Unlock()
                
                cas.logger.Debug("object already exists", "hash", hash, "ref_count", obj.RefCount)
                return nil
        }</span>
        <span class="cov0" title="0">cas.objectsMutex.RUnlock()
        
        // Calculate actual hash to verify
        actualHash, err := cas.calculateHash(sourcePath)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to calculate hash: %w", err)
        }</span>
        
        <span class="cov0" title="0">if actualHash != hash </span><span class="cov0" title="0">{
                return fmt.Errorf("hash mismatch: expected %s, got %s", hash, actualHash)
        }</span>
        
        // Get file info
        <span class="cov0" title="0">info, err := os.Stat(sourcePath)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to stat source file: %w", err)
        }</span>
        
        // Create storage path
        <span class="cov0" title="0">storagePath := cas.getStoragePath(hash)
        if err := os.MkdirAll(filepath.Dir(storagePath), 0755); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create storage directory: %w", err)
        }</span>
        
        // Copy file to storage
        <span class="cov0" title="0">if err := cas.copyFile(sourcePath, storagePath); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to copy file: %w", err)
        }</span>
        
        // Create object entry
        <span class="cov0" title="0">obj := &amp;StoredObject{
                Hash:       hash,
                Size:       info.Size(),
                Path:       storagePath,
                RefCount:   1,
                CreatedAt:  time.Now(),
                AccessedAt: time.Now(),
                Metadata:   make(map[string]string),
        }
        
        // Store object
        cas.objectsMutex.Lock()
        cas.objects[hash] = obj
        cas.objectsMutex.Unlock()
        
        cas.refMutex.Lock()
        cas.refCounts[hash] = 1
        cas.refMutex.Unlock()
        
        // Update statistics
        cas.statsMutex.Lock()
        cas.stats.TotalObjects++
        cas.stats.TotalSize += info.Size()
        cas.stats.TotalReferences++
        cas.stats.MissCount++
        cas.statsMutex.Unlock()
        
        cas.logger.Info("object stored", "hash", hash, "size", info.Size())
        return nil</span>
}

// Get retrieves an object from the store
func (cas *ContentAddressedStore) Get(hash string) (*StoredObject, error) <span class="cov0" title="0">{
        cas.objectsMutex.RLock()
        obj, exists := cas.objects[hash]
        cas.objectsMutex.RUnlock()
        
        if !exists </span><span class="cov0" title="0">{
                cas.statsMutex.Lock()
                cas.stats.MissCount++
                cas.statsMutex.Unlock()
                
                return nil, fmt.Errorf("object not found: %s", hash)
        }</span>
        
        // Update access time
        <span class="cov0" title="0">obj.AccessedAt = time.Now()
        
        cas.statsMutex.Lock()
        cas.stats.HitCount++
        cas.statsMutex.Unlock()
        
        return obj, nil</span>
}

// GetReader returns a reader for an object
func (cas *ContentAddressedStore) GetReader(hash string) (io.ReadCloser, error) <span class="cov0" title="0">{
        obj, err := cas.Get(hash)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        
        <span class="cov0" title="0">return os.Open(obj.Path)</span>
}

// Exists checks if an object exists in the store
func (cas *ContentAddressedStore) Exists(hash string) bool <span class="cov0" title="0">{
        cas.objectsMutex.RLock()
        defer cas.objectsMutex.RUnlock()
        
        _, exists := cas.objects[hash]
        return exists
}</span>

// IncrementReference increments the reference count for an object
func (cas *ContentAddressedStore) IncrementReference(hash string) error <span class="cov0" title="0">{
        cas.objectsMutex.RLock()
        obj, exists := cas.objects[hash]
        cas.objectsMutex.RUnlock()
        
        if !exists </span><span class="cov0" title="0">{
                return fmt.Errorf("object not found: %s", hash)
        }</span>
        
        <span class="cov0" title="0">cas.incrementReference(hash)
        
        cas.logger.Debug("incremented reference", "hash", hash, "ref_count", obj.RefCount)
        return nil</span>
}

// DecrementReference decrements the reference count for an object
func (cas *ContentAddressedStore) DecrementReference(hash string) error <span class="cov0" title="0">{
        cas.objectsMutex.RLock()
        obj, exists := cas.objects[hash]
        cas.objectsMutex.RUnlock()
        
        if !exists </span><span class="cov0" title="0">{
                return fmt.Errorf("object not found: %s", hash)
        }</span>
        
        <span class="cov0" title="0">cas.decrementReference(hash)
        
        cas.logger.Debug("decremented reference", "hash", hash, "ref_count", obj.RefCount)
        return nil</span>
}

// incrementReference increments the reference count
func (cas *ContentAddressedStore) incrementReference(hash string) <span class="cov0" title="0">{
        cas.refMutex.Lock()
        cas.refCounts[hash]++
        cas.refMutex.Unlock()
        
        cas.objectsMutex.Lock()
        if obj, exists := cas.objects[hash]; exists </span><span class="cov0" title="0">{
                obj.RefCount++
        }</span>
        <span class="cov0" title="0">cas.objectsMutex.Unlock()
        
        cas.statsMutex.Lock()
        cas.stats.TotalReferences++
        cas.statsMutex.Unlock()</span>
}

// decrementReference decrements the reference count
func (cas *ContentAddressedStore) decrementReference(hash string) <span class="cov0" title="0">{
        cas.refMutex.Lock()
        if cas.refCounts[hash] &gt; 0 </span><span class="cov0" title="0">{
                cas.refCounts[hash]--
        }</span>
        <span class="cov0" title="0">refCount := cas.refCounts[hash]
        cas.refMutex.Unlock()
        
        cas.objectsMutex.Lock()
        if obj, exists := cas.objects[hash]; exists </span><span class="cov0" title="0">{
                obj.RefCount = refCount
        }</span>
        <span class="cov0" title="0">cas.objectsMutex.Unlock()
        
        cas.statsMutex.Lock()
        if cas.stats.TotalReferences &gt; 0 </span><span class="cov0" title="0">{
                cas.stats.TotalReferences--
        }</span>
        <span class="cov0" title="0">cas.statsMutex.Unlock()</span>
}

// ListObjects returns all objects in the store
func (cas *ContentAddressedStore) ListObjects() []*StoredObject <span class="cov0" title="0">{
        cas.objectsMutex.RLock()
        defer cas.objectsMutex.RUnlock()
        
        objects := make([]*StoredObject, 0, len(cas.objects))
        for _, obj := range cas.objects </span><span class="cov0" title="0">{
                objects = append(objects, obj)
        }</span>
        
        <span class="cov0" title="0">return objects</span>
}

// GetStats returns store statistics
func (cas *ContentAddressedStore) GetStats() *StoreStats <span class="cov0" title="0">{
        cas.statsMutex.RLock()
        defer cas.statsMutex.RUnlock()
        
        stats := *cas.stats
        return &amp;stats
}</span>

// calculateHash calculates the SHA256 hash of a file
func (cas *ContentAddressedStore) calculateHash(filePath string) (string, error) <span class="cov0" title="0">{
        file, err := os.Open(filePath)
        if err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>
        <span class="cov0" title="0">defer file.Close()
        
        hash := sha256.New()
        if _, err := io.Copy(hash, file); err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>
        
        <span class="cov0" title="0">return hex.EncodeToString(hash.Sum(nil)), nil</span>
}

// getStoragePath returns the storage path for a hash
func (cas *ContentAddressedStore) getStoragePath(hash string) string <span class="cov0" title="0">{
        // Create a directory structure like: store/ab/cd/abcd...
        dir1 := hash[:2]
        dir2 := hash[2:4]
        return filepath.Join(cas.storeDir, dir1, dir2, hash)
}</span>

// copyFile copies a file from source to destination
func (cas *ContentAddressedStore) copyFile(src, dst string) error <span class="cov0" title="0">{
        srcFile, err := os.Open(src)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">defer srcFile.Close()
        
        dstFile, err := os.Create(dst)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">defer dstFile.Close()
        
        if _, err := io.Copy(dstFile, srcFile); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        
        <span class="cov0" title="0">return dstFile.Sync()</span>
}

// loadObjects loads existing objects from the store
func (cas *ContentAddressedStore) loadObjects() error <span class="cov0" title="0">{
        return filepath.Walk(cas.storeDir, func(path string, info os.FileInfo, err error) error </span><span class="cov0" title="0">{
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                
                <span class="cov0" title="0">if info.IsDir() </span><span class="cov0" title="0">{
                        return nil
                }</span>
                
                // Extract hash from filename
                <span class="cov0" title="0">hash := filepath.Base(path)
                if len(hash) != 64 </span><span class="cov0" title="0">{ // SHA256 hash length
                        return nil
                }</span>
                
                // Verify hash
                <span class="cov0" title="0">actualHash, err := cas.calculateHash(path)
                if err != nil </span><span class="cov0" title="0">{
                        cas.logger.Error("failed to verify object hash", "path", path, "error", err)
                        return nil
                }</span>
                
                <span class="cov0" title="0">if actualHash != hash </span><span class="cov0" title="0">{
                        cas.logger.Error("hash mismatch for stored object", "path", path, "expected", hash, "actual", actualHash)
                        return nil
                }</span>
                
                // Create object entry
                <span class="cov0" title="0">obj := &amp;StoredObject{
                        Hash:       hash,
                        Size:       info.Size(),
                        Path:       path,
                        RefCount:   1, // Default reference count
                        CreatedAt:  info.ModTime(),
                        AccessedAt: info.ModTime(),
                        Metadata:   make(map[string]string),
                }
                
                cas.objectsMutex.Lock()
                cas.objects[hash] = obj
                cas.objectsMutex.Unlock()
                
                cas.refMutex.Lock()
                cas.refCounts[hash] = 1
                cas.refMutex.Unlock()
                
                // Update statistics
                cas.statsMutex.Lock()
                cas.stats.TotalObjects++
                cas.stats.TotalSize += info.Size()
                cas.stats.TotalReferences++
                cas.statsMutex.Unlock()
                
                return nil</span>
        })
}

// cleanupRoutine runs periodic cleanup
func (cas *ContentAddressedStore) cleanupRoutine() <span class="cov0" title="0">{
        ticker := time.NewTicker(cas.cleanupInterval)
        defer ticker.Stop()
        
        for range ticker.C </span><span class="cov0" title="0">{
                if err := cas.cleanup(); err != nil </span><span class="cov0" title="0">{
                        cas.logger.Error("cleanup failed", "error", err)
                }</span>
        }
}

// cleanup removes unreferenced and old objects
func (cas *ContentAddressedStore) cleanup() error <span class="cov0" title="0">{
        cas.logger.Info("starting cleanup")
        
        var removed int
        var freedSize int64
        
        cas.objectsMutex.Lock()
        defer cas.objectsMutex.Unlock()
        
        cas.refMutex.Lock()
        defer cas.refMutex.Unlock()
        
        cutoff := time.Now().Add(-cas.maxAge)
        
        for hash, obj := range cas.objects </span><span class="cov0" title="0">{
                shouldRemove := false
                
                // Remove if no references
                if obj.RefCount == 0 </span><span class="cov0" title="0">{
                        shouldRemove = true
                }</span>
                
                // Remove if too old and not recently accessed
                <span class="cov0" title="0">if obj.AccessedAt.Before(cutoff) &amp;&amp; obj.RefCount &lt;= 1 </span><span class="cov0" title="0">{
                        shouldRemove = true
                }</span>
                
                <span class="cov0" title="0">if shouldRemove </span><span class="cov0" title="0">{
                        // Remove file
                        if err := os.Remove(obj.Path); err != nil </span><span class="cov0" title="0">{
                                cas.logger.Error("failed to remove object file", "hash", hash, "path", obj.Path, "error", err)
                                continue</span>
                        }
                        
                        // Remove from maps
                        <span class="cov0" title="0">delete(cas.objects, hash)
                        delete(cas.refCounts, hash)
                        
                        removed++
                        freedSize += obj.Size
                        
                        cas.logger.Debug("removed object", "hash", hash, "size", obj.Size)</span>
                }
        }
        
        // Update statistics
        <span class="cov0" title="0">cas.statsMutex.Lock()
        cas.stats.TotalObjects -= int64(removed)
        cas.stats.TotalSize -= freedSize
        cas.stats.LastCleanup = time.Now()
        cas.statsMutex.Unlock()
        
        cas.logger.Info("cleanup completed", "removed", removed, "freed_size", freedSize)
        
        return nil</span>
}

// Verify verifies the integrity of all objects in the store
func (cas *ContentAddressedStore) Verify() error <span class="cov0" title="0">{
        cas.logger.Info("starting verification")
        
        var errors []string
        
        cas.objectsMutex.RLock()
        objects := make([]*StoredObject, 0, len(cas.objects))
        for _, obj := range cas.objects </span><span class="cov0" title="0">{
                objects = append(objects, obj)
        }</span>
        <span class="cov0" title="0">cas.objectsMutex.RUnlock()
        
        for _, obj := range objects </span><span class="cov0" title="0">{
                // Check if file exists
                if _, err := os.Stat(obj.Path); err != nil </span><span class="cov0" title="0">{
                        errors = append(errors, fmt.Sprintf("object file missing: %s (%s)", obj.Hash, obj.Path))
                        continue</span>
                }
                
                // Verify hash
                <span class="cov0" title="0">actualHash, err := cas.calculateHash(obj.Path)
                if err != nil </span><span class="cov0" title="0">{
                        errors = append(errors, fmt.Sprintf("failed to calculate hash for %s: %v", obj.Hash, err))
                        continue</span>
                }
                
                <span class="cov0" title="0">if actualHash != obj.Hash </span><span class="cov0" title="0">{
                        errors = append(errors, fmt.Sprintf("hash mismatch for %s: expected %s, got %s", obj.Path, obj.Hash, actualHash))
                }</span>
        }
        
        <span class="cov0" title="0">if len(errors) &gt; 0 </span><span class="cov0" title="0">{
                cas.logger.Error("verification failed", "errors", len(errors))
                for _, err := range errors </span><span class="cov0" title="0">{
                        cas.logger.Error("verification error", "error", err)
                }</span>
                <span class="cov0" title="0">return fmt.Errorf("verification failed with %d errors", len(errors))</span>
        }
        
        <span class="cov0" title="0">cas.logger.Info("verification completed successfully")
        return nil</span>
}

// Close closes the content-addressed store
func (cas *ContentAddressedStore) Close() error <span class="cov0" title="0">{
        cas.logger.Info("closing content-addressed store")
        return nil
}</pre>
		
		<pre class="file" id="file26" style="display: none">package models

import (
        "context"
        "crypto/sha256"
        "encoding/hex"
        "encoding/json"
        "fmt"
        "io"
        "log/slog"
        "os"
        "path/filepath"
        "sort"
        "sync"
        "time"
)

// DeltaTracker manages delta operations for incremental model synchronization
type DeltaTracker struct {
        deltaDir   string
        logger     *slog.Logger
        
        // Delta storage
        deltas     map[string][]*Delta
        deltaMutex sync.RWMutex
        
        // Delta operations
        pendingOps map[string]*DeltaOperation
        opsMutex   sync.RWMutex
        
        // Compression settings
        compressionEnabled bool
        compressionLevel   int
        
        ctx    context.Context
        cancel context.CancelFunc
}

// Delta represents a single delta operation
type Delta struct {
        ID         string     `json:"id"`
        ModelName  string     `json:"model_name"`
        Type       DeltaType  `json:"type"`
        Offset     int64      `json:"offset"`
        Size       int64      `json:"size"`
        Hash       string     `json:"hash"`
        Data       []byte     `json:"data,omitempty"`
        Timestamp  time.Time  `json:"timestamp"`
        Compressed bool       `json:"compressed"`
}

// DeltaType represents the type of delta operation
type DeltaType string

const (
        DeltaTypeInsert DeltaType = "insert"
        DeltaTypeUpdate DeltaType = "update"
        DeltaTypeDelete DeltaType = "delete"
)

// DeltaOperation represents a complete delta operation
type DeltaOperation struct {
        ID          string        `json:"id"`
        ModelName   string        `json:"model_name"`
        SourceHash  string        `json:"source_hash"`
        TargetHash  string        `json:"target_hash"`
        Deltas      []*Delta      `json:"deltas"`
        Status      OperationStatus `json:"status"`
        CreatedAt   time.Time     `json:"created_at"`
        CompletedAt time.Time     `json:"completed_at"`
        Size        int64         `json:"size"`
        Error       string        `json:"error,omitempty"`
}

// OperationStatus represents the status of a delta operation
type OperationStatus string

const (
        OperationStatusPending   OperationStatus = "pending"
        OperationStatusInProgress OperationStatus = "in_progress"
        OperationStatusCompleted  OperationStatus = "completed"
        OperationStatusFailed     OperationStatus = "failed"
)

// DeltaMetadata contains metadata about a delta set
type DeltaMetadata struct {
        ModelName     string    `json:"model_name"`
        FromVersion   string    `json:"from_version"`
        ToVersion     string    `json:"to_version"`
        DeltaCount    int       `json:"delta_count"`
        TotalSize     int64     `json:"total_size"`
        CompressedSize int64    `json:"compressed_size"`
        CreatedAt     time.Time `json:"created_at"`
        CompressionRatio float64 `json:"compression_ratio"`
}

// NewDeltaTracker creates a new delta tracker
func NewDeltaTracker(deltaDir string, logger *slog.Logger) (*DeltaTracker, error) <span class="cov0" title="0">{
        if err := os.MkdirAll(deltaDir, 0755); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create delta directory: %w", err)
        }</span>
        
        <span class="cov0" title="0">ctx, cancel := context.WithCancel(context.Background())
        
        dt := &amp;DeltaTracker{
                deltaDir:           deltaDir,
                logger:             logger,
                deltas:             make(map[string][]*Delta),
                pendingOps:         make(map[string]*DeltaOperation),
                compressionEnabled: true,
                compressionLevel:   6,
                ctx:                ctx,
                cancel:             cancel,
        }
        
        // Load existing deltas
        if err := dt.loadDeltas(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to load deltas: %w", err)
        }</span>
        
        <span class="cov0" title="0">return dt, nil</span>
}

// CreateDelta creates a delta between two model versions
func (dt *DeltaTracker) CreateDelta(modelName, sourceFile, targetFile string) (*DeltaOperation, error) <span class="cov0" title="0">{
        dt.logger.Info("creating delta", "model", modelName, "source", sourceFile, "target", targetFile)
        
        // Calculate hashes
        sourceHash, err := dt.calculateFileHash(sourceFile)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to calculate source hash: %w", err)
        }</span>
        
        <span class="cov0" title="0">targetHash, err := dt.calculateFileHash(targetFile)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to calculate target hash: %w", err)
        }</span>
        
        // Create operation
        <span class="cov0" title="0">opID := fmt.Sprintf("%s_%s_%s", modelName, sourceHash[:8], targetHash[:8])
        op := &amp;DeltaOperation{
                ID:         opID,
                ModelName:  modelName,
                SourceHash: sourceHash,
                TargetHash: targetHash,
                Status:     OperationStatusPending,
                CreatedAt:  time.Now(),
        }
        
        // Store pending operation
        dt.opsMutex.Lock()
        dt.pendingOps[opID] = op
        dt.opsMutex.Unlock()
        
        // Generate deltas
        deltas, err := dt.generateDeltas(sourceFile, targetFile)
        if err != nil </span><span class="cov0" title="0">{
                op.Status = OperationStatusFailed
                op.Error = err.Error()
                return op, fmt.Errorf("failed to generate deltas: %w", err)
        }</span>
        
        <span class="cov0" title="0">op.Deltas = deltas
        op.Status = OperationStatusCompleted
        op.CompletedAt = time.Now()
        
        // Calculate total size
        var totalSize int64
        for _, delta := range deltas </span><span class="cov0" title="0">{
                totalSize += delta.Size
        }</span>
        <span class="cov0" title="0">op.Size = totalSize
        
        // Store deltas
        dt.deltaMutex.Lock()
        dt.deltas[modelName] = append(dt.deltas[modelName], deltas...)
        dt.deltaMutex.Unlock()
        
        // Save to disk
        if err := dt.saveDelta(op); err != nil </span><span class="cov0" title="0">{
                dt.logger.Error("failed to save delta", "operation", opID, "error", err)
        }</span>
        
        <span class="cov0" title="0">dt.logger.Info("delta created", "operation", opID, "deltas", len(deltas), "size", totalSize)
        
        return op, nil</span>
}

// ApplyDelta applies a delta operation to a model file
func (dt *DeltaTracker) ApplyDelta(targetFile string, op *DeltaOperation) error <span class="cov0" title="0">{
        dt.logger.Info("applying delta", "operation", op.ID, "target", targetFile)
        
        // Open target file
        file, err := os.OpenFile(targetFile, os.O_RDWR|os.O_CREATE, 0644)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to open target file: %w", err)
        }</span>
        <span class="cov0" title="0">defer file.Close()
        
        // Apply deltas in order
        sort.Slice(op.Deltas, func(i, j int) bool </span><span class="cov0" title="0">{
                return op.Deltas[i].Offset &lt; op.Deltas[j].Offset
        }</span>)
        
        <span class="cov0" title="0">for _, delta := range op.Deltas </span><span class="cov0" title="0">{
                if err := dt.applyDelta(file, delta); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to apply delta %s: %w", delta.ID, err)
                }</span>
        }
        
        // Verify result
        <span class="cov0" title="0">resultHash, err := dt.calculateFileHash(targetFile)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to calculate result hash: %w", err)
        }</span>
        
        <span class="cov0" title="0">if resultHash != op.TargetHash </span><span class="cov0" title="0">{
                return fmt.Errorf("delta application failed: hash mismatch (expected %s, got %s)", op.TargetHash, resultHash)
        }</span>
        
        <span class="cov0" title="0">dt.logger.Info("delta applied successfully", "operation", op.ID)
        return nil</span>
}

// GetDeltas returns all deltas for a model
func (dt *DeltaTracker) GetDeltas(modelName string) []*Delta <span class="cov0" title="0">{
        dt.deltaMutex.RLock()
        defer dt.deltaMutex.RUnlock()
        
        deltas := dt.deltas[modelName]
        result := make([]*Delta, len(deltas))
        copy(result, deltas)
        
        return result
}</span>

// GetDeltaOperation returns a delta operation by ID
func (dt *DeltaTracker) GetDeltaOperation(opID string) (*DeltaOperation, bool) <span class="cov0" title="0">{
        dt.opsMutex.RLock()
        defer dt.opsMutex.RUnlock()
        
        op, exists := dt.pendingOps[opID]
        return op, exists
}</span>

// generateDeltas generates deltas between two files
func (dt *DeltaTracker) generateDeltas(sourceFile, targetFile string) ([]*Delta, error) <span class="cov0" title="0">{
        sourceData, err := os.ReadFile(sourceFile)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to read source file: %w", err)
        }</span>
        
        <span class="cov0" title="0">targetData, err := os.ReadFile(targetFile)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to read target file: %w", err)
        }</span>
        
        <span class="cov0" title="0">return dt.generateDeltasFromData(sourceData, targetData)</span>
}

// generateDeltasFromData generates deltas from byte data
func (dt *DeltaTracker) generateDeltasFromData(sourceData, targetData []byte) ([]*Delta, error) <span class="cov0" title="0">{
        var deltas []*Delta
        
        // Simple delta generation algorithm
        // In a real implementation, this would use a more sophisticated algorithm
        // like rsync's rolling hash or binary diff algorithms
        
        chunkSize := 1024 * 4 // 4KB chunks
        
        sourceOffset := 0
        targetOffset := 0
        
        for targetOffset &lt; len(targetData) </span><span class="cov0" title="0">{
                chunkEnd := targetOffset + chunkSize
                if chunkEnd &gt; len(targetData) </span><span class="cov0" title="0">{
                        chunkEnd = len(targetData)
                }</span>
                
                <span class="cov0" title="0">targetChunk := targetData[targetOffset:chunkEnd]
                
                // Check if this chunk exists in source
                found := false
                for i := sourceOffset; i &lt; len(sourceData)-len(targetChunk); i++ </span><span class="cov0" title="0">{
                        if dt.compareChunks(sourceData[i:i+len(targetChunk)], targetChunk) </span><span class="cov0" title="0">{
                                // Chunk exists, no delta needed
                                found = true
                                sourceOffset = i + len(targetChunk)
                                break</span>
                        }
                }
                
                <span class="cov0" title="0">if !found </span><span class="cov0" title="0">{
                        // Chunk is new or modified, create delta
                        deltaID := fmt.Sprintf("delta_%d_%d", time.Now().UnixNano(), targetOffset)
                        hash := sha256.Sum256(targetChunk)
                        
                        delta := &amp;Delta{
                                ID:        deltaID,
                                Type:      DeltaTypeInsert,
                                Offset:    int64(targetOffset),
                                Size:      int64(len(targetChunk)),
                                Hash:      hex.EncodeToString(hash[:]),
                                Data:      targetChunk,
                                Timestamp: time.Now(),
                        }
                        
                        // Apply compression if enabled
                        if dt.compressionEnabled </span><span class="cov0" title="0">{
                                compressed, err := dt.compressData(targetChunk)
                                if err == nil &amp;&amp; len(compressed) &lt; len(targetChunk) </span><span class="cov0" title="0">{
                                        delta.Data = compressed
                                        delta.Compressed = true
                                }</span>
                        }
                        
                        <span class="cov0" title="0">deltas = append(deltas, delta)</span>
                }
                
                <span class="cov0" title="0">targetOffset = chunkEnd</span>
        }
        
        <span class="cov0" title="0">return deltas, nil</span>
}

// applyDelta applies a single delta to a file
func (dt *DeltaTracker) applyDelta(file *os.File, delta *Delta) error <span class="cov0" title="0">{
        // Seek to position
        if _, err := file.Seek(delta.Offset, io.SeekStart); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to seek to position: %w", err)
        }</span>
        
        <span class="cov0" title="0">data := delta.Data
        
        // Decompress if needed
        if delta.Compressed </span><span class="cov0" title="0">{
                decompressed, err := dt.decompressData(data)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to decompress data: %w", err)
                }</span>
                <span class="cov0" title="0">data = decompressed</span>
        }
        
        // Apply delta based on type
        <span class="cov0" title="0">switch delta.Type </span>{
        case DeltaTypeInsert, DeltaTypeUpdate:<span class="cov0" title="0">
                if _, err := file.Write(data); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to write data: %w", err)
                }</span>
        case DeltaTypeDelete:<span class="cov0" title="0">
                // For delete operations, we would need to handle file truncation
                // This is simplified for demonstration
                return fmt.Errorf("delete operations not fully implemented")</span>
        }
        
        <span class="cov0" title="0">return nil</span>
}

// compareChunks compares two byte slices
func (dt *DeltaTracker) compareChunks(a, b []byte) bool <span class="cov0" title="0">{
        if len(a) != len(b) </span><span class="cov0" title="0">{
                return false
        }</span>
        
        <span class="cov0" title="0">for i := range a </span><span class="cov0" title="0">{
                if a[i] != b[i] </span><span class="cov0" title="0">{
                        return false
                }</span>
        }
        
        <span class="cov0" title="0">return true</span>
}

// calculateFileHash calculates SHA256 hash of a file
func (dt *DeltaTracker) calculateFileHash(filePath string) (string, error) <span class="cov0" title="0">{
        file, err := os.Open(filePath)
        if err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>
        <span class="cov0" title="0">defer file.Close()
        
        hash := sha256.New()
        if _, err := io.Copy(hash, file); err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>
        
        <span class="cov0" title="0">return hex.EncodeToString(hash.Sum(nil)), nil</span>
}

// compressData compresses data using a simple compression algorithm
func (dt *DeltaTracker) compressData(data []byte) ([]byte, error) <span class="cov0" title="0">{
        // In a real implementation, this would use a proper compression library
        // like gzip, lz4, or zstd
        // For demonstration, we'll return the original data
        return data, nil
}</span>

// decompressData decompresses data
func (dt *DeltaTracker) decompressData(data []byte) ([]byte, error) <span class="cov0" title="0">{
        // In a real implementation, this would use a proper decompression library
        // For demonstration, we'll return the original data
        return data, nil
}</span>

// loadDeltas loads existing deltas from disk
func (dt *DeltaTracker) loadDeltas() error <span class="cov0" title="0">{
        return filepath.Walk(dt.deltaDir, func(path string, info os.FileInfo, err error) error </span><span class="cov0" title="0">{
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                
                <span class="cov0" title="0">if info.IsDir() </span><span class="cov0" title="0">{
                        return nil
                }</span>
                
                <span class="cov0" title="0">if filepath.Ext(path) == ".delta" </span><span class="cov0" title="0">{
                        if err := dt.loadDeltaFile(path); err != nil </span><span class="cov0" title="0">{
                                dt.logger.Error("failed to load delta file", "path", path, "error", err)
                        }</span>
                }
                
                <span class="cov0" title="0">return nil</span>
        })
}

// loadDeltaFile loads a single delta file
func (dt *DeltaTracker) loadDeltaFile(path string) error <span class="cov0" title="0">{
        data, err := os.ReadFile(path)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to read delta file: %w", err)
        }</span>
        
        <span class="cov0" title="0">var op DeltaOperation
        if err := json.Unmarshal(data, &amp;op); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to unmarshal delta operation: %w", err)
        }</span>
        
        // Store operation
        <span class="cov0" title="0">dt.opsMutex.Lock()
        dt.pendingOps[op.ID] = &amp;op
        dt.opsMutex.Unlock()
        
        // Store deltas
        dt.deltaMutex.Lock()
        dt.deltas[op.ModelName] = append(dt.deltas[op.ModelName], op.Deltas...)
        dt.deltaMutex.Unlock()
        
        return nil</span>
}

// saveDelta saves a delta operation to disk
func (dt *DeltaTracker) saveDelta(op *DeltaOperation) error <span class="cov0" title="0">{
        filename := fmt.Sprintf("%s.delta", op.ID)
        path := filepath.Join(dt.deltaDir, filename)
        
        data, err := json.MarshalIndent(op, "", "  ")
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal delta operation: %w", err)
        }</span>
        
        <span class="cov0" title="0">return os.WriteFile(path, data, 0644)</span>
}

// GetDeltaMetadata returns metadata about deltas for a model
func (dt *DeltaTracker) GetDeltaMetadata(modelName string) *DeltaMetadata <span class="cov0" title="0">{
        dt.deltaMutex.RLock()
        defer dt.deltaMutex.RUnlock()
        
        deltas := dt.deltas[modelName]
        if len(deltas) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        <span class="cov0" title="0">var totalSize, compressedSize int64
        for _, delta := range deltas </span><span class="cov0" title="0">{
                totalSize += delta.Size
                if delta.Compressed </span><span class="cov0" title="0">{
                        compressedSize += int64(len(delta.Data))
                }</span> else<span class="cov0" title="0"> {
                        compressedSize += delta.Size
                }</span>
        }
        
        <span class="cov0" title="0">compressionRatio := 1.0
        if totalSize &gt; 0 </span><span class="cov0" title="0">{
                compressionRatio = float64(compressedSize) / float64(totalSize)
        }</span>
        
        <span class="cov0" title="0">return &amp;DeltaMetadata{
                ModelName:        modelName,
                DeltaCount:       len(deltas),
                TotalSize:        totalSize,
                CompressedSize:   compressedSize,
                CompressionRatio: compressionRatio,
        }</span>
}

// Cleanup removes old delta files
func (dt *DeltaTracker) Cleanup(maxAge time.Duration) error <span class="cov0" title="0">{
        dt.deltaMutex.Lock()
        defer dt.deltaMutex.Unlock()
        
        cutoff := time.Now().Add(-maxAge)
        
        for modelName, deltas := range dt.deltas </span><span class="cov0" title="0">{
                var remaining []*Delta
                
                for _, delta := range deltas </span><span class="cov0" title="0">{
                        if delta.Timestamp.After(cutoff) </span><span class="cov0" title="0">{
                                remaining = append(remaining, delta)
                        }</span>
                }
                
                <span class="cov0" title="0">dt.deltas[modelName] = remaining</span>
        }
        
        <span class="cov0" title="0">return nil</span>
}

// Close closes the delta tracker
func (dt *DeltaTracker) Close() error <span class="cov0" title="0">{
        dt.cancel()
        return nil
}</pre>
		
		<pre class="file" id="file27" style="display: none">package models

import (
        "context"
        "fmt"
        "log/slog"
        "sync"
        "time"

        "github.com/libp2p/go-libp2p/core/peer"
        "github.com/ollama/ollama-distributed/internal/config"
        "github.com/ollama/ollama-distributed/pkg/p2p"
        "github.com/ollama/ollama/server"
)

// DistributedModelManager extends Ollama's model management with distributed capabilities
type DistributedModelManager struct {
        // Core components
        localManager       *Manager
        syncManager        *SyncManager
        replicationManager *ReplicationManager
        casStore           *ContentAddressedStore
        deltaTracker       *DeltaTracker
        
        // Configuration
        config *config.DistributedConfig
        p2p    *p2p.Node
        logger *slog.Logger
        
        // Ollama integration
        ollamaServer *server.Server
        
        // Distributed model registry
        registry       *DistributedRegistry
        registryMutex  sync.RWMutex
        
        // Model lifecycle management
        lifecycle      *ModelLifecycle
        lifecycleMutex sync.RWMutex
        
        // Performance monitoring
        monitor *PerformanceMonitor
        
        // Context management
        ctx     context.Context
        cancel  context.CancelFunc
        started bool
        mu      sync.RWMutex
}

// DistributedRegistry maintains a registry of all models across the network
type DistributedRegistry struct {
        models       map[string]*DistributedModel
        modelsMutex  sync.RWMutex
        
        // Peer model tracking
        peerModels   map[string]map[string]*DistributedModel // peerID -&gt; modelName -&gt; model
        peerMutex    sync.RWMutex
        
        // Network topology
        topology     *NetworkTopology
        
        // Discovery service
        discovery    *ModelDiscovery
}

// DistributedModel represents a model in the distributed network
type DistributedModel struct {
        // Base model information
        Name        string                 `json:"name"`
        Version     string                 `json:"version"`
        Hash        string                 `json:"hash"`
        Size        int64                  `json:"size"`
        Type        string                 `json:"type"`
        
        // Distributed information
        Replicas    []*ReplicaInfo         `json:"replicas"`
        Availability float64               `json:"availability"`
        
        // Version tracking
        Versions    []*ModelVersion        `json:"versions"`
        CurrentVersion string              `json:"current_version"`
        
        // Metadata
        Metadata    map[string]interface{} `json:"metadata"`
        Tags        []string               `json:"tags"`
        
        // Lifecycle
        CreatedAt   time.Time              `json:"created_at"`
        UpdatedAt   time.Time              `json:"updated_at"`
        AccessedAt  time.Time              `json:"accessed_at"`
        
        // Performance metrics
        AccessCount int64                  `json:"access_count"`
        DownloadCount int64                `json:"download_count"`
        
        // Replication policy
        Policy      *ReplicationPolicy     `json:"policy"`
        
        // Sync state
        SyncState   *SyncState             `json:"sync_state"`
}

// ModelLifecycle manages the lifecycle of distributed models
type ModelLifecycle struct {
        events      chan *LifecycleEvent
        eventsMutex sync.RWMutex
        
        // Lifecycle stages
        stages      map[string]*LifecycleStage
        stagesMutex sync.RWMutex
        
        // Hooks
        hooks       map[LifecycleEventType][]LifecycleHook
        hooksMutex  sync.RWMutex
}

// LifecycleEvent represents a model lifecycle event
type LifecycleEvent struct {
        Type      LifecycleEventType     `json:"type"`
        ModelName string                 `json:"model_name"`
        PeerID    string                 `json:"peer_id"`
        Timestamp time.Time              `json:"timestamp"`
        Data      map[string]interface{} `json:"data"`
}

// LifecycleEventType represents the type of lifecycle event
type LifecycleEventType string

const (
        EventModelCreated     LifecycleEventType = "model_created"
        EventModelUpdated     LifecycleEventType = "model_updated"
        EventModelDeleted     LifecycleEventType = "model_deleted"
        EventModelAccessed    LifecycleEventType = "model_accessed"
        EventModelReplicated  LifecycleEventType = "model_replicated"
        EventModelSynced      LifecycleEventType = "model_synced"
        EventModelCorrupted   LifecycleEventType = "model_corrupted"
        EventModelHealed      LifecycleEventType = "model_healed"
)

// LifecycleStage represents a stage in the model lifecycle
type LifecycleStage struct {
        Name        string                 `json:"name"`
        ModelName   string                 `json:"model_name"`
        Status      StageStatus            `json:"status"`
        StartTime   time.Time              `json:"start_time"`
        EndTime     time.Time              `json:"end_time"`
        Progress    float64                `json:"progress"`
        Metadata    map[string]interface{} `json:"metadata"`
        Error       string                 `json:"error,omitempty"`
}

// StageStatus represents the status of a lifecycle stage
type StageStatus string

const (
        StageStatusPending    StageStatus = "pending"
        StageStatusInProgress StageStatus = "in_progress"
        StageStatusCompleted  StageStatus = "completed"
        StageStatusFailed     StageStatus = "failed"
)

// LifecycleHook represents a hook function for lifecycle events
type LifecycleHook func(event *LifecycleEvent) error

// NetworkTopology represents the network topology for model distribution
type NetworkTopology struct {
        nodes       map[string]*TopologyNode
        nodesMutex  sync.RWMutex
        
        // Topology metadata
        Type        TopologyType           `json:"type"`
        Depth       int                    `json:"depth"`
        Diameter    int                    `json:"diameter"`
        Connectivity float64               `json:"connectivity"`
        
        // Performance metrics
        avgLatency  time.Duration
        avgBandwidth int64
}

// TopologyNode represents a node in the network topology
type TopologyNode struct {
        ID          string                 `json:"id"`
        Address     string                 `json:"address"`
        Capabilities []string              `json:"capabilities"`
        Connections []*TopologyConnection  `json:"connections"`
        Metadata    map[string]interface{} `json:"metadata"`
        
        // Performance metrics
        Latency     time.Duration          `json:"latency"`
        Bandwidth   int64                  `json:"bandwidth"`
        Reliability float64                `json:"reliability"`
}

// TopologyConnection represents a connection between nodes
type TopologyConnection struct {
        TargetID    string        `json:"target_id"`
        Weight      float64       `json:"weight"`
        Latency     time.Duration `json:"latency"`
        Bandwidth   int64         `json:"bandwidth"`
        Quality     float64       `json:"quality"`
}

// TopologyType represents the type of network topology
type TopologyType string

const (
        TopologyMesh         TopologyType = "mesh"
        TopologyHierarchical TopologyType = "hierarchical"
        TopologyRing         TopologyType = "ring"
        TopologyStar         TopologyType = "star"
        TopologyHybrid       TopologyType = "hybrid"
)

// ModelDiscovery handles model discovery across the network
type ModelDiscovery struct {
        manager     *DistributedModelManager
        
        // Discovery cache
        cache       map[string]*DiscoveryEntry
        cacheMutex  sync.RWMutex
        
        // Discovery workers
        workers     []*DiscoveryWorker
        workQueue   chan *DiscoveryRequest
        
        // Broadcast settings
        broadcastInterval time.Duration
        discoveryTimeout  time.Duration
}

// DiscoveryEntry represents a discovered model
type DiscoveryEntry struct {
        ModelName   string                 `json:"model_name"`
        PeerID      string                 `json:"peer_id"`
        Metadata    map[string]interface{} `json:"metadata"`
        Timestamp   time.Time              `json:"timestamp"`
        TTL         time.Duration          `json:"ttl"`
}

// DiscoveryRequest represents a model discovery request
type DiscoveryRequest struct {
        ModelName    string                 `json:"model_name"`
        Criteria     map[string]interface{} `json:"criteria"`
        Timeout      time.Duration          `json:"timeout"`
        ResponseChan chan *DiscoveryResponse `json:"-"`
}

// DiscoveryResponse represents a model discovery response
type DiscoveryResponse struct {
        Models    []*DistributedModel `json:"models"`
        Peers     []string            `json:"peers"`
        Error     string              `json:"error,omitempty"`
        Duration  time.Duration       `json:"duration"`
}

// DiscoveryWorker handles model discovery tasks
type DiscoveryWorker struct {
        ID         int
        discovery  *ModelDiscovery
        stopChan   chan struct{}
}

// PerformanceMonitor monitors the performance of the distributed system
type PerformanceMonitor struct {
        metrics     map[string]*PerformanceMetric
        metricsMutex sync.RWMutex
        
        // Monitoring settings
        interval    time.Duration
        retention   time.Duration
        
        // Alerting
        alerts      []*PerformanceAlert
        alertsMutex sync.RWMutex
}

// PerformanceMetric represents a performance metric
type PerformanceMetric struct {
        Name        string                 `json:"name"`
        Value       float64                `json:"value"`
        Unit        string                 `json:"unit"`
        Timestamp   time.Time              `json:"timestamp"`
        Labels      map[string]string      `json:"labels"`
        History     []MetricPoint          `json:"history"`
}

// MetricPoint represents a point in a metric's history
type MetricPoint struct {
        Timestamp time.Time `json:"timestamp"`
        Value     float64   `json:"value"`
}

// PerformanceAlert represents a performance alert
type PerformanceAlert struct {
        ID          string                 `json:"id"`
        Type        AlertType              `json:"type"`
        Severity    AlertSeverity          `json:"severity"`
        Message     string                 `json:"message"`
        Metadata    map[string]interface{} `json:"metadata"`
        Timestamp   time.Time              `json:"timestamp"`
        Resolved    bool                   `json:"resolved"`
        ResolvedAt  time.Time              `json:"resolved_at"`
}

// AlertType represents the type of alert
type AlertType string

const (
        AlertTypeLatency      AlertType = "latency"
        AlertTypeBandwidth    AlertType = "bandwidth"
        AlertTypeReplication  AlertType = "replication"
        AlertTypeSync         AlertType = "sync"
        AlertTypeStorage      AlertType = "storage"
        AlertTypeHealth       AlertType = "health"
)

// AlertSeverity represents the severity of an alert
type AlertSeverity string

const (
        SeverityInfo     AlertSeverity = "info"
        SeverityWarning  AlertSeverity = "warning"
        SeverityError    AlertSeverity = "error"
        SeverityCritical AlertSeverity = "critical"
)

// NewDistributedModelManager creates a new distributed model manager
func NewDistributedModelManager(
        config *config.DistributedConfig,
        p2pNode *p2p.Node,
        logger *slog.Logger,
) (*DistributedModelManager, error) <span class="cov0" title="0">{
        ctx, cancel := context.WithCancel(context.Background())
        
        // Create local manager
        localManager, err := NewManager(config.Storage, p2pNode)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create local manager: %w", err)
        }</span>
        
        // Create sync manager
        <span class="cov0" title="0">syncManager, err := NewSyncManager(config.Sync, p2pNode, localManager, logger)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create sync manager: %w", err)
        }</span>
        
        // Create replication manager
        <span class="cov0" title="0">replicationManager, err := NewReplicationManager(config.Replication, p2pNode, localManager, syncManager, logger)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create replication manager: %w", err)
        }</span>
        
        // Create content-addressed store
        <span class="cov0" title="0">casStore, err := NewContentAddressedStore(config.CASDir, logger)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create CAS store: %w", err)
        }</span>
        
        // Create delta tracker
        <span class="cov0" title="0">deltaTracker, err := NewDeltaTracker(config.DeltaDir, logger)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create delta tracker: %w", err)
        }</span>
        
        <span class="cov0" title="0">dmm := &amp;DistributedModelManager{
                localManager:       localManager,
                syncManager:        syncManager,
                replicationManager: replicationManager,
                casStore:           casStore,
                deltaTracker:       deltaTracker,
                config:             config,
                p2p:                p2pNode,
                logger:             logger,
                ctx:                ctx,
                cancel:             cancel,
        }
        
        // Initialize registry
        dmm.registry = &amp;DistributedRegistry{
                models:     make(map[string]*DistributedModel),
                peerModels: make(map[string]map[string]*DistributedModel),
                topology:   &amp;NetworkTopology{
                        nodes: make(map[string]*TopologyNode),
                },
        }
        
        // Initialize lifecycle manager
        dmm.lifecycle = &amp;ModelLifecycle{
                events: make(chan *LifecycleEvent, 100),
                stages: make(map[string]*LifecycleStage),
                hooks:  make(map[LifecycleEventType][]LifecycleHook),
        }
        
        // Initialize performance monitor
        dmm.monitor = &amp;PerformanceMonitor{
                metrics:  make(map[string]*PerformanceMetric),
                interval: time.Minute,
                retention: 24 * time.Hour,
        }
        
        // Initialize model discovery
        dmm.registry.discovery = &amp;ModelDiscovery{
                manager:           dmm,
                cache:             make(map[string]*DiscoveryEntry),
                workQueue:         make(chan *DiscoveryRequest, 100),
                broadcastInterval: 30 * time.Second,
                discoveryTimeout:  10 * time.Second,
        }
        
        return dmm, nil</span>
}

// Start starts the distributed model manager
func (dmm *DistributedModelManager) Start() error <span class="cov0" title="0">{
        dmm.mu.Lock()
        defer dmm.mu.Unlock()
        
        if dmm.started </span><span class="cov0" title="0">{
                return fmt.Errorf("distributed model manager already started")
        }</span>
        
        // Start local manager
        <span class="cov0" title="0">if err := dmm.localManager.Start(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start local manager: %w", err)
        }</span>
        
        // Start sync manager
        <span class="cov0" title="0">if err := dmm.syncManager.Start(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start sync manager: %w", err)
        }</span>
        
        // Start replication manager
        <span class="cov0" title="0">if err := dmm.replicationManager.Start(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start replication manager: %w", err)
        }</span>
        
        // Start lifecycle manager
        <span class="cov0" title="0">go dmm.lifecycle.start()
        
        // Start performance monitor
        go dmm.monitor.start()
        
        // Start model discovery
        go dmm.registry.discovery.start()
        
        // Start registry synchronization
        go dmm.registrySyncRoutine()
        
        dmm.started = true
        dmm.logger.Info("distributed model manager started")
        
        return nil</span>
}

// GetModel retrieves a model, either locally or from the network
func (dmm *DistributedModelManager) GetModel(modelName string) (*DistributedModel, error) <span class="cov0" title="0">{
        // Check local registry first
        dmm.registryMutex.RLock()
        if model, exists := dmm.registry.models[modelName]; exists </span><span class="cov0" title="0">{
                dmm.registryMutex.RUnlock()
                
                // Update access statistics
                model.AccessedAt = time.Now()
                model.AccessCount++
                
                // Emit lifecycle event
                dmm.emitLifecycleEvent(EventModelAccessed, modelName, dmm.p2p.ID().String(), map[string]interface{}{
                        "access_count": model.AccessCount,
                })
                
                return model, nil
        }</span>
        <span class="cov0" title="0">dmm.registryMutex.RUnlock()
        
        // Discover model on network
        return dmm.discoverAndFetchModel(modelName)</span>
}

// AddModel adds a model to the distributed system
func (dmm *DistributedModelManager) AddModel(modelName, modelPath string) (*DistributedModel, error) <span class="cov0" title="0">{
        // Create model version
        version, err := dmm.syncManager.CreateModelVersion(modelName, modelPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create model version: %w", err)
        }</span>
        
        // Create distributed model
        <span class="cov0" title="0">model := &amp;DistributedModel{
                Name:           modelName,
                Version:        version.Version,
                Hash:           version.Hash,
                Size:           version.Size,
                Type:           "gguf", // Default type
                Replicas:       []*ReplicaInfo{},
                Availability:   1.0,
                Versions:       []*ModelVersion{version},
                CurrentVersion: version.Version,
                Metadata:       make(map[string]interface{}),
                Tags:           []string{},
                CreatedAt:      time.Now(),
                UpdatedAt:      time.Now(),
                AccessedAt:     time.Now(),
                AccessCount:    0,
                DownloadCount:  0,
        }
        
        // Add to registry
        dmm.registryMutex.Lock()
        dmm.registry.models[modelName] = model
        dmm.registryMutex.Unlock()
        
        // Set default replication policy
        policy := &amp;ReplicationPolicy{
                ModelName:         modelName,
                MinReplicas:       dmm.config.Replication.DefaultMinReplicas,
                MaxReplicas:       dmm.config.Replication.DefaultMaxReplicas,
                ReplicationFactor: dmm.config.Replication.DefaultReplicationFactor,
                SyncInterval:      dmm.config.Replication.DefaultSyncInterval,
                Priority:          1,
                Constraints:       make(map[string]string),
                CreatedAt:         time.Now(),
                UpdatedAt:         time.Now(),
        }
        
        model.Policy = policy
        dmm.replicationManager.SetReplicationPolicy(modelName, policy)
        
        // Emit lifecycle event
        dmm.emitLifecycleEvent(EventModelCreated, modelName, dmm.p2p.ID().String(), map[string]interface{}{
                "version": version.Version,
                "hash":    version.Hash,
                "size":    version.Size,
        })
        
        dmm.logger.Info("model added to distributed system", "model", modelName, "version", version.Version)
        
        return model, nil</span>
}

// discoverAndFetchModel discovers a model on the network and fetches it
func (dmm *DistributedModelManager) discoverAndFetchModel(modelName string) (*DistributedModel, error) <span class="cov0" title="0">{
        // Create discovery request
        req := &amp;DiscoveryRequest{
                ModelName:    modelName,
                Criteria:     make(map[string]interface{}),
                Timeout:      dmm.registry.discovery.discoveryTimeout,
                ResponseChan: make(chan *DiscoveryResponse, 1),
        }
        
        // Submit discovery request
        select </span>{
        case dmm.registry.discovery.workQueue &lt;- req:<span class="cov0" title="0"></span>
        case &lt;-time.After(5 * time.Second):<span class="cov0" title="0">
                return nil, fmt.Errorf("discovery queue full")</span>
        }
        
        // Wait for response
        <span class="cov0" title="0">select </span>{
        case resp := &lt;-req.ResponseChan:<span class="cov0" title="0">
                if resp.Error != "" </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("discovery failed: %s", resp.Error)
                }</span>
                
                <span class="cov0" title="0">if len(resp.Models) == 0 </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("model not found: %s", modelName)
                }</span>
                
                // Use the first available model
                <span class="cov0" title="0">model := resp.Models[0]
                
                // Download model from a peer
                if len(resp.Peers) &gt; 0 </span><span class="cov0" title="0">{
                        if err := dmm.downloadModelFromPeer(modelName, resp.Peers[0]); err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("failed to download model: %w", err)
                        }</span>
                }
                
                // Add to local registry
                <span class="cov0" title="0">dmm.registryMutex.Lock()
                dmm.registry.models[modelName] = model
                dmm.registryMutex.Unlock()
                
                return model, nil</span>
                
        case &lt;-time.After(dmm.registry.discovery.discoveryTimeout):<span class="cov0" title="0">
                return nil, fmt.Errorf("discovery timeout")</span>
        }
}

// downloadModelFromPeer downloads a model from a specific peer
func (dmm *DistributedModelManager) downloadModelFromPeer(modelName, peerID string) error <span class="cov0" title="0">{
        // Use the local manager to download the model
        _, err := dmm.localManager.DownloadModel(modelName, peerID)
        return err
}</span>

// emitLifecycleEvent emits a lifecycle event
func (dmm *DistributedModelManager) emitLifecycleEvent(eventType LifecycleEventType, modelName, peerID string, data map[string]interface{}) <span class="cov0" title="0">{
        event := &amp;LifecycleEvent{
                Type:      eventType,
                ModelName: modelName,
                PeerID:    peerID,
                Timestamp: time.Now(),
                Data:      data,
        }
        
        select </span>{
        case dmm.lifecycle.events &lt;- event:<span class="cov0" title="0"></span>
        default:<span class="cov0" title="0">
                // Event queue full, log warning
                dmm.logger.Warn("lifecycle event queue full", "event", eventType, "model", modelName)</span>
        }
}

// registrySyncRoutine periodically synchronizes the registry
func (dmm *DistributedModelManager) registrySyncRoutine() <span class="cov0" title="0">{
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-dmm.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        dmm.syncRegistry()</span>
                }
        }
}

// syncRegistry synchronizes the registry with peers  
func (dmm *DistributedModelManager) syncRegistry() <span class="cov0" title="0">{
        // Get connected peers
        peerIDs := dmm.p2p.GetConnectedPeers()
        if len(peerIDs) == 0 </span><span class="cov0" title="0">{
                return // No peers to sync with
        }</span>
        
        <span class="cov0" title="0">var peers []string
        for _, peerID := range peerIDs </span><span class="cov0" title="0">{
                peers = append(peers, peerID.String())
        }</span>

        // Prepare local registry for broadcasting
        <span class="cov0" title="0">dmm.registryMutex.RLock()
        localModels := make(map[string]*DistributedModel)
        for k, v := range dmm.registry.models </span><span class="cov0" title="0">{
                localModels[k] = v
        }</span>
        <span class="cov0" title="0">dmm.registryMutex.RUnlock()

        // Broadcast local models to peers
        for _, peerStr := range peers </span><span class="cov0" title="0">{
                go dmm.syncWithPeer(peerStr, localModels)
        }</span>

        // Request model information from peers
        <span class="cov0" title="0">for _, peerStr := range peers </span><span class="cov0" title="0">{
                go dmm.requestPeerModels(peerStr)
        }</span>

        // Clean up stale peer entries
        <span class="cov0" title="0">dmm.cleanupStalePeers()</span>
}

// GetDistributedModels returns all distributed models
func (dmm *DistributedModelManager) GetDistributedModels() []*DistributedModel <span class="cov0" title="0">{
        dmm.registryMutex.RLock()
        defer dmm.registryMutex.RUnlock()
        
        models := make([]*DistributedModel, 0, len(dmm.registry.models))
        for _, model := range dmm.registry.models </span><span class="cov0" title="0">{
                models = append(models, model)
        }</span>
        
        <span class="cov0" title="0">return models</span>
}

// GetPerformanceMetrics returns performance metrics
func (dmm *DistributedModelManager) GetPerformanceMetrics() []*PerformanceMetric <span class="cov0" title="0">{
        dmm.monitor.metricsMutex.RLock()
        defer dmm.monitor.metricsMutex.RUnlock()
        
        metrics := make([]*PerformanceMetric, 0, len(dmm.monitor.metrics))
        for _, metric := range dmm.monitor.metrics </span><span class="cov0" title="0">{
                metrics = append(metrics, metric)
        }</span>
        
        <span class="cov0" title="0">return metrics</span>
}

// Shutdown gracefully shuts down the distributed model manager
func (dmm *DistributedModelManager) Shutdown(ctx context.Context) error <span class="cov0" title="0">{
        dmm.mu.Lock()
        defer dmm.mu.Unlock()
        
        if !dmm.started </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        // Shutdown components
        <span class="cov0" title="0">if err := dmm.replicationManager.Shutdown(ctx); err != nil </span><span class="cov0" title="0">{
                dmm.logger.Error("failed to shutdown replication manager", "error", err)
        }</span>
        
        <span class="cov0" title="0">if err := dmm.syncManager.Shutdown(ctx); err != nil </span><span class="cov0" title="0">{
                dmm.logger.Error("failed to shutdown sync manager", "error", err)
        }</span>
        
        <span class="cov0" title="0">if err := dmm.localManager.Shutdown(ctx); err != nil </span><span class="cov0" title="0">{
                dmm.logger.Error("failed to shutdown local manager", "error", err)
        }</span>
        
        <span class="cov0" title="0">if err := dmm.casStore.Close(); err != nil </span><span class="cov0" title="0">{
                dmm.logger.Error("failed to close CAS store", "error", err)
        }</span>
        
        <span class="cov0" title="0">if err := dmm.deltaTracker.Close(); err != nil </span><span class="cov0" title="0">{
                dmm.logger.Error("failed to close delta tracker", "error", err)
        }</span>
        
        <span class="cov0" title="0">dmm.cancel()
        dmm.started = false
        
        dmm.logger.Info("distributed model manager shutdown complete")
        return nil</span>
}

// ModelLifecycle methods

// start starts the lifecycle manager
func (ml *ModelLifecycle) start() <span class="cov0" title="0">{
        for event := range ml.events </span><span class="cov0" title="0">{
                ml.processEvent(event)
        }</span>
}

// processEvent processes a lifecycle event
func (ml *ModelLifecycle) processEvent(event *LifecycleEvent) <span class="cov0" title="0">{
        // Execute hooks
        ml.hooksMutex.RLock()
        hooks := ml.hooks[event.Type]
        ml.hooksMutex.RUnlock()
        
        for _, hook := range hooks </span><span class="cov0" title="0">{
                if err := hook(event); err != nil </span><span class="cov0" title="0">{
                        // Log hook error but continue
                        fmt.Printf("Lifecycle hook error: %v\n", err)
                }</span>
        }
}

// PerformanceMonitor methods

// start starts the performance monitor
func (pm *PerformanceMonitor) start() <span class="cov0" title="0">{
        ticker := time.NewTicker(pm.interval)
        defer ticker.Stop()
        
        for range ticker.C </span><span class="cov0" title="0">{
                pm.collectMetrics()
        }</span>
}

// collectMetrics collects performance metrics
func (pm *PerformanceMonitor) collectMetrics() <span class="cov0" title="0">{
        now := time.Now()

        // Collect model access latency
        pm.collectModelAccessMetrics(now)

        // Collect replication bandwidth
        pm.collectReplicationMetrics(now)

        // Collect sync success rate
        pm.collectSyncMetrics(now)

        // Collect storage utilization
        pm.collectStorageMetrics(now)

        // Collect network connectivity
        pm.collectNetworkMetrics(now)

        // Clean up old metrics
        pm.cleanupOldMetrics(now)
}</span>

// ModelDiscovery methods

// start starts the model discovery service
func (md *ModelDiscovery) start() <span class="cov0" title="0">{
        // Start discovery workers
        md.workers = make([]*DiscoveryWorker, 3)
        for i := 0; i &lt; 3; i++ </span><span class="cov0" title="0">{
                md.workers[i] = &amp;DiscoveryWorker{
                        ID:        i,
                        discovery: md,
                        stopChan:  make(chan struct{}),
                }
                go md.workers[i].start()
        }</span>
        
        // Start broadcast routine
        <span class="cov0" title="0">go md.broadcastRoutine()</span>
}

// broadcastRoutine periodically broadcasts model information
func (md *ModelDiscovery) broadcastRoutine() <span class="cov0" title="0">{
        ticker := time.NewTicker(md.broadcastInterval)
        defer ticker.Stop()
        
        for range ticker.C </span><span class="cov0" title="0">{
                md.broadcastModels()
        }</span>
}

// broadcastModels broadcasts local model information to peers
func (md *ModelDiscovery) broadcastModels() <span class="cov0" title="0">{
        // Get local models from manager
        models := md.manager.GetDistributedModels()
        if len(models) == 0 </span><span class="cov0" title="0">{
                return // No models to broadcast
        }</span>

        // Prepare broadcast message
        <span class="cov0" title="0">broadcast := map[string]interface{}{
                "type":      "model_broadcast",
                "peer_id":   md.manager.p2p.ID().String(),
                "timestamp": time.Now().Unix(),
                "models":    md.prepareModelBroadcast(models),
        }

        // Send to all connected peers
        peerIDs := md.manager.p2p.GetConnectedPeers()
        for _, peerID := range peerIDs </span><span class="cov0" title="0">{
                go md.sendBroadcastToPeer(peerID, broadcast)
        }</span>

        // Update broadcast metrics
        <span class="cov0" title="0">md.updateBroadcastMetrics(len(peerIDs), len(models))</span>
}

// DiscoveryWorker methods

// start starts the discovery worker
func (dw *DiscoveryWorker) start() <span class="cov0" title="0">{
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-dw.stopChan:<span class="cov0" title="0">
                        return</span>
                case req := &lt;-dw.discovery.workQueue:<span class="cov0" title="0">
                        dw.processRequest(req)</span>
                }
        }
}

// processRequest processes a discovery request
func (dw *DiscoveryWorker) processRequest(req *DiscoveryRequest) <span class="cov0" title="0">{
        start := time.Now()

        // Search local cache first
        foundModels, foundPeers := dw.searchLocalCache(req.ModelName, req.Criteria)

        // If not found locally, search network
        if len(foundModels) == 0 </span><span class="cov0" title="0">{
                networkModels, networkPeers := dw.searchNetwork(req.ModelName, req.Criteria, req.Timeout)
                foundModels = append(foundModels, networkModels...)
                foundPeers = append(foundPeers, networkPeers...)
        }</span>

        // Filter and rank results
        <span class="cov0" title="0">filteredModels := dw.filterResults(foundModels, req.Criteria)
        rankedModels := dw.rankResults(filteredModels)

        // Prepare response
        resp := &amp;DiscoveryResponse{
                Models:   rankedModels,
                Peers:    foundPeers,
                Duration: time.Since(start),
        }

        // Send response
        select </span>{
        case req.ResponseChan &lt;- resp:<span class="cov0" title="0"></span>
        case &lt;-time.After(time.Second):<span class="cov0" title="0">
                // Response channel blocked, log warning
                dw.discovery.manager.logger.Warn("discovery response channel blocked")</span>
        }
}

// Helper methods for registry synchronization

// syncWithPeer synchronizes models with a specific peer
func (dmm *DistributedModelManager) syncWithPeer(peerIDStr string, localModels map[string]*DistributedModel) <span class="cov0" title="0">{
        // Prepare sync message
        syncMessage := map[string]interface{}{
                "type":      "registry_sync",
                "peer_id":   dmm.p2p.ID().String(),
                "timestamp": time.Now().Unix(),
                "models":    localModels,
        }

        // Send via P2P (simplified implementation)
        // In practice, this would use libp2p streams
        dmm.logger.Info("syncing models with peer", "peer", peerIDStr, "models", len(localModels), "sync_message", syncMessage)
}</span>

// requestPeerModels requests model information from a peer
func (dmm *DistributedModelManager) requestPeerModels(peerIDStr string) <span class="cov0" title="0">{
        // Create request message
        request := map[string]interface{}{
                "type":      "model_request",
                "peer_id":   dmm.p2p.ID().String(),
                "timestamp": time.Now().Unix(),
        }

        // Send request via P2P (simplified implementation)
        dmm.logger.Info("requesting models from peer", "peer", peerIDStr, "request", request)
}</span>

// cleanupStalePeers removes stale peer entries
func (dmm *DistributedModelManager) cleanupStalePeers() <span class="cov0" title="0">{
        dmm.registry.peerMutex.Lock()
        defer dmm.registry.peerMutex.Unlock()

        connectedPeerIDs := dmm.p2p.GetConnectedPeers()
        connectedMap := make(map[string]bool)
        for _, peerID := range connectedPeerIDs </span><span class="cov0" title="0">{
                connectedMap[peerID.String()] = true
        }</span>

        // Remove disconnected peers
        <span class="cov0" title="0">for peerID := range dmm.registry.peerModels </span><span class="cov0" title="0">{
                if !connectedMap[peerID] </span><span class="cov0" title="0">{
                        delete(dmm.registry.peerModels, peerID)
                }</span>
        }
}

// Helper methods for performance monitoring

// collectModelAccessMetrics collects model access latency metrics
func (pm *PerformanceMonitor) collectModelAccessMetrics(now time.Time) <span class="cov0" title="0">{
        pm.metricsMutex.Lock()
        defer pm.metricsMutex.Unlock()

        // Simulate collecting access latency
        latencyMetric := &amp;PerformanceMetric{
                Name:      "model_access_latency",
                Value:     float64(50 + (now.UnixNano() % 100)), // Simulate 50-150ms
                Unit:      "milliseconds",
                Timestamp: now,
                Labels:    map[string]string{"type": "access"},
                History:   []MetricPoint{{Timestamp: now, Value: 75.5}},
        }

        pm.metrics["model_access_latency"] = latencyMetric
}</span>

// collectReplicationMetrics collects replication bandwidth metrics
func (pm *PerformanceMonitor) collectReplicationMetrics(now time.Time) <span class="cov0" title="0">{
        pm.metricsMutex.Lock()
        defer pm.metricsMutex.Unlock()

        // Simulate bandwidth metrics
        bandwidthMetric := &amp;PerformanceMetric{
                Name:      "replication_bandwidth",
                Value:     float64(1024 * 1024 * 10), // 10 MB/s
                Unit:      "bytes_per_second",
                Timestamp: now,
                Labels:    map[string]string{"type": "replication"},
                History:   []MetricPoint{{Timestamp: now, Value: 1024 * 1024 * 10}},
        }

        pm.metrics["replication_bandwidth"] = bandwidthMetric
}</span>

// collectSyncMetrics collects synchronization success rate metrics
func (pm *PerformanceMonitor) collectSyncMetrics(now time.Time) <span class="cov0" title="0">{
        pm.metricsMutex.Lock()
        defer pm.metricsMutex.Unlock()

        // Simulate sync success rate
        syncMetric := &amp;PerformanceMetric{
                Name:      "sync_success_rate",
                Value:     95.5, // 95.5% success rate
                Unit:      "percentage",
                Timestamp: now,
                Labels:    map[string]string{"type": "sync"},
                History:   []MetricPoint{{Timestamp: now, Value: 95.5}},
        }

        pm.metrics["sync_success_rate"] = syncMetric
}</span>

// collectStorageMetrics collects storage utilization metrics
func (pm *PerformanceMonitor) collectStorageMetrics(now time.Time) <span class="cov0" title="0">{
        pm.metricsMutex.Lock()
        defer pm.metricsMutex.Unlock()

        // Simulate storage usage
        storageMetric := &amp;PerformanceMetric{
                Name:      "storage_utilization",
                Value:     65.2, // 65.2% storage used
                Unit:      "percentage",
                Timestamp: now,
                Labels:    map[string]string{"type": "storage"},
                History:   []MetricPoint{{Timestamp: now, Value: 65.2}},
        }

        pm.metrics["storage_utilization"] = storageMetric
}</span>

// collectNetworkMetrics collects network connectivity metrics
func (pm *PerformanceMonitor) collectNetworkMetrics(now time.Time) <span class="cov0" title="0">{
        pm.metricsMutex.Lock()
        defer pm.metricsMutex.Unlock()

        // Simulate network connectivity
        networkMetric := &amp;PerformanceMetric{
                Name:      "network_connectivity",
                Value:     98.7, // 98.7% uptime
                Unit:      "percentage",
                Timestamp: now,
                Labels:    map[string]string{"type": "network"},
                History:   []MetricPoint{{Timestamp: now, Value: 98.7}},
        }

        pm.metrics["network_connectivity"] = networkMetric
}</span>

// cleanupOldMetrics removes old metric history points
func (pm *PerformanceMonitor) cleanupOldMetrics(now time.Time) <span class="cov0" title="0">{
        pm.metricsMutex.Lock()
        defer pm.metricsMutex.Unlock()

        cutoff := now.Add(-pm.retention)
        for _, metric := range pm.metrics </span><span class="cov0" title="0">{
                var newHistory []MetricPoint
                for _, point := range metric.History </span><span class="cov0" title="0">{
                        if point.Timestamp.After(cutoff) </span><span class="cov0" title="0">{
                                newHistory = append(newHistory, point)
                        }</span>
                }
                <span class="cov0" title="0">metric.History = newHistory</span>
        }
}

// Helper methods for model discovery

// prepareModelBroadcast prepares models for broadcasting
func (md *ModelDiscovery) prepareModelBroadcast(models []*DistributedModel) []map[string]interface{} <span class="cov0" title="0">{
        var broadcast []map[string]interface{}
        for _, model := range models </span><span class="cov0" title="0">{
                broadcast = append(broadcast, map[string]interface{}{
                        "name":         model.Name,
                        "version":      model.Version,
                        "hash":         model.Hash,
                        "size":         model.Size,
                        "availability": model.Availability,
                        "replicas":     len(model.Replicas),
                })
        }</span>
        <span class="cov0" title="0">return broadcast</span>
}

// sendBroadcastToPeer sends broadcast message to a specific peer
func (md *ModelDiscovery) sendBroadcastToPeer(peerID peer.ID, broadcast map[string]interface{}) <span class="cov0" title="0">{
        // Send via P2P (simplified implementation)
        // In practice, this would use libp2p streams
        fmt.Printf("Broadcasting models to peer %s\n", peerID.String())
}</span>

// updateBroadcastMetrics updates broadcast metrics
func (md *ModelDiscovery) updateBroadcastMetrics(peerCount, modelCount int) <span class="cov0" title="0">{
        // Update internal metrics (simplified)
        fmt.Printf("Broadcast sent to %d peers with %d models\n", peerCount, modelCount)
}</span>

// Helper methods for discovery worker

// searchLocalCache searches for models in local cache
func (dw *DiscoveryWorker) searchLocalCache(modelName string, criteria map[string]interface{}) ([]*DistributedModel, []string) <span class="cov0" title="0">{
        dw.discovery.cacheMutex.RLock()
        defer dw.discovery.cacheMutex.RUnlock()

        var foundModels []*DistributedModel
        var foundPeers []string

        for _, entry := range dw.discovery.cache </span><span class="cov0" title="0">{
                if entry.ModelName == modelName || modelName == "" </span><span class="cov0" title="0">{
                        // Create model from cache entry
                        model := &amp;DistributedModel{
                                Name:      entry.ModelName,
                                Version:   "1.0",
                                Hash:      "unknown",
                                Size:      1024,
                                Type:      "gguf",
                                Metadata:  entry.Metadata,
                                CreatedAt: entry.Timestamp,
                        }
                        foundModels = append(foundModels, model)
                        foundPeers = append(foundPeers, entry.PeerID)
                }</span>
        }

        <span class="cov0" title="0">return foundModels, foundPeers</span>
}

// searchNetwork searches for models across the network
func (dw *DiscoveryWorker) searchNetwork(modelName string, criteria map[string]interface{}, timeout time.Duration) ([]*DistributedModel, []string) <span class="cov0" title="0">{
        // Simulate network search
        // In practice, this would query connected peers
        var foundModels []*DistributedModel
        var foundPeers []string

        // Mock finding a model on the network
        if modelName != "" </span><span class="cov0" title="0">{
                model := &amp;DistributedModel{
                        Name:      modelName,
                        Version:   "1.0",
                        Hash:      "network_hash",
                        Size:      2048,
                        Type:      "gguf",
                        Metadata:  make(map[string]interface{}),
                        CreatedAt: time.Now(),
                }
                foundModels = append(foundModels, model)
                foundPeers = append(foundPeers, "network_peer_123")
        }</span>

        <span class="cov0" title="0">return foundModels, foundPeers</span>
}

// filterResults filters models based on criteria
func (dw *DiscoveryWorker) filterResults(models []*DistributedModel, criteria map[string]interface{}) []*DistributedModel <span class="cov0" title="0">{
        if len(criteria) == 0 </span><span class="cov0" title="0">{
                return models
        }</span>

        <span class="cov0" title="0">var filtered []*DistributedModel
        for _, model := range models </span><span class="cov0" title="0">{
                if dw.matchesCriteria(model, criteria) </span><span class="cov0" title="0">{
                        filtered = append(filtered, model)
                }</span>
        }
        <span class="cov0" title="0">return filtered</span>
}

// rankResults ranks models by relevance
func (dw *DiscoveryWorker) rankResults(models []*DistributedModel) []*DistributedModel <span class="cov0" title="0">{
        // Simple ranking by size (smaller first)
        for i := 0; i &lt; len(models)-1; i++ </span><span class="cov0" title="0">{
                for j := i + 1; j &lt; len(models); j++ </span><span class="cov0" title="0">{
                        if models[i].Size &gt; models[j].Size </span><span class="cov0" title="0">{
                                models[i], models[j] = models[j], models[i]
                        }</span>
                }
        }
        <span class="cov0" title="0">return models</span>
}

// matchesCriteria checks if a model matches search criteria
func (dw *DiscoveryWorker) matchesCriteria(model *DistributedModel, criteria map[string]interface{}) bool <span class="cov0" title="0">{
        // Simple criteria matching
        if minSize, exists := criteria["min_size"]; exists </span><span class="cov0" title="0">{
                if size, ok := minSize.(int64); ok &amp;&amp; model.Size &lt; size </span><span class="cov0" title="0">{
                        return false
                }</span>
        }
        <span class="cov0" title="0">if maxSize, exists := criteria["max_size"]; exists </span><span class="cov0" title="0">{
                if size, ok := maxSize.(int64); ok &amp;&amp; model.Size &gt; size </span><span class="cov0" title="0">{
                        return false
                }</span>
        }
        <span class="cov0" title="0">return true</span>
}</pre>
		
		<pre class="file" id="file28" style="display: none">package models

import (
        "context"
        "crypto/sha256"
        "fmt"
        "io"
        "os"
        "path/filepath"
        "sync"
        "time"

        "github.com/ollama/ollama-distributed/internal/config"
        "github.com/ollama/ollama-distributed/pkg/p2p"
)

// Manager manages model distribution across the network
type Manager struct {
        config *config.StorageConfig
        p2p    *p2p.Node
        
        // Local model storage
        models    map[string]*Model
        modelsMu  sync.RWMutex
        
        // Transfer management
        transfers map[string]*Transfer
        transfersMu sync.RWMutex
        
        // Download queue
        downloadQueue chan *DownloadRequest
        uploadQueue   chan *UploadRequest
        
        // Workers
        downloadWorkers []*DownloadWorker
        uploadWorkers   []*UploadWorker
        
        started bool
        mu      sync.RWMutex
        
        ctx    context.Context
        cancel context.CancelFunc
}

// Model represents a model in the distributed system
type Model struct {
        Name        string            `json:"name"`
        Version     string            `json:"version"`
        Size        int64             `json:"size"`
        Checksum    string            `json:"checksum"`
        Path        string            `json:"path"`
        Status      ModelStatus       `json:"status"`
        Replicas    []string          `json:"replicas"`    // Node IDs that have this model
        Metadata    map[string]string `json:"metadata"`
        CreatedAt   time.Time         `json:"created_at"`
        UpdatedAt   time.Time         `json:"updated_at"`
        AccessCount int64             `json:"access_count"`
        LastAccessed time.Time        `json:"last_accessed"`
}

// ModelStatus represents the status of a model
type ModelStatus string

const (
        ModelStatusDownloading ModelStatus = "downloading"
        ModelStatusAvailable   ModelStatus = "available"
        ModelStatusCorrupted   ModelStatus = "corrupted"
        ModelStatusDeleted     ModelStatus = "deleted"
)

// Transfer represents a model transfer operation
type Transfer struct {
        ID          string          `json:"id"`
        ModelName   string          `json:"model_name"`
        Type        TransferType    `json:"type"`
        Status      TransferStatus  `json:"status"`
        Progress    float64         `json:"progress"`
        BytesTotal  int64           `json:"bytes_total"`
        BytesDone   int64           `json:"bytes_done"`
        Speed       int64           `json:"speed"`       // bytes per second
        PeerID      string          `json:"peer_id"`
        StartedAt   time.Time       `json:"started_at"`
        CompletedAt time.Time       `json:"completed_at"`
        Error       string          `json:"error,omitempty"`
        
        // Internal fields
        ctx    context.Context
        cancel context.CancelFunc
}

// TransferType represents the type of transfer
type TransferType string

const (
        TransferTypeDownload TransferType = "download"
        TransferTypeUpload   TransferType = "upload"
)

// TransferStatus represents the status of a transfer
type TransferStatus string

const (
        TransferStatusPending    TransferStatus = "pending"
        TransferStatusActive     TransferStatus = "active"
        TransferStatusCompleted  TransferStatus = "completed"
        TransferStatusFailed     TransferStatus = "failed"
        TransferStatusCancelled  TransferStatus = "cancelled"
)

// DownloadRequest represents a request to download a model
type DownloadRequest struct {
        ModelName string
        PeerID    string
        Priority  int
        ResponseCh chan *DownloadResponse
}

// DownloadResponse represents a response to a download request
type DownloadResponse struct {
        Success   bool
        Model     *Model
        Error     string
        Duration  time.Duration
}

// UploadRequest represents a request to upload a model
type UploadRequest struct {
        ModelName string
        PeerID    string
        ResponseCh chan *UploadResponse
}

// UploadResponse represents a response to an upload request
type UploadResponse struct {
        Success  bool
        Error    string
        Duration time.Duration
}

// DownloadWorker handles download operations
type DownloadWorker struct {
        ID      int
        manager *Manager
        stopCh  chan struct{}
}

// UploadWorker handles upload operations
type UploadWorker struct {
        ID      int
        manager *Manager
        stopCh  chan struct{}
}

// NewManager creates a new model distribution manager
func NewManager(config *config.StorageConfig, p2pNode *p2p.Node) (*Manager, error) <span class="cov0" title="0">{
        ctx, cancel := context.WithCancel(context.Background())
        
        manager := &amp;Manager{
                config:        config,
                p2p:           p2pNode,
                models:        make(map[string]*Model),
                transfers:     make(map[string]*Transfer),
                downloadQueue: make(chan *DownloadRequest, 100),
                uploadQueue:   make(chan *UploadRequest, 100),
                ctx:           ctx,
                cancel:        cancel,
        }
        
        // Create download workers
        manager.downloadWorkers = make([]*DownloadWorker, 3)
        for i := 0; i &lt; 3; i++ </span><span class="cov0" title="0">{
                manager.downloadWorkers[i] = &amp;DownloadWorker{
                        ID:      i,
                        manager: manager,
                        stopCh:  make(chan struct{}),
                }
        }</span>
        
        // Create upload workers
        <span class="cov0" title="0">manager.uploadWorkers = make([]*UploadWorker, 3)
        for i := 0; i &lt; 3; i++ </span><span class="cov0" title="0">{
                manager.uploadWorkers[i] = &amp;UploadWorker{
                        ID:      i,
                        manager: manager,
                        stopCh:  make(chan struct{}),
                }
        }</span>
        
        <span class="cov0" title="0">return manager, nil</span>
}

// Start starts the model distribution manager
func (m *Manager) Start() error <span class="cov0" title="0">{
        m.mu.Lock()
        defer m.mu.Unlock()
        
        if m.started </span><span class="cov0" title="0">{
                return fmt.Errorf("model manager already started")
        }</span>
        
        // Create storage directories
        <span class="cov0" title="0">if err := os.MkdirAll(m.config.ModelDir, 0755); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create model directory: %w", err)
        }</span>
        
        // Load existing models
        <span class="cov0" title="0">if err := m.loadModels(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to load models: %w", err)
        }</span>
        
        // Start workers
        <span class="cov0" title="0">for _, worker := range m.downloadWorkers </span><span class="cov0" title="0">{
                go worker.start()
        }</span>
        
        <span class="cov0" title="0">for _, worker := range m.uploadWorkers </span><span class="cov0" title="0">{
                go worker.start()
        }</span>
        
        // Start cleanup routine
        <span class="cov0" title="0">go m.cleanupRoutine()
        
        m.started = true
        return nil</span>
}

// loadModels loads existing models from disk
func (m *Manager) loadModels() error <span class="cov0" title="0">{
        return filepath.Walk(m.config.ModelDir, func(path string, info os.FileInfo, err error) error </span><span class="cov0" title="0">{
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                
                <span class="cov0" title="0">if info.IsDir() </span><span class="cov0" title="0">{
                        return nil
                }</span>
                
                // Check if it's a model file (you might want to add more sophisticated detection)
                <span class="cov0" title="0">if filepath.Ext(path) == ".gguf" || filepath.Ext(path) == ".bin" </span><span class="cov0" title="0">{
                        if err := m.registerLocalModel(path); err != nil </span><span class="cov0" title="0">{
                                // Log error but continue
                                fmt.Printf("Failed to register model %s: %v\n", path, err)
                        }</span>
                }
                
                <span class="cov0" title="0">return nil</span>
        })
}

// registerLocalModel registers a local model file
func (m *Manager) registerLocalModel(path string) error <span class="cov0" title="0">{
        // Get file info
        info, err := os.Stat(path)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to stat model file: %w", err)
        }</span>
        
        // Calculate checksum
        <span class="cov0" title="0">checksum, err := m.calculateChecksum(path)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to calculate checksum: %w", err)
        }</span>
        
        // Extract model name from path
        <span class="cov0" title="0">name := filepath.Base(path)
        name = name[:len(name)-len(filepath.Ext(name))]
        
        // Create model entry
        model := &amp;Model{
                Name:         name,
                Version:      "1.0.0", // TODO: Extract version from filename or metadata
                Size:         info.Size(),
                Checksum:     checksum,
                Path:         path,
                Status:       ModelStatusAvailable,
                Replicas:     []string{m.p2p.ID().String()},
                Metadata:     make(map[string]string),
                CreatedAt:    info.ModTime(),
                UpdatedAt:    info.ModTime(),
                AccessCount:  0,
                LastAccessed: time.Now(),
        }
        
        m.modelsMu.Lock()
        m.models[name] = model
        m.modelsMu.Unlock()
        
        return nil</span>
}

// calculateChecksum calculates SHA256 checksum of a file
func (m *Manager) calculateChecksum(path string) (string, error) <span class="cov0" title="0">{
        file, err := os.Open(path)
        if err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>
        <span class="cov0" title="0">defer file.Close()
        
        hash := sha256.New()
        if _, err := io.Copy(hash, file); err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>
        
        <span class="cov0" title="0">return fmt.Sprintf("%x", hash.Sum(nil)), nil</span>
}

// cleanupRoutine runs periodic cleanup tasks
func (m *Manager) cleanupRoutine() <span class="cov0" title="0">{
        ticker := time.NewTicker(time.Hour)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-m.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        m.cleanup()</span>
                }
        }
}

// cleanup performs cleanup tasks
func (m *Manager) cleanup() <span class="cov0" title="0">{
        // Remove old transfers
        m.transfersMu.Lock()
        for id, transfer := range m.transfers </span><span class="cov0" title="0">{
                if transfer.Status == TransferStatusCompleted || transfer.Status == TransferStatusFailed </span><span class="cov0" title="0">{
                        if time.Since(transfer.CompletedAt) &gt; time.Hour </span><span class="cov0" title="0">{
                                delete(m.transfers, id)
                        }</span>
                }
        }
        <span class="cov0" title="0">m.transfersMu.Unlock()
        
        // Clean up old model files based on cleanup age
        m.modelsMu.Lock()
        for name, model := range m.models </span><span class="cov0" title="0">{
                if time.Since(model.LastAccessed) &gt; m.config.CleanupAge </span><span class="cov0" title="0">{
                        // Remove model file
                        if err := os.Remove(model.Path); err == nil </span><span class="cov0" title="0">{
                                delete(m.models, name)
                        }</span>
                }
        }
        <span class="cov0" title="0">m.modelsMu.Unlock()</span>
}

// DownloadModel downloads a model from peers
func (m *Manager) DownloadModel(modelName string, peerID string) (*Model, error) <span class="cov0" title="0">{
        responseCh := make(chan *DownloadResponse, 1)
        
        req := &amp;DownloadRequest{
                ModelName:  modelName,
                PeerID:     peerID,
                Priority:   1,
                ResponseCh: responseCh,
        }
        
        select </span>{
        case m.downloadQueue &lt;- req:<span class="cov0" title="0"></span>
        case &lt;-time.After(5 * time.Second):<span class="cov0" title="0">
                return nil, fmt.Errorf("download queue full")</span>
        }
        
        <span class="cov0" title="0">select </span>{
        case response := &lt;-responseCh:<span class="cov0" title="0">
                if response.Success </span><span class="cov0" title="0">{
                        return response.Model, nil
                }</span>
                <span class="cov0" title="0">return nil, fmt.Errorf("download failed: %s", response.Error)</span>
        case &lt;-time.After(10 * time.Minute):<span class="cov0" title="0">
                return nil, fmt.Errorf("download timeout")</span>
        }
}

// GetModel returns a model by name
func (m *Manager) GetModel(name string) (*Model, bool) <span class="cov0" title="0">{
        m.modelsMu.RLock()
        defer m.modelsMu.RUnlock()
        
        model, exists := m.models[name]
        if exists </span><span class="cov0" title="0">{
                // Update access statistics
                model.AccessCount++
                model.LastAccessed = time.Now()
        }</span>
        
        <span class="cov0" title="0">return model, exists</span>
}

// GetAllModels returns all models
func (m *Manager) GetAllModels() map[string]*Model <span class="cov0" title="0">{
        m.modelsMu.RLock()
        defer m.modelsMu.RUnlock()
        
        models := make(map[string]*Model)
        for k, v := range m.models </span><span class="cov0" title="0">{
                models[k] = v
        }</span>
        
        <span class="cov0" title="0">return models</span>
}

// GetTransfer returns a transfer by ID
func (m *Manager) GetTransfer(id string) (*Transfer, bool) <span class="cov0" title="0">{
        m.transfersMu.RLock()
        defer m.transfersMu.RUnlock()
        
        transfer, exists := m.transfers[id]
        return transfer, exists
}</span>

// GetAllTransfers returns all transfers
func (m *Manager) GetAllTransfers() map[string]*Transfer <span class="cov0" title="0">{
        m.transfersMu.RLock()
        defer m.transfersMu.RUnlock()
        
        transfers := make(map[string]*Transfer)
        for k, v := range m.transfers </span><span class="cov0" title="0">{
                transfers[k] = v
        }</span>
        
        <span class="cov0" title="0">return transfers</span>
}

// Shutdown gracefully shuts down the model manager
func (m *Manager) Shutdown(ctx context.Context) error <span class="cov0" title="0">{
        m.mu.Lock()
        defer m.mu.Unlock()
        
        if !m.started </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        // Stop workers
        <span class="cov0" title="0">for _, worker := range m.downloadWorkers </span><span class="cov0" title="0">{
                close(worker.stopCh)
        }</span>
        
        <span class="cov0" title="0">for _, worker := range m.uploadWorkers </span><span class="cov0" title="0">{
                close(worker.stopCh)
        }</span>
        
        // Cancel ongoing transfers
        <span class="cov0" title="0">m.transfersMu.Lock()
        for _, transfer := range m.transfers </span><span class="cov0" title="0">{
                if transfer.Status == TransferStatusActive </span><span class="cov0" title="0">{
                        transfer.cancel()
                }</span>
        }
        <span class="cov0" title="0">m.transfersMu.Unlock()
        
        // Cancel context
        m.cancel()
        
        m.started = false
        return nil</span>
}

// DownloadWorker methods

// start starts the download worker
func (w *DownloadWorker) start() <span class="cov0" title="0">{
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-w.stopCh:<span class="cov0" title="0">
                        return</span>
                case req := &lt;-w.manager.downloadQueue:<span class="cov0" title="0">
                        w.processDownload(req)</span>
                }
        }
}

// processDownload processes a download request
func (w *DownloadWorker) processDownload(req *DownloadRequest) <span class="cov0" title="0">{
        start := time.Now()
        
        // Create transfer entry
        transferID := fmt.Sprintf("download_%s_%d", req.ModelName, time.Now().UnixNano())
        ctx, cancel := context.WithCancel(w.manager.ctx)
        
        transfer := &amp;Transfer{
                ID:        transferID,
                ModelName: req.ModelName,
                Type:      TransferTypeDownload,
                Status:    TransferStatusPending,
                Progress:  0,
                PeerID:    req.PeerID,
                StartedAt: start,
                ctx:       ctx,
                cancel:    cancel,
        }
        
        w.manager.transfersMu.Lock()
        w.manager.transfers[transferID] = transfer
        w.manager.transfersMu.Unlock()
        
        // TODO: Implement actual download from peer
        // For now, simulate download
        model, err := w.simulateDownload(transfer)
        
        response := &amp;DownloadResponse{
                Success:  err == nil,
                Model:    model,
                Duration: time.Since(start),
        }
        
        if err != nil </span><span class="cov0" title="0">{
                response.Error = err.Error()
                transfer.Status = TransferStatusFailed
                transfer.Error = err.Error()
        }</span> else<span class="cov0" title="0"> {
                transfer.Status = TransferStatusCompleted
        }</span>
        
        <span class="cov0" title="0">transfer.CompletedAt = time.Now()
        
        select </span>{
        case req.ResponseCh &lt;- response:<span class="cov0" title="0"></span>
        case &lt;-time.After(5 * time.Second):<span class="cov0" title="0"></span>
                // Response channel blocked
        }
}

// simulateDownload simulates downloading a model
func (w *DownloadWorker) simulateDownload(transfer *Transfer) (*Model, error) <span class="cov0" title="0">{
        // Update transfer status
        transfer.Status = TransferStatusActive
        transfer.BytesTotal = 1024 * 1024 * 100 // 100MB
        
        // Simulate download progress
        for i := 0; i &lt; 10; i++ </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-transfer.ctx.Done():<span class="cov0" title="0">
                        return nil, fmt.Errorf("download cancelled")</span>
                default:<span class="cov0" title="0"></span>
                }
                
                <span class="cov0" title="0">transfer.BytesDone = int64(i+1) * (transfer.BytesTotal / 10)
                transfer.Progress = float64(transfer.BytesDone) / float64(transfer.BytesTotal) * 100
                
                time.Sleep(100 * time.Millisecond)</span>
        }
        
        // Create model file path
        <span class="cov0" title="0">modelPath := filepath.Join(w.manager.config.ModelDir, transfer.ModelName+".gguf")
        
        // Create dummy model file
        file, err := os.Create(modelPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create model file: %w", err)
        }</span>
        
        // Write some dummy data
        <span class="cov0" title="0">if _, err := file.WriteString("dummy model data"); err != nil </span><span class="cov0" title="0">{
                file.Close()
                return nil, fmt.Errorf("failed to write model file: %w", err)
        }</span>
        <span class="cov0" title="0">file.Close()
        
        // Calculate checksum
        checksum, err := w.manager.calculateChecksum(modelPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to calculate checksum: %w", err)
        }</span>
        
        // Create model entry
        <span class="cov0" title="0">model := &amp;Model{
                Name:         transfer.ModelName,
                Version:      "1.0.0",
                Size:         transfer.BytesTotal,
                Checksum:     checksum,
                Path:         modelPath,
                Status:       ModelStatusAvailable,
                Replicas:     []string{w.manager.p2p.ID().String()},
                Metadata:     make(map[string]string),
                CreatedAt:    time.Now(),
                UpdatedAt:    time.Now(),
                AccessCount:  0,
                LastAccessed: time.Now(),
        }
        
        // Store model
        w.manager.modelsMu.Lock()
        w.manager.models[transfer.ModelName] = model
        w.manager.modelsMu.Unlock()
        
        return model, nil</span>
}

// UploadWorker methods

// start starts the upload worker
func (w *UploadWorker) start() <span class="cov0" title="0">{
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-w.stopCh:<span class="cov0" title="0">
                        return</span>
                case req := &lt;-w.manager.uploadQueue:<span class="cov0" title="0">
                        w.processUpload(req)</span>
                }
        }
}

// processUpload processes an upload request
func (w *UploadWorker) processUpload(req *UploadRequest) <span class="cov0" title="0">{
        start := time.Now()
        
        // TODO: Implement actual upload to peer
        // For now, simulate upload
        err := w.simulateUpload(req)
        
        response := &amp;UploadResponse{
                Success:  err == nil,
                Duration: time.Since(start),
        }
        
        if err != nil </span><span class="cov0" title="0">{
                response.Error = err.Error()
        }</span>
        
        <span class="cov0" title="0">select </span>{
        case req.ResponseCh &lt;- response:<span class="cov0" title="0"></span>
        case &lt;-time.After(5 * time.Second):<span class="cov0" title="0"></span>
                // Response channel blocked
        }
}

// simulateUpload simulates uploading a model
func (w *UploadWorker) simulateUpload(req *UploadRequest) error <span class="cov0" title="0">{
        // Check if model exists
        model, exists := w.manager.GetModel(req.ModelName)
        if !exists </span><span class="cov0" title="0">{
                return fmt.Errorf("model %s not found", req.ModelName)
        }</span>
        
        // Simulate upload time
        <span class="cov0" title="0">time.Sleep(time.Duration(model.Size/1024/1024) * time.Millisecond)
        
        return nil</span>
}

// ShouldDistribute determines if a model should be distributed
func (m *Manager) ShouldDistribute(modelName string) bool <span class="cov0" title="0">{
        // Check if model exists and is suitable for distribution
        _, exists := m.GetModel(modelName)
        return exists
}</span>

// IsDistributed checks if a model is already distributed
func (m *Manager) IsDistributed(modelName string) bool <span class="cov0" title="0">{
        // Check if model exists in the distributed network
        _, exists := m.GetModel(modelName)
        return exists
}</span>

// GetModelInfo returns information about a model
func (m *Manager) GetModelInfo(modelName string) map[string]interface{} <span class="cov0" title="0">{
        if model, exists := m.GetModel(modelName); exists </span><span class="cov0" title="0">{
                return map[string]interface{}{
                        "name":     model.Name,
                        "version":  model.Version,
                        "size":     model.Size,
                        "checksum": model.Checksum,
                        "path":     model.Path,
                        "created":  model.CreatedAt,
                        "accessed": model.LastAccessed,
                }
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// GetDistributedModels returns all distributed models as API responses
func (m *Manager) GetDistributedModels() []interface{} <span class="cov0" title="0">{
        m.modelsMu.RLock()
        defer m.modelsMu.RUnlock()
        
        var models []interface{}
        for _, model := range m.models </span><span class="cov0" title="0">{
                models = append(models, map[string]interface{}{
                        "name":     model.Name,
                        "version":  model.Version,
                        "size":     model.Size,
                        "checksum": model.Checksum,
                        "path":     model.Path,
                        "created":  model.CreatedAt,
                        "accessed": model.LastAccessed,
                })
        }</span>
        <span class="cov0" title="0">return models</span>
}

// DeleteModel deletes a model from the distributed system
func (m *Manager) DeleteModel(modelName string) error <span class="cov0" title="0">{
        m.modelsMu.Lock()
        defer m.modelsMu.Unlock()
        
        if _, exists := m.models[modelName]; !exists </span><span class="cov0" title="0">{
                return fmt.Errorf("model %s not found", modelName)
        }</span>
        
        <span class="cov0" title="0">delete(m.models, modelName)
        return nil</span>
}

// GetDistributedModelCount returns the count of distributed models
func (m *Manager) GetDistributedModelCount() int <span class="cov0" title="0">{
        m.modelsMu.RLock()
        defer m.modelsMu.RUnlock()
        return len(m.models)
}</span>

// DownloadFromPeer downloads a model from a peer
func (m *Manager) DownloadFromPeer(modelName, peerID string) error <span class="cov0" title="0">{
        // This is a wrapper around the existing DownloadModel method
        _, err := m.DownloadModel(modelName, peerID)
        return err
}</span>

// RegisterModel registers a model in the distributed system
func (m *Manager) RegisterModel(modelName, modelPath string) error <span class="cov0" title="0">{
        return m.registerLocalModel(modelPath)
}</span>

// Rebalance rebalances models across the distributed network
func (m *Manager) Rebalance() error <span class="cov0" title="0">{
        // Stub implementation for rebalancing logic
        return nil
}</span>

// MigrateModel migrates a model to a different node
func (m *Manager) MigrateModel(modelName, targetNodeID string) error <span class="cov0" title="0">{
        // Stub implementation for model migration
        return nil
}</span>

// GetStats returns statistics about the distributed system
func (m *Manager) GetStats() map[string]interface{} <span class="cov0" title="0">{
        m.modelsMu.RLock()
        defer m.modelsMu.RUnlock()
        
        return map[string]interface{}{
                "total_models": len(m.models),
                "total_transfers": len(m.transfers),
                "active_downloads": len(m.downloadQueue),
                "active_uploads": len(m.uploadQueue),
        }
}</span>

// ForceRebalance forces a rebalancing operation
func (m *Manager) ForceRebalance() error <span class="cov0" title="0">{
        // Stub implementation for forced rebalancing
        return m.Rebalance()
}</span>

// GetTotalModels returns the total number of models in the system
func (m *Manager) GetTotalModels() int <span class="cov0" title="0">{
        return m.GetDistributedModelCount()
}</pre>
		
		<pre class="file" id="file29" style="display: none">package models

import (
        "context"
        "fmt"
        "io"
        "log/slog"
        "path/filepath"
        "sync"
        "time"

        "github.com/ollama/ollama/api"
        "github.com/ollama/ollama/types/model"
)

// OllamaIntegration provides integration with Ollama's existing model management
type OllamaIntegration struct {
        distributedManager *DistributedModelManager
        logger             *slog.Logger
        
        // Ollama server integration
        modelHooks    map[string][]ModelHook
        hooksMutex    sync.RWMutex
        
        // Model interception
        interceptor   *ModelInterceptor
        
        // Compatibility layer
        compatibility *CompatibilityLayer
}

// ModelHook represents a hook for model operations
type ModelHook func(operation string, modelName string, data map[string]interface{}) error

// ModelInterceptor intercepts Ollama model operations
type ModelInterceptor struct {
        integration *OllamaIntegration
        
        // Operation tracking
        operations    map[string]*ModelOperation
        operationsMutex sync.RWMutex
}

// ModelOperation represents an intercepted model operation
type ModelOperation struct {
        ID        string                 `json:"id"`
        Type      string                 `json:"type"`
        ModelName string                 `json:"model_name"`
        Status    string                 `json:"status"`
        StartTime time.Time              `json:"start_time"`
        EndTime   time.Time              `json:"end_time"`
        Metadata  map[string]interface{} `json:"metadata"`
        Error     string                 `json:"error,omitempty"`
}

// CompatibilityLayer provides compatibility with existing Ollama APIs
type CompatibilityLayer struct {
        integration *OllamaIntegration
        
        // API translation
        apiTranslator *APITranslator
        
        // Legacy support
        legacySupport *LegacySupport
}

// APITranslator translates between Ollama APIs and distributed APIs
type APITranslator struct {
        // Request/response mapping
        requestMappings  map[string]RequestMapping
        responseMappings map[string]ResponseMapping
}

// RequestMapping maps Ollama requests to distributed requests
type RequestMapping struct {
        SourceType   string                 `json:"source_type"`
        TargetType   string                 `json:"target_type"`
        FieldMapping map[string]string      `json:"field_mapping"`
        Transform    func(interface{}) interface{} `json:"-"`
}

// ResponseMapping maps distributed responses to Ollama responses
type ResponseMapping struct {
        SourceType   string                 `json:"source_type"`
        TargetType   string                 `json:"target_type"`
        FieldMapping map[string]string      `json:"field_mapping"`
        Transform    func(interface{}) interface{} `json:"-"`
}

// LegacySupport provides support for legacy Ollama functionality
type LegacySupport struct {
        // Legacy model paths
        legacyPaths map[string]string
        pathsMutex  sync.RWMutex
        
        // Legacy metadata
        legacyMetadata map[string]map[string]interface{}
        metadataMutex  sync.RWMutex
}

// NewOllamaIntegration creates a new Ollama integration
func NewOllamaIntegration(distributedManager *DistributedModelManager, logger *slog.Logger) *OllamaIntegration <span class="cov0" title="0">{
        integration := &amp;OllamaIntegration{
                distributedManager: distributedManager,
                logger:             logger,
                modelHooks:         make(map[string][]ModelHook),
        }
        
        // Initialize interceptor
        integration.interceptor = &amp;ModelInterceptor{
                integration: integration,
                operations:  make(map[string]*ModelOperation),
        }
        
        // Initialize compatibility layer
        integration.compatibility = &amp;CompatibilityLayer{
                integration: integration,
                apiTranslator: &amp;APITranslator{
                        requestMappings:  make(map[string]RequestMapping),
                        responseMappings: make(map[string]ResponseMapping),
                },
                legacySupport: &amp;LegacySupport{
                        legacyPaths:    make(map[string]string),
                        legacyMetadata: make(map[string]map[string]interface{}),
                },
        }
        
        // Setup API mappings
        integration.setupAPIMappings()
        
        return integration
}</span>

// setupAPIMappings sets up API mappings between Ollama and distributed APIs
func (oi *OllamaIntegration) setupAPIMappings() <span class="cov0" title="0">{
        // Map Ollama model requests to distributed model requests
        oi.compatibility.apiTranslator.requestMappings["model.Name"] = RequestMapping{
                SourceType: "model.Name",
                TargetType: "DistributedModel",
                FieldMapping: map[string]string{
                        "name":    "Name",
                        "tag":     "Version",
                        "digest":  "Hash",
                },
                Transform: func(src interface{}) interface{} </span><span class="cov0" title="0">{
                        if name, ok := src.(model.Name); ok </span><span class="cov0" title="0">{
                                return &amp;DistributedModel{
                                        Name:    name.String(),
                                        Version: name.Tag,
                                        Hash:    "", // Note: model.Name doesn't have Digest field
                                }
                        }</span>
                        <span class="cov0" title="0">return src</span>
                },
        }
        
        // Map distributed model responses to Ollama responses
        <span class="cov0" title="0">oi.compatibility.apiTranslator.responseMappings["DistributedModel"] = ResponseMapping{
                SourceType: "DistributedModel",
                TargetType: "api.ListModelResponse",
                FieldMapping: map[string]string{
                        "Name":      "name",
                        "Version":   "model",
                        "Hash":      "digest",
                        "Size":      "size",
                        "CreatedAt": "created_at",
                        "UpdatedAt": "modified_at",
                },
                Transform: func(src interface{}) interface{} </span><span class="cov0" title="0">{
                        if dm, ok := src.(*DistributedModel); ok </span><span class="cov0" title="0">{
                                return &amp;api.ListModelResponse{
                                        Name:       dm.Name,
                                        Model:      dm.Name,
                                        Size:       dm.Size,
                                        Digest:     dm.Hash,
                                        ModifiedAt: dm.UpdatedAt,
                                }
                        }</span>
                        <span class="cov0" title="0">return src</span>
                },
        }
}

// InterceptModelPull intercepts Ollama model pull operations
func (oi *OllamaIntegration) InterceptModelPull(ctx context.Context, name model.Name, fn func(api.ProgressResponse)) error <span class="cov0" title="0">{
        oi.logger.Info("intercepting model pull", "model", name.String())
        
        // Create operation record
        op := &amp;ModelOperation{
                ID:        fmt.Sprintf("pull_%s_%d", name.String(), time.Now().UnixNano()),
                Type:      "pull",
                ModelName: name.String(),
                Status:    "starting",
                StartTime: time.Now(),
                Metadata:  make(map[string]interface{}),
        }
        
        oi.interceptor.operationsMutex.Lock()
        oi.interceptor.operations[op.ID] = op
        oi.interceptor.operationsMutex.Unlock()
        
        // Execute pre-pull hooks
        if err := oi.executeHooks("pre-pull", name.String(), map[string]interface{}{
                "operation_id": op.ID,
                "model_name":   name.String(),
        }); err != nil </span><span class="cov0" title="0">{
                op.Status = "failed"
                op.Error = err.Error()
                op.EndTime = time.Now()
                return fmt.Errorf("pre-pull hook failed: %w", err)
        }</span>
        
        // Check if model exists in distributed system
        <span class="cov0" title="0">if distributedModel, err := oi.distributedManager.GetModel(name.String()); err == nil </span><span class="cov0" title="0">{
                oi.logger.Info("model found in distributed system", "model", name.String())
                
                // Report progress
                if fn != nil </span><span class="cov0" title="0">{
                        fn(api.ProgressResponse{
                                Status:    "pulling model",
                                Digest:    distributedModel.Hash,
                                Total:     distributedModel.Size,
                                Completed: 0,
                        })
                }</span>
                
                // Simulate download progress
                <span class="cov0" title="0">chunkSize := distributedModel.Size / 10
                for i := int64(0); i &lt; 10; i++ </span><span class="cov0" title="0">{
                        if fn != nil </span><span class="cov0" title="0">{
                                fn(api.ProgressResponse{
                                        Status:    "downloading",
                                        Digest:    distributedModel.Hash,
                                        Total:     distributedModel.Size,
                                        Completed: (i + 1) * chunkSize,
                                })
                        }</span>
                        <span class="cov0" title="0">time.Sleep(100 * time.Millisecond)</span>
                }
                
                <span class="cov0" title="0">if fn != nil </span><span class="cov0" title="0">{
                        fn(api.ProgressResponse{
                                Status:    "verifying sha256 digest",
                                Digest:    distributedModel.Hash,
                                Total:     distributedModel.Size,
                                Completed: distributedModel.Size,
                        })
                }</span>
                
                <span class="cov0" title="0">op.Status = "completed"
                op.EndTime = time.Now()
                
                // Execute post-pull hooks
                oi.executeHooks("post-pull", name.String(), map[string]interface{}{
                        "operation_id": op.ID,
                        "model_name":   name.String(),
                        "success":      true,
                })
                
                return nil</span>
        }
        
        // Model not found in distributed system, fall back to original pull
        <span class="cov0" title="0">oi.logger.Info("model not found in distributed system, falling back to original pull", "model", name.String())
        
        // Use original Ollama pull mechanism
        // Note: server.PullModel and server.RegistryOptions are not available in current API
        // Creating compatibility stub
        if err := oi.fallbackPullModel(ctx, name.String(), fn); err != nil </span><span class="cov0" title="0">{
                op.Status = "failed"
                op.Error = err.Error()
                op.EndTime = time.Now()
                
                // Execute post-pull hooks
                oi.executeHooks("post-pull", name.String(), map[string]interface{}{
                        "operation_id": op.ID,
                        "model_name":   name.String(),
                        "success":      false,
                        "error":        err.Error(),
                })
                
                return err
        }</span>
        
        // Add pulled model to distributed system
        <span class="cov0" title="0">if err := oi.addPulledModelToDistributedSystem(name.String()); err != nil </span><span class="cov0" title="0">{
                oi.logger.Error("failed to add pulled model to distributed system", "model", name.String(), "error", err)
        }</span>
        
        <span class="cov0" title="0">op.Status = "completed"
        op.EndTime = time.Now()
        
        // Execute post-pull hooks
        oi.executeHooks("post-pull", name.String(), map[string]interface{}{
                "operation_id": op.ID,
                "model_name":   name.String(),
                "success":      true,
        })
        
        return nil</span>
}

// InterceptModelList intercepts Ollama model list operations
func (oi *OllamaIntegration) InterceptModelList() ([]api.ListModelResponse, error) <span class="cov0" title="0">{
        oi.logger.Info("intercepting model list")
        
        // Get distributed models
        distributedModels := oi.distributedManager.GetDistributedModels()
        
        // Convert to Ollama API responses
        var responses []api.ListModelResponse
        for _, dm := range distributedModels </span><span class="cov0" title="0">{
                response := api.ListModelResponse{
                        Name:       dm.Name,
                        Model:      dm.Name,
                        Size:       dm.Size,
                        Digest:     dm.Hash,
                        ModifiedAt: dm.UpdatedAt,
                }
                responses = append(responses, response)
        }</span>
        
        // Also get local models that might not be in distributed system
        <span class="cov0" title="0">localModels, err := oi.getLocalModels()
        if err != nil </span><span class="cov0" title="0">{
                oi.logger.Error("failed to get local models", "error", err)
        }</span> else<span class="cov0" title="0"> {
                // Merge local models that aren't already in distributed system
                for _, local := range localModels </span><span class="cov0" title="0">{
                        found := false
                        for _, distributed := range responses </span><span class="cov0" title="0">{
                                if distributed.Name == local.Name </span><span class="cov0" title="0">{
                                        found = true
                                        break</span>
                                }
                        }
                        <span class="cov0" title="0">if !found </span><span class="cov0" title="0">{
                                responses = append(responses, local)
                        }</span>
                }
        }
        
        <span class="cov0" title="0">return responses, nil</span>
}

// InterceptModelShow intercepts Ollama model show operations
func (oi *OllamaIntegration) InterceptModelShow(name model.Name) (*api.ShowResponse, error) <span class="cov0" title="0">{
        oi.logger.Info("intercepting model show", "model", name.String())
        
        // Try to get from distributed system first
        if distributedModel, err := oi.distributedManager.GetModel(name.String()); err == nil </span><span class="cov0" title="0">{
                // Create ModelInfo from map[string]interface{}
                modelInfo := map[string]interface{}{
                        "name":        distributedModel.Name,
                        "size":        distributedModel.Size,
                        "digest":      distributedModel.Hash,
                        "created_at":  distributedModel.CreatedAt,
                        "modified_at": distributedModel.UpdatedAt,
                }
                
                return &amp;api.ShowResponse{
                        ModelInfo: modelInfo,
                        Details: api.ModelDetails{
                                Format:   "gguf",
                                Family:   "llama",
                                Families: []string{"llama"},
                        },
                }, nil
        }</span>
        
        // Fall back to original show
        <span class="cov0" title="0">return oi.getOriginalModelShow(name)</span>
}

// InterceptModelDelete intercepts Ollama model delete operations
func (oi *OllamaIntegration) InterceptModelDelete(name model.Name) error <span class="cov0" title="0">{
        oi.logger.Info("intercepting model delete", "model", name.String())
        
        // Execute pre-delete hooks
        if err := oi.executeHooks("pre-delete", name.String(), map[string]interface{}{
                "model_name": name.String(),
        }); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("pre-delete hook failed: %w", err)
        }</span>
        
        // Remove from distributed system
        <span class="cov0" title="0">if err := oi.removeFromDistributedSystem(name.String()); err != nil </span><span class="cov0" title="0">{
                oi.logger.Error("failed to remove from distributed system", "model", name.String(), "error", err)
        }</span>
        
        // Execute original delete
        <span class="cov0" title="0">if err := oi.executeOriginalDelete(name); err != nil </span><span class="cov0" title="0">{
                // Execute post-delete hooks
                oi.executeHooks("post-delete", name.String(), map[string]interface{}{
                        "model_name": name.String(),
                        "success":    false,
                        "error":      err.Error(),
                })
                return err
        }</span>
        
        // Execute post-delete hooks
        <span class="cov0" title="0">oi.executeHooks("post-delete", name.String(), map[string]interface{}{
                "model_name": name.String(),
                "success":    true,
        })
        
        return nil</span>
}

// AddModelHook adds a hook for model operations
func (oi *OllamaIntegration) AddModelHook(operation string, hook ModelHook) <span class="cov0" title="0">{
        oi.hooksMutex.Lock()
        defer oi.hooksMutex.Unlock()
        
        oi.modelHooks[operation] = append(oi.modelHooks[operation], hook)
}</span>

// executeHooks executes hooks for a given operation
func (oi *OllamaIntegration) executeHooks(operation string, modelName string, data map[string]interface{}) error <span class="cov0" title="0">{
        oi.hooksMutex.RLock()
        hooks := oi.modelHooks[operation]
        oi.hooksMutex.RUnlock()
        
        for _, hook := range hooks </span><span class="cov0" title="0">{
                if err := hook(operation, modelName, data); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
        }
        
        <span class="cov0" title="0">return nil</span>
}

// addPulledModelToDistributedSystem adds a pulled model to the distributed system
func (oi *OllamaIntegration) addPulledModelToDistributedSystem(modelName string) error <span class="cov0" title="0">{
        // Get model path from Ollama
        modelPath, err := oi.getModelPath(modelName)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get model path: %w", err)
        }</span>
        
        // Add to distributed system
        <span class="cov0" title="0">_, err = oi.distributedManager.AddModel(modelName, modelPath)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to add model to distributed system: %w", err)
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// getModelPath gets the local path for a model
func (oi *OllamaIntegration) getModelPath(modelName string) (string, error) <span class="cov0" title="0">{
        // This would need to integrate with Ollama's model path resolution
        // For now, return a placeholder path
        return filepath.Join("/tmp/models", modelName+".gguf"), nil
}</span>

// getLocalModels gets models from local Ollama installation
func (oi *OllamaIntegration) getLocalModels() ([]api.ListModelResponse, error) <span class="cov0" title="0">{
        // This would need to integrate with Ollama's model listing
        // For now, return empty list
        return []api.ListModelResponse{}, nil
}</span>

// getOriginalModelShow gets model show from original Ollama
func (oi *OllamaIntegration) getOriginalModelShow(name model.Name) (*api.ShowResponse, error) <span class="cov0" title="0">{
        // This would need to integrate with Ollama's model show
        // For now, return a placeholder response
        return &amp;api.ShowResponse{
                ModelInfo: map[string]interface{}{
                        "name":   name.String(),
                        "size":   int64(0),
                        "digest": "",
                },
                Details: api.ModelDetails{
                        Format:   "gguf",
                        Family:   "llama",
                        Families: []string{"llama"},
                },
        }, nil
}</span>

// executeOriginalDelete executes the original model delete
func (oi *OllamaIntegration) executeOriginalDelete(name model.Name) error <span class="cov0" title="0">{
        // This would need to integrate with Ollama's model deletion
        // For now, return success
        return nil
}</span>

// removeFromDistributedSystem removes a model from the distributed system
func (oi *OllamaIntegration) removeFromDistributedSystem(modelName string) error <span class="cov0" title="0">{
        // This would need to be implemented in the distributed manager
        // For now, just log the operation
        oi.logger.Info("removing model from distributed system", "model", modelName)
        return nil
}</span>

// fallbackPullModel provides a fallback implementation for pulling models
// since server.PullModel is not available in the current Ollama API
func (oi *OllamaIntegration) fallbackPullModel(ctx context.Context, modelName string, fn func(api.ProgressResponse)) error <span class="cov0" title="0">{
        oi.logger.Info("fallback pull model implementation", "model", modelName)
        
        // Simulate progress reporting
        if fn != nil </span><span class="cov0" title="0">{
                fn(api.ProgressResponse{
                        Status: "pulling model",
                        Total:  100,
                        Completed: 0,
                })
                
                // Simulate download progress
                for i := 0; i &lt;= 100; i += 10 </span><span class="cov0" title="0">{
                        fn(api.ProgressResponse{
                                Status: "downloading",
                                Total:  100,
                                Completed: int64(i),
                        })
                }</span>
                
                <span class="cov0" title="0">fn(api.ProgressResponse{
                        Status: "verifying sha256 digest",
                        Total:  100,
                        Completed: 100,
                })</span>
        }
        
        // TODO: Implement actual model pulling logic
        // This is a stub implementation
        <span class="cov0" title="0">return nil</span>
}

// GetOperationStatus returns the status of a model operation
func (oi *OllamaIntegration) GetOperationStatus(operationID string) (*ModelOperation, bool) <span class="cov0" title="0">{
        oi.interceptor.operationsMutex.RLock()
        defer oi.interceptor.operationsMutex.RUnlock()
        
        op, exists := oi.interceptor.operations[operationID]
        return op, exists
}</span>

// GetAllOperations returns all model operations
func (oi *OllamaIntegration) GetAllOperations() []*ModelOperation <span class="cov0" title="0">{
        oi.interceptor.operationsMutex.RLock()
        defer oi.interceptor.operationsMutex.RUnlock()
        
        operations := make([]*ModelOperation, 0, len(oi.interceptor.operations))
        for _, op := range oi.interceptor.operations </span><span class="cov0" title="0">{
                operations = append(operations, op)
        }</span>
        
        <span class="cov0" title="0">return operations</span>
}

// CreateFromModelfile creates a model from a Modelfile with distributed support
func (oi *OllamaIntegration) CreateFromModelfile(ctx context.Context, name model.Name, modelfile io.Reader, fn func(api.ProgressResponse)) error <span class="cov0" title="0">{
        oi.logger.Info("creating model from Modelfile with distributed support", "model", name.String())
        
        // Create operation record
        op := &amp;ModelOperation{
                ID:        fmt.Sprintf("create_%s_%d", name.String(), time.Now().UnixNano()),
                Type:      "create",
                ModelName: name.String(),
                Status:    "starting",
                StartTime: time.Now(),
                Metadata:  make(map[string]interface{}),
        }
        
        oi.interceptor.operationsMutex.Lock()
        oi.interceptor.operations[op.ID] = op
        oi.interceptor.operationsMutex.Unlock()
        
        // Execute pre-create hooks
        if err := oi.executeHooks("pre-create", name.String(), map[string]interface{}{
                "operation_id": op.ID,
                "model_name":   name.String(),
        }); err != nil </span><span class="cov0" title="0">{
                op.Status = "failed"
                op.Error = err.Error()
                op.EndTime = time.Now()
                return fmt.Errorf("pre-create hook failed: %w", err)
        }</span>
        
        // TODO: Implement actual model creation with distributed support
        // This would involve:
        // 1. Processing the Modelfile
        // 2. Creating the model locally
        // 3. Adding to distributed system
        // 4. Setting up replication
        
        // For now, simulate creation
        <span class="cov0" title="0">time.Sleep(1 * time.Second)
        
        op.Status = "completed"
        op.EndTime = time.Now()
        
        // Execute post-create hooks
        oi.executeHooks("post-create", name.String(), map[string]interface{}{
                "operation_id": op.ID,
                "model_name":   name.String(),
                "success":      true,
        })
        
        return nil</span>
}

// SetupDefaultHooks sets up default hooks for common operations
func (oi *OllamaIntegration) SetupDefaultHooks() <span class="cov0" title="0">{
        // Pre-pull hook to check distributed availability
        oi.AddModelHook("pre-pull", func(operation string, modelName string, data map[string]interface{}) error </span><span class="cov0" title="0">{
                oi.logger.Info("pre-pull hook: checking distributed availability", "model", modelName)
                return nil
        }</span>)
        
        // Post-pull hook to add to distributed system
        <span class="cov0" title="0">oi.AddModelHook("post-pull", func(operation string, modelName string, data map[string]interface{}) error </span><span class="cov0" title="0">{
                if success, ok := data["success"].(bool); ok &amp;&amp; success </span><span class="cov0" title="0">{
                        oi.logger.Info("post-pull hook: adding to distributed system", "model", modelName)
                        // Add to distributed system
                        if err := oi.addPulledModelToDistributedSystem(modelName); err != nil </span><span class="cov0" title="0">{
                                oi.logger.Error("failed to add pulled model to distributed system", "model", modelName, "error", err)
                        }</span>
                }
                <span class="cov0" title="0">return nil</span>
        })
        
        // Pre-delete hook to check replication requirements
        <span class="cov0" title="0">oi.AddModelHook("pre-delete", func(operation string, modelName string, data map[string]interface{}) error </span><span class="cov0" title="0">{
                oi.logger.Info("pre-delete hook: checking replication requirements", "model", modelName)
                
                // Check if this is the last replica
                if dm, err := oi.distributedManager.GetModel(modelName); err == nil </span><span class="cov0" title="0">{
                        if len(dm.Replicas) &lt;= 1 </span><span class="cov0" title="0">{
                                oi.logger.Warn("deleting last replica of model", "model", modelName)
                                // Could add confirmation logic here
                        }</span>
                }
                
                <span class="cov0" title="0">return nil</span>
        })
        
        // Post-delete hook to update distributed system
        <span class="cov0" title="0">oi.AddModelHook("post-delete", func(operation string, modelName string, data map[string]interface{}) error </span><span class="cov0" title="0">{
                if success, ok := data["success"].(bool); ok &amp;&amp; success </span><span class="cov0" title="0">{
                        oi.logger.Info("post-delete hook: updating distributed system", "model", modelName)
                        // Update distributed system
                        if err := oi.removeFromDistributedSystem(modelName); err != nil </span><span class="cov0" title="0">{
                                oi.logger.Error("failed to remove from distributed system", "model", modelName, "error", err)
                        }</span>
                }
                <span class="cov0" title="0">return nil</span>
        })
}</pre>
		
		<pre class="file" id="file30" style="display: none">package models

import (
        "context"
        "fmt"
        "log/slog"
        "sync"
        "time"

        "github.com/ollama/ollama-distributed/internal/config"
        "github.com/ollama/ollama-distributed/pkg/p2p"
)

// ReplicationManager manages model replication across peers
type ReplicationManager struct {
        config     *config.ReplicationConfig
        p2p        *p2p.Node
        manager    *Manager
        syncMgr    *SyncManager
        logger     *slog.Logger
        
        // Replication state
        replicas      map[string]*ReplicaInfo
        replicasMutex sync.RWMutex
        
        // Replication policies
        policies      map[string]*ReplicationPolicy
        policiesMutex sync.RWMutex
        
        // Replication workers
        workers     []*ReplicationWorker
        workQueue   chan *ReplicationTask
        
        // Health monitoring
        healthChecker *HealthChecker
        
        ctx     context.Context
        cancel  context.CancelFunc
        started bool
        mu      sync.RWMutex
}

// ReplicaInfo contains information about a model replica
type ReplicaInfo struct {
        ModelName    string            `json:"model_name"`
        PeerID       string            `json:"peer_id"`
        Status       ReplicaStatus     `json:"status"`
        LastSync     time.Time         `json:"last_sync"`
        SyncAttempts int               `json:"sync_attempts"`
        Health       ReplicaHealth     `json:"health"`
        Metadata     map[string]string `json:"metadata"`
        CreatedAt    time.Time         `json:"created_at"`
        UpdatedAt    time.Time         `json:"updated_at"`
}

// ReplicaStatus represents the status of a replica
type ReplicaStatus string

const (
        ReplicaStatusHealthy     ReplicaStatus = "healthy"
        ReplicaStatusSyncing     ReplicaStatus = "syncing"
        ReplicaStatusOutOfSync   ReplicaStatus = "out_of_sync"
        ReplicaStatusUnhealthy   ReplicaStatus = "unhealthy"
        ReplicaStatusUnreachable ReplicaStatus = "unreachable"
)

// ReplicaHealth represents the health status of a replica
type ReplicaHealth string

const (
        HealthGood    ReplicaHealth = "good"
        HealthWarning ReplicaHealth = "warning"
        HealthError   ReplicaHealth = "error"
)

// ReplicationPolicy defines how a model should be replicated
type ReplicationPolicy struct {
        ModelName         string            `json:"model_name"`
        MinReplicas       int               `json:"min_replicas"`
        MaxReplicas       int               `json:"max_replicas"`
        PreferredPeers    []string          `json:"preferred_peers"`
        ExcludedPeers     []string          `json:"excluded_peers"`
        ReplicationFactor int               `json:"replication_factor"`
        SyncInterval      time.Duration     `json:"sync_interval"`
        Priority          int               `json:"priority"`
        Constraints       map[string]string `json:"constraints"`
        CreatedAt         time.Time         `json:"created_at"`
        UpdatedAt         time.Time         `json:"updated_at"`
}

// ReplicationTask represents a replication task
type ReplicationTask struct {
        Type         TaskType    `json:"type"`
        ModelName    string      `json:"model_name"`
        SourcePeer   string      `json:"source_peer"`
        TargetPeer   string      `json:"target_peer"`
        Priority     int         `json:"priority"`
        Retries      int         `json:"retries"`
        MaxRetries   int         `json:"max_retries"`
        CreatedAt    time.Time   `json:"created_at"`
        ResponseChan chan error  `json:"-"`
}

// TaskType represents the type of replication task
type TaskType string

const (
        TaskTypeReplicate TaskType = "replicate"
        TaskTypeSync      TaskType = "sync"
        TaskTypeRemove    TaskType = "remove"
        TaskTypeVerify    TaskType = "verify"
)

// ReplicationWorker handles replication tasks
type ReplicationWorker struct {
        ID         int
        manager    *ReplicationManager
        stopChan   chan struct{}
}

// HealthChecker monitors replica health
type HealthChecker struct {
        manager       *ReplicationManager
        checkInterval time.Duration
        timeout       time.Duration
        stopChan      chan struct{}
}

// NewReplicationManager creates a new replication manager
func NewReplicationManager(
        config *config.ReplicationConfig,
        p2pNode *p2p.Node,
        manager *Manager,
        syncMgr *SyncManager,
        logger *slog.Logger,
) (*ReplicationManager, error) <span class="cov0" title="0">{
        ctx, cancel := context.WithCancel(context.Background())
        
        rm := &amp;ReplicationManager{
                config:    config,
                p2p:       p2pNode,
                manager:   manager,
                syncMgr:   syncMgr,
                logger:    logger,
                replicas:  make(map[string]*ReplicaInfo),
                policies:  make(map[string]*ReplicationPolicy),
                workQueue: make(chan *ReplicationTask, 100),
                ctx:       ctx,
                cancel:    cancel,
        }
        
        // Create workers
        rm.workers = make([]*ReplicationWorker, config.WorkerCount)
        for i := 0; i &lt; config.WorkerCount; i++ </span><span class="cov0" title="0">{
                rm.workers[i] = &amp;ReplicationWorker{
                        ID:       i,
                        manager:  rm,
                        stopChan: make(chan struct{}),
                }
        }</span>
        
        // Create health checker
        <span class="cov0" title="0">rm.healthChecker = &amp;HealthChecker{
                manager:       rm,
                checkInterval: config.HealthCheckInterval,
                timeout:       config.HealthCheckTimeout,
                stopChan:      make(chan struct{}),
        }
        
        return rm, nil</span>
}

// Start starts the replication manager
func (rm *ReplicationManager) Start() error <span class="cov0" title="0">{
        rm.mu.Lock()
        defer rm.mu.Unlock()
        
        if rm.started </span><span class="cov0" title="0">{
                return fmt.Errorf("replication manager already started")
        }</span>
        
        // Load existing policies
        <span class="cov0" title="0">if err := rm.loadPolicies(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to load policies: %w", err)
        }</span>
        
        // Start workers
        <span class="cov0" title="0">for _, worker := range rm.workers </span><span class="cov0" title="0">{
                go worker.start()
        }</span>
        
        // Start health checker
        <span class="cov0" title="0">go rm.healthChecker.start()
        
        // Start policy enforcement routine
        go rm.policyEnforcementRoutine()
        
        rm.started = true
        rm.logger.Info("replication manager started", "workers", len(rm.workers))
        
        return nil</span>
}

// SetReplicationPolicy sets a replication policy for a model
func (rm *ReplicationManager) SetReplicationPolicy(modelName string, policy *ReplicationPolicy) error <span class="cov0" title="0">{
        policy.ModelName = modelName
        policy.UpdatedAt = time.Now()
        if policy.CreatedAt.IsZero() </span><span class="cov0" title="0">{
                policy.CreatedAt = time.Now()
        }</span>
        
        <span class="cov0" title="0">rm.policiesMutex.Lock()
        rm.policies[modelName] = policy
        rm.policiesMutex.Unlock()
        
        // Trigger policy enforcement
        go rm.enforcePolicy(modelName)
        
        rm.logger.Info("replication policy set", "model", modelName, "min_replicas", policy.MinReplicas, "max_replicas", policy.MaxReplicas)
        
        return nil</span>
}

// GetReplicationPolicy gets the replication policy for a model
func (rm *ReplicationManager) GetReplicationPolicy(modelName string) (*ReplicationPolicy, bool) <span class="cov0" title="0">{
        rm.policiesMutex.RLock()
        defer rm.policiesMutex.RUnlock()
        
        policy, exists := rm.policies[modelName]
        return policy, exists
}</span>

// ReplicateModel replicates a model to a specific peer
func (rm *ReplicationManager) ReplicateModel(modelName, targetPeer string) error <span class="cov0" title="0">{
        task := &amp;ReplicationTask{
                Type:         TaskTypeReplicate,
                ModelName:    modelName,
                TargetPeer:   targetPeer,
                Priority:     1,
                MaxRetries:   3,
                CreatedAt:    time.Now(),
                ResponseChan: make(chan error, 1),
        }
        
        select </span>{
        case rm.workQueue &lt;- task:<span class="cov0" title="0"></span>
        case &lt;-time.After(5 * time.Second):<span class="cov0" title="0">
                return fmt.Errorf("replication queue full")</span>
        }
        
        <span class="cov0" title="0">select </span>{
        case err := &lt;-task.ResponseChan:<span class="cov0" title="0">
                return err</span>
        case &lt;-time.After(10 * time.Minute):<span class="cov0" title="0">
                return fmt.Errorf("replication timeout")</span>
        }
}

// GetReplicas returns all replicas for a model
func (rm *ReplicationManager) GetReplicas(modelName string) []*ReplicaInfo <span class="cov0" title="0">{
        rm.replicasMutex.RLock()
        defer rm.replicasMutex.RUnlock()
        
        var replicas []*ReplicaInfo
        for _, replica := range rm.replicas </span><span class="cov0" title="0">{
                if replica.ModelName == modelName </span><span class="cov0" title="0">{
                        replicas = append(replicas, replica)
                }</span>
        }
        
        <span class="cov0" title="0">return replicas</span>
}

// GetAllReplicas returns all replicas
func (rm *ReplicationManager) GetAllReplicas() []*ReplicaInfo <span class="cov0" title="0">{
        rm.replicasMutex.RLock()
        defer rm.replicasMutex.RUnlock()
        
        replicas := make([]*ReplicaInfo, 0, len(rm.replicas))
        for _, replica := range rm.replicas </span><span class="cov0" title="0">{
                replicas = append(replicas, replica)
        }</span>
        
        <span class="cov0" title="0">return replicas</span>
}

// enforcePolicy enforces the replication policy for a model
func (rm *ReplicationManager) enforcePolicy(modelName string) <span class="cov0" title="0">{
        policy, exists := rm.GetReplicationPolicy(modelName)
        if !exists </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">replicas := rm.GetReplicas(modelName)
        currentReplicas := len(replicas)
        
        rm.logger.Info("enforcing policy", "model", modelName, "current_replicas", currentReplicas, "min_replicas", policy.MinReplicas)
        
        if currentReplicas &lt; policy.MinReplicas </span><span class="cov0" title="0">{
                // Need to create more replicas
                needed := policy.MinReplicas - currentReplicas
                rm.logger.Info("need more replicas", "model", modelName, "needed", needed)
                
                // Find suitable peers
                peers := rm.findSuitablePeers(modelName, policy, needed)
                
                for _, peer := range peers </span><span class="cov0" title="0">{
                        task := &amp;ReplicationTask{
                                Type:         TaskTypeReplicate,
                                ModelName:    modelName,
                                TargetPeer:   peer,
                                Priority:     policy.Priority,
                                MaxRetries:   3,
                                CreatedAt:    time.Now(),
                                ResponseChan: make(chan error, 1),
                        }
                        
                        select </span>{
                        case rm.workQueue &lt;- task:<span class="cov0" title="0"></span>
                        default:<span class="cov0" title="0">
                                rm.logger.Error("replication queue full", "model", modelName, "peer", peer)</span>
                        }
                }
        } else<span class="cov0" title="0"> if currentReplicas &gt; policy.MaxReplicas </span><span class="cov0" title="0">{
                // Need to remove some replicas
                excess := currentReplicas - policy.MaxReplicas
                rm.logger.Info("need fewer replicas", "model", modelName, "excess", excess)
                
                // Find replicas to remove (prefer unhealthy ones)
                toRemove := rm.selectReplicasToRemove(modelName, excess)
                
                for _, replica := range toRemove </span><span class="cov0" title="0">{
                        task := &amp;ReplicationTask{
                                Type:         TaskTypeRemove,
                                ModelName:    modelName,
                                TargetPeer:   replica.PeerID,
                                Priority:     policy.Priority,
                                MaxRetries:   3,
                                CreatedAt:    time.Now(),
                                ResponseChan: make(chan error, 1),
                        }
                        
                        select </span>{
                        case rm.workQueue &lt;- task:<span class="cov0" title="0"></span>
                        default:<span class="cov0" title="0">
                                rm.logger.Error("replication queue full", "model", modelName, "peer", replica.PeerID)</span>
                        }
                }
        }
}

// findSuitablePeers finds suitable peers for replication
func (rm *ReplicationManager) findSuitablePeers(modelName string, policy *ReplicationPolicy, count int) []string <span class="cov0" title="0">{
        // Get all connected peers
        connectedPeerIDs := rm.p2p.GetConnectedPeers()
        var connectedPeers []string
        for _, peerID := range connectedPeerIDs </span><span class="cov0" title="0">{
                connectedPeers = append(connectedPeers, peerID.String())
        }</span>
        
        // Filter based on policy
        <span class="cov0" title="0">var suitable []string
        existing := make(map[string]bool)
        
        // Get existing replicas
        replicas := rm.GetReplicas(modelName)
        for _, replica := range replicas </span><span class="cov0" title="0">{
                existing[replica.PeerID] = true
        }</span>
        
        // Check preferred peers first
        <span class="cov0" title="0">for _, peer := range policy.PreferredPeers </span><span class="cov0" title="0">{
                if len(suitable) &gt;= count </span><span class="cov0" title="0">{
                        break</span>
                }
                
                <span class="cov0" title="0">if existing[peer] </span><span class="cov0" title="0">{
                        continue</span> // Already has replica
                }
                
                <span class="cov0" title="0">if rm.isPeerConnected(peer, connectedPeers) </span><span class="cov0" title="0">{
                        suitable = append(suitable, peer)
                }</span>
        }
        
        // Add other suitable peers if needed
        <span class="cov0" title="0">for _, peer := range connectedPeers </span><span class="cov0" title="0">{
                if len(suitable) &gt;= count </span><span class="cov0" title="0">{
                        break</span>
                }
                
                <span class="cov0" title="0">if existing[peer] </span><span class="cov0" title="0">{
                        continue</span> // Already has replica
                }
                
                <span class="cov0" title="0">if rm.isPeerExcluded(peer, policy.ExcludedPeers) </span><span class="cov0" title="0">{
                        continue</span> // Excluded
                }
                
                <span class="cov0" title="0">if rm.isPeerSuitable(peer, policy.Constraints) </span><span class="cov0" title="0">{
                        suitable = append(suitable, peer)
                }</span>
        }
        
        <span class="cov0" title="0">return suitable</span>
}

// selectReplicasToRemove selects replicas to remove
func (rm *ReplicationManager) selectReplicasToRemove(modelName string, count int) []*ReplicaInfo <span class="cov0" title="0">{
        replicas := rm.GetReplicas(modelName)
        
        // Sort by health and last sync time (prefer to remove unhealthy ones)
        // This is a simplified selection logic
        var toRemove []*ReplicaInfo
        
        for _, replica := range replicas </span><span class="cov0" title="0">{
                if len(toRemove) &gt;= count </span><span class="cov0" title="0">{
                        break</span>
                }
                
                <span class="cov0" title="0">if replica.Health == HealthError || replica.Status == ReplicaStatusUnhealthy </span><span class="cov0" title="0">{
                        toRemove = append(toRemove, replica)
                }</span>
        }
        
        // If still need more, remove based on last sync time
        <span class="cov0" title="0">if len(toRemove) &lt; count </span><span class="cov0" title="0">{
                for _, replica := range replicas </span><span class="cov0" title="0">{
                        if len(toRemove) &gt;= count </span><span class="cov0" title="0">{
                                break</span>
                        }
                        
                        <span class="cov0" title="0">alreadySelected := false
                        for _, selected := range toRemove </span><span class="cov0" title="0">{
                                if selected.PeerID == replica.PeerID </span><span class="cov0" title="0">{
                                        alreadySelected = true
                                        break</span>
                                }
                        }
                        
                        <span class="cov0" title="0">if !alreadySelected </span><span class="cov0" title="0">{
                                toRemove = append(toRemove, replica)
                        }</span>
                }
        }
        
        <span class="cov0" title="0">return toRemove</span>
}

// isPeerConnected checks if a peer is connected
func (rm *ReplicationManager) isPeerConnected(peer string, connectedPeers []string) bool <span class="cov0" title="0">{
        for _, connected := range connectedPeers </span><span class="cov0" title="0">{
                if connected == peer </span><span class="cov0" title="0">{
                        return true
                }</span>
        }
        <span class="cov0" title="0">return false</span>
}

// isPeerExcluded checks if a peer is excluded
func (rm *ReplicationManager) isPeerExcluded(peer string, excludedPeers []string) bool <span class="cov0" title="0">{
        for _, excluded := range excludedPeers </span><span class="cov0" title="0">{
                if excluded == peer </span><span class="cov0" title="0">{
                        return true
                }</span>
        }
        <span class="cov0" title="0">return false</span>
}

// isPeerSuitable checks if a peer meets the constraints
func (rm *ReplicationManager) isPeerSuitable(peer string, constraints map[string]string) bool <span class="cov0" title="0">{
        // TODO: Implement constraint checking
        // This would check things like:
        // - Available storage space
        // - Network bandwidth
        // - Geographic location
        // - Hardware capabilities
        return true
}</span>

// loadPolicies loads existing replication policies
func (rm *ReplicationManager) loadPolicies() error <span class="cov0" title="0">{
        // TODO: Load policies from persistent storage
        // For now, create default policies for existing models
        
        models := rm.manager.GetAllModels()
        for modelName := range models </span><span class="cov0" title="0">{
                if _, exists := rm.GetReplicationPolicy(modelName); !exists </span><span class="cov0" title="0">{
                        // Create default policy
                        policy := &amp;ReplicationPolicy{
                                ModelName:         modelName,
                                MinReplicas:       rm.config.DefaultMinReplicas,
                                MaxReplicas:       rm.config.DefaultMaxReplicas,
                                ReplicationFactor: rm.config.DefaultReplicationFactor,
                                SyncInterval:      rm.config.DefaultSyncInterval,
                                Priority:          1,
                                Constraints:       make(map[string]string),
                                CreatedAt:         time.Now(),
                                UpdatedAt:         time.Now(),
                        }
                        
                        rm.policiesMutex.Lock()
                        rm.policies[modelName] = policy
                        rm.policiesMutex.Unlock()
                }</span>
        }
        
        <span class="cov0" title="0">return nil</span>
}

// policyEnforcementRoutine runs periodic policy enforcement
func (rm *ReplicationManager) policyEnforcementRoutine() <span class="cov0" title="0">{
        ticker := time.NewTicker(rm.config.PolicyEnforcementInterval)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-rm.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        rm.enforceAllPolicies()</span>
                }
        }
}

// enforceAllPolicies enforces all replication policies
func (rm *ReplicationManager) enforceAllPolicies() <span class="cov0" title="0">{
        rm.policiesMutex.RLock()
        policies := make(map[string]*ReplicationPolicy)
        for k, v := range rm.policies </span><span class="cov0" title="0">{
                policies[k] = v
        }</span>
        <span class="cov0" title="0">rm.policiesMutex.RUnlock()
        
        for modelName := range policies </span><span class="cov0" title="0">{
                rm.enforcePolicy(modelName)
        }</span>
}

// Shutdown gracefully shuts down the replication manager
func (rm *ReplicationManager) Shutdown(ctx context.Context) error <span class="cov0" title="0">{
        rm.mu.Lock()
        defer rm.mu.Unlock()
        
        if !rm.started </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        // Stop workers
        <span class="cov0" title="0">for _, worker := range rm.workers </span><span class="cov0" title="0">{
                close(worker.stopChan)
        }</span>
        
        // Stop health checker
        <span class="cov0" title="0">close(rm.healthChecker.stopChan)
        
        rm.cancel()
        rm.started = false
        
        rm.logger.Info("replication manager shutdown complete")
        return nil</span>
}

// ReplicationWorker methods

// start starts the replication worker
func (w *ReplicationWorker) start() <span class="cov0" title="0">{
        w.manager.logger.Info("replication worker started", "worker_id", w.ID)
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-w.stopChan:<span class="cov0" title="0">
                        w.manager.logger.Info("replication worker stopped", "worker_id", w.ID)
                        return</span>
                case task := &lt;-w.manager.workQueue:<span class="cov0" title="0">
                        w.processTask(task)</span>
                }
        }
}

// processTask processes a replication task
func (w *ReplicationWorker) processTask(task *ReplicationTask) <span class="cov0" title="0">{
        w.manager.logger.Info("processing replication task", "worker_id", w.ID, "type", task.Type, "model", task.ModelName, "peer", task.TargetPeer)
        
        var err error
        
        switch task.Type </span>{
        case TaskTypeReplicate:<span class="cov0" title="0">
                err = w.processReplicate(task)</span>
        case TaskTypeSync:<span class="cov0" title="0">
                err = w.processSync(task)</span>
        case TaskTypeRemove:<span class="cov0" title="0">
                err = w.processRemove(task)</span>
        case TaskTypeVerify:<span class="cov0" title="0">
                err = w.processVerify(task)</span>
        default:<span class="cov0" title="0">
                err = fmt.Errorf("unknown task type: %s", task.Type)</span>
        }
        
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                w.manager.logger.Error("replication task failed", "worker_id", w.ID, "type", task.Type, "model", task.ModelName, "error", err)
                
                // Retry if possible
                if task.Retries &lt; task.MaxRetries </span><span class="cov0" title="0">{
                        task.Retries++
                        go func() </span><span class="cov0" title="0">{
                                time.Sleep(time.Duration(task.Retries) * time.Second)
                                select </span>{
                                case w.manager.workQueue &lt;- task:<span class="cov0" title="0"></span>
                                default:<span class="cov0" title="0">
                                        // Queue full, send error
                                        select </span>{
                                        case task.ResponseChan &lt;- fmt.Errorf("retry failed: queue full"):<span class="cov0" title="0"></span>
                                        default:<span class="cov0" title="0"></span>
                                        }
                                }
                        }()
                        <span class="cov0" title="0">return</span>
                }
        } else<span class="cov0" title="0"> {
                w.manager.logger.Info("replication task completed", "worker_id", w.ID, "type", task.Type, "model", task.ModelName)
        }</span>
        
        // Send response
        <span class="cov0" title="0">select </span>{
        case task.ResponseChan &lt;- err:<span class="cov0" title="0"></span>
        case &lt;-time.After(time.Second):<span class="cov0" title="0"></span>
                // Response channel blocked
        }
}

// processReplicate processes a replicate task
func (w *ReplicationWorker) processReplicate(task *ReplicationTask) error <span class="cov0" title="0">{
        // TODO: Implement actual replication logic
        // This would involve:
        // 1. Checking if model exists locally
        // 2. Initiating transfer to target peer
        // 3. Monitoring transfer progress
        // 4. Updating replica information
        
        time.Sleep(100 * time.Millisecond) // Simulate work
        
        // Create replica info
        replica := &amp;ReplicaInfo{
                ModelName:    task.ModelName,
                PeerID:       task.TargetPeer,
                Status:       ReplicaStatusHealthy,
                LastSync:     time.Now(),
                SyncAttempts: 1,
                Health:       HealthGood,
                Metadata:     make(map[string]string),
                CreatedAt:    time.Now(),
                UpdatedAt:    time.Now(),
        }
        
        // Store replica info
        replicaKey := fmt.Sprintf("%s:%s", task.ModelName, task.TargetPeer)
        w.manager.replicasMutex.Lock()
        w.manager.replicas[replicaKey] = replica
        w.manager.replicasMutex.Unlock()
        
        return nil
}</span>

// processSync processes a sync task
func (w *ReplicationWorker) processSync(task *ReplicationTask) error <span class="cov0" title="0">{
        // Use sync manager to synchronize the model
        return w.manager.syncMgr.SynchronizeModel(task.ModelName, task.TargetPeer, SyncTypeIncremental)
}</span>

// processRemove processes a remove task
func (w *ReplicationWorker) processRemove(task *ReplicationTask) error <span class="cov0" title="0">{
        // TODO: Implement replica removal logic
        // This would involve:
        // 1. Sending remove request to target peer
        // 2. Waiting for confirmation
        // 3. Updating replica information
        
        time.Sleep(50 * time.Millisecond) // Simulate work
        
        // Remove replica info
        replicaKey := fmt.Sprintf("%s:%s", task.ModelName, task.TargetPeer)
        w.manager.replicasMutex.Lock()
        delete(w.manager.replicas, replicaKey)
        w.manager.replicasMutex.Unlock()
        
        return nil
}</span>

// processVerify processes a verify task
func (w *ReplicationWorker) processVerify(task *ReplicationTask) error <span class="cov0" title="0">{
        // TODO: Implement replica verification logic
        // This would involve:
        // 1. Getting replica hash from target peer
        // 2. Comparing with local hash
        // 3. Updating replica health status
        
        time.Sleep(25 * time.Millisecond) // Simulate work
        return nil
}</span>

// HealthChecker methods

// start starts the health checker
func (hc *HealthChecker) start() <span class="cov0" title="0">{
        hc.manager.logger.Info("health checker started")
        
        ticker := time.NewTicker(hc.checkInterval)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-hc.stopChan:<span class="cov0" title="0">
                        hc.manager.logger.Info("health checker stopped")
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        hc.checkAllReplicas()</span>
                }
        }
}

// checkAllReplicas checks the health of all replicas
func (hc *HealthChecker) checkAllReplicas() <span class="cov0" title="0">{
        replicas := hc.manager.GetAllReplicas()
        
        for _, replica := range replicas </span><span class="cov0" title="0">{
                go hc.checkReplica(replica)
        }</span>
}

// checkReplica checks the health of a single replica
func (hc *HealthChecker) checkReplica(replica *ReplicaInfo) <span class="cov0" title="0">{
        // TODO: Implement actual health checking
        // This would involve:
        // 1. Pinging the peer
        // 2. Checking model availability
        // 3. Verifying model integrity
        // 4. Updating health status
        
        // For now, simulate health check
        healthy := true // Assume healthy for simulation
        
        hc.manager.replicasMutex.Lock()
        defer hc.manager.replicasMutex.Unlock()
        
        replicaKey := fmt.Sprintf("%s:%s", replica.ModelName, replica.PeerID)
        if storedReplica, exists := hc.manager.replicas[replicaKey]; exists </span><span class="cov0" title="0">{
                if healthy </span><span class="cov0" title="0">{
                        storedReplica.Health = HealthGood
                        storedReplica.Status = ReplicaStatusHealthy
                }</span> else<span class="cov0" title="0"> {
                        storedReplica.Health = HealthError
                        storedReplica.Status = ReplicaStatusUnhealthy
                }</span>
                <span class="cov0" title="0">storedReplica.UpdatedAt = time.Now()</span>
        }
}</pre>
		
		<pre class="file" id="file31" style="display: none">package models

import (
        "context"
        "crypto/sha256"
        "encoding/hex"
        "encoding/json"
        "fmt"
        "io"
        "log/slog"
        "os"
        "path/filepath"
        "sync"
        "time"

        "github.com/ollama/ollama-distributed/internal/config"
        "github.com/ollama/ollama-distributed/pkg/p2p"
)

// SyncManager manages model synchronization across the distributed network
type SyncManager struct {
        config      *config.SyncConfig
        p2p         *p2p.Node
        manager     *Manager
        logger      *slog.Logger
        
        // Sync state
        syncStates  map[string]*SyncState
        syncMutex   sync.RWMutex
        
        // Version tracking
        modelVersions map[string]*ModelVersion
        versionMutex  sync.RWMutex
        
        // Sync workers
        syncWorkers    []*SyncWorker
        syncQueue      chan *SyncRequest
        
        // Delta tracking
        deltaTracker   *DeltaTracker
        
        // Content-addressed storage
        casStore       *ContentAddressedStore
        
        ctx     context.Context
        cancel  context.CancelFunc
        started bool
        mu      sync.RWMutex
}

// SyncState represents the synchronization state of a model
type SyncState struct {
        ModelName      string                 `json:"model_name"`
        LocalVersion   string                 `json:"local_version"`
        RemoteVersions map[string]string      `json:"remote_versions"` // peerID -&gt; version
        Status         SyncStatus             `json:"status"`
        LastSyncTime   time.Time              `json:"last_sync_time"`
        PendingDeltas  []string               `json:"pending_deltas"`
        Conflicts      []SyncConflict         `json:"conflicts"`
        Metadata       map[string]interface{} `json:"metadata"`
}

// SyncStatus represents the status of model synchronization
type SyncStatus string

const (
        SyncStatusInSync     SyncStatus = "in_sync"
        SyncStatusOutOfSync  SyncStatus = "out_of_sync"
        SyncStatusSyncing    SyncStatus = "syncing"
        SyncStatusConflict   SyncStatus = "conflict"
        SyncStatusError      SyncStatus = "error"
)

// SyncConflict represents a synchronization conflict
type SyncConflict struct {
        Type        ConflictType `json:"type"`
        LocalHash   string       `json:"local_hash"`
        RemoteHash  string       `json:"remote_hash"`
        PeerID      string       `json:"peer_id"`
        Description string       `json:"description"`
        Timestamp   time.Time    `json:"timestamp"`
}

// ConflictType represents the type of synchronization conflict
type ConflictType string

const (
        ConflictTypeVersion    ConflictType = "version"
        ConflictTypeChecksum   ConflictType = "checksum"
        ConflictTypeTimestamp  ConflictType = "timestamp"
        ConflictTypeMetadata   ConflictType = "metadata"
)

// ModelVersion represents a versioned model with content addressing
type ModelVersion struct {
        Name        string            `json:"name"`
        Version     string            `json:"version"`
        Hash        string            `json:"hash"`        // Content-addressed hash
        ParentHash  string            `json:"parent_hash"` // Previous version hash
        Size        int64             `json:"size"`
        Chunks      []ChunkInfo       `json:"chunks"`
        Metadata    map[string]string `json:"metadata"`
        Timestamp   time.Time         `json:"timestamp"`
        Author      string            `json:"author"`      // Node ID that created this version
        Signature   string            `json:"signature"`   // Cryptographic signature
}

// ChunkInfo represents a chunk of a model file
type ChunkInfo struct {
        Hash   string `json:"hash"`
        Size   int64  `json:"size"`
        Offset int64  `json:"offset"`
}

// SyncRequest represents a request to synchronize a model
type SyncRequest struct {
        ModelName    string      `json:"model_name"`
        PeerID       string      `json:"peer_id"`
        SyncType     SyncType    `json:"sync_type"`
        Priority     int         `json:"priority"`
        ResponseChan chan error  `json:"-"`
}

// SyncType represents the type of synchronization
type SyncType string

const (
        SyncTypeFull        SyncType = "full"
        SyncTypeIncremental SyncType = "incremental"
        SyncTypeDelta       SyncType = "delta"
)

// SyncWorker handles synchronization operations
type SyncWorker struct {
        ID         int
        manager    *SyncManager
        stopChan   chan struct{}
}

// NewSyncManager creates a new model synchronization manager
func NewSyncManager(config *config.SyncConfig, p2pNode *p2p.Node, manager *Manager, logger *slog.Logger) (*SyncManager, error) <span class="cov0" title="0">{
        ctx, cancel := context.WithCancel(context.Background())
        
        sm := &amp;SyncManager{
                config:        config,
                p2p:           p2pNode,
                manager:       manager,
                logger:        logger,
                syncStates:    make(map[string]*SyncState),
                modelVersions: make(map[string]*ModelVersion),
                syncQueue:     make(chan *SyncRequest, 100),
                ctx:           ctx,
                cancel:        cancel,
        }
        
        // Initialize delta tracker
        deltaTracker, err := NewDeltaTracker(config.DeltaDir, logger)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create delta tracker: %w", err)
        }</span>
        <span class="cov0" title="0">sm.deltaTracker = deltaTracker
        
        // Initialize content-addressed store
        casStore, err := NewContentAddressedStore(config.CASDir, logger)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create CAS store: %w", err)
        }</span>
        <span class="cov0" title="0">sm.casStore = casStore
        
        // Create sync workers
        sm.syncWorkers = make([]*SyncWorker, config.WorkerCount)
        for i := 0; i &lt; config.WorkerCount; i++ </span><span class="cov0" title="0">{
                sm.syncWorkers[i] = &amp;SyncWorker{
                        ID:       i,
                        manager:  sm,
                        stopChan: make(chan struct{}),
                }
        }</span>
        
        <span class="cov0" title="0">return sm, nil</span>
}

// Start starts the synchronization manager
func (sm *SyncManager) Start() error <span class="cov0" title="0">{
        sm.mu.Lock()
        defer sm.mu.Unlock()
        
        if sm.started </span><span class="cov0" title="0">{
                return fmt.Errorf("sync manager already started")
        }</span>
        
        // Create necessary directories
        <span class="cov0" title="0">if err := os.MkdirAll(sm.config.DeltaDir, 0755); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create delta directory: %w", err)
        }</span>
        
        <span class="cov0" title="0">if err := os.MkdirAll(sm.config.CASDir, 0755); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create CAS directory: %w", err)
        }</span>
        
        // Load existing sync states
        <span class="cov0" title="0">if err := sm.loadSyncStates(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to load sync states: %w", err)
        }</span>
        
        // Start sync workers
        <span class="cov0" title="0">for _, worker := range sm.syncWorkers </span><span class="cov0" title="0">{
                go worker.start()
        }</span>
        
        // Start periodic sync routine
        <span class="cov0" title="0">go sm.periodicSyncRoutine()
        
        // Start version tracking routine
        go sm.versionTrackingRoutine()
        
        sm.started = true
        sm.logger.Info("sync manager started", "workers", len(sm.syncWorkers))
        
        return nil</span>
}

// SynchronizeModel synchronizes a model with a specific peer
func (sm *SyncManager) SynchronizeModel(modelName, peerID string, syncType SyncType) error <span class="cov0" title="0">{
        req := &amp;SyncRequest{
                ModelName:    modelName,
                PeerID:       peerID,
                SyncType:     syncType,
                Priority:     1,
                ResponseChan: make(chan error, 1),
        }
        
        select </span>{
        case sm.syncQueue &lt;- req:<span class="cov0" title="0"></span>
        case &lt;-time.After(5 * time.Second):<span class="cov0" title="0">
                return fmt.Errorf("sync queue full")</span>
        }
        
        <span class="cov0" title="0">select </span>{
        case err := &lt;-req.ResponseChan:<span class="cov0" title="0">
                return err</span>
        case &lt;-time.After(10 * time.Minute):<span class="cov0" title="0">
                return fmt.Errorf("sync timeout")</span>
        }
}

// GetSyncState returns the synchronization state of a model
func (sm *SyncManager) GetSyncState(modelName string) (*SyncState, bool) <span class="cov0" title="0">{
        sm.syncMutex.RLock()
        defer sm.syncMutex.RUnlock()
        
        state, exists := sm.syncStates[modelName]
        return state, exists
}</span>

// GetModelVersion returns the version information for a model
func (sm *SyncManager) GetModelVersion(modelName string) (*ModelVersion, bool) <span class="cov0" title="0">{
        sm.versionMutex.RLock()
        defer sm.versionMutex.RUnlock()
        
        version, exists := sm.modelVersions[modelName]
        return version, exists
}</span>

// CreateModelVersion creates a new version for a model
func (sm *SyncManager) CreateModelVersion(modelName, modelPath string) (*ModelVersion, error) <span class="cov0" title="0">{
        // Calculate content hash
        hash, err := sm.calculateModelHash(modelPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to calculate model hash: %w", err)
        }</span>
        
        // Get file info
        <span class="cov0" title="0">info, err := os.Stat(modelPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to stat model file: %w", err)
        }</span>
        
        // Create chunks
        <span class="cov0" title="0">chunks, err := sm.createChunks(modelPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create chunks: %w", err)
        }</span>
        
        // Get previous version if exists
        <span class="cov0" title="0">var parentHash string
        if prevVersion, exists := sm.GetModelVersion(modelName); exists </span><span class="cov0" title="0">{
                parentHash = prevVersion.Hash
        }</span>
        
        // Create version
        <span class="cov0" title="0">version := &amp;ModelVersion{
                Name:       modelName,
                Version:    sm.generateVersion(),
                Hash:       hash,
                ParentHash: parentHash,
                Size:       info.Size(),
                Chunks:     chunks,
                Metadata:   make(map[string]string),
                Timestamp:  time.Now(),
                Author:     sm.p2p.ID().String(),
        }
        
        // Store in content-addressed store
        if err := sm.casStore.Store(hash, modelPath); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to store in CAS: %w", err)
        }</span>
        
        // Update version tracking
        <span class="cov0" title="0">sm.versionMutex.Lock()
        sm.modelVersions[modelName] = version
        sm.versionMutex.Unlock()
        
        sm.logger.Info("created model version", "model", modelName, "version", version.Version, "hash", hash)
        
        return version, nil</span>
}

// loadSyncStates loads existing synchronization states
func (sm *SyncManager) loadSyncStates() error <span class="cov0" title="0">{
        stateFile := filepath.Join(sm.config.DeltaDir, "sync_states.json")
        
        if _, err := os.Stat(stateFile); os.IsNotExist(err) </span><span class="cov0" title="0">{
                return nil // No existing states
        }</span>
        
        <span class="cov0" title="0">data, err := os.ReadFile(stateFile)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to read sync states: %w", err)
        }</span>
        
        <span class="cov0" title="0">var states map[string]*SyncState
        if err := json.Unmarshal(data, &amp;states); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to unmarshal sync states: %w", err)
        }</span>
        
        <span class="cov0" title="0">sm.syncMutex.Lock()
        sm.syncStates = states
        sm.syncMutex.Unlock()
        
        return nil</span>
}

// saveSyncStates saves synchronization states to disk
func (sm *SyncManager) saveSyncStates() error <span class="cov0" title="0">{
        sm.syncMutex.RLock()
        defer sm.syncMutex.RUnlock()
        
        stateFile := filepath.Join(sm.config.DeltaDir, "sync_states.json")
        
        data, err := json.MarshalIndent(sm.syncStates, "", "  ")
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal sync states: %w", err)
        }</span>
        
        <span class="cov0" title="0">return os.WriteFile(stateFile, data, 0644)</span>
}

// calculateModelHash calculates the content hash of a model file
func (sm *SyncManager) calculateModelHash(modelPath string) (string, error) <span class="cov0" title="0">{
        file, err := os.Open(modelPath)
        if err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>
        <span class="cov0" title="0">defer file.Close()
        
        hash := sha256.New()
        if _, err := io.Copy(hash, file); err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>
        
        <span class="cov0" title="0">return hex.EncodeToString(hash.Sum(nil)), nil</span>
}

// createChunks creates chunks for a model file
func (sm *SyncManager) createChunks(modelPath string) ([]ChunkInfo, error) <span class="cov0" title="0">{
        file, err := os.Open(modelPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">defer file.Close()
        
        chunkSize := sm.config.ChunkSize
        if chunkSize == 0 </span><span class="cov0" title="0">{
                chunkSize = 1024 * 1024 // Default 1MB chunks
        }</span>
        
        <span class="cov0" title="0">var chunks []ChunkInfo
        buffer := make([]byte, chunkSize)
        offset := int64(0)
        
        for </span><span class="cov0" title="0">{
                n, err := file.Read(buffer)
                if err != nil &amp;&amp; err != io.EOF </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                
                <span class="cov0" title="0">if n == 0 </span><span class="cov0" title="0">{
                        break</span>
                }
                
                // Calculate chunk hash
                <span class="cov0" title="0">hash := sha256.Sum256(buffer[:n])
                
                chunks = append(chunks, ChunkInfo{
                        Hash:   hex.EncodeToString(hash[:]),
                        Size:   int64(n),
                        Offset: offset,
                })
                
                offset += int64(n)</span>
        }
        
        <span class="cov0" title="0">return chunks, nil</span>
}

// generateVersion generates a new version string
func (sm *SyncManager) generateVersion() string <span class="cov0" title="0">{
        return fmt.Sprintf("%d", time.Now().UnixNano())
}</span>

// periodicSyncRoutine runs periodic synchronization tasks
func (sm *SyncManager) periodicSyncRoutine() <span class="cov0" title="0">{
        ticker := time.NewTicker(sm.config.SyncInterval)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-sm.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        sm.performPeriodicSync()</span>
                }
        }
}

// performPeriodicSync performs periodic synchronization tasks
func (sm *SyncManager) performPeriodicSync() <span class="cov0" title="0">{
        // Save sync states
        if err := sm.saveSyncStates(); err != nil </span><span class="cov0" title="0">{
                sm.logger.Error("failed to save sync states", "error", err)
        }</span>
        
        // Check for models that need synchronization
        <span class="cov0" title="0">models := sm.manager.GetAllModels()
        for modelName := range models </span><span class="cov0" title="0">{
                state, exists := sm.GetSyncState(modelName)
                if !exists </span><span class="cov0" title="0">{
                        // Create initial sync state
                        state = &amp;SyncState{
                                ModelName:      modelName,
                                LocalVersion:   "1.0.0",
                                RemoteVersions: make(map[string]string),
                                Status:         SyncStatusInSync,
                                LastSyncTime:   time.Now(),
                                PendingDeltas:  []string{},
                                Conflicts:      []SyncConflict{},
                                Metadata:       make(map[string]interface{}),
                        }
                        
                        sm.syncMutex.Lock()
                        sm.syncStates[modelName] = state
                        sm.syncMutex.Unlock()
                }</span>
                
                // Check if sync is needed
                <span class="cov0" title="0">if time.Since(state.LastSyncTime) &gt; sm.config.SyncInterval </span><span class="cov0" title="0">{
                        // Queue for synchronization
                        go func(name string) </span><span class="cov0" title="0">{
                                sm.SynchronizeModel(name, "", SyncTypeIncremental)
                        }</span>(modelName)
                }
        }
}

// versionTrackingRoutine runs version tracking tasks
func (sm *SyncManager) versionTrackingRoutine() <span class="cov0" title="0">{
        ticker := time.NewTicker(time.Minute * 5)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-sm.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        sm.trackModelVersions()</span>
                }
        }
}

// trackModelVersions tracks changes in model versions
func (sm *SyncManager) trackModelVersions() <span class="cov0" title="0">{
        models := sm.manager.GetAllModels()
        
        for modelName, model := range models </span><span class="cov0" title="0">{
                // Check if version has changed
                currentVersion, exists := sm.GetModelVersion(modelName)
                if !exists </span><span class="cov0" title="0">{
                        // Create initial version
                        if _, err := sm.CreateModelVersion(modelName, model.Path); err != nil </span><span class="cov0" title="0">{
                                sm.logger.Error("failed to create initial version", "model", modelName, "error", err)
                        }</span>
                        <span class="cov0" title="0">continue</span>
                }
                
                // Calculate current hash
                <span class="cov0" title="0">currentHash, err := sm.calculateModelHash(model.Path)
                if err != nil </span><span class="cov0" title="0">{
                        sm.logger.Error("failed to calculate model hash", "model", modelName, "error", err)
                        continue</span>
                }
                
                // Check if model has changed
                <span class="cov0" title="0">if currentHash != currentVersion.Hash </span><span class="cov0" title="0">{
                        // Create new version
                        if _, err := sm.CreateModelVersion(modelName, model.Path); err != nil </span><span class="cov0" title="0">{
                                sm.logger.Error("failed to create new version", "model", modelName, "error", err)
                        }</span> else<span class="cov0" title="0"> {
                                sm.logger.Info("model version updated", "model", modelName, "old_hash", currentVersion.Hash, "new_hash", currentHash)
                        }</span>
                }
        }
}

// Shutdown gracefully shuts down the synchronization manager
func (sm *SyncManager) Shutdown(ctx context.Context) error <span class="cov0" title="0">{
        sm.mu.Lock()
        defer sm.mu.Unlock()
        
        if !sm.started </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        // Stop workers
        <span class="cov0" title="0">for _, worker := range sm.syncWorkers </span><span class="cov0" title="0">{
                close(worker.stopChan)
        }</span>
        
        // Save final state
        <span class="cov0" title="0">if err := sm.saveSyncStates(); err != nil </span><span class="cov0" title="0">{
                sm.logger.Error("failed to save final sync states", "error", err)
        }</span>
        
        // Close delta tracker
        <span class="cov0" title="0">if sm.deltaTracker != nil </span><span class="cov0" title="0">{
                sm.deltaTracker.Close()
        }</span>
        
        // Close CAS store
        <span class="cov0" title="0">if sm.casStore != nil </span><span class="cov0" title="0">{
                sm.casStore.Close()
        }</span>
        
        <span class="cov0" title="0">sm.cancel()
        sm.started = false
        
        sm.logger.Info("sync manager shutdown complete")
        return nil</span>
}

// SyncWorker methods

// start starts the sync worker
func (w *SyncWorker) start() <span class="cov0" title="0">{
        w.manager.logger.Info("sync worker started", "worker_id", w.ID)
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-w.stopChan:<span class="cov0" title="0">
                        w.manager.logger.Info("sync worker stopped", "worker_id", w.ID)
                        return</span>
                case req := &lt;-w.manager.syncQueue:<span class="cov0" title="0">
                        w.processSyncRequest(req)</span>
                }
        }
}

// processSyncRequest processes a synchronization request
func (w *SyncWorker) processSyncRequest(req *SyncRequest) <span class="cov0" title="0">{
        w.manager.logger.Info("processing sync request", "worker_id", w.ID, "model", req.ModelName, "peer", req.PeerID, "type", req.SyncType)
        
        var err error
        
        switch req.SyncType </span>{
        case SyncTypeFull:<span class="cov0" title="0">
                err = w.performFullSync(req)</span>
        case SyncTypeIncremental:<span class="cov0" title="0">
                err = w.performIncrementalSync(req)</span>
        case SyncTypeDelta:<span class="cov0" title="0">
                err = w.performDeltaSync(req)</span>
        default:<span class="cov0" title="0">
                err = fmt.Errorf("unknown sync type: %s", req.SyncType)</span>
        }
        
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                w.manager.logger.Error("sync request failed", "worker_id", w.ID, "model", req.ModelName, "error", err)
        }</span> else<span class="cov0" title="0"> {
                w.manager.logger.Info("sync request completed", "worker_id", w.ID, "model", req.ModelName)
        }</span>
        
        // Send response
        <span class="cov0" title="0">select </span>{
        case req.ResponseChan &lt;- err:<span class="cov0" title="0"></span>
        case &lt;-time.After(time.Second):<span class="cov0" title="0"></span>
                // Response channel blocked
        }
}

// performFullSync performs a full synchronization
func (w *SyncWorker) performFullSync(req *SyncRequest) error <span class="cov0" title="0">{
        // TODO: Implement full sync logic
        // This would involve:
        // 1. Getting the complete model from peer
        // 2. Verifying integrity
        // 3. Replacing local model
        // 4. Updating sync state
        
        time.Sleep(100 * time.Millisecond) // Simulate work
        
        // Update sync state
        w.manager.syncMutex.Lock()
        if state, exists := w.manager.syncStates[req.ModelName]; exists </span><span class="cov0" title="0">{
                state.Status = SyncStatusInSync
                state.LastSyncTime = time.Now()
                if req.PeerID != "" </span><span class="cov0" title="0">{
                        state.RemoteVersions[req.PeerID] = "1.0.0"
                }</span>
        }
        <span class="cov0" title="0">w.manager.syncMutex.Unlock()
        
        return nil</span>
}

// performIncrementalSync performs an incremental synchronization
func (w *SyncWorker) performIncrementalSync(req *SyncRequest) error <span class="cov0" title="0">{
        // TODO: Implement incremental sync logic
        // This would involve:
        // 1. Comparing model versions
        // 2. Identifying differences
        // 3. Downloading only changed parts
        // 4. Applying changes
        // 5. Updating sync state
        
        time.Sleep(50 * time.Millisecond) // Simulate work
        
        // Update sync state
        w.manager.syncMutex.Lock()
        if state, exists := w.manager.syncStates[req.ModelName]; exists </span><span class="cov0" title="0">{
                state.Status = SyncStatusInSync
                state.LastSyncTime = time.Now()
                if req.PeerID != "" </span><span class="cov0" title="0">{
                        state.RemoteVersions[req.PeerID] = "1.0.1"
                }</span>
        }
        <span class="cov0" title="0">w.manager.syncMutex.Unlock()
        
        return nil</span>
}

// performDeltaSync performs a delta synchronization
func (w *SyncWorker) performDeltaSync(req *SyncRequest) error <span class="cov0" title="0">{
        // TODO: Implement delta sync logic
        // This would involve:
        // 1. Getting delta information from peer
        // 2. Applying deltas to local model
        // 3. Verifying result integrity
        // 4. Updating sync state
        
        time.Sleep(25 * time.Millisecond) // Simulate work
        
        // Update sync state
        w.manager.syncMutex.Lock()
        if state, exists := w.manager.syncStates[req.ModelName]; exists </span><span class="cov0" title="0">{
                state.Status = SyncStatusInSync
                state.LastSyncTime = time.Now()
                if req.PeerID != "" </span><span class="cov0" title="0">{
                        state.RemoteVersions[req.PeerID] = "1.0.2"
                }</span>
        }
        <span class="cov0" title="0">w.manager.syncMutex.Unlock()
        
        return nil</span>
}</pre>
		
		<pre class="file" id="file32" style="display: none">package discovery

import (
        "context"
        "fmt"
        "log"
        "sync"
        "time"

        "github.com/libp2p/go-libp2p/core/discovery"
        "github.com/libp2p/go-libp2p/core/host"
        "github.com/libp2p/go-libp2p/core/network"
        "github.com/libp2p/go-libp2p/core/peer"
        "github.com/libp2p/go-libp2p/p2p/discovery/mdns"
        "github.com/libp2p/go-libp2p/p2p/discovery/routing"
        dht "github.com/libp2p/go-libp2p-kad-dht"
        "github.com/multiformats/go-multiaddr"
)

// DiscoveryConfig represents configuration needed by the discovery engine
type DiscoveryConfig interface {
        GetBootstrapPeers() []string
        GetRendezvousString() string
        IsAutoDiscoveryEnabled() bool
}

// DiscoveryEngine manages multi-strategy peer discovery
type DiscoveryEngine struct {
        host        host.Host
        config      DiscoveryConfig
        dht         *dht.IpfsDHT
        mdns        mdns.Service
        bootstrap   *BootstrapDiscovery
        rendezvous  *RendezvousDiscovery
        
        // Discovery strategies
        strategies  []DiscoveryStrategy
        
        // Peer cache
        peerCache   *PeerCache
        
        // Events
        peerFound   chan peer.AddrInfo
        peerLost    chan peer.ID
        
        // Lifecycle
        ctx         context.Context
        cancel      context.CancelFunc
        wg          sync.WaitGroup
        
        // Metrics
        metrics     *DiscoveryMetrics
}

// DiscoveryStrategy defines interface for discovery strategies
type DiscoveryStrategy interface {
        Name() string
        FindPeers(ctx context.Context, ns string, opts ...discovery.Option) (&lt;-chan peer.AddrInfo, error)
        Advertise(ctx context.Context, ns string, opts ...discovery.Option) (time.Duration, error)
}

// DiscoveryMetrics tracks discovery performance
type DiscoveryMetrics struct {
        PeersFound      int
        PeersLost       int
        ActivePeers     int
        DiscoveryErrors int
        LastDiscovery   time.Time
        StartTime       time.Time
        
        // Strategy metrics
        StrategyMetrics map[string]*StrategyMetrics
}

// StrategyMetrics tracks metrics for individual strategies
type StrategyMetrics struct {
        PeersFound      int
        Errors          int
        LastSuccess     time.Time
        AverageLatency  time.Duration
}

// PeerCache manages discovered peers
type PeerCache struct {
        peers    map[peer.ID]*CachedPeer
        peersMux sync.RWMutex
        
        // Cache settings
        maxSize    int
        ttl        time.Duration
        
        // Cleanup
        cleanupInterval time.Duration
}

// CachedPeer represents a cached peer
type CachedPeer struct {
        AddrInfo    peer.AddrInfo
        DiscoveredAt time.Time
        LastSeen    time.Time
        Source      string
        Quality     *PeerQuality
}

// PeerQuality represents peer quality metrics
type PeerQuality struct {
        Latency     time.Duration
        Reliability float64
        Bandwidth   int64
        LastTest    time.Time
}

// NewDiscoveryEngine creates a new discovery engine
func NewDiscoveryEngine(ctx context.Context, h host.Host, config DiscoveryConfig) (*DiscoveryEngine, error) <span class="cov0" title="0">{
        ctx, cancel := context.WithCancel(ctx)
        
        engine := &amp;DiscoveryEngine{
                host:       h,
                config:     config,
                peerFound:  make(chan peer.AddrInfo, 100),
                peerLost:   make(chan peer.ID, 100),
                ctx:        ctx,
                cancel:     cancel,
                metrics: &amp;DiscoveryMetrics{
                        StartTime:       time.Now(),
                        StrategyMetrics: make(map[string]*StrategyMetrics),
                },
        }
        
        // Initialize peer cache
        engine.peerCache = NewPeerCache(1000, 5*time.Minute)
        
        // Initialize discovery strategies
        if err := engine.initializeStrategies(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to initialize discovery strategies: %w", err)
        }</span>
        
        <span class="cov0" title="0">return engine, nil</span>
}

// initializeStrategies initializes all discovery strategies
func (d *DiscoveryEngine) initializeStrategies() error <span class="cov0" title="0">{
        // Initialize DHT if enabled
        if isDHTEnabled(d.config) </span><span class="cov0" title="0">{
                if err := d.initializeDHT(); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to initialize DHT: %w", err)
                }</span>
        }
        
        // Initialize mDNS
        <span class="cov0" title="0">if err := d.initializeMDNS(); err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to initialize mDNS: %v", err)
        }</span>
        
        // Initialize bootstrap discovery
        <span class="cov0" title="0">if err := d.initializeBootstrap(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to initialize bootstrap: %w", err)
        }</span>
        
        // Initialize rendezvous discovery
        <span class="cov0" title="0">if err := d.initializeRendezvous(); err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to initialize rendezvous: %v", err)
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// initializeDHT initializes DHT discovery
func (d *DiscoveryEngine) initializeDHT() error <span class="cov0" title="0">{
        // Configure DHT mode
        var mode dht.ModeOpt
        switch getDHTMode(d.config) </span>{
        case "client":<span class="cov0" title="0">
                mode = dht.ModeClient</span>
        case "server":<span class="cov0" title="0">
                mode = dht.ModeServer</span>
        default:<span class="cov0" title="0">
                mode = dht.ModeAuto</span>
        }
        
        // Create DHT
        <span class="cov0" title="0">kadDHT, err := dht.New(d.ctx, d.host, dht.Mode(mode))
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create DHT: %w", err)
        }</span>
        
        <span class="cov0" title="0">d.dht = kadDHT
        
        // Bootstrap DHT
        if err := d.bootstrapDHT(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to bootstrap DHT: %w", err)
        }</span>
        
        // Add DHT strategy
        <span class="cov0" title="0">dhtStrategy := &amp;DHTStrategy{
                dht:     kadDHT,
                routing: routing.NewRoutingDiscovery(kadDHT),
        }
        d.strategies = append(d.strategies, dhtStrategy)
        d.metrics.StrategyMetrics["dht"] = &amp;StrategyMetrics{}
        
        log.Printf("DHT initialized in %s mode", getDHTMode(d.config))
        return nil</span>
}

// bootstrapDHT bootstraps the DHT with configured peers
func (d *DiscoveryEngine) bootstrapDHT() error <span class="cov0" title="0">{
        bootstrapPeers, err := parseBootstrapPeers(d.config)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to parse bootstrap peers: %w", err)
        }</span>
        
        <span class="cov0" title="0">if len(bootstrapPeers) == 0 </span><span class="cov0" title="0">{
                log.Printf("No bootstrap peers configured")
                return nil
        }</span>
        
        // Connect to bootstrap peers
        <span class="cov0" title="0">for _, peerInfo := range bootstrapPeers </span><span class="cov0" title="0">{
                go func(p peer.AddrInfo) </span><span class="cov0" title="0">{
                        ctx, cancel := context.WithTimeout(d.ctx, 30*time.Second)
                        defer cancel()
                        
                        if err := d.host.Connect(ctx, p); err != nil </span><span class="cov0" title="0">{
                                log.Printf("Failed to connect to bootstrap peer %s: %v", p.ID, err)
                                return
                        }</span>
                        
                        <span class="cov0" title="0">log.Printf("Connected to bootstrap peer: %s", p.ID)</span>
                }(peerInfo)
        }
        
        // Bootstrap the DHT
        <span class="cov0" title="0">if err := d.dht.Bootstrap(d.ctx); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to bootstrap DHT: %w", err)
        }</span>
        
        <span class="cov0" title="0">log.Printf("DHT bootstrapped with %d peers", len(bootstrapPeers))
        return nil</span>
}

// initializeMDNS initializes mDNS discovery
func (d *DiscoveryEngine) initializeMDNS() error <span class="cov0" title="0">{
        notifee := &amp;mdnsNotifee{
                peerFound: d.peerFound,
        }
        
        mdnsService := mdns.NewMdnsService(d.host, "ollamacron", notifee)
        d.mdns = mdnsService
        
        // Add mDNS strategy
        mdnsStrategy := &amp;MDNSStrategy{
                service: mdnsService,
        }
        d.strategies = append(d.strategies, mdnsStrategy)
        d.metrics.StrategyMetrics["mdns"] = &amp;StrategyMetrics{}
        
        log.Printf("mDNS discovery initialized")
        return nil
}</span>

// initializeBootstrap initializes bootstrap discovery
func (d *DiscoveryEngine) initializeBootstrap() error <span class="cov0" title="0">{
        bootstrapPeers, err := parseBootstrapPeers(d.config)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to parse bootstrap peers: %w", err)
        }</span>
        
        <span class="cov0" title="0">d.bootstrap = NewBootstrapDiscovery(d.host, bootstrapPeers, 5, 20)
        
        // Add bootstrap strategy
        d.strategies = append(d.strategies, d.bootstrap)
        d.metrics.StrategyMetrics["bootstrap"] = &amp;StrategyMetrics{}
        
        log.Printf("Bootstrap discovery initialized with %d peers", len(bootstrapPeers))
        return nil</span>
}

// initializeRendezvous initializes rendezvous discovery
func (d *DiscoveryEngine) initializeRendezvous() error <span class="cov0" title="0">{
        if d.dht == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("rendezvous requires DHT")
        }</span>
        
        <span class="cov0" title="0">d.rendezvous = NewRendezvousDiscovery(d.host, d.dht)
        
        // Add rendezvous strategy
        d.strategies = append(d.strategies, d.rendezvous)
        d.metrics.StrategyMetrics["rendezvous"] = &amp;StrategyMetrics{}
        
        log.Printf("Rendezvous discovery initialized")
        return nil</span>
}

// Start starts the discovery engine
func (d *DiscoveryEngine) Start() <span class="cov0" title="0">{
        log.Printf("Starting discovery engine with %d strategies", len(d.strategies))
        
        // Start peer cache cleanup
        d.wg.Add(1)
        go d.peerCache.start(d.ctx, &amp;d.wg)
        
        // Start discovery strategies
        for _, strategy := range d.strategies </span><span class="cov0" title="0">{
                d.wg.Add(1)
                go d.runStrategy(strategy)
        }</span>
        
        // Start bootstrap discovery
        <span class="cov0" title="0">if d.bootstrap != nil </span><span class="cov0" title="0">{
                d.wg.Add(1)
                go d.bootstrap.Start(d.ctx, &amp;d.wg)
        }</span>
        
        // Start metrics collection
        <span class="cov0" title="0">d.wg.Add(1)
        go d.collectMetrics()
        
        // Start event processing
        d.wg.Add(1)
        go d.processEvents()
        
        log.Printf("Discovery engine started")</span>
}

// runStrategy runs a discovery strategy
func (d *DiscoveryEngine) runStrategy(strategy DiscoveryStrategy) <span class="cov0" title="0">{
        defer d.wg.Done()
        
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-d.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        d.runDiscovery(strategy)</span>
                }
        }
}

// runDiscovery runs discovery for a strategy
func (d *DiscoveryEngine) runDiscovery(strategy DiscoveryStrategy) <span class="cov0" title="0">{
        start := time.Now()
        
        // Advertise our presence
        if _, err := strategy.Advertise(d.ctx, "ollamacron"); err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to advertise on %s: %v", strategy.Name(), err)
                d.metrics.StrategyMetrics[strategy.Name()].Errors++
                return
        }</span>
        
        // Find peers
        <span class="cov0" title="0">peerChan, err := strategy.FindPeers(d.ctx, "ollamacron", discovery.Limit(50))
        if err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to find peers on %s: %v", strategy.Name(), err)
                d.metrics.StrategyMetrics[strategy.Name()].Errors++
                return
        }</span>
        
        // Process found peers
        <span class="cov0" title="0">peersFound := 0
        for peer := range peerChan </span><span class="cov0" title="0">{
                // Skip ourselves
                if peer.ID == d.host.ID() </span><span class="cov0" title="0">{
                        continue</span>
                }
                
                // Add to cache
                <span class="cov0" title="0">d.peerCache.Add(peer, strategy.Name())
                
                // Send to event channel
                select </span>{
                case d.peerFound &lt;- peer:<span class="cov0" title="0">
                        peersFound++</span>
                case &lt;-d.ctx.Done():<span class="cov0" title="0">
                        return</span>
                }
        }
        
        // Update metrics
        <span class="cov0" title="0">metrics := d.metrics.StrategyMetrics[strategy.Name()]
        metrics.PeersFound += peersFound
        metrics.LastSuccess = time.Now()
        metrics.AverageLatency = time.Since(start)
        
        if peersFound &gt; 0 </span><span class="cov0" title="0">{
                log.Printf("Found %d peers using %s strategy", peersFound, strategy.Name())
        }</span>
}

// processEvents processes discovery events
func (d *DiscoveryEngine) processEvents() <span class="cov0" title="0">{
        defer d.wg.Done()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-d.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case peer := &lt;-d.peerFound:<span class="cov0" title="0">
                        d.handlePeerFound(peer)</span>
                case peerID := &lt;-d.peerLost:<span class="cov0" title="0">
                        d.handlePeerLost(peerID)</span>
                }
        }
}

// handlePeerFound handles peer discovery events
func (d *DiscoveryEngine) handlePeerFound(peer peer.AddrInfo) <span class="cov0" title="0">{
        // Connect to peer if not already connected
        if d.host.Network().Connectedness(peer.ID) != network.Connected </span><span class="cov0" title="0">{
                go func() </span><span class="cov0" title="0">{
                        ctx, cancel := context.WithTimeout(d.ctx, 10*time.Second)
                        defer cancel()
                        
                        if err := d.host.Connect(ctx, peer); err != nil </span><span class="cov0" title="0">{
                                log.Printf("Failed to connect to discovered peer %s: %v", peer.ID, err)
                                return
                        }</span>
                        
                        <span class="cov0" title="0">log.Printf("Connected to discovered peer: %s", peer.ID)</span>
                }()
        }
        
        <span class="cov0" title="0">d.metrics.PeersFound++
        d.metrics.LastDiscovery = time.Now()</span>
}

// handlePeerLost handles peer loss events
func (d *DiscoveryEngine) handlePeerLost(peerID peer.ID) <span class="cov0" title="0">{
        d.peerCache.Remove(peerID)
        d.metrics.PeersLost++
        log.Printf("Peer lost: %s", peerID)
}</span>

// collectMetrics collects discovery metrics
func (d *DiscoveryEngine) collectMetrics() <span class="cov0" title="0">{
        defer d.wg.Done()
        
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-d.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        d.updateMetrics()</span>
                }
        }
}

// updateMetrics updates discovery metrics
func (d *DiscoveryEngine) updateMetrics() <span class="cov0" title="0">{
        d.metrics.ActivePeers = len(d.host.Network().Peers())
}</span>

// GetMetrics returns discovery metrics
func (d *DiscoveryEngine) GetMetrics() *DiscoveryMetrics <span class="cov0" title="0">{
        return d.metrics
}</span>

// GetDHT returns the DHT instance
func (d *DiscoveryEngine) GetDHT() *dht.IpfsDHT <span class="cov0" title="0">{
        return d.dht
}</span>

// Stop stops the discovery engine
func (d *DiscoveryEngine) Stop() <span class="cov0" title="0">{
        log.Printf("Stopping discovery engine")
        d.cancel()
        d.wg.Wait()
        
        if d.dht != nil </span><span class="cov0" title="0">{
                d.dht.Close()
        }</span>
        
        <span class="cov0" title="0">log.Printf("Discovery engine stopped")</span>
}

// mdnsNotifee handles mDNS notifications
type mdnsNotifee struct {
        peerFound chan peer.AddrInfo
}

func (n *mdnsNotifee) HandlePeerFound(peer peer.AddrInfo) <span class="cov0" title="0">{
        select </span>{
        case n.peerFound &lt;- peer:<span class="cov0" title="0"></span>
        default:<span class="cov0" title="0"></span>
                // Channel full, drop event
        }
}

// NewPeerCache creates a new peer cache
func NewPeerCache(maxSize int, ttl time.Duration) *PeerCache <span class="cov0" title="0">{
        return &amp;PeerCache{
                peers:           make(map[peer.ID]*CachedPeer),
                maxSize:         maxSize,
                ttl:             ttl,
                cleanupInterval: ttl / 2,
        }
}</span>

// Add adds a peer to the cache
func (c *PeerCache) Add(peer peer.AddrInfo, source string) <span class="cov0" title="0">{
        c.peersMux.Lock()
        defer c.peersMux.Unlock()
        
        now := time.Now()
        cachedPeer := &amp;CachedPeer{
                AddrInfo:     peer,
                DiscoveredAt: now,
                LastSeen:     now,
                Source:       source,
        }
        
        c.peers[peer.ID] = cachedPeer
        
        // Cleanup if cache is full
        if len(c.peers) &gt; c.maxSize </span><span class="cov0" title="0">{
                c.cleanup()
        }</span>
}

// Remove removes a peer from the cache
func (c *PeerCache) Remove(peerID peer.ID) <span class="cov0" title="0">{
        c.peersMux.Lock()
        defer c.peersMux.Unlock()
        
        delete(c.peers, peerID)
}</span>

// Get retrieves a peer from the cache
func (c *PeerCache) Get(peerID peer.ID) (*CachedPeer, bool) <span class="cov0" title="0">{
        c.peersMux.RLock()
        defer c.peersMux.RUnlock()
        
        peer, exists := c.peers[peerID]
        if !exists </span><span class="cov0" title="0">{
                return nil, false
        }</span>
        
        // Check if expired
        <span class="cov0" title="0">if time.Since(peer.LastSeen) &gt; c.ttl </span><span class="cov0" title="0">{
                return nil, false
        }</span>
        
        <span class="cov0" title="0">return peer, true</span>
}

// cleanup removes expired peers from cache
func (c *PeerCache) cleanup() <span class="cov0" title="0">{
        now := time.Now()
        
        for id, peer := range c.peers </span><span class="cov0" title="0">{
                if now.Sub(peer.LastSeen) &gt; c.ttl </span><span class="cov0" title="0">{
                        delete(c.peers, id)
                }</span>
        }
}

// start starts the peer cache cleanup routine
func (c *PeerCache) start(ctx context.Context, wg *sync.WaitGroup) <span class="cov0" title="0">{
        defer wg.Done()
        
        ticker := time.NewTicker(c.cleanupInterval)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        c.peersMux.Lock()
                        c.cleanup()
                        c.peersMux.Unlock()</span>
                }
        }
}

// Helper functions to work with DiscoveryConfig interface

// isDHTEnabled checks if DHT is enabled in the configuration
func isDHTEnabled(config DiscoveryConfig) bool <span class="cov0" title="0">{
        // Use reflection to check for EnableDHT field
        // For now, default to true since DHT is generally enabled
        return true
}</span>

// getDHTMode gets the DHT mode from the configuration
func getDHTMode(config DiscoveryConfig) string <span class="cov0" title="0">{
        // Use reflection to check for DHTMode field
        // For now, default to auto mode
        return "auto"
}</span>

// parseBootstrapPeers parses bootstrap peer addresses from the configuration
func parseBootstrapPeers(config DiscoveryConfig) ([]peer.AddrInfo, error) <span class="cov0" title="0">{
        bootstrapAddrs := config.GetBootstrapPeers()
        var peers []peer.AddrInfo
        
        for _, addr := range bootstrapAddrs </span><span class="cov0" title="0">{
                maddr, err := multiaddr.NewMultiaddr(addr)
                if err != nil </span><span class="cov0" title="0">{
                        log.Printf("Invalid bootstrap address %s: %v", addr, err)
                        continue</span>
                }
                
                <span class="cov0" title="0">peerInfo, err := peer.AddrInfoFromP2pAddr(maddr)
                if err != nil </span><span class="cov0" title="0">{
                        log.Printf("Failed to parse peer info from %s: %v", addr, err)
                        continue</span>
                }
                
                <span class="cov0" title="0">peers = append(peers, *peerInfo)</span>
        }
        
        <span class="cov0" title="0">return peers, nil</span>
}</pre>
		
		<pre class="file" id="file33" style="display: none">package discovery

import (
        "context"
        "fmt"
        "log"
        "sync"
        "time"

        "github.com/libp2p/go-libp2p/core/discovery"
        "github.com/libp2p/go-libp2p/core/host"
        "github.com/libp2p/go-libp2p/core/network"
        "github.com/libp2p/go-libp2p/core/peer"
        "github.com/libp2p/go-libp2p/p2p/discovery/mdns"
        "github.com/libp2p/go-libp2p/p2p/discovery/routing"
        dht "github.com/libp2p/go-libp2p-kad-dht"
)

// DHTStrategy implements DHT-based discovery
type DHTStrategy struct {
        dht     *dht.IpfsDHT
        routing *routing.RoutingDiscovery
}

// Name returns the strategy name
func (d *DHTStrategy) Name() string <span class="cov0" title="0">{
        return "dht"
}</span>

// FindPeers finds peers using DHT
func (d *DHTStrategy) FindPeers(ctx context.Context, ns string, opts ...discovery.Option) (&lt;-chan peer.AddrInfo, error) <span class="cov0" title="0">{
        return d.routing.FindPeers(ctx, ns, opts...)
}</span>

// Advertise advertises our presence in DHT
func (d *DHTStrategy) Advertise(ctx context.Context, ns string, opts ...discovery.Option) (time.Duration, error) <span class="cov0" title="0">{
        return d.routing.Advertise(ctx, ns, opts...)
}</span>

// MDNSStrategy implements mDNS-based discovery
type MDNSStrategy struct {
        service mdns.Service
}

// Name returns the strategy name
func (m *MDNSStrategy) Name() string <span class="cov0" title="0">{
        return "mdns"
}</span>

// FindPeers finds peers using mDNS
func (m *MDNSStrategy) FindPeers(ctx context.Context, ns string, opts ...discovery.Option) (&lt;-chan peer.AddrInfo, error) <span class="cov0" title="0">{
        // mDNS discovery is passive - peers are found via notifications
        peerChan := make(chan peer.AddrInfo)
        close(peerChan)
        return peerChan, nil
}</span>

// Advertise advertises our presence via mDNS
func (m *MDNSStrategy) Advertise(ctx context.Context, ns string, opts ...discovery.Option) (time.Duration, error) <span class="cov0" title="0">{
        // mDNS advertising is handled by the service itself
        return 5 * time.Minute, nil
}</span>

// BootstrapDiscovery implements bootstrap peer discovery
type BootstrapDiscovery struct {
        host            host.Host
        bootstrapPeers  []peer.AddrInfo
        minPeers        int
        maxPeers        int
        
        // Connection tracking
        connections     map[peer.ID]*ConnectionInfo
        connectionsMux  sync.RWMutex
}

// ConnectionInfo tracks connection information
type ConnectionInfo struct {
        ConnectedAt time.Time
        LastSeen    time.Time
        Attempts    int
        Failures    int
}

// NewBootstrapDiscovery creates a new bootstrap discovery strategy
func NewBootstrapDiscovery(host host.Host, bootstrapPeers []peer.AddrInfo, minPeers, maxPeers int) *BootstrapDiscovery <span class="cov0" title="0">{
        return &amp;BootstrapDiscovery{
                host:           host,
                bootstrapPeers: bootstrapPeers,
                minPeers:       minPeers,
                maxPeers:       maxPeers,
                connections:    make(map[peer.ID]*ConnectionInfo),
        }
}</span>

// Name returns the strategy name
func (b *BootstrapDiscovery) Name() string <span class="cov0" title="0">{
        return "bootstrap"
}</span>

// FindPeers finds peers from bootstrap list
func (b *BootstrapDiscovery) FindPeers(ctx context.Context, ns string, opts ...discovery.Option) (&lt;-chan peer.AddrInfo, error) <span class="cov0" title="0">{
        peerChan := make(chan peer.AddrInfo, len(b.bootstrapPeers))
        
        go func() </span><span class="cov0" title="0">{
                defer close(peerChan)
                
                for _, peer := range b.bootstrapPeers </span><span class="cov0" title="0">{
                        select </span>{
                        case peerChan &lt;- peer:<span class="cov0" title="0"></span>
                        case &lt;-ctx.Done():<span class="cov0" title="0">
                                return</span>
                        }
                }
        }()
        
        <span class="cov0" title="0">return peerChan, nil</span>
}

// Advertise advertises to bootstrap peers
func (b *BootstrapDiscovery) Advertise(ctx context.Context, ns string, opts ...discovery.Option) (time.Duration, error) <span class="cov0" title="0">{
        // Bootstrap peers don't need advertisement
        return 5 * time.Minute, nil
}</span>

// Start starts the bootstrap discovery process
func (b *BootstrapDiscovery) Start(ctx context.Context, wg *sync.WaitGroup) <span class="cov0" title="0">{
        defer wg.Done()
        
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        b.ensureConnections(ctx)</span>
                }
        }
}

// ensureConnections ensures minimum connection requirements
func (b *BootstrapDiscovery) ensureConnections(ctx context.Context) <span class="cov0" title="0">{
        connected := len(b.host.Network().Peers())
        
        if connected &lt; b.minPeers </span><span class="cov0" title="0">{
                // Connect to more bootstrap peers
                for _, peer := range b.bootstrapPeers </span><span class="cov0" title="0">{
                        if connected &gt;= b.maxPeers </span><span class="cov0" title="0">{
                                break</span>
                        }
                        
                        // Skip if already connected
                        <span class="cov0" title="0">if b.host.Network().Connectedness(peer.ID) == network.Connected </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        
                        // Skip if too many recent failures
                        <span class="cov0" title="0">b.connectionsMux.RLock()
                        connInfo, exists := b.connections[peer.ID]
                        b.connectionsMux.RUnlock()
                        
                        if exists &amp;&amp; connInfo.Failures &gt; 5 &amp;&amp; time.Since(connInfo.LastSeen) &lt; 5*time.Minute </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        
                        <span class="cov0" title="0">go b.connectToPeer(ctx, peer)
                        connected++</span>
                }
        }
}

// connectToPeer connects to a bootstrap peer
func (b *BootstrapDiscovery) connectToPeer(ctx context.Context, peer peer.AddrInfo) <span class="cov0" title="0">{
        b.connectionsMux.Lock()
        connInfo, exists := b.connections[peer.ID]
        if !exists </span><span class="cov0" title="0">{
                connInfo = &amp;ConnectionInfo{}
                b.connections[peer.ID] = connInfo
        }</span>
        <span class="cov0" title="0">connInfo.Attempts++
        b.connectionsMux.Unlock()
        
        connectCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
        defer cancel()
        
        if err := b.host.Connect(connectCtx, peer); err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to connect to bootstrap peer %s: %v", peer.ID, err)
                
                b.connectionsMux.Lock()
                connInfo.Failures++
                connInfo.LastSeen = time.Now()
                b.connectionsMux.Unlock()
                return
        }</span>
        
        <span class="cov0" title="0">log.Printf("Connected to bootstrap peer: %s", peer.ID)
        
        b.connectionsMux.Lock()
        connInfo.ConnectedAt = time.Now()
        connInfo.LastSeen = time.Now()
        b.connectionsMux.Unlock()</span>
}

// RendezvousDiscovery implements rendezvous-based discovery
type RendezvousDiscovery struct {
        host      host.Host
        dht       *dht.IpfsDHT
        routing   *routing.RoutingDiscovery
        
        // Rendezvous points
        rendezvous map[string]*RendezvousPoint
        rendMux    sync.RWMutex
}

// RendezvousPoint represents a rendezvous point
type RendezvousPoint struct {
        Namespace   string
        TTL         time.Duration
        LastUpdate  time.Time
        PeerCount   int
}

// NewRendezvousDiscovery creates a new rendezvous discovery strategy
func NewRendezvousDiscovery(host host.Host, dht *dht.IpfsDHT) *RendezvousDiscovery <span class="cov0" title="0">{
        return &amp;RendezvousDiscovery{
                host:       host,
                dht:        dht,
                routing:    routing.NewRoutingDiscovery(dht),
                rendezvous: make(map[string]*RendezvousPoint),
        }
}</span>

// Name returns the strategy name
func (r *RendezvousDiscovery) Name() string <span class="cov0" title="0">{
        return "rendezvous"
}</span>

// FindPeers finds peers at rendezvous points
func (r *RendezvousDiscovery) FindPeers(ctx context.Context, ns string, opts ...discovery.Option) (&lt;-chan peer.AddrInfo, error) <span class="cov0" title="0">{
        // Create rendezvous namespaces
        rendezvousPoints := []string{
                fmt.Sprintf("%s/general", ns),
                fmt.Sprintf("%s/models", ns),
                fmt.Sprintf("%s/compute", ns),
        }
        
        peerChan := make(chan peer.AddrInfo, 100)
        
        go func() </span><span class="cov0" title="0">{
                defer close(peerChan)
                
                for _, rdv := range rendezvousPoints </span><span class="cov0" title="0">{
                        peerStream, err := r.routing.FindPeers(ctx, rdv, opts...)
                        if err != nil </span><span class="cov0" title="0">{
                                log.Printf("Failed to find peers at rendezvous %s: %v", rdv, err)
                                continue</span>
                        }
                        
                        <span class="cov0" title="0">for peer := range peerStream </span><span class="cov0" title="0">{
                                select </span>{
                                case peerChan &lt;- peer:<span class="cov0" title="0"></span>
                                case &lt;-ctx.Done():<span class="cov0" title="0">
                                        return</span>
                                }
                        }
                }
        }()
        
        <span class="cov0" title="0">return peerChan, nil</span>
}

// Advertise advertises at rendezvous points
func (r *RendezvousDiscovery) Advertise(ctx context.Context, ns string, opts ...discovery.Option) (time.Duration, error) <span class="cov0" title="0">{
        // Advertise at multiple rendezvous points
        rendezvousPoints := []string{
                fmt.Sprintf("%s/general", ns),
                fmt.Sprintf("%s/models", ns),
                fmt.Sprintf("%s/compute", ns),
        }
        
        var minTTL time.Duration
        
        for _, rdv := range rendezvousPoints </span><span class="cov0" title="0">{
                ttl, err := r.routing.Advertise(ctx, rdv, opts...)
                if err != nil </span><span class="cov0" title="0">{
                        log.Printf("Failed to advertise at rendezvous %s: %v", rdv, err)
                        continue</span>
                }
                
                // Track rendezvous point
                <span class="cov0" title="0">r.rendMux.Lock()
                r.rendezvous[rdv] = &amp;RendezvousPoint{
                        Namespace:  rdv,
                        TTL:        ttl,
                        LastUpdate: time.Now(),
                }
                r.rendMux.Unlock()
                
                if minTTL == 0 || ttl &lt; minTTL </span><span class="cov0" title="0">{
                        minTTL = ttl
                }</span>
                
                <span class="cov0" title="0">log.Printf("Advertised at rendezvous point: %s (TTL: %v)", rdv, ttl)</span>
        }
        
        <span class="cov0" title="0">if minTTL == 0 </span><span class="cov0" title="0">{
                return 5 * time.Minute, nil
        }</span>
        
        <span class="cov0" title="0">return minTTL, nil</span>
}

// GetRendezvousPoints returns active rendezvous points
func (r *RendezvousDiscovery) GetRendezvousPoints() map[string]*RendezvousPoint <span class="cov0" title="0">{
        r.rendMux.RLock()
        defer r.rendMux.RUnlock()
        
        points := make(map[string]*RendezvousPoint)
        for k, v := range r.rendezvous </span><span class="cov0" title="0">{
                points[k] = v
        }</span>
        
        <span class="cov0" title="0">return points</span>
}

// CustomDiscovery implements custom discovery strategies
type CustomDiscovery struct {
        host     host.Host
        name     string
        finder   func(context.Context, string, ...discovery.Option) (&lt;-chan peer.AddrInfo, error)
        advertiser func(context.Context, string, ...discovery.Option) (time.Duration, error)
}

// NewCustomDiscovery creates a new custom discovery strategy
func NewCustomDiscovery(
        host host.Host,
        name string,
        finder func(context.Context, string, ...discovery.Option) (&lt;-chan peer.AddrInfo, error),
        advertiser func(context.Context, string, ...discovery.Option) (time.Duration, error),
) *CustomDiscovery <span class="cov0" title="0">{
        return &amp;CustomDiscovery{
                host:       host,
                name:       name,
                finder:     finder,
                advertiser: advertiser,
        }
}</span>

// Name returns the strategy name
func (c *CustomDiscovery) Name() string <span class="cov0" title="0">{
        return c.name
}</span>

// FindPeers finds peers using custom logic
func (c *CustomDiscovery) FindPeers(ctx context.Context, ns string, opts ...discovery.Option) (&lt;-chan peer.AddrInfo, error) <span class="cov0" title="0">{
        if c.finder == nil </span><span class="cov0" title="0">{
                peerChan := make(chan peer.AddrInfo)
                close(peerChan)
                return peerChan, nil
        }</span>
        
        <span class="cov0" title="0">return c.finder(ctx, ns, opts...)</span>
}

// Advertise advertises using custom logic
func (c *CustomDiscovery) Advertise(ctx context.Context, ns string, opts ...discovery.Option) (time.Duration, error) <span class="cov0" title="0">{
        if c.advertiser == nil </span><span class="cov0" title="0">{
                return 5 * time.Minute, nil
        }</span>
        
        <span class="cov0" title="0">return c.advertiser(ctx, ns, opts...)</span>
}

// HybridDiscovery combines multiple discovery strategies
type HybridDiscovery struct {
        strategies []DiscoveryStrategy
        weights    map[string]float64
        
        // Load balancing
        lastUsed   map[string]time.Time
        usageCount map[string]int
}

// NewHybridDiscovery creates a new hybrid discovery strategy
func NewHybridDiscovery(strategies []DiscoveryStrategy) *HybridDiscovery <span class="cov0" title="0">{
        weights := make(map[string]float64)
        lastUsed := make(map[string]time.Time)
        usageCount := make(map[string]int)
        
        // Initialize equal weights
        for _, strategy := range strategies </span><span class="cov0" title="0">{
                weights[strategy.Name()] = 1.0
                lastUsed[strategy.Name()] = time.Now()
                usageCount[strategy.Name()] = 0
        }</span>
        
        <span class="cov0" title="0">return &amp;HybridDiscovery{
                strategies: strategies,
                weights:    weights,
                lastUsed:   lastUsed,
                usageCount: usageCount,
        }</span>
}

// Name returns the strategy name
func (h *HybridDiscovery) Name() string <span class="cov0" title="0">{
        return "hybrid"
}</span>

// FindPeers finds peers using multiple strategies
func (h *HybridDiscovery) FindPeers(ctx context.Context, ns string, opts ...discovery.Option) (&lt;-chan peer.AddrInfo, error) <span class="cov0" title="0">{
        peerChan := make(chan peer.AddrInfo, 100)
        
        go func() </span><span class="cov0" title="0">{
                defer close(peerChan)
                
                var wg sync.WaitGroup
                
                // Run all strategies in parallel
                for _, strategy := range h.strategies </span><span class="cov0" title="0">{
                        wg.Add(1)
                        go func(s DiscoveryStrategy) </span><span class="cov0" title="0">{
                                defer wg.Done()
                                
                                strategyPeers, err := s.FindPeers(ctx, ns, opts...)
                                if err != nil </span><span class="cov0" title="0">{
                                        log.Printf("Strategy %s failed: %v", s.Name(), err)
                                        return
                                }</span>
                                
                                <span class="cov0" title="0">for peer := range strategyPeers </span><span class="cov0" title="0">{
                                        select </span>{
                                        case peerChan &lt;- peer:<span class="cov0" title="0">
                                                h.usageCount[s.Name()]++</span>
                                        case &lt;-ctx.Done():<span class="cov0" title="0">
                                                return</span>
                                        }
                                }
                        }(strategy)
                }
                
                <span class="cov0" title="0">wg.Wait()</span>
        }()
        
        <span class="cov0" title="0">return peerChan, nil</span>
}

// Advertise advertises using all strategies
func (h *HybridDiscovery) Advertise(ctx context.Context, ns string, opts ...discovery.Option) (time.Duration, error) <span class="cov0" title="0">{
        var minTTL time.Duration
        var lastErr error
        
        for _, strategy := range h.strategies </span><span class="cov0" title="0">{
                ttl, err := strategy.Advertise(ctx, ns, opts...)
                if err != nil </span><span class="cov0" title="0">{
                        lastErr = err
                        continue</span>
                }
                
                <span class="cov0" title="0">h.lastUsed[strategy.Name()] = time.Now()
                
                if minTTL == 0 || ttl &lt; minTTL </span><span class="cov0" title="0">{
                        minTTL = ttl
                }</span>
        }
        
        <span class="cov0" title="0">if minTTL == 0 </span><span class="cov0" title="0">{
                return 5 * time.Minute, lastErr
        }</span>
        
        <span class="cov0" title="0">return minTTL, nil</span>
}

// UpdateWeights updates strategy weights based on performance
func (h *HybridDiscovery) UpdateWeights(performance map[string]float64) <span class="cov0" title="0">{
        for strategy, weight := range performance </span><span class="cov0" title="0">{
                if _, exists := h.weights[strategy]; exists </span><span class="cov0" title="0">{
                        h.weights[strategy] = weight
                }</span>
        }
}

// GetWeights returns current strategy weights
func (h *HybridDiscovery) GetWeights() map[string]float64 <span class="cov0" title="0">{
        weights := make(map[string]float64)
        for k, v := range h.weights </span><span class="cov0" title="0">{
                weights[k] = v
        }</span>
        <span class="cov0" title="0">return weights</span>
}

// GetUsageStats returns usage statistics
func (h *HybridDiscovery) GetUsageStats() map[string]interface{} <span class="cov0" title="0">{
        stats := make(map[string]interface{})
        
        for strategy := range h.weights </span><span class="cov0" title="0">{
                stats[strategy] = map[string]interface{}{
                        "weight":     h.weights[strategy],
                        "last_used":  h.lastUsed[strategy],
                        "usage_count": h.usageCount[strategy],
                }
        }</span>
        
        <span class="cov0" title="0">return stats</span>
}</pre>
		
		<pre class="file" id="file34" style="display: none">package host

import (
        "context"
        "fmt"
        "log"
        "time"

        "github.com/libp2p/go-libp2p"
        "github.com/libp2p/go-libp2p/core/crypto"
        "github.com/libp2p/go-libp2p/core/host"
        "github.com/libp2p/go-libp2p/core/network"
        "github.com/libp2p/go-libp2p/core/peer"
        "github.com/libp2p/go-libp2p/core/protocol"
        "github.com/libp2p/go-libp2p/p2p/net/connmgr"
        "github.com/libp2p/go-libp2p/p2p/protocol/circuitv2/relay"
        "github.com/libp2p/go-libp2p/p2p/security/noise"
        libp2ptls "github.com/libp2p/go-libp2p/p2p/security/tls"
        "github.com/libp2p/go-libp2p/p2p/transport/tcp"
        "github.com/libp2p/go-libp2p/p2p/transport/websocket"
        libp2pwebtransport "github.com/libp2p/go-libp2p/p2p/transport/webtransport"
        "github.com/multiformats/go-multiaddr"
        
        "github.com/ollama/ollama-distributed/pkg/config"
)

// P2PHost wraps libp2p host with enhanced functionality
type P2PHost struct {
        host.Host
        config         *config.NodeConfig
        capabilities   *config.NodeCapabilities
        relayService   *relay.Relay
        
        // Protocol handlers
        protocols      map[protocol.ID]network.StreamHandler
        
        // Event handlers
        connectHandler    func(network.Network, network.Conn)
        disconnectHandler func(network.Network, network.Conn)
        
        // Metrics
        metrics        *HostMetrics
        
        // Lifecycle
        ctx            context.Context
        cancel         context.CancelFunc
}

// HostMetrics tracks host performance metrics
type HostMetrics struct {
        ConnectionCount    int
        StreamCount        int
        BytesReceived      int64
        BytesSent          int64
        ProtocolHandlers   int
        LastActivity       time.Time
        StartTime          time.Time
}

// NewP2PHost creates a new enhanced P2P host
func NewP2PHost(ctx context.Context, config *config.NodeConfig) (*P2PHost, error) <span class="cov0" title="0">{
        // Load or generate private key
        priv, err := loadOrGenerateKey(config)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to initialize key: %w", err)
        }</span>
        
        // Build listen addresses
        <span class="cov0" title="0">listenAddrs := make([]multiaddr.Multiaddr, 0, len(config.Listen))
        for _, addr := range config.Listen </span><span class="cov0" title="0">{
                maddr, err := multiaddr.NewMultiaddr(addr)
                if err != nil </span><span class="cov0" title="0">{
                        log.Printf("Invalid listen address %s: %v", addr, err)
                        continue</span>
                }
                <span class="cov0" title="0">listenAddrs = append(listenAddrs, maddr)</span>
        }
        
        // Configure transports
        <span class="cov0" title="0">transports := []libp2p.Option{
                libp2p.Transport(tcp.NewTCPTransport),
                libp2p.Transport(websocket.New),
                libp2p.Transport(libp2pwebtransport.New),
        }
        
        // Configure security
        security := []libp2p.Option{}
        if config.EnableNoise </span><span class="cov0" title="0">{
                security = append(security, libp2p.Security(noise.ID, noise.New))
        }</span>
        <span class="cov0" title="0">if config.EnableTLS </span><span class="cov0" title="0">{
                security = append(security, libp2p.Security(libp2ptls.ID, libp2ptls.New))
        }</span>
        
        // Configure NAT traversal
        <span class="cov0" title="0">natOptions := []libp2p.Option{}
        if config.EnableNATService </span><span class="cov0" title="0">{
                natOptions = append(natOptions, libp2p.EnableNATService())
        }</span>
        <span class="cov0" title="0">if config.EnableHolePunching </span><span class="cov0" title="0">{
                natOptions = append(natOptions, libp2p.EnableHolePunching())
        }</span>
        <span class="cov0" title="0">if config.EnableAutoRelay </span><span class="cov0" title="0">{
                staticRelays, err := config.ParseStaticRelays()
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to parse static relays: %w", err)
                }</span>
                <span class="cov0" title="0">natOptions = append(natOptions, libp2p.EnableAutoRelayWithStaticRelays(staticRelays))</span>
        }
        
        // Configure connection manager
        <span class="cov0" title="0">connMgr, err := connmgr.NewConnManager(
                config.ConnMgrLow,
                config.ConnMgrHigh,
                connmgr.WithGracePeriod(config.ConnMgrGrace),
        )
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create connection manager: %w", err)
        }</span>
        
        // Build host options
        <span class="cov0" title="0">opts := []libp2p.Option{
                libp2p.Identity(priv),
                libp2p.ListenAddrs(listenAddrs...),
                libp2p.ConnectionManager(connMgr),
                libp2p.EnableRelay(),
        }
        
        // Add transport options
        opts = append(opts, transports...)
        opts = append(opts, security...)
        opts = append(opts, natOptions...)
        
        // Add announce addresses
        if len(config.AnnounceAddresses) &gt; 0 </span><span class="cov0" title="0">{
                announceAddrs := make([]multiaddr.Multiaddr, 0, len(config.AnnounceAddresses))
                for _, addr := range config.AnnounceAddresses </span><span class="cov0" title="0">{
                        maddr, err := multiaddr.NewMultiaddr(addr)
                        if err != nil </span><span class="cov0" title="0">{
                                log.Printf("Invalid announce address %s: %v", addr, err)
                                continue</span>
                        }
                        <span class="cov0" title="0">announceAddrs = append(announceAddrs, maddr)</span>
                }
                <span class="cov0" title="0">opts = append(opts, libp2p.AddrsFactory(func([]multiaddr.Multiaddr) []multiaddr.Multiaddr </span><span class="cov0" title="0">{
                        return announceAddrs
                }</span>))
        }
        
        // Create host
        <span class="cov0" title="0">libp2pHost, err := libp2p.New(opts...)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create libp2p host: %w", err)
        }</span>
        
        // Create enhanced host wrapper
        <span class="cov0" title="0">ctx, cancel := context.WithCancel(ctx)
        p2pHost := &amp;P2PHost{
                Host:      libp2pHost,
                config:    config,
                protocols: make(map[protocol.ID]network.StreamHandler),
                metrics: &amp;HostMetrics{
                        StartTime: time.Now(),
                },
                ctx:    ctx,
                cancel: cancel,
        }
        
        // Setup network event handlers
        p2pHost.setupEventHandlers()
        
        // Start metrics collection
        go p2pHost.collectMetrics()
        
        log.Printf("P2P host created with ID: %s", libp2pHost.ID())
        log.Printf("Listen addresses: %v", libp2pHost.Addrs())
        
        return p2pHost, nil</span>
}

// setupEventHandlers configures network event handlers
func (h *P2PHost) setupEventHandlers() <span class="cov0" title="0">{
        net := h.Host.Network()
        
        // Connection events
        notifee := &amp;network.NotifyBundle{
                ConnectedF: func(net network.Network, conn network.Conn) </span><span class="cov0" title="0">{
                        h.metrics.ConnectionCount++
                        h.metrics.LastActivity = time.Now()
                        log.Printf("Connected to peer: %s", conn.RemotePeer())
                        
                        if h.connectHandler != nil </span><span class="cov0" title="0">{
                                h.connectHandler(net, conn)
                        }</span>
                },
                DisconnectedF: func(net network.Network, conn network.Conn) <span class="cov0" title="0">{
                        h.metrics.ConnectionCount--
                        h.metrics.LastActivity = time.Now()
                        log.Printf("Disconnected from peer: %s", conn.RemotePeer())
                        
                        if h.disconnectHandler != nil </span><span class="cov0" title="0">{
                                h.disconnectHandler(net, conn)
                        }</span>
                },
        }
        
        <span class="cov0" title="0">net.Notify(notifee)</span>
}

// collectMetrics periodically collects host metrics
func (h *P2PHost) collectMetrics() <span class="cov0" title="0">{
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-h.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        h.updateMetrics()</span>
                }
        }
}

// updateMetrics updates host metrics
func (h *P2PHost) updateMetrics() <span class="cov0" title="0">{
        network := h.Host.Network()
        
        // Update connection count
        h.metrics.ConnectionCount = len(network.Peers())
        
        // Update stream count
        streamCount := 0
        for _, peer := range network.Peers() </span><span class="cov0" title="0">{
                streams := network.ConnsToPeer(peer)
                for _, conn := range streams </span><span class="cov0" title="0">{
                        streamCount += len(conn.GetStreams())
                }</span>
        }
        <span class="cov0" title="0">h.metrics.StreamCount = streamCount
        
        // Update protocol handler count
        h.metrics.ProtocolHandlers = len(h.protocols)
        
        h.metrics.LastActivity = time.Now()</span>
}

// RegisterProtocol registers a protocol handler
func (h *P2PHost) RegisterProtocol(protocolID protocol.ID, handler network.StreamHandler) <span class="cov0" title="0">{
        h.Host.SetStreamHandler(protocolID, handler)
        h.protocols[protocolID] = handler
        log.Printf("Registered protocol: %s", protocolID)
}</span>

// UnregisterProtocol unregisters a protocol handler
func (h *P2PHost) UnregisterProtocol(protocolID protocol.ID) <span class="cov0" title="0">{
        h.Host.RemoveStreamHandler(protocolID)
        delete(h.protocols, protocolID)
        log.Printf("Unregistered protocol: %s", protocolID)
}</span>

// GetMetrics returns current host metrics
func (h *P2PHost) GetMetrics() *HostMetrics <span class="cov0" title="0">{
        return h.metrics
}</span>

// GetConfig returns host configuration
func (h *P2PHost) GetConfig() *config.NodeConfig <span class="cov0" title="0">{
        return h.config
}</span>

// SetCapabilities sets node capabilities
func (h *P2PHost) SetCapabilities(caps interface{}) <span class="cov0" title="0">{
        // Accept both config.NodeCapabilities and resources.NodeCapabilities
        switch v := caps.(type) </span>{
        case *config.NodeCapabilities:<span class="cov0" title="0">
                h.capabilities = v</span>
        default:<span class="cov0" title="0">
                // For resources.NodeCapabilities, we don't store them directly
                // as they're managed by the resource layer
                log.Printf("Setting capabilities of type %T", caps)</span>
        }
}

// GetCapabilities returns node capabilities
func (h *P2PHost) GetCapabilities() *config.NodeCapabilities <span class="cov0" title="0">{
        return h.capabilities
}</span>

// OnConnect sets connection event handler
func (h *P2PHost) OnConnect(handler func(network.Network, network.Conn)) <span class="cov0" title="0">{
        h.connectHandler = handler
}</span>

// OnDisconnect sets disconnection event handler
func (h *P2PHost) OnDisconnect(handler func(network.Network, network.Conn)) <span class="cov0" title="0">{
        h.disconnectHandler = handler
}</span>

// Close closes the host and releases resources
func (h *P2PHost) Close() error <span class="cov0" title="0">{
        h.cancel()
        return h.Host.Close()
}</span>

// loadOrGenerateKey loads existing key or generates new one
func loadOrGenerateKey(config *config.NodeConfig) (crypto.PrivKey, error) <span class="cov0" title="0">{
        // Try to load existing key
        if config.PrivateKey != "" </span><span class="cov0" title="0">{
                return config.GetPrivateKey()
        }</span>
        
        // Generate new key
        <span class="cov0" title="0">if err := config.GenerateKey(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to generate key: %w", err)
        }</span>
        
        <span class="cov0" title="0">return config.GetPrivateKey()</span>
}

// GetPeerCount returns number of connected peers
func (h *P2PHost) GetPeerCount() int <span class="cov0" title="0">{
        return len(h.Host.Network().Peers())
}</span>

// GetConnectedPeers returns list of connected peers
func (h *P2PHost) GetConnectedPeers() []peer.ID <span class="cov0" title="0">{
        return h.Host.Network().Peers()
}</span>

// IsConnected checks if peer is connected
func (h *P2PHost) IsConnected(peerID peer.ID) bool <span class="cov0" title="0">{
        return h.Host.Network().Connectedness(peerID) == network.Connected
}</span>

// GetProtocols returns registered protocols
func (h *P2PHost) GetProtocols() []protocol.ID <span class="cov0" title="0">{
        protocols := make([]protocol.ID, 0, len(h.protocols))
        for id := range h.protocols </span><span class="cov0" title="0">{
                protocols = append(protocols, id)
        }</span>
        <span class="cov0" title="0">return protocols</span>
}</pre>
		
		<pre class="file" id="file35" style="display: none">package p2p

import (
        "context"
        "fmt"
        "log"
        "os"
        "runtime"
        "strconv"
        "strings"
        "sync"
        "time"

        "github.com/libp2p/go-libp2p/core/host"
        "github.com/libp2p/go-libp2p/core/peer"
        "github.com/libp2p/go-libp2p/core/network"
        "github.com/multiformats/go-multiaddr"
        
        "github.com/ollama/ollama-distributed/pkg/config"
        internalconfig "github.com/ollama/ollama-distributed/internal/config"
        "github.com/ollama/ollama-distributed/pkg/p2p/discovery"
        p2phost "github.com/ollama/ollama-distributed/pkg/p2p/host"
        "github.com/ollama/ollama-distributed/pkg/p2p/resources"
        "github.com/ollama/ollama-distributed/pkg/p2p/routing"
        "github.com/ollama/ollama-distributed/pkg/p2p/security"
)

// Node is an alias for P2PNode for compatibility
type Node = P2PNode

// P2PNode represents a complete P2P node implementation
type P2PNode struct {
        // Core components
        host              *p2phost.P2PHost
        config            *config.NodeConfig
        
        // Network components
        discoveryEngine   *discovery.DiscoveryEngine
        securityManager   *security.SecurityManager
        resourceAdvertiser *resources.ResourceAdvertiser
        contentRouter     *routing.ContentRouter
        
        // Node state
        capabilities      *resources.NodeCapabilities
        resourceMetrics   *resources.ResourceMetrics
        
        // Event handlers
        eventHandlers     map[string][]EventHandler
        eventMux          sync.RWMutex
        
        // Metrics
        metrics           *NodeMetrics
        
        // Lifecycle
        ctx               context.Context
        cancel            context.CancelFunc
        wg                sync.WaitGroup
        started           bool
        startedMux        sync.RWMutex
}

// NodeMetrics tracks node performance metrics
type NodeMetrics struct {
        // Connection metrics
        ConnectedPeers    int
        TotalConnections  int
        ConnectionErrors  int
        
        // Discovery metrics
        PeersDiscovered   int
        DiscoveryErrors   int
        
        // Security metrics
        AuthAttempts      int
        AuthSuccesses     int
        AuthFailures      int
        
        // Resource metrics
        ResourcesAdvertised int
        ResourcesDiscovered int
        
        // Content metrics
        ContentPublished  int
        ContentRequests   int
        ContentProvided   int
        
        // Performance metrics
        AverageLatency    time.Duration
        MessageThroughput int64
        
        // Timestamps
        StartTime         time.Time
        LastActivity      time.Time
        Uptime            time.Duration
}

// EventHandler defines event handler interface
type EventHandler func(event *NodeEvent)

// NodeEvent represents a node event
type NodeEvent struct {
        Type      string
        Data      interface{}
        PeerID    peer.ID
        Timestamp time.Time
}

// PeerInfo represents information about a peer
type PeerInfo struct {
        ID        peer.ID
        Addresses []string
        Connected bool
        LastSeen  time.Time
}

// Event types
const (
        EventPeerConnected    = "peer_connected"
        EventPeerDisconnected = "peer_disconnected"
        EventPeerDiscovered   = "peer_discovered"
        EventResourceUpdated  = "resource_updated"
        EventContentPublished = "content_published"
        EventContentRequested = "content_requested"
        EventAuthSuccess      = "auth_success"
        EventAuthFailure      = "auth_failure"
        EventError            = "error"
)

// NewNode creates a new P2P node with internal P2PConfig
func NewNode(ctx context.Context, p2pConfig *internalconfig.P2PConfig) (*P2PNode, error) <span class="cov0" title="0">{
        // Create a proper pkg/config NodeConfig from the internal P2PConfig
        nodeConfig := config.DefaultConfig()
        
        // Copy P2P config fields if provided
        if p2pConfig != nil </span><span class="cov0" title="0">{
                nodeConfig.PrivateKey = p2pConfig.PrivateKey
                nodeConfig.Listen = []string{p2pConfig.Listen}
                nodeConfig.BootstrapPeers = p2pConfig.Bootstrap
                nodeConfig.EnableDHT = p2pConfig.EnableDHT
                nodeConfig.ConnMgrLow = p2pConfig.ConnMgrLow
                nodeConfig.ConnMgrHigh = p2pConfig.ConnMgrHigh
                if gracePeriod, err := time.ParseDuration(p2pConfig.ConnMgrGrace); err == nil </span><span class="cov0" title="0">{
                        nodeConfig.ConnMgrGrace = gracePeriod
                }</span> else<span class="cov0" title="0"> {
                        nodeConfig.ConnMgrGrace = time.Minute // Default fallback
                }</span>
        }
        
        <span class="cov0" title="0">return NewP2PNode(ctx, nodeConfig)</span>
}

// NewP2PNode creates a new P2P node
func NewP2PNode(ctx context.Context, nodeConfig *config.NodeConfig) (*P2PNode, error) <span class="cov0" title="0">{
        if nodeConfig == nil </span><span class="cov0" title="0">{
                nodeConfig = config.DefaultConfig()
        }</span>
        
        // Generate key if not provided
        <span class="cov0" title="0">if nodeConfig.PrivateKey == "" </span><span class="cov0" title="0">{
                if err := nodeConfig.GenerateKey(); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to generate node key: %w", err)
                }</span>
        }
        
        <span class="cov0" title="0">ctx, cancel := context.WithCancel(ctx)
        
        node := &amp;P2PNode{
                config:        nodeConfig,
                eventHandlers: make(map[string][]EventHandler),
                metrics: &amp;NodeMetrics{
                        StartTime: time.Now(),
                },
                ctx:    ctx,
                cancel: cancel,
        }
        
        // Initialize components
        if err := node.initializeComponents(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to initialize components: %w", err)
        }</span>
        
        // Setup event handlers
        <span class="cov0" title="0">node.setupEventHandlers()
        
        log.Printf("P2P node initialized with ID: %s", node.ID())
        return node, nil</span>
}

// initializeComponents initializes all node components
func (n *P2PNode) initializeComponents() error <span class="cov0" title="0">{
        var err error
        
        // Initialize libp2p host
        n.host, err = p2phost.NewP2PHost(n.ctx, n.config)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create host: %w", err)
        }</span>
        
        // Initialize discovery engine
        <span class="cov0" title="0">n.discoveryEngine, err = discovery.NewDiscoveryEngine(n.ctx, n.host, n.config)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create discovery engine: %w", err)
        }</span>
        
        // Initialize security manager
        <span class="cov0" title="0">securityConfig := security.DefaultSecurityConfig()
        n.securityManager, err = security.NewSecurityManager(n.ctx, n.host, securityConfig)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create security manager: %w", err)
        }</span>
        
        // Initialize resource advertiser
        // Note: We'll need to get the DHT from discovery engine
        <span class="cov0" title="0">dht := n.discoveryEngine.GetDHT()
        if dht != nil </span><span class="cov0" title="0">{
                advertiserConfig := resources.DefaultAdvertiserConfig()
                n.resourceAdvertiser, err = resources.NewResourceAdvertiser(n.ctx, n.host, dht, advertiserConfig)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to create resource advertiser: %w", err)
                }</span>
        }
        
        // Initialize content router
        <span class="cov0" title="0">if dht != nil </span><span class="cov0" title="0">{
                routerConfig := routing.DefaultContentRouterConfig()
                n.contentRouter, err = routing.NewContentRouter(n.ctx, n.host, dht, routerConfig)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to create content router: %w", err)
                }</span>
        }
        
        <span class="cov0" title="0">return nil</span>
}

// setupEventHandlers sets up internal event handlers
func (n *P2PNode) setupEventHandlers() <span class="cov0" title="0">{
        // Connection events
        n.host.OnConnect(func(net network.Network, conn network.Conn) </span><span class="cov0" title="0">{
                n.metrics.ConnectedPeers++
                n.metrics.TotalConnections++
                n.metrics.LastActivity = time.Now()
                
                n.emitEvent(EventPeerConnected, map[string]interface{}{
                        "peer_id": conn.RemotePeer(),
                        "addr":    conn.RemoteMultiaddr(),
                }, conn.RemotePeer())
        }</span>)
        
        <span class="cov0" title="0">n.host.OnDisconnect(func(net network.Network, conn network.Conn) </span><span class="cov0" title="0">{
                n.metrics.ConnectedPeers--
                n.metrics.LastActivity = time.Now()
                
                n.emitEvent(EventPeerDisconnected, map[string]interface{}{
                        "peer_id": conn.RemotePeer(),
                        "addr":    conn.RemoteMultiaddr(),
                }, conn.RemotePeer())
        }</span>)
}

// Start starts the P2P node
func (n *P2PNode) Start() error <span class="cov0" title="0">{
        n.startedMux.Lock()
        defer n.startedMux.Unlock()
        
        if n.started </span><span class="cov0" title="0">{
                return fmt.Errorf("node already started")
        }</span>
        
        <span class="cov0" title="0">log.Printf("Starting P2P node...")
        
        // Start discovery engine
        n.discoveryEngine.Start()
        
        // Start resource advertiser
        if n.resourceAdvertiser != nil </span><span class="cov0" title="0">{
                n.resourceAdvertiser.Start()
        }</span>
        
        // Start content router
        <span class="cov0" title="0">if n.contentRouter != nil </span><span class="cov0" title="0">{
                n.contentRouter.Start()
        }</span>
        
        // Start metrics collection
        <span class="cov0" title="0">n.wg.Add(1)
        go n.metricsTask()
        
        // Start resource monitoring
        n.wg.Add(1)
        go n.resourceMonitoringTask()
        
        n.started = true
        log.Printf("P2P node started successfully")
        log.Printf("Node ID: %s", n.host.ID())
        log.Printf("Listen addresses: %v", n.host.Addrs())
        
        return nil</span>
}

// Stop stops the P2P node
func (n *P2PNode) Stop() error <span class="cov0" title="0">{
        n.startedMux.Lock()
        defer n.startedMux.Unlock()
        
        if !n.started </span><span class="cov0" title="0">{
                return fmt.Errorf("node not started")
        }</span>
        
        <span class="cov0" title="0">log.Printf("Stopping P2P node...")
        
        // Cancel context
        n.cancel()
        
        // Wait for background tasks
        n.wg.Wait()
        
        // Stop components
        if n.discoveryEngine != nil </span><span class="cov0" title="0">{
                n.discoveryEngine.Stop()
        }</span>
        
        <span class="cov0" title="0">if n.resourceAdvertiser != nil </span><span class="cov0" title="0">{
                n.resourceAdvertiser.Stop()
        }</span>
        
        <span class="cov0" title="0">if n.contentRouter != nil </span><span class="cov0" title="0">{
                n.contentRouter.Stop()
        }</span>
        
        <span class="cov0" title="0">if n.securityManager != nil </span><span class="cov0" title="0">{
                n.securityManager.Close()
        }</span>
        
        // Close host
        <span class="cov0" title="0">if n.host != nil </span><span class="cov0" title="0">{
                n.host.Close()
        }</span>
        
        <span class="cov0" title="0">n.started = false
        log.Printf("P2P node stopped")
        
        return nil</span>
}

// ConnectToPeer connects to a specific peer
func (n *P2PNode) ConnectToPeer(ctx context.Context, peerInfo peer.AddrInfo) error <span class="cov0" title="0">{
        if err := n.host.Connect(ctx, peerInfo); err != nil </span><span class="cov0" title="0">{
                n.metrics.ConnectionErrors++
                return fmt.Errorf("failed to connect to peer: %w", err)
        }</span>
        
        <span class="cov0" title="0">log.Printf("Connected to peer: %s", peerInfo.ID)
        return nil</span>
}

// DisconnectFromPeer disconnects from a specific peer
func (n *P2PNode) DisconnectFromPeer(peerID peer.ID) error <span class="cov0" title="0">{
        if err := n.host.Network().ClosePeer(peerID); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to disconnect from peer: %w", err)
        }</span>
        
        <span class="cov0" title="0">log.Printf("Disconnected from peer: %s", peerID)
        return nil</span>
}

// GetConnectedPeers returns list of connected peers
func (n *P2PNode) GetConnectedPeers() []peer.ID <span class="cov0" title="0">{
        return n.host.GetConnectedPeers()
}</span>

// ConnectedPeers returns list of connected peers (compatibility method)
func (n *P2PNode) ConnectedPeers() []peer.ID <span class="cov0" title="0">{
        return n.GetConnectedPeers()
}</span>

// GetAllPeers returns comprehensive peer information
func (n *P2PNode) GetAllPeers() map[peer.ID]*PeerInfo <span class="cov0" title="0">{
        peers := make(map[peer.ID]*PeerInfo)
        connectedPeers := n.host.GetConnectedPeers()
        
        for _, peerID := range connectedPeers </span><span class="cov0" title="0">{
                // Get peer connection info
                conn := n.host.Network().ConnsToPeer(peerID)
                var addresses []string
                
                if len(conn) &gt; 0 </span><span class="cov0" title="0">{
                        addresses = append(addresses, conn[0].RemoteMultiaddr().String())
                }</span>
                
                <span class="cov0" title="0">peers[peerID] = &amp;PeerInfo{
                        ID:        peerID,
                        Addresses: addresses,
                        Connected: true,
                        LastSeen:  time.Now(),
                }</span>
        }
        
        <span class="cov0" title="0">return peers</span>
}

// GetPeerCount returns number of connected peers
func (n *P2PNode) GetPeerCount() int <span class="cov0" title="0">{
        return n.host.GetPeerCount()
}</span>

// IsConnected checks if peer is connected
func (n *P2PNode) IsConnected(peerID peer.ID) bool <span class="cov0" title="0">{
        return n.host.IsConnected(peerID)
}</span>

// SetCapabilities sets node capabilities
func (n *P2PNode) SetCapabilities(caps *resources.NodeCapabilities) <span class="cov0" title="0">{
        n.capabilities = caps
        n.host.SetCapabilities(caps)
        
        // Update advertiser
        if n.resourceAdvertiser != nil </span><span class="cov0" title="0">{
                n.resourceAdvertiser.SetCapabilities(caps)
        }</span>
        
        <span class="cov0" title="0">n.emitEvent(EventResourceUpdated, caps, "")</span>
}

// GetCapabilities returns node capabilities
func (n *P2PNode) GetCapabilities() *resources.NodeCapabilities <span class="cov0" title="0">{
        return n.capabilities
}</span>

// SetResourceMetrics sets resource metrics
func (n *P2PNode) SetResourceMetrics(metrics *resources.ResourceMetrics) <span class="cov0" title="0">{
        n.resourceMetrics = metrics
        
        // Update advertiser
        if n.resourceAdvertiser != nil </span><span class="cov0" title="0">{
                n.resourceAdvertiser.SetResourceMetrics(metrics)
        }</span>
        
        <span class="cov0" title="0">n.emitEvent(EventResourceUpdated, metrics, "")</span>
}

// GetResourceMetrics returns resource metrics
func (n *P2PNode) GetResourceMetrics() *resources.ResourceMetrics <span class="cov0" title="0">{
        return n.resourceMetrics
}</span>

// PublishContent publishes content to the network
func (n *P2PNode) PublishContent(ctx context.Context, content *routing.ContentMetadata) error <span class="cov0" title="0">{
        if n.contentRouter == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("content router not available")
        }</span>
        
        <span class="cov0" title="0">if err := n.contentRouter.PublishContent(ctx, content); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to publish content: %w", err)
        }</span>
        
        <span class="cov0" title="0">n.metrics.ContentPublished++
        n.emitEvent(EventContentPublished, content, "")
        
        return nil</span>
}

// RequestContent requests content from the network
func (n *P2PNode) RequestContent(ctx context.Context, contentID string, priority int) (*routing.ContentRequest, error) <span class="cov0" title="0">{
        if n.contentRouter == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("content router not available")
        }</span>
        
        <span class="cov0" title="0">request, err := n.contentRouter.RequestContent(ctx, contentID, priority)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to request content: %w", err)
        }</span>
        
        <span class="cov0" title="0">n.metrics.ContentRequests++
        n.emitEvent(EventContentRequested, request, "")
        
        return request, nil</span>
}

// FindContent finds content in the network
func (n *P2PNode) FindContent(ctx context.Context, contentID string) (*routing.ContentMetadata, []peer.ID, error) <span class="cov0" title="0">{
        if n.contentRouter == nil </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("content router not available")
        }</span>
        
        <span class="cov0" title="0">return n.contentRouter.FindContent(ctx, contentID)</span>
}

// EstablishSecureChannel establishes a secure channel with a peer
func (n *P2PNode) EstablishSecureChannel(ctx context.Context, peerID peer.ID) (*security.SecureChannel, error) <span class="cov0" title="0">{
        if n.securityManager == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("security manager not available")
        }</span>
        
        <span class="cov0" title="0">return n.securityManager.EstablishSecureChannel(ctx, peerID)</span>
}

// Event system

// On registers an event handler
func (n *P2PNode) On(eventType string, handler EventHandler) <span class="cov0" title="0">{
        n.eventMux.Lock()
        defer n.eventMux.Unlock()
        
        n.eventHandlers[eventType] = append(n.eventHandlers[eventType], handler)
}</span>

// Off removes an event handler
func (n *P2PNode) Off(eventType string, handler EventHandler) <span class="cov0" title="0">{
        n.eventMux.Lock()
        defer n.eventMux.Unlock()
        
        handlers := n.eventHandlers[eventType]
        for i, h := range handlers </span><span class="cov0" title="0">{
                // Note: In Go, we can't directly compare functions
                // This is a simplified implementation
                if &amp;h == &amp;handler </span><span class="cov0" title="0">{
                        n.eventHandlers[eventType] = append(handlers[:i], handlers[i+1:]...)
                        break</span>
                }
        }
}

// emitEvent emits an event
func (n *P2PNode) emitEvent(eventType string, data interface{}, peerID peer.ID) <span class="cov0" title="0">{
        n.eventMux.RLock()
        handlers := n.eventHandlers[eventType]
        n.eventMux.RUnlock()
        
        if len(handlers) == 0 </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">event := &amp;NodeEvent{
                Type:      eventType,
                Data:      data,
                PeerID:    peerID,
                Timestamp: time.Now(),
        }
        
        // Call handlers in separate goroutines
        for _, handler := range handlers </span><span class="cov0" title="0">{
                go handler(event)
        }</span>
}

// Background tasks

// metricsTask collects node metrics
func (n *P2PNode) metricsTask() <span class="cov0" title="0">{
        defer n.wg.Done()
        
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-n.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        n.updateMetrics()</span>
                }
        }
}

// resourceMonitoringTask monitors resource usage
func (n *P2PNode) resourceMonitoringTask() <span class="cov0" title="0">{
        defer n.wg.Done()
        
        ticker := time.NewTicker(10 * time.Second)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-n.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        n.updateResourceMetrics()</span>
                }
        }
}

// updateMetrics updates node metrics
func (n *P2PNode) updateMetrics() <span class="cov0" title="0">{
        // Update uptime
        n.metrics.Uptime = time.Since(n.metrics.StartTime)
        
        // Update peer count
        n.metrics.ConnectedPeers = n.host.GetPeerCount()
        
        // Update last activity
        n.metrics.LastActivity = time.Now()
        
        // Aggregate metrics from components
        if n.discoveryEngine != nil </span><span class="cov0" title="0">{
                discoveryMetrics := n.discoveryEngine.GetMetrics()
                n.metrics.PeersDiscovered = discoveryMetrics.PeersFound
                n.metrics.DiscoveryErrors = discoveryMetrics.DiscoveryErrors
        }</span>
        
        <span class="cov0" title="0">if n.securityManager != nil </span><span class="cov0" title="0">{
                securityMetrics := n.securityManager.GetMetrics()
                n.metrics.AuthAttempts = securityMetrics.AuthAttempts
                n.metrics.AuthSuccesses = securityMetrics.AuthAttempts - securityMetrics.AuthFailures
                n.metrics.AuthFailures = securityMetrics.AuthFailures
        }</span>
        
        <span class="cov0" title="0">if n.resourceAdvertiser != nil </span><span class="cov0" title="0">{
                advertiserMetrics := n.resourceAdvertiser.GetMetrics()
                n.metrics.ResourcesAdvertised = advertiserMetrics.AdvertisementsSent
                n.metrics.ResourcesDiscovered = advertiserMetrics.AdvertisementsReceived
        }</span>
        
        <span class="cov0" title="0">if n.contentRouter != nil </span><span class="cov0" title="0">{
                routerMetrics := n.contentRouter.GetMetrics()
                n.metrics.ContentPublished = routerMetrics.ContentPublished
                n.metrics.ContentRequests = routerMetrics.ContentRequests
                n.metrics.ContentProvided = routerMetrics.ContentProvided
        }</span>
}

// updateResourceMetrics updates resource metrics
func (n *P2PNode) updateResourceMetrics() <span class="cov0" title="0">{
        if n.resourceMetrics == nil </span><span class="cov0" title="0">{
                n.resourceMetrics = &amp;resources.ResourceMetrics{
                        Timestamp: time.Now(),
                }
        }</span>
        
        // Get system resource usage
        <span class="cov0" title="0">cpuUsage, err := n.getCPUUsage()
        if err != nil </span><span class="cov0" title="0">{
                cpuUsage = 0.0
        }</span>
        
        <span class="cov0" title="0">memoryUsage, _, err := n.getMemoryUsage()
        if err != nil </span><span class="cov0" title="0">{
                memoryUsage = 0.0
        }</span>
        
        <span class="cov0" title="0">diskUsage, _, err := n.getDiskUsage()
        if err != nil </span><span class="cov0" title="0">{
                diskUsage = 0.0
        }</span>
        
        <span class="cov0" title="0">networkBandwidth := n.getNetworkBandwidth()
        
        // Update metrics
        n.resourceMetrics.CPUUsage = cpuUsage
        n.resourceMetrics.MemoryUsage = int64(memoryUsage)
        n.resourceMetrics.DiskUsage = int64(diskUsage)
        n.resourceMetrics.NetworkRx = int64(networkBandwidth)
        n.resourceMetrics.NetworkTx = int64(networkBandwidth)
        n.resourceMetrics.Timestamp = time.Now()
        
        // Update advertiser
        if n.resourceAdvertiser != nil </span><span class="cov0" title="0">{
                n.resourceAdvertiser.SetResourceMetrics(n.resourceMetrics)
        }</span>
}

// Status and information

// GetStatus returns node status
func (n *P2PNode) GetStatus() *NodeStatus <span class="cov0" title="0">{
        n.startedMux.RLock()
        defer n.startedMux.RUnlock()
        
        return &amp;NodeStatus{
                ID:              n.host.ID(),
                Started:         n.started,
                Uptime:          n.metrics.Uptime,
                ConnectedPeers:  n.metrics.ConnectedPeers,
                ListenAddresses: n.host.Addrs(),
                Capabilities:    n.capabilities,
                ResourceMetrics: n.resourceMetrics,
                LastActivity:    n.metrics.LastActivity,
        }
}</span>

// GetMetrics returns node metrics
func (n *P2PNode) GetMetrics() *NodeMetrics <span class="cov0" title="0">{
        return n.metrics
}</span>

// GetConfig returns node configuration
func (n *P2PNode) GetConfig() *config.NodeConfig <span class="cov0" title="0">{
        return n.config
}</span>

// GetHost returns the underlying host
func (n *P2PNode) GetHost() host.Host <span class="cov0" title="0">{
        return n.host
}</span>

// ID returns the peer ID of the node
func (n *P2PNode) ID() peer.ID <span class="cov0" title="0">{
        return n.host.ID()
}</span>

// NodeStatus represents node status
type NodeStatus struct {
        ID              peer.ID
        Started         bool
        Uptime          time.Duration
        ConnectedPeers  int
        ListenAddresses []multiaddr.Multiaddr
        Capabilities    *resources.NodeCapabilities
        ResourceMetrics *resources.ResourceMetrics
        LastActivity    time.Time
}

// String returns string representation of node status
func (s *NodeStatus) String() string <span class="cov0" title="0">{
        return fmt.Sprintf("Node %s: Started=%t, Uptime=%v, Peers=%d, Addrs=%v",
                s.ID, s.Started, s.Uptime, s.ConnectedPeers, s.ListenAddresses)
}</span>

// System resource monitoring methods

// getCPUUsage returns current CPU usage percentage
func (n *P2PNode) getCPUUsage() (float64, error) <span class="cov0" title="0">{
        // Implementation depends on platform
        // This is a simplified cross-platform approach
        var usage float64
        
        // Try to read /proc/stat on Linux
        if data, err := os.ReadFile("/proc/stat"); err == nil </span><span class="cov0" title="0">{
                lines := strings.Split(string(data), "\n")
                if len(lines) &gt; 0 &amp;&amp; strings.HasPrefix(lines[0], "cpu ") </span><span class="cov0" title="0">{
                        fields := strings.Fields(lines[0])
                        if len(fields) &gt;= 8 </span><span class="cov0" title="0">{
                                user, _ := strconv.ParseFloat(fields[1], 64)
                                nice, _ := strconv.ParseFloat(fields[2], 64)
                                system, _ := strconv.ParseFloat(fields[3], 64)
                                idle, _ := strconv.ParseFloat(fields[4], 64)
                                
                                total := user + nice + system + idle
                                if total &gt; 0 </span><span class="cov0" title="0">{
                                        usage = ((total - idle) / total) * 100
                                }</span>
                        }
                }
        } else<span class="cov0" title="0"> {
                // Fallback: use runtime statistics
                var m runtime.MemStats
                runtime.ReadMemStats(&amp;m)
                // Approximate CPU usage based on GC activity
                usage = float64(m.NumGC % 100)
        }</span>
        
        <span class="cov0" title="0">return usage, nil</span>
}

// getMemoryUsage returns current memory usage and total memory
func (n *P2PNode) getMemoryUsage() (float64, int64, error) <span class="cov0" title="0">{
        var m runtime.MemStats
        runtime.ReadMemStats(&amp;m)
        
        // Get process memory usage
        processMemory := int64(m.Alloc)
        
        // Try to get system memory info
        var totalMemory int64
        var usage float64
        
        // Try to read /proc/meminfo on Linux
        if data, err := os.ReadFile("/proc/meminfo"); err == nil </span><span class="cov0" title="0">{
                lines := strings.Split(string(data), "\n")
                var memTotal, memAvailable int64
                
                for _, line := range lines </span><span class="cov0" title="0">{
                        if strings.HasPrefix(line, "MemTotal:") </span><span class="cov0" title="0">{
                                fields := strings.Fields(line)
                                if len(fields) &gt;= 2 </span><span class="cov0" title="0">{
                                        if val, err := strconv.ParseInt(fields[1], 10, 64); err == nil </span><span class="cov0" title="0">{
                                                memTotal = val * 1024 // Convert KB to bytes
                                        }</span>
                                }
                        } else<span class="cov0" title="0"> if strings.HasPrefix(line, "MemAvailable:") </span><span class="cov0" title="0">{
                                fields := strings.Fields(line)
                                if len(fields) &gt;= 2 </span><span class="cov0" title="0">{
                                        if val, err := strconv.ParseInt(fields[1], 10, 64); err == nil </span><span class="cov0" title="0">{
                                                memAvailable = val * 1024 // Convert KB to bytes
                                        }</span>
                                }
                        }
                }
                
                <span class="cov0" title="0">if memTotal &gt; 0 </span><span class="cov0" title="0">{
                        totalMemory = memTotal
                        if memAvailable &gt; 0 </span><span class="cov0" title="0">{
                                usage = float64(memTotal-memAvailable) / float64(memTotal) * 100
                        }</span>
                }
        }
        
        // Fallback to process memory
        <span class="cov0" title="0">if totalMemory == 0 </span><span class="cov0" title="0">{
                totalMemory = processMemory * 10 // Rough estimate
                usage = 10.0 // Rough estimate
        }</span>
        
        <span class="cov0" title="0">return usage, totalMemory, nil</span>
}

// getDiskUsage returns current disk usage and total disk space
func (n *P2PNode) getDiskUsage() (float64, int64, error) <span class="cov0" title="0">{
        // Get current working directory disk usage
        pwd, err := os.Getwd()
        if err != nil </span><span class="cov0" title="0">{
                return 0, 0, err
        }</span>
        
        // Try to get disk usage for the current directory
        // This is a cross-platform approach using file stat
        <span class="cov0" title="0">var totalSpace, usedSpace int64
        
        if info, err := os.Stat(pwd); err == nil </span><span class="cov0" title="0">{
                // This is a rough approximation
                // In a real implementation, you'd use platform-specific syscalls
                totalSpace = 1024 * 1024 * 1024 * 100 // Assume 100GB
                usedSpace = info.Size() * 1000         // Rough estimate
        }</span>
        
        <span class="cov0" title="0">usage := float64(usedSpace) / float64(totalSpace) * 100
        if usage &gt; 100 </span><span class="cov0" title="0">{
                usage = 100
        }</span>
        
        <span class="cov0" title="0">return usage, totalSpace, nil</span>
}

// getNetworkBandwidth returns current network bandwidth estimate
func (n *P2PNode) getNetworkBandwidth() int64 <span class="cov0" title="0">{
        // Simple bandwidth estimation based on peer connections
        peerCount := n.GetPeerCount()
        
        // Estimate bandwidth based on number of peers
        // This is a rough approximation
        baseBandwidth := int64(1024 * 1024) // 1 MB/s base
        peerBandwidth := int64(peerCount * 100 * 1024) // 100 KB/s per peer
        
        return baseBandwidth + peerBandwidth
}</pre>
		
		<pre class="file" id="file36" style="display: none">package resources

import (
        "context"
        "encoding/json"
        "fmt"
        "log"
        "sync"
        "time"

        "github.com/libp2p/go-libp2p/core/host"
        "github.com/libp2p/go-libp2p/core/peer"
        "github.com/libp2p/go-libp2p/core/protocol"
        "github.com/libp2p/go-libp2p/core/network"
        dht "github.com/libp2p/go-libp2p-kad-dht"
)

const (
        // Advertisement protocols
        ResourceAdvertisementProtocol = protocol.ID("/ollamacron/resource-advertisement/1.0.0")
        ResourceDiscoveryProtocol     = protocol.ID("/ollamacron/resource-discovery/1.0.0")
        
        // DHT keys
        ResourceKeyPrefix = "/ollamacron/resources/"
        ModelKeyPrefix    = "/ollamacron/models/"
        NodeKeyPrefix     = "/ollamacron/nodes/"
)

// ResourceAdvertiser manages resource advertisement and discovery
type ResourceAdvertiser struct {
        host           host.Host
        dht            *dht.IpfsDHT
        
        // Resource information
        capabilities   *NodeCapabilities
        resources      *ResourceMetrics
        
        // Advertisement management
        advertisements map[string]*Advertisement
        advMux         sync.RWMutex
        
        // Update channels
        capabilityUpdates chan *NodeCapabilities
        resourceUpdates   chan *ResourceMetrics
        
        // Subscriptions
        subscriptions     map[string]*ResourceSubscription
        subMux           sync.RWMutex
        
        // Discovery cache
        discoveryCache    *DiscoveryCache
        
        // Configuration
        config           *AdvertiserConfig
        
        // Metrics
        metrics          *AdvertiserMetrics
        
        // Lifecycle
        ctx              context.Context
        cancel           context.CancelFunc
        wg               sync.WaitGroup
}

// Advertisement represents a resource advertisement
type Advertisement struct {
        ID            string                `json:"id"`
        NodeID        peer.ID               `json:"node_id"`
        Capabilities  *NodeCapabilities `json:"capabilities"`
        Resources     *ResourceMetrics  `json:"resources"`
        Timestamp     time.Time             `json:"timestamp"`
        TTL           time.Duration         `json:"ttl"`
        Version       int                   `json:"version"`
        Signature     []byte                `json:"signature,omitempty"`
        
        // Advertisement metadata
        Priority      int                   `json:"priority"`
        Tags          map[string]string     `json:"tags"`
        Geo           *GeographicInfo       `json:"geo,omitempty"`
        Availability  *AvailabilityInfo     `json:"availability"`
}

// GeographicInfo contains geographic information
type GeographicInfo struct {
        Country     string  `json:"country"`
        Region      string  `json:"region"`
        City        string  `json:"city"`
        Latitude    float64 `json:"latitude"`
        Longitude   float64 `json:"longitude"`
        Timezone    string  `json:"timezone"`
}

// AvailabilityInfo contains availability information
type AvailabilityInfo struct {
        Online        bool              `json:"online"`
        LastSeen      time.Time         `json:"last_seen"`
        Uptime        time.Duration     `json:"uptime"`
        MaintenanceWindow *TimeWindow   `json:"maintenance_window,omitempty"`
        ServiceLevel  string            `json:"service_level"`
}

// TimeWindow represents a time window
type TimeWindow struct {
        Start time.Time `json:"start"`
        End   time.Time `json:"end"`
}

// ResourceSubscription represents a resource subscription
type ResourceSubscription struct {
        ID            string
        Query         *ResourceQuery
        Callback      func(*Advertisement)
        CreatedAt     time.Time
        LastMatched   time.Time
        MatchCount    int
}

// AdvertiserConfig holds advertiser configuration
type AdvertiserConfig struct {
        AdvertisementInterval time.Duration `json:"advertisement_interval"`
        TTL                   time.Duration `json:"ttl"`
        MaxAdvertisements     int           `json:"max_advertisements"`
        EnableSigning         bool          `json:"enable_signing"`
        EnableGeoLocation     bool          `json:"enable_geo_location"`
        Priority              int           `json:"priority"`
        Tags                  map[string]string `json:"tags"`
}

// AdvertiserMetrics tracks advertiser metrics
type AdvertiserMetrics struct {
        AdvertisementsSent     int
        AdvertisementsReceived int
        DiscoveryQueries       int
        SubscriptionMatches    int
        CacheHits              int
        CacheMisses            int
        LastAdvertisement      time.Time
        LastDiscovery          time.Time
        StartTime              time.Time
}

// NewResourceAdvertiser creates a new resource advertiser
func NewResourceAdvertiser(ctx context.Context, host host.Host, dht *dht.IpfsDHT, config *AdvertiserConfig) (*ResourceAdvertiser, error) <span class="cov0" title="0">{
        if config == nil </span><span class="cov0" title="0">{
                config = DefaultAdvertiserConfig()
        }</span>
        
        <span class="cov0" title="0">ctx, cancel := context.WithCancel(ctx)
        
        ra := &amp;ResourceAdvertiser{
                host:              host,
                dht:               dht,
                config:            config,
                advertisements:    make(map[string]*Advertisement),
                capabilityUpdates: make(chan *NodeCapabilities, 10),
                resourceUpdates:   make(chan *ResourceMetrics, 10),
                subscriptions:     make(map[string]*ResourceSubscription),
                metrics: &amp;AdvertiserMetrics{
                        StartTime: time.Now(),
                },
                ctx:    ctx,
                cancel: cancel,
        }
        
        // Initialize discovery cache
        ra.discoveryCache = NewDiscoveryCache(1000, 5*time.Minute)
        
        // Setup protocol handlers
        ra.setupProtocolHandlers()
        
        return ra, nil</span>
}

// setupProtocolHandlers sets up protocol handlers
func (ra *ResourceAdvertiser) setupProtocolHandlers() <span class="cov0" title="0">{
        ra.host.SetStreamHandler(ResourceAdvertisementProtocol, ra.handleResourceAdvertisement)
        ra.host.SetStreamHandler(ResourceDiscoveryProtocol, ra.handleResourceDiscovery)
}</span>

// Start starts the resource advertiser
func (ra *ResourceAdvertiser) Start() <span class="cov0" title="0">{
        log.Printf("Starting resource advertiser")
        
        // Start periodic advertisement
        ra.wg.Add(1)
        go ra.advertisementTask()
        
        // Start update processing
        ra.wg.Add(1)
        go ra.updateProcessor()
        
        // Start metrics collection
        ra.wg.Add(1)
        go ra.metricsTask()
        
        // Start cache cleanup
        ra.wg.Add(1)
        go ra.cacheCleanupTask()
        
        log.Printf("Resource advertiser started")
}</span>

// advertisementTask handles periodic advertisements
func (ra *ResourceAdvertiser) advertisementTask() <span class="cov0" title="0">{
        defer ra.wg.Done()
        
        // Initial advertisement
        ra.advertiseResources()
        
        ticker := time.NewTicker(ra.config.AdvertisementInterval)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ra.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        ra.advertiseResources()</span>
                }
        }
}

// updateProcessor processes capability and resource updates
func (ra *ResourceAdvertiser) updateProcessor() <span class="cov0" title="0">{
        defer ra.wg.Done()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ra.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case caps := &lt;-ra.capabilityUpdates:<span class="cov0" title="0">
                        ra.capabilities = caps
                        ra.advertiseResources()</span>
                case metrics := &lt;-ra.resourceUpdates:<span class="cov0" title="0">
                        ra.resources = metrics
                        ra.advertiseResources()</span>
                }
        }
}

// advertiseResources advertises current resources
func (ra *ResourceAdvertiser) advertiseResources() <span class="cov0" title="0">{
        if ra.capabilities == nil </span><span class="cov0" title="0">{
                return
        }</span>
        
        // Create advertisement
        <span class="cov0" title="0">ad := &amp;Advertisement{
                ID:           fmt.Sprintf("%s-%d", ra.host.ID(), time.Now().UnixNano()),
                NodeID:       ra.host.ID(),
                Capabilities: ra.capabilities,
                Resources:    ra.resources,
                Timestamp:    time.Now(),
                TTL:          ra.config.TTL,
                Version:      1,
                Priority:     ra.config.Priority,
                Tags:         ra.config.Tags,
                Availability: &amp;AvailabilityInfo{
                        Online:       true,
                        LastSeen:     time.Now(),
                        Uptime:       time.Since(ra.metrics.StartTime),
                        ServiceLevel: "standard",
                },
        }
        
        // Add geographic info if enabled
        if ra.config.EnableGeoLocation </span><span class="cov0" title="0">{
                ad.Geo = ra.getGeographicInfo()
        }</span>
        
        // Sign advertisement if enabled
        <span class="cov0" title="0">if ra.config.EnableSigning </span><span class="cov0" title="0">{
                signature, err := ra.signAdvertisement(ad)
                if err != nil </span><span class="cov0" title="0">{
                        log.Printf("Failed to sign advertisement: %v", err)
                }</span> else<span class="cov0" title="0"> {
                        ad.Signature = signature
                }</span>
        }
        
        // Store advertisement
        <span class="cov0" title="0">ra.advMux.Lock()
        ra.advertisements[ad.ID] = ad
        ra.advMux.Unlock()
        
        // Publish to DHT
        if err := ra.publishAdvertisement(ad); err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to publish advertisement: %v", err)
                return
        }</span>
        
        // Broadcast to interested peers
        <span class="cov0" title="0">ra.broadcastAdvertisement(ad)
        
        // Check subscriptions
        ra.checkSubscriptions(ad)
        
        ra.metrics.AdvertisementsSent++
        ra.metrics.LastAdvertisement = time.Now()
        
        log.Printf("Advertised resources: %d models, %d GPUs, %.2f CPU", 
                len(ra.capabilities.SupportedModels), 
                len(ra.capabilities.GPUs), 
                float64(ra.capabilities.CPUCores))</span>
}

// publishAdvertisement publishes advertisement to DHT
func (ra *ResourceAdvertiser) publishAdvertisement(ad *Advertisement) error <span class="cov0" title="0">{
        // Serialize advertisement
        data, err := json.Marshal(ad)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to serialize advertisement: %w", err)
        }</span>
        
        // Store in DHT with multiple keys for discoverability
        <span class="cov0" title="0">keys := []string{
                fmt.Sprintf("%s%s", ResourceKeyPrefix, ad.NodeID),
                fmt.Sprintf("%s%s", NodeKeyPrefix, ad.NodeID),
        }
        
        // Add model-specific keys
        for _, model := range ad.Capabilities.SupportedModels </span><span class="cov0" title="0">{
                keys = append(keys, fmt.Sprintf("%s%s", ModelKeyPrefix, model))
        }</span>
        
        // Store with all keys
        <span class="cov0" title="0">for _, key := range keys </span><span class="cov0" title="0">{
                if err := ra.dht.PutValue(ra.ctx, key, data); err != nil </span><span class="cov0" title="0">{
                        log.Printf("Failed to store advertisement with key %s: %v", key, err)
                        continue</span>
                }
        }
        
        <span class="cov0" title="0">return nil</span>
}

// broadcastAdvertisement broadcasts advertisement to connected peers
func (ra *ResourceAdvertiser) broadcastAdvertisement(ad *Advertisement) <span class="cov0" title="0">{
        // Get connected peers
        peers := ra.host.Network().Peers()
        
        // Broadcast to random subset to avoid flooding
        maxBroadcast := 10
        if len(peers) &gt; maxBroadcast </span><span class="cov0" title="0">{
                // Randomly select peers
                selected := make([]peer.ID, maxBroadcast)
                for i := 0; i &lt; maxBroadcast; i++ </span><span class="cov0" title="0">{
                        selected[i] = peers[i]
                }</span>
                <span class="cov0" title="0">peers = selected</span>
        }
        
        // Send to selected peers
        <span class="cov0" title="0">for _, peerID := range peers </span><span class="cov0" title="0">{
                go ra.sendAdvertisement(peerID, ad)
        }</span>
}

// sendAdvertisement sends advertisement to a specific peer
func (ra *ResourceAdvertiser) sendAdvertisement(peerID peer.ID, ad *Advertisement) <span class="cov0" title="0">{
        stream, err := ra.host.NewStream(ra.ctx, peerID, ResourceAdvertisementProtocol)
        if err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to create stream to peer %s: %v", peerID, err)
                return
        }</span>
        <span class="cov0" title="0">defer stream.Close()
        
        // Send advertisement
        data, err := json.Marshal(ad)
        if err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to serialize advertisement: %v", err)
                return
        }</span>
        
        <span class="cov0" title="0">if _, err := stream.Write(data); err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to send advertisement to peer %s: %v", peerID, err)
                return
        }</span>
}

// SetCapabilities updates node capabilities
func (ra *ResourceAdvertiser) SetCapabilities(caps *NodeCapabilities) <span class="cov0" title="0">{
        select </span>{
        case ra.capabilityUpdates &lt;- caps:<span class="cov0" title="0"></span>
        default:<span class="cov0" title="0">
                // Channel full, update directly
                ra.capabilities = caps
                go ra.advertiseResources()</span>
        }
}

// SetResourceMetrics updates resource metrics
func (ra *ResourceAdvertiser) SetResourceMetrics(metrics *ResourceMetrics) <span class="cov0" title="0">{
        select </span>{
        case ra.resourceUpdates &lt;- metrics:<span class="cov0" title="0"></span>
        default:<span class="cov0" title="0">
                // Channel full, update directly
                ra.resources = metrics
                go ra.advertiseResources()</span>
        }
}

// Subscribe creates a subscription for resource updates
func (ra *ResourceAdvertiser) Subscribe(query *ResourceQuery, callback func(*Advertisement)) string <span class="cov0" title="0">{
        ra.subMux.Lock()
        defer ra.subMux.Unlock()
        
        subscriptionID := fmt.Sprintf("sub-%d", time.Now().UnixNano())
        subscription := &amp;ResourceSubscription{
                ID:        subscriptionID,
                Query:     query,
                Callback:  callback,
                CreatedAt: time.Now(),
        }
        
        ra.subscriptions[subscriptionID] = subscription
        
        log.Printf("Created resource subscription: %s", subscriptionID)
        return subscriptionID
}</span>

// Unsubscribe removes a resource subscription
func (ra *ResourceAdvertiser) Unsubscribe(subscriptionID string) <span class="cov0" title="0">{
        ra.subMux.Lock()
        defer ra.subMux.Unlock()
        
        delete(ra.subscriptions, subscriptionID)
        log.Printf("Removed resource subscription: %s", subscriptionID)
}</span>

// checkSubscriptions checks if advertisement matches any subscriptions
func (ra *ResourceAdvertiser) checkSubscriptions(ad *Advertisement) <span class="cov0" title="0">{
        ra.subMux.RLock()
        defer ra.subMux.RUnlock()
        
        for _, sub := range ra.subscriptions </span><span class="cov0" title="0">{
                if ra.matchesQuery(ad, sub.Query) </span><span class="cov0" title="0">{
                        sub.LastMatched = time.Now()
                        sub.MatchCount++
                        ra.metrics.SubscriptionMatches++
                        
                        // Call callback
                        go sub.Callback(ad)
                }</span>
        }
}

// Protocol handlers

// handleResourceAdvertisement handles incoming resource advertisements
func (ra *ResourceAdvertiser) handleResourceAdvertisement(stream network.Stream) <span class="cov0" title="0">{
        defer stream.Close()
        
        // Read advertisement
        buf := make([]byte, 4096)
        n, err := stream.Read(buf)
        if err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to read advertisement: %v", err)
                return
        }</span>
        
        <span class="cov0" title="0">var ad Advertisement
        if err := json.Unmarshal(buf[:n], &amp;ad); err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to unmarshal advertisement: %v", err)
                return
        }</span>
        
        // Verify advertisement if signed
        <span class="cov0" title="0">if ad.Signature != nil </span><span class="cov0" title="0">{
                if err := ra.verifyAdvertisement(&amp;ad); err != nil </span><span class="cov0" title="0">{
                        log.Printf("Advertisement verification failed: %v", err)
                        return
                }</span>
        }
        
        // Store in cache
        <span class="cov0" title="0">ra.discoveryCache.Store(&amp;ad)
        
        // Check subscriptions
        ra.checkSubscriptions(&amp;ad)
        
        ra.metrics.AdvertisementsReceived++
        
        log.Printf("Received resource advertisement from: %s", ad.NodeID)</span>
}

// handleResourceDiscovery handles resource discovery requests
func (ra *ResourceAdvertiser) handleResourceDiscovery(stream network.Stream) <span class="cov0" title="0">{
        defer stream.Close()
        
        // Read query
        buf := make([]byte, 4096)
        n, err := stream.Read(buf)
        if err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to read discovery query: %v", err)
                return
        }</span>
        
        <span class="cov0" title="0">var query ResourceQuery
        if err := json.Unmarshal(buf[:n], &amp;query); err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to unmarshal discovery query: %v", err)
                return
        }</span>
        
        // Find matching resources
        <span class="cov0" title="0">results := ra.findMatchingResources(&amp;query)
        
        // Send results
        response := &amp;DiscoveryResponse{
                QueryID:   query.ID,
                Results:   results,
                Timestamp: time.Now(),
        }
        
        data, err := json.Marshal(response)
        if err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to serialize discovery response: %v", err)
                return
        }</span>
        
        <span class="cov0" title="0">if _, err := stream.Write(data); err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to send discovery response: %v", err)
                return
        }</span>
        
        <span class="cov0" title="0">ra.metrics.DiscoveryQueries++
        
        log.Printf("Processed discovery query: %s", query.ID)</span>
}

// findMatchingResources finds resources matching a query
func (ra *ResourceAdvertiser) findMatchingResources(query *ResourceQuery) []*Advertisement <span class="cov0" title="0">{
        var results []*Advertisement
        
        // Check cache first
        cached := ra.discoveryCache.Find(query)
        if len(cached) &gt; 0 </span><span class="cov0" title="0">{
                ra.metrics.CacheHits++
                return cached
        }</span>
        
        <span class="cov0" title="0">ra.metrics.CacheMisses++
        
        // Query DHT
        results = ra.queryDHT(query)
        
        // Store in cache
        for _, ad := range results </span><span class="cov0" title="0">{
                ra.discoveryCache.Store(ad)
        }</span>
        
        <span class="cov0" title="0">return results</span>
}

// queryDHT queries DHT for matching resources
func (ra *ResourceAdvertiser) queryDHT(query *ResourceQuery) []*Advertisement <span class="cov0" title="0">{
        var results []*Advertisement
        
        // Search by model types
        for _, modelType := range query.ModelTypes </span><span class="cov0" title="0">{
                key := fmt.Sprintf("%s%s", ModelKeyPrefix, modelType)
                
                val, err := ra.dht.GetValue(ra.ctx, key)
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }
                
                <span class="cov0" title="0">var ad Advertisement
                if err := json.Unmarshal(val, &amp;ad); err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }
                
                <span class="cov0" title="0">if ra.matchesQuery(&amp;ad, query) </span><span class="cov0" title="0">{
                        results = append(results, &amp;ad)
                }</span>
        }
        
        <span class="cov0" title="0">return results</span>
}

// matchesQuery checks if advertisement matches query
func (ra *ResourceAdvertiser) matchesQuery(ad *Advertisement, query *ResourceQuery) bool <span class="cov0" title="0">{
        // Check model types
        if len(query.ModelTypes) &gt; 0 </span><span class="cov0" title="0">{
                hasModel := false
                for _, modelType := range query.ModelTypes </span><span class="cov0" title="0">{
                        for _, supportedModel := range ad.Capabilities.SupportedModels </span><span class="cov0" title="0">{
                                if supportedModel == modelType </span><span class="cov0" title="0">{
                                        hasModel = true
                                        break</span>
                                }
                        }
                        <span class="cov0" title="0">if hasModel </span><span class="cov0" title="0">{
                                break</span>
                        }
                }
                <span class="cov0" title="0">if !hasModel </span><span class="cov0" title="0">{
                        return false
                }</span>
        }
        
        // Check CPU requirements
        <span class="cov0" title="0">if query.MinCPU &gt; 0 &amp;&amp; ad.Capabilities.CPUCores &lt; query.MinCPU </span><span class="cov0" title="0">{
                return false
        }</span>
        
        // Check memory requirements
        <span class="cov0" title="0">if query.MinMemory &gt; 0 &amp;&amp; ad.Capabilities.Memory &lt; query.MinMemory </span><span class="cov0" title="0">{
                return false
        }</span>
        
        // Check GPU requirements
        <span class="cov0" title="0">if query.RequiredGPU &amp;&amp; len(ad.Capabilities.GPUs) == 0 </span><span class="cov0" title="0">{
                return false
        }</span>
        
        // Check latency requirements
        <span class="cov0" title="0">if query.MaxLatency &gt; 0 &amp;&amp; ad.Capabilities.Latency &gt; query.MaxLatency </span><span class="cov0" title="0">{
                return false
        }</span>
        
        // Check price requirements
        <span class="cov0" title="0">if query.MaxPrice &gt; 0 &amp;&amp; ad.Capabilities.PricePerToken &gt; query.MaxPrice </span><span class="cov0" title="0">{
                return false
        }</span>
        
        <span class="cov0" title="0">return true</span>
}

// Utility methods

// getGeographicInfo returns geographic information
func (ra *ResourceAdvertiser) getGeographicInfo() *GeographicInfo <span class="cov0" title="0">{
        // TODO: Implement geographic info detection
        return &amp;GeographicInfo{
                Country:  "Unknown",
                Region:   "Unknown",
                City:     "Unknown",
                Timezone: "UTC",
        }
}</span>

// signAdvertisement signs an advertisement
func (ra *ResourceAdvertiser) signAdvertisement(ad *Advertisement) ([]byte, error) <span class="cov0" title="0">{
        // Create signature payload
        payload := fmt.Sprintf("%s:%s:%d", ad.NodeID, ad.ID, ad.Timestamp.Unix())
        
        // Sign with host's private key
        privKey := ra.host.Peerstore().PrivKey(ra.host.ID())
        return privKey.Sign([]byte(payload))
}</span>

// verifyAdvertisement verifies an advertisement signature
func (ra *ResourceAdvertiser) verifyAdvertisement(ad *Advertisement) error <span class="cov0" title="0">{
        // Get peer's public key
        pubKey, err := ad.NodeID.ExtractPublicKey()
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to extract public key: %w", err)
        }</span>
        
        // Verify signature
        <span class="cov0" title="0">payload := fmt.Sprintf("%s:%s:%d", ad.NodeID, ad.ID, ad.Timestamp.Unix())
        valid, err := pubKey.Verify([]byte(payload), ad.Signature)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("signature verification failed: %w", err)
        }</span>
        
        <span class="cov0" title="0">if !valid </span><span class="cov0" title="0">{
                return fmt.Errorf("invalid signature")
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// metricsTask collects metrics
func (ra *ResourceAdvertiser) metricsTask() <span class="cov0" title="0">{
        defer ra.wg.Done()
        
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ra.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        ra.updateMetrics()</span>
                }
        }
}

// updateMetrics updates metrics
func (ra *ResourceAdvertiser) updateMetrics() {<span class="cov0" title="0">
        // TODO: Implement metrics collection
}</span>

// cacheCleanupTask cleans up expired cache entries
func (ra *ResourceAdvertiser) cacheCleanupTask() <span class="cov0" title="0">{
        defer ra.wg.Done()
        
        ticker := time.NewTicker(5 * time.Minute)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ra.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        ra.discoveryCache.Cleanup()</span>
                }
        }
}

// GetMetrics returns advertiser metrics
func (ra *ResourceAdvertiser) GetMetrics() *AdvertiserMetrics <span class="cov0" title="0">{
        return ra.metrics
}</span>

// Stop stops the resource advertiser
func (ra *ResourceAdvertiser) Stop() <span class="cov0" title="0">{
        log.Printf("Stopping resource advertiser")
        ra.cancel()
        ra.wg.Wait()
        log.Printf("Resource advertiser stopped")
}</span>

// DefaultAdvertiserConfig returns default configuration
func DefaultAdvertiserConfig() *AdvertiserConfig <span class="cov0" title="0">{
        return &amp;AdvertiserConfig{
                AdvertisementInterval: 30 * time.Second,
                TTL:                   5 * time.Minute,
                MaxAdvertisements:     100,
                EnableSigning:         true,
                EnableGeoLocation:     false,
                Priority:              1,
                Tags:                  make(map[string]string),
        }
}</pre>
		
		<pre class="file" id="file37" style="display: none">package resources

import (
        "sync"
        "time"
)

// ResourceQuery represents a query for discovering resources
type ResourceQuery struct {
        ID             string        `json:"id"`
        ModelTypes     []string      `json:"model_types,omitempty"`
        MinCPU         int           `json:"min_cpu,omitempty"`
        MinMemory      int64         `json:"min_memory,omitempty"`
        RequiredGPU    bool          `json:"required_gpu,omitempty"`
        MaxLatency     time.Duration `json:"max_latency,omitempty"`
        MaxPrice       float64       `json:"max_price,omitempty"`
        PreferredZones []string      `json:"preferred_zones,omitempty"`
        Tags           map[string]string `json:"tags,omitempty"`
        Timestamp      time.Time     `json:"timestamp"`
}

// DiscoveryResponse represents a response to a resource discovery query
type DiscoveryResponse struct {
        QueryID   string          `json:"query_id"`
        Results   []*Advertisement `json:"results"`
        Timestamp time.Time       `json:"timestamp"`
        Source    string          `json:"source"`
}

// DiscoveryCache manages a cache of discovered resources
type DiscoveryCache struct {
        cache     map[string]*Advertisement
        mutex     sync.RWMutex
        maxSize   int
        ttl       time.Duration
        lastClean time.Time
}

// NewDiscoveryCache creates a new discovery cache
func NewDiscoveryCache(maxSize int, ttl time.Duration) *DiscoveryCache <span class="cov0" title="0">{
        return &amp;DiscoveryCache{
                cache:     make(map[string]*Advertisement),
                maxSize:   maxSize,
                ttl:       ttl,
                lastClean: time.Now(),
        }
}</span>

// Store stores an advertisement in the cache
func (dc *DiscoveryCache) Store(ad *Advertisement) <span class="cov0" title="0">{
        dc.mutex.Lock()
        defer dc.mutex.Unlock()
        
        // Check if cache is full
        if len(dc.cache) &gt;= dc.maxSize </span><span class="cov0" title="0">{
                // Remove oldest entries
                dc.evictOldest()
        }</span>
        
        <span class="cov0" title="0">dc.cache[ad.ID] = ad</span>
}

// Find searches for advertisements matching a query
func (dc *DiscoveryCache) Find(query *ResourceQuery) []*Advertisement <span class="cov0" title="0">{
        dc.mutex.RLock()
        defer dc.mutex.RUnlock()
        
        var results []*Advertisement
        now := time.Now()
        
        for _, ad := range dc.cache </span><span class="cov0" title="0">{
                // Check if advertisement is still valid
                if now.Sub(ad.Timestamp) &gt; dc.ttl </span><span class="cov0" title="0">{
                        continue</span>
                }
                
                // Check if advertisement matches query
                <span class="cov0" title="0">if dc.matchesQuery(ad, query) </span><span class="cov0" title="0">{
                        results = append(results, ad)
                }</span>
        }
        
        <span class="cov0" title="0">return results</span>
}

// matchesQuery checks if an advertisement matches a query (internal helper)
func (dc *DiscoveryCache) matchesQuery(ad *Advertisement, query *ResourceQuery) bool <span class="cov0" title="0">{
        // Check model types
        if len(query.ModelTypes) &gt; 0 </span><span class="cov0" title="0">{
                hasModel := false
                for _, modelType := range query.ModelTypes </span><span class="cov0" title="0">{
                        for _, supportedModel := range ad.Capabilities.SupportedModels </span><span class="cov0" title="0">{
                                if supportedModel == modelType </span><span class="cov0" title="0">{
                                        hasModel = true
                                        break</span>
                                }
                        }
                        <span class="cov0" title="0">if hasModel </span><span class="cov0" title="0">{
                                break</span>
                        }
                }
                <span class="cov0" title="0">if !hasModel </span><span class="cov0" title="0">{
                        return false
                }</span>
        }
        
        // Check CPU requirements
        <span class="cov0" title="0">if query.MinCPU &gt; 0 &amp;&amp; ad.Capabilities.CPUCores &lt; query.MinCPU </span><span class="cov0" title="0">{
                return false
        }</span>
        
        // Check memory requirements
        <span class="cov0" title="0">if query.MinMemory &gt; 0 &amp;&amp; ad.Capabilities.Memory &lt; query.MinMemory </span><span class="cov0" title="0">{
                return false
        }</span>
        
        // Check GPU requirements
        <span class="cov0" title="0">if query.RequiredGPU &amp;&amp; len(ad.Capabilities.GPUs) == 0 </span><span class="cov0" title="0">{
                return false
        }</span>
        
        // Check latency requirements
        <span class="cov0" title="0">if query.MaxLatency &gt; 0 &amp;&amp; ad.Capabilities.Latency &gt; query.MaxLatency </span><span class="cov0" title="0">{
                return false
        }</span>
        
        // Check price requirements
        <span class="cov0" title="0">if query.MaxPrice &gt; 0 &amp;&amp; ad.Capabilities.PricePerToken &gt; query.MaxPrice </span><span class="cov0" title="0">{
                return false
        }</span>
        
        <span class="cov0" title="0">return true</span>
}

// Cleanup removes expired entries from the cache
func (dc *DiscoveryCache) Cleanup() <span class="cov0" title="0">{
        dc.mutex.Lock()
        defer dc.mutex.Unlock()
        
        now := time.Now()
        
        for id, ad := range dc.cache </span><span class="cov0" title="0">{
                if now.Sub(ad.Timestamp) &gt; dc.ttl </span><span class="cov0" title="0">{
                        delete(dc.cache, id)
                }</span>
        }
        
        <span class="cov0" title="0">dc.lastClean = now</span>
}

// evictOldest removes the oldest entries when cache is full
func (dc *DiscoveryCache) evictOldest() <span class="cov0" title="0">{
        if len(dc.cache) == 0 </span><span class="cov0" title="0">{
                return
        }</span>
        
        // Find oldest entry
        <span class="cov0" title="0">var oldestID string
        var oldestTime time.Time
        
        for id, ad := range dc.cache </span><span class="cov0" title="0">{
                if oldestID == "" || ad.Timestamp.Before(oldestTime) </span><span class="cov0" title="0">{
                        oldestID = id
                        oldestTime = ad.Timestamp
                }</span>
        }
        
        // Remove oldest entry
        <span class="cov0" title="0">if oldestID != "" </span><span class="cov0" title="0">{
                delete(dc.cache, oldestID)
        }</span>
}

// GetSize returns the current cache size
func (dc *DiscoveryCache) GetSize() int <span class="cov0" title="0">{
        dc.mutex.RLock()
        defer dc.mutex.RUnlock()
        return len(dc.cache)
}</span>

// Clear empties the cache
func (dc *DiscoveryCache) Clear() <span class="cov0" title="0">{
        dc.mutex.Lock()
        defer dc.mutex.Unlock()
        dc.cache = make(map[string]*Advertisement)
}</pre>
		
		<pre class="file" id="file38" style="display: none">package routing

import (
        "context"
        "encoding/json"
        "fmt"
        "log"
        "sync"
        "time"

        "github.com/libp2p/go-libp2p/core/host"
        "github.com/libp2p/go-libp2p/core/network"
        "github.com/libp2p/go-libp2p/core/peer"
        "github.com/libp2p/go-libp2p/core/protocol"
        dht "github.com/libp2p/go-libp2p-kad-dht"
        "github.com/ipfs/go-cid"
        "github.com/multiformats/go-multihash"
)

const (
        // Content routing protocols
        ContentRoutingProtocol = protocol.ID("/ollamacron/content-routing/1.0.0")
        ContentRequestProtocol = protocol.ID("/ollamacron/content-request/1.0.0")
        ContentProvideProtocol = protocol.ID("/ollamacron/content-provide/1.0.0")
        
        // DHT content keys
        ContentKeyPrefix = "/ollamacron/content/"
        ModelKeyPrefix   = "/ollamacron/models/"
        DataKeyPrefix    = "/ollamacron/data/"
)

// ContentRouter manages content routing and discovery
type ContentRouter struct {
        host           host.Host
        dht            *dht.IpfsDHT
        
        // Content storage
        contentStore   *ContentStore
        
        // Routing table
        routingTable   *RoutingTable
        
        // Provider management
        providers      map[string][]peer.ID
        providersMux   sync.RWMutex
        
        // Content discovery
        discovery      *ContentDiscovery
        
        // Request tracking
        activeRequests map[string]*ContentRequest
        requestsMux    sync.RWMutex
        
        // Configuration
        config         *ContentRouterConfig
        
        // Metrics
        metrics        *ContentRouterMetrics
        
        // Lifecycle
        ctx            context.Context
        cancel         context.CancelFunc
        wg             sync.WaitGroup
}

// ContentStore manages local and remote content references
type ContentStore struct {
        // Local content
        localContent   map[string]*ContentMetadata
        localMux       sync.RWMutex
        
        // Remote references
        remoteContent  map[string]*RemoteContent
        remoteMux      sync.RWMutex
        
        // Cache management
        cache          *ContentCache
        
        // Storage backend
        storage        Storage
        
        // Indexing
        index          *ContentIndex
}

// ContentMetadata represents content metadata
type ContentMetadata struct {
        ID             string            `json:"id"`
        Name           string            `json:"name"`
        Type           string            `json:"type"`
        Size           int64             `json:"size"`
        Checksum       string            `json:"checksum"`
        
        // Model-specific metadata
        ModelType      string            `json:"model_type"`
        Architecture   string            `json:"architecture"`
        Parameters     int64             `json:"parameters"`
        Quantization   string            `json:"quantization"`
        
        // Availability
        Providers      []peer.ID         `json:"providers"`
        Replicas       int               `json:"replicas"`
        
        // Access control
        AccessLevel    string            `json:"access_level"`
        RequiredAuth   bool              `json:"required_auth"`
        
        // Versioning
        Version        string            `json:"version"`
        ParentID       string            `json:"parent_id,omitempty"`
        
        // Timestamps
        CreatedAt      time.Time         `json:"created_at"`
        UpdatedAt      time.Time         `json:"updated_at"`
        LastAccessed   time.Time         `json:"last_accessed"`
        
        // Tags and labels
        Tags           map[string]string `json:"tags"`
        Labels         []string          `json:"labels"`
}

// RemoteContent represents remote content reference
type RemoteContent struct {
        Metadata       *ContentMetadata
        Providers      []peer.ID
        LastUpdated    time.Time
        RetrievalCost  int64
        Availability   float64
}

// ContentRequest represents a content request
type ContentRequest struct {
        ID             string
        ContentID      string
        RequestorID    peer.ID
        Priority       int
        Timeout        time.Duration
        CreatedAt      time.Time
        Status         RequestStatus
        Progress       float64
        Providers      []peer.ID
        FailedProviders []peer.ID
}

// RequestStatus represents request status
type RequestStatus int

const (
        RequestStatusPending RequestStatus = iota
        RequestStatusActive
        RequestStatusCompleted
        RequestStatusFailed
        RequestStatusCancelled
)

// ContentRouterConfig holds configuration
type ContentRouterConfig struct {
        MaxProviders       int           `json:"max_providers"`
        ProviderTimeout    time.Duration `json:"provider_timeout"`
        RequestTimeout     time.Duration `json:"request_timeout"`
        CacheSize          int           `json:"cache_size"`
        CacheTTL           time.Duration `json:"cache_ttl"`
        ReplicationFactor  int           `json:"replication_factor"`
        EnableCaching      bool          `json:"enable_caching"`
        EnableIndexing     bool          `json:"enable_indexing"`
}

// ContentRouterMetrics tracks routing metrics
type ContentRouterMetrics struct {
        ContentPublished   int
        ContentRequests    int
        ContentProvided    int
        CacheHits          int
        CacheMisses        int
        ProviderQueries    int
        SuccessfulRoutes   int
        FailedRoutes       int
        AverageLatency     time.Duration
        StartTime          time.Time
}

// NewContentRouter creates a new content router
func NewContentRouter(ctx context.Context, host host.Host, dht *dht.IpfsDHT, config *ContentRouterConfig) (*ContentRouter, error) <span class="cov0" title="0">{
        if config == nil </span><span class="cov0" title="0">{
                config = DefaultContentRouterConfig()
        }</span>
        
        <span class="cov0" title="0">ctx, cancel := context.WithCancel(ctx)
        
        cr := &amp;ContentRouter{
                host:           host,
                dht:            dht,
                providers:      make(map[string][]peer.ID),
                activeRequests: make(map[string]*ContentRequest),
                config:         config,
                metrics: &amp;ContentRouterMetrics{
                        StartTime: time.Now(),
                },
                ctx:    ctx,
                cancel: cancel,
        }
        
        // Initialize content store
        contentStore, err := NewContentStore(config)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to initialize content store: %w", err)
        }</span>
        <span class="cov0" title="0">cr.contentStore = contentStore
        
        // Initialize routing table
        cr.routingTable = NewRoutingTable(host.ID())
        
        // Initialize content discovery
        cr.discovery = NewContentDiscovery(host, dht, config)
        
        // Setup protocol handlers
        cr.setupProtocolHandlers()
        
        return cr, nil</span>
}

// setupProtocolHandlers sets up protocol handlers
func (cr *ContentRouter) setupProtocolHandlers() <span class="cov0" title="0">{
        cr.host.SetStreamHandler(ContentRoutingProtocol, cr.handleContentRouting)
        cr.host.SetStreamHandler(ContentRequestProtocol, cr.handleContentRequest)
        cr.host.SetStreamHandler(ContentProvideProtocol, cr.handleContentProvide)
}</span>

// Start starts the content router
func (cr *ContentRouter) Start() <span class="cov0" title="0">{
        log.Printf("Starting content router")
        
        // Start discovery
        cr.discovery.Start()
        
        // Start provider management
        cr.wg.Add(1)
        go cr.providerManagementTask()
        
        // Start request processing
        cr.wg.Add(1)
        go cr.requestProcessingTask()
        
        // Start metrics collection
        cr.wg.Add(1)
        go cr.metricsTask()
        
        // Start cache cleanup
        cr.wg.Add(1)
        go cr.cacheCleanupTask()
        
        log.Printf("Content router started")
}</span>

// PublishContent publishes content to the network
func (cr *ContentRouter) PublishContent(ctx context.Context, content *ContentMetadata) error <span class="cov0" title="0">{
        log.Printf("Publishing content: %s", content.ID)
        
        // Store content locally
        cr.contentStore.StoreLocal(content)
        
        // Announce to DHT
        key := fmt.Sprintf("%s%s", ContentKeyPrefix, content.ID)
        data, err := json.Marshal(content)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal content: %w", err)
        }</span>
        
        <span class="cov0" title="0">if err := cr.dht.PutValue(ctx, key, data); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to publish to DHT: %w", err)
        }</span>
        
        // Become provider
        <span class="cov0" title="0">contentHash, err := cr.calculateContentHash(content.ID)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to calculate content hash: %w", err)
        }</span>
        
        <span class="cov0" title="0">if err := cr.dht.Provide(ctx, contentHash, true); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to announce as provider: %w", err)
        }</span>
        
        // Update routing table
        <span class="cov0" title="0">cr.routingTable.AddRoute(content.ID, cr.host.ID())
        
        // Update metrics
        cr.metrics.ContentPublished++
        
        log.Printf("Published content: %s", content.ID)
        return nil</span>
}

// FindContent finds content in the network
func (cr *ContentRouter) FindContent(ctx context.Context, contentID string) (*ContentMetadata, []peer.ID, error) <span class="cov0" title="0">{
        log.Printf("Finding content: %s", contentID)
        
        // Check local store first
        if content, exists := cr.contentStore.GetLocal(contentID); exists </span><span class="cov0" title="0">{
                return content, []peer.ID{cr.host.ID()}, nil
        }</span>
        
        // Check cache
        <span class="cov0" title="0">if cr.config.EnableCaching </span><span class="cov0" title="0">{
                if cached, exists := cr.contentStore.GetCached(contentID); exists </span><span class="cov0" title="0">{
                        cr.metrics.CacheHits++
                        return cached.Metadata, cached.Providers, nil
                }</span>
                <span class="cov0" title="0">cr.metrics.CacheMisses++</span>
        }
        
        // Query DHT
        <span class="cov0" title="0">key := fmt.Sprintf("%s%s", ContentKeyPrefix, contentID)
        val, err := cr.dht.GetValue(ctx, key)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("content not found in DHT: %w", err)
        }</span>
        
        <span class="cov0" title="0">var content ContentMetadata
        if err := json.Unmarshal(val, &amp;content); err != nil </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("failed to unmarshal content: %w", err)
        }</span>
        
        // Find providers
        <span class="cov0" title="0">providers, err := cr.findProviders(ctx, contentID)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("failed to find providers: %w", err)
        }</span>
        
        // Cache the result
        <span class="cov0" title="0">if cr.config.EnableCaching </span><span class="cov0" title="0">{
                cr.contentStore.CacheRemote(contentID, &amp;content, providers)
        }</span>
        
        <span class="cov0" title="0">log.Printf("Found content: %s with %d providers", contentID, len(providers))
        return &amp;content, providers, nil</span>
}

// findProviders finds providers for content
func (cr *ContentRouter) findProviders(ctx context.Context, contentID string) ([]peer.ID, error) <span class="cov0" title="0">{
        contentHash, err := cr.calculateContentHash(contentID)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to calculate content hash: %w", err)
        }</span>
        
        <span class="cov0" title="0">providersChan := cr.dht.FindProvidersAsync(ctx, contentHash, cr.config.MaxProviders)
        
        var providerIDs []peer.ID
        for provider := range providersChan </span><span class="cov0" title="0">{
                providerIDs = append(providerIDs, provider.ID)
        }</span>
        
        <span class="cov0" title="0">cr.metrics.ProviderQueries++
        return providerIDs, nil</span>
}

// RequestContent requests content from the network
func (cr *ContentRouter) RequestContent(ctx context.Context, contentID string, priority int) (*ContentRequest, error) <span class="cov0" title="0">{
        log.Printf("Requesting content: %s with priority %d", contentID, priority)
        
        // Create request
        requestID := fmt.Sprintf("req-%d", time.Now().UnixNano())
        request := &amp;ContentRequest{
                ID:          requestID,
                ContentID:   contentID,
                RequestorID: cr.host.ID(),
                Priority:    priority,
                Timeout:     cr.config.RequestTimeout,
                CreatedAt:   time.Now(),
                Status:      RequestStatusPending,
                Progress:    0,
        }
        
        // Store request
        cr.requestsMux.Lock()
        cr.activeRequests[requestID] = request
        cr.requestsMux.Unlock()
        
        // Find providers
        providers, err := cr.findProviders(ctx, contentID)
        if err != nil </span><span class="cov0" title="0">{
                request.Status = RequestStatusFailed
                return request, fmt.Errorf("failed to find providers: %w", err)
        }</span>
        
        <span class="cov0" title="0">request.Providers = providers
        request.Status = RequestStatusActive
        
        // Start request processing
        go cr.processContentRequest(request)
        
        cr.metrics.ContentRequests++
        return request, nil</span>
}

// processContentRequest processes a content request
func (cr *ContentRouter) processContentRequest(request *ContentRequest) <span class="cov0" title="0">{
        log.Printf("Processing content request: %s", request.ID)
        
        ctx, cancel := context.WithTimeout(cr.ctx, request.Timeout)
        defer cancel()
        
        // Try providers in order
        for _, providerID := range request.Providers </span><span class="cov0" title="0">{
                if cr.ctx.Err() != nil </span><span class="cov0" title="0">{
                        request.Status = RequestStatusCancelled
                        return
                }</span>
                
                // Skip failed providers
                <span class="cov0" title="0">if cr.isFailedProvider(request, providerID) </span><span class="cov0" title="0">{
                        continue</span>
                }
                
                // Request from provider
                <span class="cov0" title="0">if err := cr.requestFromProvider(ctx, request, providerID); err != nil </span><span class="cov0" title="0">{
                        log.Printf("Failed to request from provider %s: %v", providerID, err)
                        request.FailedProviders = append(request.FailedProviders, providerID)
                        continue</span>
                }
                
                // Success
                <span class="cov0" title="0">request.Status = RequestStatusCompleted
                request.Progress = 1.0
                cr.metrics.SuccessfulRoutes++
                log.Printf("Completed content request: %s", request.ID)
                return</span>
        }
        
        // All providers failed
        <span class="cov0" title="0">request.Status = RequestStatusFailed
        cr.metrics.FailedRoutes++
        log.Printf("Failed content request: %s", request.ID)</span>
}

// requestFromProvider requests content from a specific provider
func (cr *ContentRouter) requestFromProvider(ctx context.Context, request *ContentRequest, providerID peer.ID) error <span class="cov0" title="0">{
        // Create stream to provider
        stream, err := cr.host.NewStream(ctx, providerID, ContentRequestProtocol)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create stream: %w", err)
        }</span>
        <span class="cov0" title="0">defer stream.Close()
        
        // Send request
        requestMsg := &amp;ContentRequestMessage{
                RequestID: request.ID,
                ContentID: request.ContentID,
                Priority:  request.Priority,
                Timestamp: time.Now(),
        }
        
        data, err := json.Marshal(requestMsg)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal request: %w", err)
        }</span>
        
        <span class="cov0" title="0">if _, err := stream.Write(data); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to send request: %w", err)
        }</span>
        
        // Read response
        <span class="cov0" title="0">buf := make([]byte, 4096)
        n, err := stream.Read(buf)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to read response: %w", err)
        }</span>
        
        <span class="cov0" title="0">var response ContentResponseMessage
        if err := json.Unmarshal(buf[:n], &amp;response); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to unmarshal response: %w", err)
        }</span>
        
        <span class="cov0" title="0">if !response.Success </span><span class="cov0" title="0">{
                return fmt.Errorf("provider rejected request: %s", response.Message)
        }</span>
        
        // Update progress
        <span class="cov0" title="0">request.Progress = 0.5
        
        // Handle content transfer (simplified)
        // In a real implementation, this would involve chunked transfers
        if response.ContentData != nil </span><span class="cov0" title="0">{
                // Process content data
                request.Progress = 1.0
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// Protocol handlers

// handleContentRouting handles content routing requests
func (cr *ContentRouter) handleContentRouting(stream network.Stream) <span class="cov0" title="0">{
        defer stream.Close()
        
        // Read routing request
        buf := make([]byte, 4096)
        n, err := stream.Read(buf)
        if err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to read routing request: %v", err)
                return
        }</span>
        
        <span class="cov0" title="0">var routingMsg RoutingMessage
        if err := json.Unmarshal(buf[:n], &amp;routingMsg); err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to unmarshal routing request: %v", err)
                return
        }</span>
        
        // Process routing request
        <span class="cov0" title="0">response := cr.processRoutingRequest(&amp;routingMsg)
        
        // Send response
        data, err := json.Marshal(response)
        if err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to marshal routing response: %v", err)
                return
        }</span>
        
        <span class="cov0" title="0">if _, err := stream.Write(data); err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to send routing response: %v", err)
                return
        }</span>
}

// handleContentRequest handles incoming content requests
func (cr *ContentRouter) handleContentRequest(stream network.Stream) <span class="cov0" title="0">{
        defer stream.Close()
        
        peerID := stream.Conn().RemotePeer()
        
        // Read request
        buf := make([]byte, 4096)
        n, err := stream.Read(buf)
        if err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to read content request: %v", err)
                return
        }</span>
        
        <span class="cov0" title="0">var request ContentRequestMessage
        if err := json.Unmarshal(buf[:n], &amp;request); err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to unmarshal content request: %v", err)
                return
        }</span>
        
        // Process request
        <span class="cov0" title="0">response := cr.processIncomingContentRequest(&amp;request, peerID)
        
        // Send response
        data, err := json.Marshal(response)
        if err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to marshal content response: %v", err)
                return
        }</span>
        
        <span class="cov0" title="0">if _, err := stream.Write(data); err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to send content response: %v", err)
                return
        }</span>
        
        <span class="cov0" title="0">cr.metrics.ContentProvided++</span>
}

// handleContentProvide handles content provision announcements
func (cr *ContentRouter) handleContentProvide(stream network.Stream) <span class="cov0" title="0">{
        defer stream.Close()
        
        peerID := stream.Conn().RemotePeer()
        
        // Read provision announcement
        buf := make([]byte, 4096)
        n, err := stream.Read(buf)
        if err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to read provision announcement: %v", err)
                return
        }</span>
        
        <span class="cov0" title="0">var announcement ProvisionAnnouncement
        if err := json.Unmarshal(buf[:n], &amp;announcement); err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to unmarshal provision announcement: %v", err)
                return
        }</span>
        
        // Process announcement
        <span class="cov0" title="0">cr.processProvisionAnnouncement(&amp;announcement, peerID)</span>
}

// processRoutingRequest processes a routing request
func (cr *ContentRouter) processRoutingRequest(msg *RoutingMessage) *RoutingResponse <span class="cov0" title="0">{
        // Find routes for the requested content
        routes := cr.routingTable.FindRoutes(msg.ContentID)
        
        return &amp;RoutingResponse{
                MessageID: msg.MessageID,
                Success:   len(routes) &gt; 0,
                Routes:    routes,
                Timestamp: time.Now(),
        }
}</span>

// processIncomingContentRequest processes an incoming content request from a peer
func (cr *ContentRouter) processIncomingContentRequest(request *ContentRequestMessage, requesterID peer.ID) *ContentResponseMessage <span class="cov0" title="0">{
        // Check if we have the content
        content, exists := cr.contentStore.GetLocal(request.ContentID)
        if !exists </span><span class="cov0" title="0">{
                return &amp;ContentResponseMessage{
                        RequestID: request.RequestID,
                        Success:   false,
                        Message:   "Content not found",
                        Timestamp: time.Now(),
                }
        }</span>
        
        // TODO: Implement actual content transfer
        // For now, just return metadata
        <span class="cov0" title="0">return &amp;ContentResponseMessage{
                RequestID:   request.RequestID,
                Success:     true,
                ContentMeta: content,
                Timestamp:   time.Now(),
        }</span>
}

// processProvisionAnnouncement processes a provision announcement
func (cr *ContentRouter) processProvisionAnnouncement(announcement *ProvisionAnnouncement, providerID peer.ID) <span class="cov0" title="0">{
        cr.providersMux.Lock()
        defer cr.providersMux.Unlock()
        
        // Add provider to the list
        providers := cr.providers[announcement.ContentID]
        for _, p := range providers </span><span class="cov0" title="0">{
                if p == providerID </span><span class="cov0" title="0">{
                        return // Already in list
                }</span>
        }
        
        <span class="cov0" title="0">cr.providers[announcement.ContentID] = append(providers, providerID)
        log.Printf("Added provider %s for content %s", providerID, announcement.ContentID)</span>
}

// Background tasks

// providerManagementTask manages provider information
func (cr *ContentRouter) providerManagementTask() <span class="cov0" title="0">{
        defer cr.wg.Done()
        
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-cr.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        cr.updateProviderInfo()</span>
                }
        }
}

// requestProcessingTask processes pending requests
func (cr *ContentRouter) requestProcessingTask() <span class="cov0" title="0">{
        defer cr.wg.Done()
        
        ticker := time.NewTicker(5 * time.Second)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-cr.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        cr.processTimeouts()</span>
                }
        }
}

// metricsTask collects metrics
func (cr *ContentRouter) metricsTask() <span class="cov0" title="0">{
        defer cr.wg.Done()
        
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-cr.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        cr.updateMetrics()</span>
                }
        }
}

// cacheCleanupTask cleans up expired cache entries
func (cr *ContentRouter) cacheCleanupTask() <span class="cov0" title="0">{
        defer cr.wg.Done()
        
        ticker := time.NewTicker(5 * time.Minute)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-cr.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        cr.contentStore.CleanupCache()</span>
                }
        }
}

// Utility methods

// calculateContentHash calculates hash for content ID
func (cr *ContentRouter) calculateContentHash(contentID string) (cid.Cid, error) <span class="cov0" title="0">{
        // Simple hash calculation - in production use proper content addressing
        mh, err := multihash.Sum([]byte(contentID), multihash.SHA2_256, -1)
        if err != nil </span><span class="cov0" title="0">{
                return cid.Cid{}, err
        }</span>
        <span class="cov0" title="0">return cid.NewCidV1(cid.Raw, mh), nil</span>
}

// isFailedProvider checks if provider has failed recently
func (cr *ContentRouter) isFailedProvider(request *ContentRequest, providerID peer.ID) bool <span class="cov0" title="0">{
        for _, failed := range request.FailedProviders </span><span class="cov0" title="0">{
                if failed == providerID </span><span class="cov0" title="0">{
                        return true
                }</span>
        }
        <span class="cov0" title="0">return false</span>
}

// updateProviderInfo updates provider information
func (cr *ContentRouter) updateProviderInfo() {<span class="cov0" title="0">
        // TODO: Implement provider health checking
}</span>

// processTimeouts processes request timeouts
func (cr *ContentRouter) processTimeouts() <span class="cov0" title="0">{
        cr.requestsMux.Lock()
        defer cr.requestsMux.Unlock()
        
        now := time.Now()
        for id, request := range cr.activeRequests </span><span class="cov0" title="0">{
                if now.Sub(request.CreatedAt) &gt; request.Timeout </span><span class="cov0" title="0">{
                        request.Status = RequestStatusFailed
                        delete(cr.activeRequests, id)
                        log.Printf("Request timeout: %s", id)
                }</span>
        }
}

// updateMetrics updates router metrics
func (cr *ContentRouter) updateMetrics() {<span class="cov0" title="0">
        // TODO: Implement metrics collection
}</span>

// GetMetrics returns router metrics
func (cr *ContentRouter) GetMetrics() *ContentRouterMetrics <span class="cov0" title="0">{
        return cr.metrics
}</span>

// GetActiveRequests returns active requests
func (cr *ContentRouter) GetActiveRequests() map[string]*ContentRequest <span class="cov0" title="0">{
        cr.requestsMux.RLock()
        defer cr.requestsMux.RUnlock()
        
        requests := make(map[string]*ContentRequest)
        for k, v := range cr.activeRequests </span><span class="cov0" title="0">{
                requests[k] = v
        }</span>
        <span class="cov0" title="0">return requests</span>
}

// Stop stops the content router
func (cr *ContentRouter) Stop() <span class="cov0" title="0">{
        log.Printf("Stopping content router")
        cr.cancel()
        cr.wg.Wait()
        
        if cr.discovery != nil </span><span class="cov0" title="0">{
                cr.discovery.Stop()
        }</span>
        
        <span class="cov0" title="0">log.Printf("Content router stopped")</span>
}

// DefaultContentRouterConfig returns default configuration
func DefaultContentRouterConfig() *ContentRouterConfig <span class="cov0" title="0">{
        return &amp;ContentRouterConfig{
                MaxProviders:      10,
                ProviderTimeout:   30 * time.Second,
                RequestTimeout:    60 * time.Second,
                CacheSize:         1000,
                CacheTTL:          10 * time.Minute,
                ReplicationFactor: 3,
                EnableCaching:     true,
                EnableIndexing:    true,
        }
}</span>

// Message types

// RoutingMessage represents a routing message
type RoutingMessage struct {
        MessageID string    `json:"message_id"`
        ContentID string    `json:"content_id"`
        Type      string    `json:"type"`
        Timestamp time.Time `json:"timestamp"`
}

// RoutingResponse represents a routing response
type RoutingResponse struct {
        MessageID string     `json:"message_id"`
        Success   bool       `json:"success"`
        Routes    []peer.ID  `json:"routes"`
        Message   string     `json:"message,omitempty"`
        Timestamp time.Time  `json:"timestamp"`
}

// ContentRequestMessage represents a content request
type ContentRequestMessage struct {
        RequestID string    `json:"request_id"`
        ContentID string    `json:"content_id"`
        Priority  int       `json:"priority"`
        Timestamp time.Time `json:"timestamp"`
}

// ContentResponseMessage represents a content response
type ContentResponseMessage struct {
        RequestID   string           `json:"request_id"`
        Success     bool             `json:"success"`
        ContentMeta *ContentMetadata `json:"content_meta,omitempty"`
        ContentData []byte           `json:"content_data,omitempty"`
        Message     string           `json:"message,omitempty"`
        Timestamp   time.Time        `json:"timestamp"`
}

// ProvisionAnnouncement represents a provision announcement
type ProvisionAnnouncement struct {
        ContentID string    `json:"content_id"`
        Provider  peer.ID   `json:"provider"`
        TTL       time.Duration `json:"ttl"`
        Timestamp time.Time `json:"timestamp"`
}

// RoutingTable manages peer routing information
type RoutingTable struct {
        localPeerID peer.ID
        routes      map[string][]peer.ID
        mu          sync.RWMutex
}

// NewRoutingTable creates a new routing table
func NewRoutingTable(localPeerID peer.ID) *RoutingTable <span class="cov0" title="0">{
        return &amp;RoutingTable{
                localPeerID: localPeerID,
                routes:      make(map[string][]peer.ID),
        }
}</span>

// AddRoute adds a route to the routing table
func (rt *RoutingTable) AddRoute(contentID string, peerID peer.ID) <span class="cov0" title="0">{
        rt.mu.Lock()
        defer rt.mu.Unlock()
        
        routes := rt.routes[contentID]
        for _, p := range routes </span><span class="cov0" title="0">{
                if p == peerID </span><span class="cov0" title="0">{
                        return // Already exists
                }</span>
        }
        <span class="cov0" title="0">rt.routes[contentID] = append(routes, peerID)</span>
}

// FindRoutes finds routes for a content ID
func (rt *RoutingTable) FindRoutes(contentID string) []peer.ID <span class="cov0" title="0">{
        rt.mu.RLock()
        defer rt.mu.RUnlock()
        
        routes := rt.routes[contentID]
        result := make([]peer.ID, len(routes))
        copy(result, routes)
        return result
}</span>

// ContentDiscovery manages content discovery in the network
type ContentDiscovery struct {
        host   host.Host
        dht    *dht.IpfsDHT
        config *ContentRouterConfig
        ctx    context.Context
        cancel context.CancelFunc
}

// NewContentDiscovery creates a new content discovery instance
func NewContentDiscovery(host host.Host, dht *dht.IpfsDHT, config *ContentRouterConfig) *ContentDiscovery <span class="cov0" title="0">{
        ctx, cancel := context.WithCancel(context.Background())
        return &amp;ContentDiscovery{
                host:   host,
                dht:    dht,
                config: config,
                ctx:    ctx,
                cancel: cancel,
        }
}</span>

// Start starts the content discovery service
func (cd *ContentDiscovery) Start() {<span class="cov0" title="0">
        // TODO: Implement discovery service
}</span>

// Stop stops the content discovery service
func (cd *ContentDiscovery) Stop() <span class="cov0" title="0">{
        cd.cancel()
}</span>

// ContentCache manages cached content
type ContentCache struct {
        cache    map[string]*CacheEntry
        maxSize  int
        ttl      time.Duration
        mu       sync.RWMutex
}

// CacheEntry represents a cache entry
type CacheEntry struct {
        Content   *RemoteContent
        ExpiresAt time.Time
}

// NewContentCache creates a new content cache
func NewContentCache(maxSize int, ttl time.Duration) *ContentCache <span class="cov0" title="0">{
        return &amp;ContentCache{
                cache:   make(map[string]*CacheEntry),
                maxSize: maxSize,
                ttl:     ttl,
        }
}</span>

// Get retrieves content from cache
func (cc *ContentCache) Get(contentID string) (*RemoteContent, bool) <span class="cov0" title="0">{
        cc.mu.RLock()
        defer cc.mu.RUnlock()
        
        entry, exists := cc.cache[contentID]
        if !exists || time.Now().After(entry.ExpiresAt) </span><span class="cov0" title="0">{
                return nil, false
        }</span>
        <span class="cov0" title="0">return entry.Content, true</span>
}

// Put stores content in cache
func (cc *ContentCache) Put(contentID string, content *RemoteContent) <span class="cov0" title="0">{
        cc.mu.Lock()
        defer cc.mu.Unlock()
        
        cc.cache[contentID] = &amp;CacheEntry{
                Content:   content,
                ExpiresAt: time.Now().Add(cc.ttl),
        }
        
        // Simple eviction if cache is full
        if len(cc.cache) &gt; cc.maxSize </span><span class="cov0" title="0">{
                // Remove oldest entry
                var oldestID string
                var oldestTime time.Time
                for id, entry := range cc.cache </span><span class="cov0" title="0">{
                        if oldestTime.IsZero() || entry.ExpiresAt.Before(oldestTime) </span><span class="cov0" title="0">{
                                oldestID = id
                                oldestTime = entry.ExpiresAt
                        }</span>
                }
                <span class="cov0" title="0">delete(cc.cache, oldestID)</span>
        }
}

// Cleanup removes expired entries
func (cc *ContentCache) Cleanup() <span class="cov0" title="0">{
        cc.mu.Lock()
        defer cc.mu.Unlock()
        
        now := time.Now()
        for id, entry := range cc.cache </span><span class="cov0" title="0">{
                if now.After(entry.ExpiresAt) </span><span class="cov0" title="0">{
                        delete(cc.cache, id)
                }</span>
        }
}

// Storage interface for content storage
type Storage interface {
        Get(key string) ([]byte, error)
        Put(key string, value []byte) error
        Delete(key string) error
        Has(key string) bool
}

// MemoryStorage implements in-memory storage
type MemoryStorage struct {
        data map[string][]byte
        mu   sync.RWMutex
}

// NewMemoryStorage creates a new memory storage
func NewMemoryStorage() *MemoryStorage <span class="cov0" title="0">{
        return &amp;MemoryStorage{
                data: make(map[string][]byte),
        }
}</span>

// Get retrieves data from storage
func (ms *MemoryStorage) Get(key string) ([]byte, error) <span class="cov0" title="0">{
        ms.mu.RLock()
        defer ms.mu.RUnlock()
        
        data, exists := ms.data[key]
        if !exists </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("key not found: %s", key)
        }</span>
        <span class="cov0" title="0">return data, nil</span>
}

// Put stores data in storage
func (ms *MemoryStorage) Put(key string, value []byte) error <span class="cov0" title="0">{
        ms.mu.Lock()
        defer ms.mu.Unlock()
        
        ms.data[key] = value
        return nil
}</span>

// Delete removes data from storage
func (ms *MemoryStorage) Delete(key string) error <span class="cov0" title="0">{
        ms.mu.Lock()
        defer ms.mu.Unlock()
        
        delete(ms.data, key)
        return nil
}</span>

// Has checks if key exists in storage
func (ms *MemoryStorage) Has(key string) bool <span class="cov0" title="0">{
        ms.mu.RLock()
        defer ms.mu.RUnlock()
        
        _, exists := ms.data[key]
        return exists
}</span>

// ContentIndex manages content indexing
type ContentIndex struct {
        index map[string]*IndexEntry
        mu    sync.RWMutex
}

// IndexEntry represents an index entry
type IndexEntry struct {
        ContentID string
        Metadata  *ContentMetadata
        Keywords  []string
        UpdatedAt time.Time
}

// NewContentIndex creates a new content index
func NewContentIndex() *ContentIndex <span class="cov0" title="0">{
        return &amp;ContentIndex{
                index: make(map[string]*IndexEntry),
        }
}</span>

// Add adds content to the index
func (ci *ContentIndex) Add(contentID string, metadata *ContentMetadata) <span class="cov0" title="0">{
        ci.mu.Lock()
        defer ci.mu.Unlock()
        
        ci.index[contentID] = &amp;IndexEntry{
                ContentID: contentID,
                Metadata:  metadata,
                Keywords:  extractKeywords(metadata),
                UpdatedAt: time.Now(),
        }
}</span>

// Search searches the index
func (ci *ContentIndex) Search(query string) []*IndexEntry <span class="cov0" title="0">{
        ci.mu.RLock()
        defer ci.mu.RUnlock()
        
        var results []*IndexEntry
        for _, entry := range ci.index </span><span class="cov0" title="0">{
                if matchesQuery(entry, query) </span><span class="cov0" title="0">{
                        results = append(results, entry)
                }</span>
        }
        <span class="cov0" title="0">return results</span>
}

// extractKeywords extracts keywords from metadata
func extractKeywords(metadata *ContentMetadata) []string <span class="cov0" title="0">{
        keywords := []string{metadata.Name, metadata.Type, metadata.ModelType}
        keywords = append(keywords, metadata.Labels...)
        return keywords
}</span>

// matchesQuery checks if entry matches query
func matchesQuery(entry *IndexEntry, query string) bool <span class="cov0" title="0">{
        // Simple substring matching
        for _, keyword := range entry.Keywords </span><span class="cov0" title="0">{
                if keyword == query </span><span class="cov0" title="0">{
                        return true
                }</span>
        }
        <span class="cov0" title="0">return false</span>
}

// NewContentStore creates a new content store
func NewContentStore(config *ContentRouterConfig) (*ContentStore, error) <span class="cov0" title="0">{
        cache := NewContentCache(config.CacheSize, config.CacheTTL)
        storage := NewMemoryStorage()
        index := NewContentIndex()
        
        return &amp;ContentStore{
                localContent:  make(map[string]*ContentMetadata),
                remoteContent: make(map[string]*RemoteContent),
                cache:         cache,
                storage:       storage,
                index:         index,
        }, nil
}</span>

// StoreLocal stores content locally
func (cs *ContentStore) StoreLocal(content *ContentMetadata) <span class="cov0" title="0">{
        cs.localMux.Lock()
        defer cs.localMux.Unlock()
        
        cs.localContent[content.ID] = content
        if cs.index != nil </span><span class="cov0" title="0">{
                cs.index.Add(content.ID, content)
        }</span>
}

// GetLocal retrieves local content
func (cs *ContentStore) GetLocal(contentID string) (*ContentMetadata, bool) <span class="cov0" title="0">{
        cs.localMux.RLock()
        defer cs.localMux.RUnlock()
        
        content, exists := cs.localContent[contentID]
        return content, exists
}</span>

// CacheRemote caches remote content
func (cs *ContentStore) CacheRemote(contentID string, metadata *ContentMetadata, providers []peer.ID) <span class="cov0" title="0">{
        cs.remoteMux.Lock()
        defer cs.remoteMux.Unlock()
        
        remote := &amp;RemoteContent{
                Metadata:     metadata,
                Providers:    providers,
                LastUpdated:  time.Now(),
                Availability: float64(len(providers)) / 10.0, // Simple availability metric
        }
        
        cs.remoteContent[contentID] = remote
        if cs.cache != nil </span><span class="cov0" title="0">{
                cs.cache.Put(contentID, remote)
        }</span>
}

// GetCached retrieves cached content
func (cs *ContentStore) GetCached(contentID string) (*RemoteContent, bool) <span class="cov0" title="0">{
        if cs.cache != nil </span><span class="cov0" title="0">{
                return cs.cache.Get(contentID)
        }</span>
        
        <span class="cov0" title="0">cs.remoteMux.RLock()
        defer cs.remoteMux.RUnlock()
        
        content, exists := cs.remoteContent[contentID]
        return content, exists</span>
}

// CleanupCache cleans up the cache
func (cs *ContentStore) CleanupCache() <span class="cov0" title="0">{
        if cs.cache != nil </span><span class="cov0" title="0">{
                cs.cache.Cleanup()
        }</span>
}</pre>
		
		<pre class="file" id="file39" style="display: none">package security

import (
        "context"
        "crypto/rand"
        "crypto/rsa"
        "crypto/x509"
        "encoding/json"
        "encoding/pem"
        "fmt"
        "log"
        "sync"
        "time"

        "github.com/libp2p/go-libp2p/core/crypto"
        "github.com/libp2p/go-libp2p/core/host"
        "github.com/libp2p/go-libp2p/core/network"
        "github.com/libp2p/go-libp2p/core/peer"
        "github.com/libp2p/go-libp2p/core/protocol"
)

const (
        // Security protocols
        SecureChannelProtocol = protocol.ID("/ollamacron/secure-channel/1.0.0")
        AuthProtocol         = protocol.ID("/ollamacron/auth/1.0.0")
        KeyExchangeProtocol  = protocol.ID("/ollamacron/key-exchange/1.0.0")
        
        // Security levels
        SecurityLevelNone   = "none"
        SecurityLevelBasic  = "basic"
        SecurityLevelHigh   = "high"
        
        // Key rotation intervals
        DefaultKeyRotationInterval = 24 * time.Hour
        SessionKeyTTL             = 4 * time.Hour
)

// ===============================
// Supporting Type Definitions
// ===============================

// SessionKey represents a session encryption key
type SessionKey struct {
        PublicKey  []byte
        PrivateKey []byte
        CreatedAt  time.Time
        ExpiresAt  time.Time
}

// KeyManager manages cryptographic keys
type KeyManager struct {
        sessionKeys    map[string]*SessionKey
        keysMu        sync.RWMutex
        
        // Peer public keys
        peerKeys      map[string]crypto.PubKey
        peerKeysMu    sync.RWMutex
        
        config        *SecurityConfig
}

// EncryptionManager handles encryption/decryption
type EncryptionManager struct {
        keyManager *KeyManager
        config     *SecurityConfig
}

// AccessControl manages access control policies
type AccessControl struct {
        policies  map[peer.ID]*AccessPolicy
        policyMu  sync.RWMutex
        config    *SecurityConfig
}

// AccessPolicy defines access permissions for a peer
type AccessPolicy struct {
        PeerID      peer.ID
        Permissions []string
        CreatedAt   time.Time
        ExpiresAt   time.Time
}

// RateLimiter manages rate limiting
type RateLimiter struct {
        limits   map[string]*RateLimit
        limitMu  sync.RWMutex
        config   *SecurityConfig
}

// RateLimit defines rate limiting parameters
type RateLimit struct {
        RequestsPerSecond int
        BurstSize         int
        Window            time.Duration
        lastReset         time.Time
        currentCount      int
}

// ProtocolAccessControl defines protocol-specific access control
type ProtocolAccessControl struct {
        AllowAll      bool
        AllowedPeers  []peer.ID
        BlockedPeers  []peer.ID
        RequiredPerms []string
}

// AuthManager manages authentication for P2P communications
type AuthManager struct {
        authenticatedPeers map[peer.ID]time.Time
        peersMu           sync.RWMutex
        
        // Private key for signing
        privateKey        crypto.PrivKey
        publicKey         crypto.PubKey
        
        // Session management
        sessions          map[string]*AuthSession
        sessionsMu        sync.RWMutex
        sessionTTL        time.Duration
        
        // Authentication configuration
        config            *SecurityConfig
}

// AuthSession represents an authenticated session
type AuthSession struct {
        PeerID    peer.ID
        Token     string
        CreatedAt time.Time
        ExpiresAt time.Time
        Metadata  map[string]interface{}
}

// SecurityManager manages security for P2P communications
type SecurityManager struct {
        host           host.Host
        
        // Key management
        keyManager     *KeyManager
        
        // Protocol handlers
        protocols      map[protocol.ID]*SecureProtocol
        protocolsMux   sync.RWMutex
        
        // Authentication
        authManager    *AuthManager
        
        // Encryption
        encryptionMgr  *EncryptionManager
        
        // Access control
        accessControl  *AccessControl
        
        // Rate limiting
        rateLimiter    *RateLimiter
        
        // Metrics
        metrics        *SecurityMetrics
        
        // Configuration
        config         *SecurityConfig
        
        // Lifecycle
        ctx            context.Context
        cancel         context.CancelFunc
        wg             sync.WaitGroup
}

// SecurityConfig holds security configuration
type SecurityConfig struct {
        SecurityLevel      string        `json:"security_level"`
        EnableEncryption   bool          `json:"enable_encryption"`
        EnableAuth         bool          `json:"enable_auth"`
        KeyRotationInterval time.Duration `json:"key_rotation_interval"`
        SessionKeyTTL      time.Duration `json:"session_key_ttl"`
        MaxConnections     int           `json:"max_connections"`
        RateLimits         map[string]int `json:"rate_limits"`
        TrustedPeers       []string      `json:"trusted_peers"`
        BlockedPeers       []string      `json:"blocked_peers"`
}

// SecurityMetrics tracks security-related metrics
type SecurityMetrics struct {
        AuthAttempts       int
        AuthFailures       int
        EncryptedSessions  int
        ActiveSessions     int
        KeyRotations       int
        BlockedConnections int
        RateLimitHits      int
        LastKeyRotation    time.Time
        StartTime          time.Time
        
        // Protocol metrics
        ProtocolMetrics    map[protocol.ID]*ProtocolMetrics
}

// ProtocolMetrics tracks metrics for specific protocols
type ProtocolMetrics struct {
        RequestCount       int
        ErrorCount         int
        AverageLatency     time.Duration
        LastActivity       time.Time
}

// SecureProtocol represents a secure protocol handler
type SecureProtocol struct {
        ID                protocol.ID
        Handler           network.StreamHandler
        
        // Security settings
        RequireAuth       bool
        RequireEncryption bool
        SecurityLevel     string
        
        // Rate limiting
        RateLimit         *RateLimit
        
        // Access control
        AccessControl     *ProtocolAccessControl
        
        // Metrics
        Metrics           *ProtocolMetrics
}

// NewSecurityManager creates a new security manager
func NewSecurityManager(ctx context.Context, host host.Host, config *SecurityConfig) (*SecurityManager, error) <span class="cov0" title="0">{
        if config == nil </span><span class="cov0" title="0">{
                config = DefaultSecurityConfig()
        }</span>
        
        <span class="cov0" title="0">ctx, cancel := context.WithCancel(ctx)
        
        sm := &amp;SecurityManager{
                host:      host,
                config:    config,
                protocols: make(map[protocol.ID]*SecureProtocol),
                metrics: &amp;SecurityMetrics{
                        StartTime:       time.Now(),
                        ProtocolMetrics: make(map[protocol.ID]*ProtocolMetrics),
                },
                ctx:    ctx,
                cancel: cancel,
        }
        
        // Initialize components
        if err := sm.initializeComponents(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to initialize security components: %w", err)
        }</span>
        
        // Setup protocol handlers
        <span class="cov0" title="0">sm.setupProtocolHandlers()
        
        // Start background tasks
        sm.startBackgroundTasks()
        
        log.Printf("Security manager initialized with level: %s", config.SecurityLevel)
        return sm, nil</span>
}

// initializeComponents initializes security components
func (sm *SecurityManager) initializeComponents() error <span class="cov0" title="0">{
        // Initialize key manager
        keyManager, err := NewKeyManager(sm.host, sm.config)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to initialize key manager: %w", err)
        }</span>
        <span class="cov0" title="0">sm.keyManager = keyManager
        
        // Initialize authentication manager
        authManager, err := NewAuthManager(sm.host, sm.config)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to initialize auth manager: %w", err)
        }</span>
        <span class="cov0" title="0">sm.authManager = authManager
        
        // Initialize encryption manager
        encryptionMgr, err := NewEncryptionManager(sm.keyManager, sm.config)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to initialize encryption manager: %w", err)
        }</span>
        <span class="cov0" title="0">sm.encryptionMgr = encryptionMgr
        
        // Initialize access control
        accessControl, err := NewAccessControl(sm.config)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to initialize access control: %w", err)
        }</span>
        <span class="cov0" title="0">sm.accessControl = accessControl
        
        // Initialize rate limiter
        rateLimiter, err := NewRateLimiter(sm.config)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to initialize rate limiter: %w", err)
        }</span>
        <span class="cov0" title="0">sm.rateLimiter = rateLimiter
        
        return nil</span>
}

// setupProtocolHandlers sets up secure protocol handlers
func (sm *SecurityManager) setupProtocolHandlers() <span class="cov0" title="0">{
        // Secure channel protocol
        sm.RegisterSecureProtocol(SecureChannelProtocol, &amp;SecureProtocol{
                ID:                SecureChannelProtocol,
                Handler:           sm.handleSecureChannel,
                RequireAuth:       true,
                RequireEncryption: true,
                SecurityLevel:     SecurityLevelHigh,
                RateLimit:         &amp;RateLimit{RequestsPerSecond: 10, BurstSize: 20},
                AccessControl:     &amp;ProtocolAccessControl{AllowAll: false},
                Metrics:           &amp;ProtocolMetrics{},
        })
        
        // Authentication protocol
        sm.RegisterSecureProtocol(AuthProtocol, &amp;SecureProtocol{
                ID:                AuthProtocol,
                Handler:           sm.handleAuth,
                RequireAuth:       false,
                RequireEncryption: true,
                SecurityLevel:     SecurityLevelHigh,
                RateLimit:         &amp;RateLimit{RequestsPerSecond: 5, BurstSize: 10},
                AccessControl:     &amp;ProtocolAccessControl{AllowAll: true},
                Metrics:           &amp;ProtocolMetrics{},
        })
        
        // Key exchange protocol
        sm.RegisterSecureProtocol(KeyExchangeProtocol, &amp;SecureProtocol{
                ID:                KeyExchangeProtocol,
                Handler:           sm.handleKeyExchange,
                RequireAuth:       false,
                RequireEncryption: false,
                SecurityLevel:     SecurityLevelBasic,
                RateLimit:         &amp;RateLimit{RequestsPerSecond: 2, BurstSize: 5},
                AccessControl:     &amp;ProtocolAccessControl{AllowAll: true},
                Metrics:           &amp;ProtocolMetrics{},
        })
}</span>

// startBackgroundTasks starts background security tasks
func (sm *SecurityManager) startBackgroundTasks() <span class="cov0" title="0">{
        // Key rotation
        sm.wg.Add(1)
        go sm.keyRotationTask()
        
        // Metrics collection
        sm.wg.Add(1)
        go sm.metricsTask()
        
        // Rate limit cleanup
        sm.wg.Add(1)
        go sm.rateLimitCleanupTask()
        
        // Session cleanup
        sm.wg.Add(1)
        go sm.sessionCleanupTask()
}</span>

// RegisterSecureProtocol registers a secure protocol handler
func (sm *SecurityManager) RegisterSecureProtocol(protocolID protocol.ID, protocol *SecureProtocol) <span class="cov0" title="0">{
        sm.protocolsMux.Lock()
        defer sm.protocolsMux.Unlock()
        
        // Wrap handler with security middleware
        wrappedHandler := sm.wrapHandler(protocol)
        
        sm.host.SetStreamHandler(protocolID, wrappedHandler)
        sm.protocols[protocolID] = protocol
        sm.metrics.ProtocolMetrics[protocolID] = protocol.Metrics
        
        log.Printf("Registered secure protocol: %s", protocolID)
}</span>

// wrapHandler wraps a protocol handler with security middleware
func (sm *SecurityManager) wrapHandler(protocol *SecureProtocol) network.StreamHandler <span class="cov0" title="0">{
        return func(stream network.Stream) </span><span class="cov0" title="0">{
                start := time.Now()
                peerID := stream.Conn().RemotePeer()
                
                // Update metrics
                protocol.Metrics.RequestCount++
                protocol.Metrics.LastActivity = time.Now()
                
                // Check access control
                if !sm.accessControl.IsAllowed(peerID, protocol.ID) </span><span class="cov0" title="0">{
                        log.Printf("Access denied for peer %s on protocol %s", peerID, protocol.ID)
                        stream.Reset()
                        return
                }</span>
                
                // Check rate limits
                <span class="cov0" title="0">if !sm.rateLimiter.Allow(peerID, protocol.ID) </span><span class="cov0" title="0">{
                        log.Printf("Rate limit exceeded for peer %s on protocol %s", peerID, protocol.ID)
                        sm.metrics.RateLimitHits++
                        stream.Reset()
                        return
                }</span>
                
                // Check authentication if required
                <span class="cov0" title="0">if protocol.RequireAuth </span><span class="cov0" title="0">{
                        if !sm.authManager.IsAuthenticated(peerID) </span><span class="cov0" title="0">{
                                log.Printf("Authentication required for peer %s on protocol %s", peerID, protocol.ID)
                                stream.Reset()
                                return
                        }</span>
                }
                
                // Handle encryption if required
                <span class="cov0" title="0">if protocol.RequireEncryption </span><span class="cov0" title="0">{
                        if !sm.isEncryptedConnection(stream.Conn()) </span><span class="cov0" title="0">{
                                log.Printf("Encryption required for peer %s on protocol %s", peerID, protocol.ID)
                                stream.Reset()
                                return
                        }</span>
                }
                
                // Call original handler
                <span class="cov0" title="0">protocol.Handler(stream)
                
                // Update latency metrics
                protocol.Metrics.AverageLatency = time.Since(start)</span>
        }
}

// EstablishSecureChannel establishes a secure channel with a peer
func (sm *SecurityManager) EstablishSecureChannel(ctx context.Context, peerID peer.ID) (*SecureChannel, error) <span class="cov0" title="0">{
        // Create new stream
        stream, err := sm.host.NewStream(ctx, peerID, SecureChannelProtocol)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create stream: %w", err)
        }</span>
        
        // Perform handshake
        <span class="cov0" title="0">sessionKey, err := sm.performHandshake(ctx, stream)
        if err != nil </span><span class="cov0" title="0">{
                stream.Close()
                return nil, fmt.Errorf("handshake failed: %w", err)
        }</span>
        
        // Create secure channel
        <span class="cov0" title="0">channel := &amp;SecureChannel{
                Stream:     stream,
                SessionKey: sessionKey,
                Peer:       peerID,
                CreatedAt:  time.Now(),
                manager:    sm,
        }
        
        sm.metrics.EncryptedSessions++
        sm.metrics.ActiveSessions++
        
        return channel, nil</span>
}

// performHandshake performs security handshake
func (sm *SecurityManager) performHandshake(ctx context.Context, stream network.Stream) (*SessionKey, error) <span class="cov0" title="0">{
        // Generate session key
        sessionKey, err := sm.keyManager.GenerateSessionKey()
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to generate session key: %w", err)
        }</span>
        
        // Perform noise protocol handshake
        <span class="cov0" title="0">handshake := &amp;HandshakeMessage{
                Type:      "key_exchange",
                PublicKey: sessionKey.PublicKey,
                Timestamp: time.Now(),
        }
        
        // Send handshake
        if err := sm.sendHandshake(stream, handshake); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to send handshake: %w", err)
        }</span>
        
        // Receive response
        <span class="cov0" title="0">response, err := sm.receiveHandshake(stream)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to receive handshake response: %w", err)
        }</span>
        
        // Verify response
        <span class="cov0" title="0">if err := sm.verifyHandshake(response); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("handshake verification failed: %w", err)
        }</span>
        
        <span class="cov0" title="0">return sessionKey, nil</span>
}

// Protocol handlers

// handleSecureChannel handles secure channel establishment
func (sm *SecurityManager) handleSecureChannel(stream network.Stream) <span class="cov0" title="0">{
        defer stream.Close()
        
        // Handle handshake
        handshake, err := sm.receiveHandshake(stream)
        if err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to receive handshake: %v", err)
                return
        }</span>
        
        // Verify handshake
        <span class="cov0" title="0">if err := sm.verifyHandshake(handshake); err != nil </span><span class="cov0" title="0">{
                log.Printf("Handshake verification failed: %v", err)
                return
        }</span>
        
        // Generate session key
        <span class="cov0" title="0">sessionKey, err := sm.keyManager.GenerateSessionKey()
        if err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to generate session key: %v", err)
                return
        }</span>
        
        // Send response
        <span class="cov0" title="0">response := &amp;HandshakeMessage{
                Type:      "key_exchange_response",
                PublicKey: sessionKey.PublicKey,
                Timestamp: time.Now(),
        }
        
        if err := sm.sendHandshake(stream, response); err != nil </span><span class="cov0" title="0">{
                log.Printf("Failed to send handshake response: %v", err)
                return
        }</span>
        
        <span class="cov0" title="0">log.Printf("Secure channel established with peer: %s", stream.Conn().RemotePeer())</span>
}

// handleAuth handles authentication requests
func (sm *SecurityManager) handleAuth(stream network.Stream) <span class="cov0" title="0">{
        defer stream.Close()
        
        // Handle authentication
        if err := sm.authManager.HandleAuthRequest(stream); err != nil </span><span class="cov0" title="0">{
                log.Printf("Authentication failed: %v", err)
                return
        }</span>
        
        <span class="cov0" title="0">sm.metrics.AuthAttempts++
        log.Printf("Authentication successful for peer: %s", stream.Conn().RemotePeer())</span>
}

// handleKeyExchange handles key exchange requests
func (sm *SecurityManager) handleKeyExchange(stream network.Stream) <span class="cov0" title="0">{
        defer stream.Close()
        
        // Handle key exchange
        if err := sm.keyManager.HandleKeyExchange(stream); err != nil </span><span class="cov0" title="0">{
                log.Printf("Key exchange failed: %v", err)
                return
        }</span>
        
        <span class="cov0" title="0">log.Printf("Key exchange successful with peer: %s", stream.Conn().RemotePeer())</span>
}

// Background tasks

// keyRotationTask handles periodic key rotation
func (sm *SecurityManager) keyRotationTask() <span class="cov0" title="0">{
        defer sm.wg.Done()
        
        ticker := time.NewTicker(sm.config.KeyRotationInterval)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-sm.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        if err := sm.keyManager.RotateKeys(); err != nil </span><span class="cov0" title="0">{
                                log.Printf("Key rotation failed: %v", err)
                        }</span> else<span class="cov0" title="0"> {
                                sm.metrics.KeyRotations++
                                sm.metrics.LastKeyRotation = time.Now()
                                log.Printf("Key rotation completed")
                        }</span>
                }
        }
}

// metricsTask collects security metrics
func (sm *SecurityManager) metricsTask() <span class="cov0" title="0">{
        defer sm.wg.Done()
        
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-sm.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        sm.updateMetrics()</span>
                }
        }
}

// updateMetrics updates security metrics
func (sm *SecurityManager) updateMetrics() <span class="cov0" title="0">{
        // Update active sessions
        sm.metrics.ActiveSessions = sm.keyManager.GetActiveSessionCount()
        
        // Update protocol metrics
        for protocolID, protocol := range sm.protocols </span><span class="cov0" title="0">{
                if metrics, exists := sm.metrics.ProtocolMetrics[protocolID]; exists </span><span class="cov0" title="0">{
                        metrics.RequestCount = protocol.Metrics.RequestCount
                        metrics.ErrorCount = protocol.Metrics.ErrorCount
                        metrics.AverageLatency = protocol.Metrics.AverageLatency
                        metrics.LastActivity = protocol.Metrics.LastActivity
                }</span>
        }
}

// rateLimitCleanupTask cleans up expired rate limit entries
func (sm *SecurityManager) rateLimitCleanupTask() <span class="cov0" title="0">{
        defer sm.wg.Done()
        
        ticker := time.NewTicker(5 * time.Minute)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-sm.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        sm.rateLimiter.Cleanup()</span>
                }
        }
}

// sessionCleanupTask cleans up expired sessions
func (sm *SecurityManager) sessionCleanupTask() <span class="cov0" title="0">{
        defer sm.wg.Done()
        
        ticker := time.NewTicker(10 * time.Minute)
        defer ticker.Stop()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-sm.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        sm.keyManager.CleanupExpiredSessions()</span>
                }
        }
}

// Utility methods

// isEncryptedConnection checks if connection is encrypted
func (sm *SecurityManager) isEncryptedConnection(conn network.Conn) bool <span class="cov0" title="0">{
        // Check if connection uses encrypted transport
        // For libp2p, connections are generally encrypted by default
        return true
}</span>

// sendHandshake sends handshake message
func (sm *SecurityManager) sendHandshake(stream network.Stream, handshake *HandshakeMessage) error <span class="cov0" title="0">{
        data, err := json.Marshal(handshake)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal handshake: %w", err)
        }</span>
        
        <span class="cov0" title="0">_, err = stream.Write(data)
        return err</span>
}

// receiveHandshake receives handshake message
func (sm *SecurityManager) receiveHandshake(stream network.Stream) (*HandshakeMessage, error) <span class="cov0" title="0">{
        buf := make([]byte, 4096)
        n, err := stream.Read(buf)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to read handshake: %w", err)
        }</span>
        
        <span class="cov0" title="0">var handshake HandshakeMessage
        if err := json.Unmarshal(buf[:n], &amp;handshake); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to unmarshal handshake: %w", err)
        }</span>
        
        <span class="cov0" title="0">return &amp;handshake, nil</span>
}

// verifyHandshake verifies handshake message
func (sm *SecurityManager) verifyHandshake(handshake *HandshakeMessage) error <span class="cov0" title="0">{
        // Check timestamp
        if time.Since(handshake.Timestamp) &gt; 5*time.Minute </span><span class="cov0" title="0">{
                return fmt.Errorf("handshake timestamp too old")
        }</span>
        
        // Verify signature if present
        <span class="cov0" title="0">if handshake.Signature != nil </span><span class="cov0" title="0">{
                // Implement proper signature verification
                if err := sm.verifyHandshakeSignature(handshake); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("signature verification failed: %w", err)
                }</span>
        }
        
        <span class="cov0" title="0">return nil</span>
}

// verifyHandshakeSignature verifies the cryptographic signature of a handshake
func (sm *SecurityManager) verifyHandshakeSignature(handshake *HandshakeMessage) error <span class="cov0" title="0">{
        // Create message hash for signature verification
        messageData := fmt.Sprintf("%s:%x:%d", handshake.Type, handshake.PublicKey, handshake.Timestamp.Unix())
        
        // Get peer's public key from key manager
        peerPubKey, err := sm.keyManager.GetPeerPublicKey(handshake.PublicKey)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get peer public key: %w", err)
        }</span>
        
        // Verify signature using libp2p crypto
        <span class="cov0" title="0">valid, err := peerPubKey.Verify([]byte(messageData), handshake.Signature)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("signature verification error: %w", err)
        }</span>
        
        <span class="cov0" title="0">if !valid </span><span class="cov0" title="0">{
                return fmt.Errorf("invalid signature")
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// GetMetrics returns security metrics
func (sm *SecurityManager) GetMetrics() *SecurityMetrics <span class="cov0" title="0">{
        return sm.metrics
}</span>

// GetConfig returns security configuration
func (sm *SecurityManager) GetConfig() *SecurityConfig <span class="cov0" title="0">{
        return sm.config
}</span>

// Close closes the security manager
func (sm *SecurityManager) Close() error <span class="cov0" title="0">{
        log.Printf("Closing security manager")
        sm.cancel()
        sm.wg.Wait()
        
        if sm.keyManager != nil </span><span class="cov0" title="0">{
                sm.keyManager.Close()
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// DefaultSecurityConfig returns default security configuration
func DefaultSecurityConfig() *SecurityConfig <span class="cov0" title="0">{
        return &amp;SecurityConfig{
                SecurityLevel:       SecurityLevelBasic,
                EnableEncryption:    true,
                EnableAuth:          true,
                KeyRotationInterval: DefaultKeyRotationInterval,
                SessionKeyTTL:       SessionKeyTTL,
                MaxConnections:      100,
                RateLimits: map[string]int{
                        "default": 10,
                        "auth":    5,
                        "key":     2,
                },
                TrustedPeers: []string{},
                BlockedPeers: []string{},
        }
}</span>

// HandshakeMessage represents a security handshake message
type HandshakeMessage struct {
        Type      string    `json:"type"`
        PublicKey []byte    `json:"public_key"`
        Timestamp time.Time `json:"timestamp"`
        Signature []byte    `json:"signature,omitempty"`
}

// SecureChannel represents a secure communication channel
type SecureChannel struct {
        Stream     network.Stream
        SessionKey *SessionKey
        Peer       peer.ID
        CreatedAt  time.Time
        manager    *SecurityManager
}

// Close closes the secure channel
func (sc *SecureChannel) Close() error <span class="cov0" title="0">{
        sc.manager.metrics.ActiveSessions--
        return sc.Stream.Close()
}</span>

// Send sends encrypted data through the channel
func (sc *SecureChannel) Send(data []byte) error <span class="cov0" title="0">{
        encrypted, err := sc.manager.encryptionMgr.Encrypt(data, sc.SessionKey)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to encrypt data: %w", err)
        }</span>
        
        <span class="cov0" title="0">_, err = sc.Stream.Write(encrypted)
        return err</span>
}

// Receive receives and decrypts data from the channel
func (sc *SecureChannel) Receive() ([]byte, error) <span class="cov0" title="0">{
        buf := make([]byte, 4096)
        n, err := sc.Stream.Read(buf)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to read data: %w", err)
        }</span>
        
        <span class="cov0" title="0">return sc.manager.encryptionMgr.Decrypt(buf[:n], sc.SessionKey)</span>
}

// ===============================
// Implementation Functions
// ===============================

// NewKeyManager creates a new key manager
func NewKeyManager(host host.Host, config *SecurityConfig) (*KeyManager, error) <span class="cov0" title="0">{
        return &amp;KeyManager{
                sessionKeys: make(map[string]*SessionKey),
                peerKeys:    make(map[string]crypto.PubKey),
                config:      config,
        }, nil
}</span>

// GenerateSessionKey generates a new session key
func (km *KeyManager) GenerateSessionKey() (*SessionKey, error) <span class="cov0" title="0">{
        // Generate RSA key pair
        privateKey, err := rsa.GenerateKey(rand.Reader, 2048)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to generate private key: %w", err)
        }</span>

        // Marshal private key
        <span class="cov0" title="0">privateKeyBytes := x509.MarshalPKCS1PrivateKey(privateKey)
        privateKeyPEM := pem.EncodeToMemory(&amp;pem.Block{
                Type:  "RSA PRIVATE KEY",
                Bytes: privateKeyBytes,
        })

        // Marshal public key
        publicKeyBytes, err := x509.MarshalPKIXPublicKey(&amp;privateKey.PublicKey)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to marshal public key: %w", err)
        }</span>

        <span class="cov0" title="0">publicKeyPEM := pem.EncodeToMemory(&amp;pem.Block{
                Type:  "PUBLIC KEY",
                Bytes: publicKeyBytes,
        })

        sessionKey := &amp;SessionKey{
                PublicKey:  publicKeyPEM,
                PrivateKey: privateKeyPEM,
                CreatedAt:  time.Now(),
                ExpiresAt:  time.Now().Add(4 * time.Hour),
        }

        km.keysMu.Lock()
        km.sessionKeys[string(publicKeyPEM)] = sessionKey
        km.keysMu.Unlock()

        return sessionKey, nil</span>
}

// GetPeerPublicKey retrieves a peer's public key
func (km *KeyManager) GetPeerPublicKey(publicKey []byte) (crypto.PubKey, error) <span class="cov0" title="0">{
        km.peerKeysMu.RLock()
        defer km.peerKeysMu.RUnlock()

        keyStr := string(publicKey)
        if pubKey, exists := km.peerKeys[keyStr]; exists </span><span class="cov0" title="0">{
                return pubKey, nil
        }</span>

        // Parse PEM encoded public key
        <span class="cov0" title="0">block, _ := pem.Decode(publicKey)
        if block == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to decode PEM block")
        }</span>

        <span class="cov0" title="0">pub, err := x509.ParsePKIXPublicKey(block.Bytes)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to parse public key: %w", err)
        }</span>

        // Convert to libp2p crypto.PubKey
        <span class="cov0" title="0">rsaPub, ok := pub.(*rsa.PublicKey)
        if !ok </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("unsupported public key type")
        }</span>

        <span class="cov0" title="0">_, libp2pKey, err := crypto.KeyPairFromStdKey(rsaPub)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to convert to libp2p key: %w", err)
        }</span>

        // Cache the key
        <span class="cov0" title="0">km.peerKeys[keyStr] = libp2pKey
        return libp2pKey, nil</span>
}

// GetActiveSessionCount returns the number of active sessions
func (km *KeyManager) GetActiveSessionCount() int <span class="cov0" title="0">{
        km.keysMu.RLock()
        defer km.keysMu.RUnlock()
        
        activeCount := 0
        now := time.Now()
        for _, session := range km.sessionKeys </span><span class="cov0" title="0">{
                if session.ExpiresAt.After(now) </span><span class="cov0" title="0">{
                        activeCount++
                }</span>
        }
        <span class="cov0" title="0">return activeCount</span>
}

// CleanupExpiredSessions removes expired sessions
func (km *KeyManager) CleanupExpiredSessions() <span class="cov0" title="0">{
        km.keysMu.Lock()
        defer km.keysMu.Unlock()
        
        now := time.Now()
        for keyStr, session := range km.sessionKeys </span><span class="cov0" title="0">{
                if session.ExpiresAt.Before(now) </span><span class="cov0" title="0">{
                        delete(km.sessionKeys, keyStr)
                }</span>
        }
}

// HandleKeyExchange handles key exchange requests
func (km *KeyManager) HandleKeyExchange(stream network.Stream) error <span class="cov0" title="0">{
        // Stub implementation for key exchange
        defer stream.Close()
        return nil
}</span>

// RotateKeys rotates all session keys
func (km *KeyManager) RotateKeys() error <span class="cov0" title="0">{
        // Generate new session keys and mark old ones for expiration
        km.keysMu.Lock()
        defer km.keysMu.Unlock()
        
        // Mark all current keys as expiring soon
        expireTime := time.Now().Add(1 * time.Hour)
        for _, session := range km.sessionKeys </span><span class="cov0" title="0">{
                if session.ExpiresAt.After(expireTime) </span><span class="cov0" title="0">{
                        session.ExpiresAt = expireTime
                }</span>
        }
        
        <span class="cov0" title="0">return nil</span>
}

// Close closes the key manager
func (km *KeyManager) Close() error <span class="cov0" title="0">{
        km.keysMu.Lock()
        defer km.keysMu.Unlock()
        
        // Clear all sessions
        km.sessionKeys = make(map[string]*SessionKey)
        km.peerKeys = make(map[string]crypto.PubKey)
        
        return nil
}</span>

// NewAuthManager creates a new authentication manager
func NewAuthManager(host host.Host, config *SecurityConfig) (*AuthManager, error) <span class="cov0" title="0">{
        // Generate key pair for authentication
        privateKey, publicKey, err := crypto.GenerateKeyPair(crypto.RSA, 2048)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to generate key pair: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;AuthManager{
                authenticatedPeers: make(map[peer.ID]time.Time),
                privateKey:         privateKey,
                publicKey:          publicKey,
                sessions:           make(map[string]*AuthSession),
                sessionTTL:         4 * time.Hour,
                config:             config,
        }, nil</span>
}

// IsAuthenticated checks if a peer is authenticated
func (am *AuthManager) IsAuthenticated(peerID peer.ID) bool <span class="cov0" title="0">{
        am.peersMu.RLock()
        defer am.peersMu.RUnlock()
        
        if authTime, exists := am.authenticatedPeers[peerID]; exists </span><span class="cov0" title="0">{
                return time.Since(authTime) &lt; am.sessionTTL
        }</span>
        <span class="cov0" title="0">return false</span>
}

// HandleAuthRequest handles authentication requests
func (am *AuthManager) HandleAuthRequest(stream network.Stream) error <span class="cov0" title="0">{
        // Stub implementation for authentication
        defer stream.Close()
        return nil
}</span>

// NewEncryptionManager creates a new encryption manager
func NewEncryptionManager(keyManager *KeyManager, config *SecurityConfig) (*EncryptionManager, error) <span class="cov0" title="0">{
        return &amp;EncryptionManager{
                keyManager: keyManager,
                config:     config,
        }, nil
}</span>

// Encrypt encrypts data using session key
func (em *EncryptionManager) Encrypt(data []byte, sessionKey *SessionKey) ([]byte, error) <span class="cov0" title="0">{
        // Stub implementation - return data as-is for compatibility
        return data, nil
}</span>

// Decrypt decrypts data using session key
func (em *EncryptionManager) Decrypt(data []byte, sessionKey *SessionKey) ([]byte, error) <span class="cov0" title="0">{
        // Stub implementation - return data as-is for compatibility
        return data, nil
}</span>

// NewAccessControl creates a new access control manager
func NewAccessControl(config *SecurityConfig) (*AccessControl, error) <span class="cov0" title="0">{
        return &amp;AccessControl{
                policies: make(map[peer.ID]*AccessPolicy),
                config:   config,
        }, nil
}</span>

// IsAllowed checks if a peer is allowed to access a protocol
func (ac *AccessControl) IsAllowed(peerID peer.ID, protocolID protocol.ID) bool <span class="cov0" title="0">{
        ac.policyMu.RLock()
        defer ac.policyMu.RUnlock()
        
        // Check if peer is in blocked list
        for _, blockedPeer := range ac.config.BlockedPeers </span><span class="cov0" title="0">{
                if blockedPeer == peerID.String() </span><span class="cov0" title="0">{
                        return false
                }</span>
        }
        
        // Check if peer is in trusted list
        <span class="cov0" title="0">for _, trustedPeer := range ac.config.TrustedPeers </span><span class="cov0" title="0">{
                if trustedPeer == peerID.String() </span><span class="cov0" title="0">{
                        return true
                }</span>
        }
        
        // Default policy - allow if no specific policy
        <span class="cov0" title="0">return true</span>
}

// NewRateLimiter creates a new rate limiter
func NewRateLimiter(config *SecurityConfig) (*RateLimiter, error) <span class="cov0" title="0">{
        return &amp;RateLimiter{
                limits: make(map[string]*RateLimit),
                config: config,
        }, nil
}</span>

// Allow checks if a request is allowed under rate limits
func (rl *RateLimiter) Allow(peerID peer.ID, protocolID protocol.ID) bool <span class="cov0" title="0">{
        rl.limitMu.Lock()
        defer rl.limitMu.Unlock()
        
        key := fmt.Sprintf("%s:%s", peerID.String(), protocolID)
        
        limit, exists := rl.limits[key]
        if !exists </span><span class="cov0" title="0">{
                // Create new rate limit for this peer/protocol
                limit = &amp;RateLimit{
                        RequestsPerSecond: 10, // Default
                        BurstSize:        20,
                        Window:           1 * time.Second,
                        lastReset:        time.Now(),
                        currentCount:     0,
                }
                rl.limits[key] = limit
        }</span>
        
        <span class="cov0" title="0">now := time.Now()
        
        // Reset counter if window has passed
        if now.Sub(limit.lastReset) &gt;= limit.Window </span><span class="cov0" title="0">{
                limit.currentCount = 0
                limit.lastReset = now
        }</span>
        
        // Check if limit is exceeded
        <span class="cov0" title="0">if limit.currentCount &gt;= limit.RequestsPerSecond </span><span class="cov0" title="0">{
                return false
        }</span>
        
        <span class="cov0" title="0">limit.currentCount++
        return true</span>
}

// Cleanup removes old rate limit entries
func (rl *RateLimiter) Cleanup() <span class="cov0" title="0">{
        rl.limitMu.Lock()
        defer rl.limitMu.Unlock()
        
        now := time.Now()
        for key, limit := range rl.limits </span><span class="cov0" title="0">{
                if now.Sub(limit.lastReset) &gt; 5*time.Minute </span><span class="cov0" title="0">{
                        delete(rl.limits, key)
                }</span>
        }
}</pre>
		
		<pre class="file" id="file40" style="display: none">package scheduler

import (
        "context"
        "fmt"
        "sync"
        "time"

        "github.com/libp2p/go-libp2p/core/peer"
        "github.com/ollama/ollama-distributed/internal/config"
        "github.com/ollama/ollama-distributed/pkg/consensus"
        "github.com/ollama/ollama-distributed/pkg/p2p"
)

// Engine represents the distributed scheduling engine
type Engine struct {
        config    *config.SchedulerConfig
        p2p       *p2p.Node
        consensus *consensus.Engine

        // Model registry
        models   map[string]*ModelInfo
        modelsMu sync.RWMutex

        // Node registry
        nodes   map[string]*NodeInfo
        nodesMu sync.RWMutex

        // Request queue
        requests chan *Request

        // Workers
        workers   []*Worker
        workersMu sync.RWMutex

        // Health checker
        healthChecker *HealthChecker

        // Load balancer
        loadBalancer *LoadBalancer

        // Statistics
        stats     *Stats
        statsMu   sync.RWMutex
        startTime time.Time

        started bool
        mu      sync.RWMutex

        ctx    context.Context
        cancel context.CancelFunc
}

// ModelInfo represents information about a model
type ModelInfo struct {
        Name         string            `json:"name"`
        Size         int64             `json:"size"`
        Checksum     string            `json:"checksum"`
        Locations    []string          `json:"locations"` // Node IDs that have this model
        AccessCount  int64             `json:"access_count"`
        LastAccessed time.Time         `json:"last_accessed"`
        Metadata     map[string]string `json:"metadata"`
}

// NodeInfo represents information about a node
type NodeInfo struct {
        ID       string            `json:"id"`
        Address  string            `json:"address"`
        Status   NodeStatus        `json:"status"`
        Capacity NodeCapacity      `json:"capacity"`
        Usage    NodeUsage         `json:"usage"`
        Models   []string          `json:"models"`
        LastSeen time.Time         `json:"last_seen"`
        Metadata map[string]string `json:"metadata"`
}

// NodeStatus represents the status of a node
type NodeStatus string

const (
        NodeStatusOnline      NodeStatus = "online"
        NodeStatusOffline     NodeStatus = "offline"
        NodeStatusDraining    NodeStatus = "draining"
        NodeStatusMaintenance NodeStatus = "maintenance"
)

// NodeCapacity represents the capacity of a node
type NodeCapacity struct {
        CPU    int64 `json:"cpu"`    // CPU cores
        Memory int64 `json:"memory"` // Memory in bytes
        Disk   int64 `json:"disk"`   // Disk space in bytes
        GPU    int64 `json:"gpu"`    // GPU count
}

// NodeUsage represents the current usage of a node
type NodeUsage struct {
        CPU    float64 `json:"cpu"`    // CPU usage percentage
        Memory float64 `json:"memory"` // Memory usage percentage
        Disk   float64 `json:"disk"`   // Disk usage percentage
        GPU    float64 `json:"gpu"`    // GPU usage percentage
}

// Request represents a request for model inference
type Request struct {
        ID        string            `json:"id"`
        ModelName string            `json:"model_name"`
        Type      string            `json:"type"`
        Priority  int               `json:"priority"`
        Timeout   time.Duration     `json:"timeout"`
        Metadata  map[string]string `json:"metadata"`
        Payload   map[string]interface{} `json:"payload"`

        // Response channel
        ResponseCh chan *Response

        // Timing
        CreatedAt   time.Time `json:"created_at"`
        ScheduledAt time.Time `json:"scheduled_at"`
        CompletedAt time.Time `json:"completed_at"`
}

// Response represents a response to a request
type Response struct {
        RequestID string        `json:"request_id"`
        NodeID    string        `json:"node_id"`
        Success   bool          `json:"success"`
        Error     string        `json:"error,omitempty"`
        Data      interface{}   `json:"data,omitempty"`
        Duration  time.Duration `json:"duration"`
}

// Stats represents scheduler statistics
type Stats struct {
        TotalRequests     int64         `json:"total_requests"`
        CompletedRequests int64         `json:"completed_requests"`
        FailedRequests    int64         `json:"failed_requests"`
        QueuedRequests    int64         `json:"queued_requests"`
        AverageLatency    time.Duration `json:"average_latency"`
        NodesTotal        int           `json:"nodes_total"`
        NodesOnline       int           `json:"nodes_online"`
        NodesOffline      int           `json:"nodes_offline"`
        ModelsTotal       int           `json:"models_total"`
        WorkersActive     int           `json:"workers_active"`
        Uptime            time.Duration `json:"uptime"`
        LastUpdated       time.Time     `json:"last_updated"`
}

// Worker represents a worker that processes requests
type Worker struct {
        ID     int
        engine *Engine
        stopCh chan struct{}
}

// HealthChecker monitors node health
type HealthChecker struct {
        engine   *Engine
        interval time.Duration
        stopCh   chan struct{}
}

// LoadBalancer handles load balancing algorithms
type LoadBalancer struct {
        algorithm string
        engine    *Engine
}

// NewEngine creates a new scheduling engine
func NewEngine(config *config.SchedulerConfig, p2pNode *p2p.Node, consensusEngine *consensus.Engine) (*Engine, error) <span class="cov0" title="0">{
        ctx, cancel := context.WithCancel(context.Background())

        engine := &amp;Engine{
                config:    config,
                p2p:       p2pNode,
                consensus: consensusEngine,
                models:    make(map[string]*ModelInfo),
                nodes:     make(map[string]*NodeInfo),
                requests:  make(chan *Request, config.QueueSize),
                stats:     &amp;Stats{LastUpdated: time.Now()},
                startTime: time.Now(),
                ctx:       ctx,
                cancel:    cancel,
        }

        // Initialize health checker
        engine.healthChecker = &amp;HealthChecker{
                engine:   engine,
                interval: config.HealthCheckInterval,
                stopCh:   make(chan struct{}),
        }

        // Initialize load balancer
        engine.loadBalancer = &amp;LoadBalancer{
                algorithm: config.LoadBalancing,
                engine:    engine,
        }

        // Create workers
        engine.workers = make([]*Worker, config.WorkerCount)
        for i := 0; i &lt; config.WorkerCount; i++ </span><span class="cov0" title="0">{
                engine.workers[i] = &amp;Worker{
                        ID:     i,
                        engine: engine,
                        stopCh: make(chan struct{}),
                }
        }</span>

        <span class="cov0" title="0">return engine, nil</span>
}

// Start starts the scheduling engine
func (e *Engine) Start() error <span class="cov0" title="0">{
        e.mu.Lock()
        defer e.mu.Unlock()

        if e.started </span><span class="cov0" title="0">{
                return fmt.Errorf("scheduler already started")
        }</span>

        // Start workers
        <span class="cov0" title="0">for _, worker := range e.workers </span><span class="cov0" title="0">{
                go worker.start()
        }</span>

        // Start health checker
        <span class="cov0" title="0">go e.healthChecker.start()

        // Start node discovery
        go e.discoverNodes()

        // Start model registry sync
        go e.syncModelRegistry()

        e.started = true
        return nil</span>
}

// discoverNodes discovers nodes in the network
func (e *Engine) discoverNodes() <span class="cov0" title="0">{
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-e.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        e.updateNodeRegistry()</span>
                }
        }
}

// updateNodeRegistry updates the node registry from P2P peers
func (e *Engine) updateNodeRegistry() <span class="cov0" title="0">{
        defer func() </span><span class="cov0" title="0">{
                if r := recover(); r != nil </span><span class="cov0" title="0">{
                        fmt.Printf("Recovered from panic in updateNodeRegistry: %v\n", r)
                }</span>
        }()

        // Safely check if P2P is available
        <span class="cov0" title="0">if e.p2p == nil </span><span class="cov0" title="0">{
                fmt.Printf("Warning: P2P node is nil, skipping node registry update\n")
                return
        }</span>

        <span class="cov0" title="0">peers := e.p2p.GetAllPeers()
        if peers == nil </span><span class="cov0" title="0">{
                fmt.Printf("Warning: No peers found from P2P node\n")
                return
        }</span>

        <span class="cov0" title="0">e.nodesMu.Lock()
        defer e.nodesMu.Unlock()

        // Update existing nodes and add new ones
        for peerID, peerInfo := range peers </span><span class="cov0" title="0">{
                nodeID := peerID.String()

                if node, exists := e.nodes[nodeID]; exists </span><span class="cov0" title="0">{
                        // Update existing node
                        node.Status = NodeStatusOnline
                        node.LastSeen = time.Now()
                }</span> else<span class="cov0" title="0"> {
                        // Add new node with safe address handling
                        var address string
                        if len(peerInfo.Addresses) &gt; 0 </span><span class="cov0" title="0">{
                                address = peerInfo.Addresses[0]
                        }</span> else<span class="cov0" title="0"> {
                                address = "unknown"
                        }</span>

                        // Get node capabilities from P2P metadata
                        <span class="cov0" title="0">capacity := NodeCapacity{
                                CPU:    4,  // Default values
                                Memory: 8 * 1024 * 1024 * 1024, // 8GB
                                Disk:   100 * 1024 * 1024 * 1024, // 100GB
                                GPU:    0,
                        }

                        usage := NodeUsage{
                                CPU:    0.0,
                                Memory: 0.0,
                                Disk:   0.0,
                                GPU:    0.0,
                        }

                        e.nodes[nodeID] = &amp;NodeInfo{
                                ID:       nodeID,
                                Address:  address,
                                Status:   NodeStatusOnline,
                                Capacity: capacity,
                                Usage:    usage,
                                Models:   []string{},
                                LastSeen: time.Now(),
                                Metadata: make(map[string]string),
                        }</span>
                }
        }

        // Mark offline nodes
        <span class="cov0" title="0">for _, node := range e.nodes </span><span class="cov0" title="0">{
                if time.Since(node.LastSeen) &gt; 5*time.Minute </span><span class="cov0" title="0">{
                        node.Status = NodeStatusOffline
                }</span>
        }
}

// syncModelRegistry syncs the model registry with consensus
func (e *Engine) syncModelRegistry() <span class="cov0" title="0">{
        ticker := time.NewTicker(60 * time.Second)
        defer ticker.Stop()

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-e.ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        e.syncModels()</span>
                }
        }
}

// syncModels syncs model information with consensus
func (e *Engine) syncModels() <span class="cov0" title="0">{
        // Get model registry from consensus
        if registry, exists := e.consensus.Get("model_registry"); exists </span><span class="cov0" title="0">{
                if models, ok := registry.(map[string]*ModelInfo); ok </span><span class="cov0" title="0">{
                        e.modelsMu.Lock()
                        e.models = models
                        e.modelsMu.Unlock()
                }</span>
        }

        // Update consensus with local changes
        <span class="cov0" title="0">if e.consensus.IsLeader() </span><span class="cov0" title="0">{
                e.modelsMu.RLock()
                models := make(map[string]*ModelInfo)
                for k, v := range e.models </span><span class="cov0" title="0">{
                        models[k] = v
                }</span>
                <span class="cov0" title="0">e.modelsMu.RUnlock()

                e.consensus.Apply("model_registry", models, nil)</span>
        }
}

// Schedule schedules a request for execution
func (e *Engine) Schedule(req *Request) error <span class="cov0" title="0">{
        req.CreatedAt = time.Now()

        select </span>{
        case e.requests &lt;- req:<span class="cov0" title="0">
                return nil</span>
        case &lt;-time.After(5 * time.Second):<span class="cov0" title="0">
                return fmt.Errorf("request queue full")</span>
        }
}

// RegisterModel registers a model in the registry
func (e *Engine) RegisterModel(name string, size int64, checksum string, nodeID string) error <span class="cov0" title="0">{
        e.modelsMu.Lock()
        defer e.modelsMu.Unlock()

        if model, exists := e.models[name]; exists </span><span class="cov0" title="0">{
                // Update existing model
                if !contains(model.Locations, nodeID) </span><span class="cov0" title="0">{
                        model.Locations = append(model.Locations, nodeID)
                }</span>
        } else<span class="cov0" title="0"> {
                // Create new model
                e.models[name] = &amp;ModelInfo{
                        Name:         name,
                        Size:         size,
                        Checksum:     checksum,
                        Locations:    []string{nodeID},
                        AccessCount:  0,
                        LastAccessed: time.Now(),
                        Metadata:     make(map[string]string),
                }
        }</span>

        <span class="cov0" title="0">return nil</span>
}

// GetModel gets model information
func (e *Engine) GetModel(name string) (*ModelInfo, bool) <span class="cov0" title="0">{
        e.modelsMu.RLock()
        defer e.modelsMu.RUnlock()

        model, exists := e.models[name]
        return model, exists
}</span>

// GetAllModels returns all registered models
func (e *Engine) GetAllModels() map[string]*ModelInfo <span class="cov0" title="0">{
        e.modelsMu.RLock()
        defer e.modelsMu.RUnlock()

        models := make(map[string]*ModelInfo)
        for k, v := range e.models </span><span class="cov0" title="0">{
                models[k] = v
        }</span>

        <span class="cov0" title="0">return models</span>
}

// DeleteModel removes a model from the registry
func (e *Engine) DeleteModel(name string) error <span class="cov0" title="0">{
        e.modelsMu.Lock()
        defer e.modelsMu.Unlock()

        if _, exists := e.models[name]; !exists </span><span class="cov0" title="0">{
                return fmt.Errorf("model %s not found", name)
        }</span>

        <span class="cov0" title="0">delete(e.models, name)
        return nil</span>
}

// GetModelCount returns the number of registered models
func (e *Engine) GetModelCount() int <span class="cov0" title="0">{
        e.modelsMu.RLock()
        defer e.modelsMu.RUnlock()

        return len(e.models)
}</span>

// GetOnlineNodeCount returns the number of online nodes
func (e *Engine) GetOnlineNodeCount() int <span class="cov0" title="0">{
        e.nodesMu.RLock()
        defer e.nodesMu.RUnlock()

        count := 0
        for _, node := range e.nodes </span><span class="cov0" title="0">{
                if node.Status == NodeStatusOnline </span><span class="cov0" title="0">{
                        count++
                }</span>
        }

        <span class="cov0" title="0">return count</span>
}

// GetNodes returns all registered nodes
func (e *Engine) GetNodes() map[string]*NodeInfo <span class="cov0" title="0">{
        e.nodesMu.RLock()
        defer e.nodesMu.RUnlock()

        nodes := make(map[string]*NodeInfo)
        for k, v := range e.nodes </span><span class="cov0" title="0">{
                nodes[k] = v
        }</span>

        <span class="cov0" title="0">return nodes</span>
}

// GetAvailableNodes returns nodes that are online and available
func (e *Engine) GetAvailableNodes() []*NodeInfo <span class="cov0" title="0">{
        e.nodesMu.RLock()
        defer e.nodesMu.RUnlock()

        var available []*NodeInfo
        for _, node := range e.nodes </span><span class="cov0" title="0">{
                if node.Status == NodeStatusOnline </span><span class="cov0" title="0">{
                        available = append(available, node)
                }</span>
        }

        <span class="cov0" title="0">return available</span>
}

// GetClusterSize returns the total number of nodes in the cluster
func (e *Engine) GetClusterSize() int <span class="cov0" title="0">{
        e.nodesMu.RLock()
        defer e.nodesMu.RUnlock()

        return len(e.nodes)
}</span>

// GetActiveNodes returns the count of active (online) nodes
func (e *Engine) GetActiveNodes() int <span class="cov0" title="0">{
        e.nodesMu.RLock()
        defer e.nodesMu.RUnlock()

        count := 0
        for _, node := range e.nodes </span><span class="cov0" title="0">{
                if node.Status == NodeStatusOnline </span><span class="cov0" title="0">{
                        count++
                }</span>
        }

        <span class="cov0" title="0">return count</span>
}

// GetStats returns current scheduler statistics
func (e *Engine) GetStats() *Stats <span class="cov0" title="0">{
        // Get current counts without holding locks together
        nodesTotal := e.GetClusterSize()
        nodesOnline := e.GetActiveNodes()
        modelsTotal := e.GetModelCount()

        e.statsMu.Lock()
        defer e.statsMu.Unlock()

        // Update current stats
        e.stats.NodesTotal = nodesTotal
        e.stats.NodesOnline = nodesOnline
        e.stats.NodesOffline = nodesTotal - nodesOnline
        e.stats.ModelsTotal = modelsTotal
        e.stats.WorkersActive = len(e.workers)
        e.stats.QueuedRequests = int64(len(e.requests))
        e.stats.Uptime = time.Since(e.startTime)
        e.stats.LastUpdated = time.Now()

        // Return a copy of the stats
        return &amp;Stats{
                TotalRequests:     e.stats.TotalRequests,
                CompletedRequests: e.stats.CompletedRequests,
                FailedRequests:    e.stats.FailedRequests,
                QueuedRequests:    e.stats.QueuedRequests,
                AverageLatency:    e.stats.AverageLatency,
                NodesTotal:        e.stats.NodesTotal,
                NodesOnline:       e.stats.NodesOnline,
                NodesOffline:      e.stats.NodesOffline,
                ModelsTotal:       e.stats.ModelsTotal,
                WorkersActive:     e.stats.WorkersActive,
                Uptime:            e.stats.Uptime,
                LastUpdated:       e.stats.LastUpdated,
        }
}</span>

// IsHealthy returns true if the scheduler is healthy
func (e *Engine) IsHealthy() bool <span class="cov0" title="0">{
        e.mu.RLock()
        defer e.mu.RUnlock()

        // Check if scheduler is started
        if !e.started </span><span class="cov0" title="0">{
                return false
        }</span>

        // Check if we have at least one online node
        <span class="cov0" title="0">if e.GetActiveNodes() == 0 </span><span class="cov0" title="0">{
                return false
        }</span>

        // Check if workers are running
        <span class="cov0" title="0">if len(e.workers) == 0 </span><span class="cov0" title="0">{
                return false
        }</span>

        // Check if request queue is not completely full
        <span class="cov0" title="0">if len(e.requests) &gt;= cap(e.requests) </span><span class="cov0" title="0">{
                return false
        }</span>

        <span class="cov0" title="0">return true</span>
}

// Shutdown gracefully shuts down the scheduling engine
func (e *Engine) Shutdown(ctx context.Context) error <span class="cov0" title="0">{
        e.mu.Lock()
        defer e.mu.Unlock()

        if !e.started </span><span class="cov0" title="0">{
                return nil
        }</span>

        // Stop workers
        <span class="cov0" title="0">for _, worker := range e.workers </span><span class="cov0" title="0">{
                close(worker.stopCh)
        }</span>

        // Stop health checker
        <span class="cov0" title="0">close(e.healthChecker.stopCh)

        // Cancel context
        e.cancel()

        e.started = false
        return nil</span>
}

// Worker methods

// start starts the worker
func (w *Worker) start() <span class="cov0" title="0">{
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-w.stopCh:<span class="cov0" title="0">
                        return</span>
                case req := &lt;-w.engine.requests:<span class="cov0" title="0">
                        w.processRequest(req)</span>
                }
        }
}

// processRequest processes a single request
func (w *Worker) processRequest(req *Request) <span class="cov0" title="0">{
        req.ScheduledAt = time.Now()

        // Find the best node for this request
        node, err := w.engine.loadBalancer.SelectNode(req)
        if err != nil </span><span class="cov0" title="0">{
                w.sendResponse(req, &amp;Response{
                        RequestID: req.ID,
                        Success:   false,
                        Error:     fmt.Sprintf("failed to select node: %v", err),
                        Duration:  time.Since(req.CreatedAt),
                })
                return
        }</span>

        // Execute the request on the selected node
        <span class="cov0" title="0">response := w.executeRequest(req, node)
        w.sendResponse(req, response)</span>
}

// executeRequest executes a request on a specific node
func (w *Worker) executeRequest(req *Request, node *NodeInfo) *Response <span class="cov0" title="0">{
        start := time.Now()

        // Execute request via P2P communication
        ctx, cancel := context.WithTimeout(context.Background(), req.Timeout)
        defer cancel()

        // Prepare request payload
        payload := map[string]interface{}{
                "id":         req.ID,
                "model_name": req.ModelName,
                "type":       req.Type,
                "priority":   req.Priority,
                "payload":    req.Payload,
                "created_at": req.CreatedAt,
        }

        // Send request to node via P2P
        responseData, err := w.sendP2PRequest(ctx, node, payload)
        if err != nil </span><span class="cov0" title="0">{
                return &amp;Response{
                        RequestID: req.ID,
                        NodeID:    node.ID,
                        Success:   false,
                        Error:     fmt.Sprintf("P2P request failed: %v", err),
                        Duration:  time.Since(start),
                }
        }</span>

        // Parse response
        <span class="cov0" title="0">if responseMap, ok := responseData.(map[string]interface{}); ok </span><span class="cov0" title="0">{
                if success, exists := responseMap["success"]; exists </span><span class="cov0" title="0">{
                        if successBool, ok := success.(bool); ok &amp;&amp; successBool </span><span class="cov0" title="0">{
                                return &amp;Response{
                                        RequestID: req.ID,
                                        NodeID:    node.ID,
                                        Success:   true,
                                        Data:      responseMap["data"],
                                        Duration:  time.Since(start),
                                }
                        }</span>
                }
                
                <span class="cov0" title="0">if errorMsg, exists := responseMap["error"]; exists </span><span class="cov0" title="0">{
                        return &amp;Response{
                                RequestID: req.ID,
                                NodeID:    node.ID,
                                Success:   false,
                                Error:     fmt.Sprintf("%v", errorMsg),
                                Duration:  time.Since(start),
                        }
                }</span>
        }

        // Successful response
        <span class="cov0" title="0">return &amp;Response{
                RequestID: req.ID,
                NodeID:    node.ID,
                Success:   true,
                Data:      responseData,
                Duration:  time.Since(start),
        }</span>
}

// sendResponse sends a response back to the requester
func (w *Worker) sendResponse(req *Request, response *Response) <span class="cov0" title="0">{
        req.CompletedAt = time.Now()

        // Update statistics
        w.engine.statsMu.Lock()
        w.engine.stats.TotalRequests++
        if response.Success </span><span class="cov0" title="0">{
                w.engine.stats.CompletedRequests++

                // Update average latency for successful requests only
                if w.engine.stats.CompletedRequests == 1 </span><span class="cov0" title="0">{
                        w.engine.stats.AverageLatency = response.Duration
                }</span> else<span class="cov0" title="0"> {
                        totalLatency := w.engine.stats.AverageLatency * time.Duration(w.engine.stats.CompletedRequests-1)
                        w.engine.stats.AverageLatency = (totalLatency + response.Duration) / time.Duration(w.engine.stats.CompletedRequests)
                }</span>
        } else<span class="cov0" title="0"> {
                w.engine.stats.FailedRequests++
        }</span>
        <span class="cov0" title="0">w.engine.statsMu.Unlock()

        select </span>{
        case req.ResponseCh &lt;- response:<span class="cov0" title="0"></span>
        case &lt;-time.After(5 * time.Second):<span class="cov0" title="0"></span>
                // Response channel blocked or closed
        }
}

// HealthChecker methods

// start starts the health checker
func (h *HealthChecker) start() <span class="cov0" title="0">{
        ticker := time.NewTicker(h.interval)
        defer ticker.Stop()

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-h.stopCh:<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        h.checkHealth()</span>
                }
        }
}

// checkHealth checks the health of all nodes
func (h *HealthChecker) checkHealth() <span class="cov0" title="0">{
        nodes := h.engine.GetAvailableNodes()

        for _, node := range nodes </span><span class="cov0" title="0">{
                go h.checkNodeHealth(node)
        }</span>
}

// checkNodeHealth checks the health of a specific node
func (h *HealthChecker) checkNodeHealth(node *NodeInfo) <span class="cov0" title="0">{
        start := time.Now()
        ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
        defer cancel()

        // Send health check ping
        ping := map[string]interface{}{
                "type":      "health_check",
                "timestamp": start.Unix(),
                "node_id":   h.engine.p2p.ID().String(),
        }

        // Attempt to send ping via P2P
        response, err := h.sendHealthPing(ctx, node, ping)
        
        h.engine.nodesMu.Lock()
        defer h.engine.nodesMu.Unlock()

        if err != nil </span><span class="cov0" title="0">{
                // Health check failed
                if time.Since(node.LastSeen) &gt; 2*time.Minute </span><span class="cov0" title="0">{
                        node.Status = NodeStatusOffline
                }</span> else<span class="cov0" title="0"> {
                        node.Status = NodeStatusDraining
                }</span>
                <span class="cov0" title="0">return</span>
        }

        // Parse health response
        <span class="cov0" title="0">if healthData, ok := response.(map[string]interface{}); ok </span><span class="cov0" title="0">{
                // Update node capacity and usage from health response
                if capacity, exists := healthData["capacity"]; exists </span><span class="cov0" title="0">{
                        if capacityMap, ok := capacity.(map[string]interface{}); ok </span><span class="cov0" title="0">{
                                h.updateNodeCapacity(node, capacityMap)
                        }</span>
                }
                
                <span class="cov0" title="0">if usage, exists := healthData["usage"]; exists </span><span class="cov0" title="0">{
                        if usageMap, ok := usage.(map[string]interface{}); ok </span><span class="cov0" title="0">{
                                h.updateNodeUsage(node, usageMap)
                        }</span>
                }
                
                <span class="cov0" title="0">if models, exists := healthData["models"]; exists </span><span class="cov0" title="0">{
                        if modelSlice, ok := models.([]interface{}); ok </span><span class="cov0" title="0">{
                                node.Models = make([]string, len(modelSlice))
                                for i, model := range modelSlice </span><span class="cov0" title="0">{
                                        if modelStr, ok := model.(string); ok </span><span class="cov0" title="0">{
                                                node.Models[i] = modelStr
                                        }</span>
                                }
                        }
                }
        }

        // Health check successful
        <span class="cov0" title="0">node.Status = NodeStatusOnline
        node.LastSeen = time.Now()</span>
}

// LoadBalancer methods

// SelectNode selects the best node for a request
func (lb *LoadBalancer) SelectNode(req *Request) (*NodeInfo, error) <span class="cov0" title="0">{
        nodes := lb.engine.GetAvailableNodes()

        if len(nodes) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no available nodes")
        }</span>

        // Check if any nodes have the required model
        <span class="cov0" title="0">var candidateNodes []*NodeInfo
        for _, node := range nodes </span><span class="cov0" title="0">{
                if contains(node.Models, req.ModelName) </span><span class="cov0" title="0">{
                        candidateNodes = append(candidateNodes, node)
                }</span>
        }

        // If no nodes have the model, use all available nodes
        <span class="cov0" title="0">if len(candidateNodes) == 0 </span><span class="cov0" title="0">{
                candidateNodes = nodes
        }</span>

        // Apply load balancing algorithm
        <span class="cov0" title="0">switch lb.algorithm </span>{
        case "round_robin":<span class="cov0" title="0">
                return lb.roundRobin(candidateNodes)</span>
        case "least_connections":<span class="cov0" title="0">
                return lb.leastConnections(candidateNodes)</span>
        case "random":<span class="cov0" title="0">
                return lb.random(candidateNodes)</span>
        default:<span class="cov0" title="0">
                return lb.roundRobin(candidateNodes)</span>
        }
}

// roundRobin implements round-robin load balancing
func (lb *LoadBalancer) roundRobin(nodes []*NodeInfo) (*NodeInfo, error) <span class="cov0" title="0">{
        if len(nodes) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no nodes available")
        }</span>

        // Get or create round-robin state
        <span class="cov0" title="0">state := lb.getRoundRobinState()
        
        // Select next node in rotation
        currentIndex := state.currentIndex
        selectedNode := nodes[currentIndex]
        
        // Update state for next request
        state.currentIndex = (currentIndex + 1) % len(nodes)
        
        return selectedNode, nil</span>
}

// leastConnections implements least connections load balancing
func (lb *LoadBalancer) leastConnections(nodes []*NodeInfo) (*NodeInfo, error) <span class="cov0" title="0">{
        if len(nodes) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no nodes available")
        }</span>

        // Find node with least connections/load
        <span class="cov0" title="0">var selectedNode *NodeInfo
        lowestLoad := float64(100) // Start with max load

        for _, node := range nodes </span><span class="cov0" title="0">{
                // Calculate current load based on CPU and memory usage
                currentLoad := (node.Usage.CPU + node.Usage.Memory) / 2
                
                // Prefer nodes with lower load
                if currentLoad &lt; lowestLoad </span><span class="cov0" title="0">{
                        lowestLoad = currentLoad
                        selectedNode = node
                }</span>
        }

        <span class="cov0" title="0">if selectedNode == nil </span><span class="cov0" title="0">{
                // Fallback to first node if no suitable node found
                selectedNode = nodes[0]
        }</span>

        <span class="cov0" title="0">return selectedNode, nil</span>
}

// random implements random load balancing
func (lb *LoadBalancer) random(nodes []*NodeInfo) (*NodeInfo, error) <span class="cov0" title="0">{
        if len(nodes) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no nodes available")
        }</span>

        // Use current time as seed for randomness
        <span class="cov0" title="0">seed := time.Now().UnixNano()
        randomIndex := int(seed % int64(len(nodes)))
        
        // Ensure index is within bounds
        if randomIndex &lt; 0 </span><span class="cov0" title="0">{
                randomIndex = 0
        }</span>
        <span class="cov0" title="0">if randomIndex &gt;= len(nodes) </span><span class="cov0" title="0">{
                randomIndex = len(nodes) - 1
        }</span>

        <span class="cov0" title="0">return nodes[randomIndex], nil</span>
}

// Helper functions

// contains checks if a slice contains a string
func contains(slice []string, item string) bool <span class="cov0" title="0">{
        for _, s := range slice </span><span class="cov0" title="0">{
                if s == item </span><span class="cov0" title="0">{
                        return true
                }</span>
        }
        <span class="cov0" title="0">return false</span>
}

// RoundRobinState tracks round-robin load balancing state
type RoundRobinState struct {
        currentIndex int
        mu           sync.Mutex
}

var globalRoundRobinState = &amp;RoundRobinState{}

// getRoundRobinState returns the global round-robin state
func (lb *LoadBalancer) getRoundRobinState() *RoundRobinState <span class="cov0" title="0">{
        return globalRoundRobinState
}</span>

// sendP2PRequest sends a request to a node via P2P
func (w *Worker) sendP2PRequest(ctx context.Context, node *NodeInfo, payload map[string]interface{}) (interface{}, error) <span class="cov0" title="0">{
        // Convert node ID to peer ID
        peerID, err := peer.Decode(node.ID)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("invalid peer ID: %w", err)
        }</span>

        // Check if connected to peer
        <span class="cov0" title="0">if !w.engine.p2p.IsConnected(peerID) </span><span class="cov0" title="0">{
                // Try to connect
                peerInfo := peer.AddrInfo{
                        ID: peerID,
                        // Note: In a real implementation, we'd have the multiaddrs
                }
                if err := w.engine.p2p.ConnectToPeer(ctx, peerInfo); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to connect to peer: %w", err)
                }</span>
        }

        // Send request via P2P stream
        // This is a simplified implementation
        // In practice, you'd use libp2p streams for communication
        
        // For now, simulate successful communication
        <span class="cov0" title="0">response := map[string]interface{}{
                "success": true,
                "data":    "processed successfully",
                "node_id": node.ID,
        }

        return response, nil</span>
}

// sendHealthPing sends a health check ping to a node
func (h *HealthChecker) sendHealthPing(ctx context.Context, node *NodeInfo, ping map[string]interface{}) (interface{}, error) <span class="cov0" title="0">{
        // Convert node ID to peer ID
        peerID, err := peer.Decode(node.ID)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("invalid peer ID: %w", err)
        }</span>

        // Check if connected to peer
        <span class="cov0" title="0">if !h.engine.p2p.IsConnected(peerID) </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("peer not connected")
        }</span>

        // Send health ping via P2P
        // This is a simplified implementation
        
        // Simulate health response
        <span class="cov0" title="0">response := map[string]interface{}{
                "status": "healthy",
                "capacity": map[string]interface{}{
                        "cpu":    8,
                        "memory": 16 * 1024 * 1024 * 1024, // 16GB
                        "disk":   1024 * 1024 * 1024 * 1024, // 1TB
                        "gpu":    1,
                },
                "usage": map[string]interface{}{
                        "cpu":    30.5,
                        "memory": 45.2,
                        "disk":   25.8,
                        "gpu":    0.0,
                },
                "models": []string{"llama2", "codellama"},
        }

        return response, nil</span>
}

// updateNodeCapacity updates node capacity from health response
func (h *HealthChecker) updateNodeCapacity(node *NodeInfo, capacity map[string]interface{}) <span class="cov0" title="0">{
        if cpu, ok := capacity["cpu"].(float64); ok </span><span class="cov0" title="0">{
                node.Capacity.CPU = int64(cpu)
        }</span>
        <span class="cov0" title="0">if memory, ok := capacity["memory"].(float64); ok </span><span class="cov0" title="0">{
                node.Capacity.Memory = int64(memory)
        }</span>
        <span class="cov0" title="0">if disk, ok := capacity["disk"].(float64); ok </span><span class="cov0" title="0">{
                node.Capacity.Disk = int64(disk)
        }</span>
        <span class="cov0" title="0">if gpu, ok := capacity["gpu"].(float64); ok </span><span class="cov0" title="0">{
                node.Capacity.GPU = int64(gpu)
        }</span>
}

// updateNodeUsage updates node usage from health response
func (h *HealthChecker) updateNodeUsage(node *NodeInfo, usage map[string]interface{}) <span class="cov0" title="0">{
        if cpu, ok := usage["cpu"].(float64); ok </span><span class="cov0" title="0">{
                node.Usage.CPU = cpu
        }</span>
        <span class="cov0" title="0">if memory, ok := usage["memory"].(float64); ok </span><span class="cov0" title="0">{
                node.Usage.Memory = memory
        }</span>
        <span class="cov0" title="0">if disk, ok := usage["disk"].(float64); ok </span><span class="cov0" title="0">{
                node.Usage.Disk = disk
        }</span>
        <span class="cov0" title="0">if gpu, ok := usage["gpu"].(float64); ok </span><span class="cov0" title="0">{
                node.Usage.GPU = gpu
        }</span>
}
</pre>
		
		<pre class="file" id="file41" style="display: none">package fault_tolerance

import (
        "context"
        "fmt"
        "log/slog"
        "sync"
        "time"
)

// FaultToleranceManager manages fault tolerance and recovery mechanisms
type FaultToleranceManager struct {
        config           *Config
        detectionSystem  *FaultDetector
        recoveryEngine   *RecoveryEngine
        replicationMgr   *ReplicationManager
        circuitBreaker   *CircuitBreaker
        checkpointing    *CheckpointManager
        metrics          *FaultToleranceMetrics
        mu               sync.RWMutex
        ctx              context.Context
        cancel           context.CancelFunc
        started          bool
}

// Config holds fault tolerance configuration
type Config struct {
        ReplicationFactor     int           `json:"replication_factor"`
        HealthCheckInterval   time.Duration `json:"health_check_interval"`
        RecoveryTimeout       time.Duration `json:"recovery_timeout"`
        CircuitBreakerEnabled bool          `json:"circuit_breaker_enabled"`
        CheckpointInterval    time.Duration `json:"checkpoint_interval"`
        MaxRetries            int           `json:"max_retries"`
        RetryBackoff          time.Duration `json:"retry_backoff"`
}

// FaultDetector monitors system health and detects faults
type FaultDetector struct {
        manager        *FaultToleranceManager
        healthCheckers map[string]HealthChecker
        monitors       []SystemMonitor
        alerting       *AlertingSystem
        thresholds     map[string]float64
        detections     map[string]*FaultDetection
        detectionsMu   sync.RWMutex
}

// HealthChecker interface for different health checking mechanisms
type HealthChecker interface {
        Check(ctx context.Context, target string) (*HealthResult, error)
        GetName() string
}

// SystemMonitor interface for system monitoring
type SystemMonitor interface {
        Monitor(ctx context.Context) (*MonitorResult, error)
        GetName() string
}

// AlertingSystem manages fault alerts
type AlertingSystem struct {
        alerts    []*FaultAlert
        alertsMu  sync.RWMutex
        handlers  map[string]AlertHandler
        config    *AlertConfig
}

// AlertHandler interface for handling alerts
type AlertHandler interface {
        Handle(alert *FaultAlert) error
        GetName() string
}

// AlertConfig holds alerting configuration
type AlertConfig struct {
        Enabled       bool          `json:"enabled"`
        Channels      []string      `json:"channels"`
        ThrottleTime  time.Duration `json:"throttle_time"`
        SeverityLevel string        `json:"severity_level"`
}

// FaultDetection represents a detected fault
type FaultDetection struct {
        ID          string                 `json:"id"`
        Type        FaultType              `json:"type"`
        Severity    FaultSeverity          `json:"severity"`
        Target      string                 `json:"target"`
        Description string                 `json:"description"`
        DetectedAt  time.Time              `json:"detected_at"`
        ResolvedAt  *time.Time             `json:"resolved_at,omitempty"`
        Status      FaultStatus            `json:"status"`
        Metadata    map[string]interface{} `json:"metadata"`
}

// FaultType represents the type of fault
type FaultType string

const (
        FaultTypeNodeFailure     FaultType = "node_failure"
        FaultTypeNetworkPartition FaultType = "network_partition"
        FaultTypeResourceExhaustion FaultType = "resource_exhaustion"
        FaultTypePerformanceAnomaly FaultType = "performance_anomaly"
        FaultTypeServiceUnavailable FaultType = "service_unavailable"
)

// FaultSeverity represents the severity of a fault
type FaultSeverity string

const (
        FaultSeverityLow      FaultSeverity = "low"
        FaultSeverityMedium   FaultSeverity = "medium"
        FaultSeverityHigh     FaultSeverity = "high"
        FaultSeverityCritical FaultSeverity = "critical"
)

// FaultStatus represents the status of a fault
type FaultStatus string

const (
        FaultStatusDetected   FaultStatus = "detected"
        FaultStatusRecovering FaultStatus = "recovering"
        FaultStatusResolved   FaultStatus = "resolved"
        FaultStatusPersistent FaultStatus = "persistent"
)

// HealthResult represents a health check result
type HealthResult struct {
        Target    string                 `json:"target"`
        Healthy   bool                   `json:"healthy"`
        Latency   time.Duration          `json:"latency"`
        Error     string                 `json:"error,omitempty"`
        Metrics   map[string]interface{} `json:"metrics"`
        Timestamp time.Time              `json:"timestamp"`
}

// MonitorResult represents a system monitoring result
type MonitorResult struct {
        System    string                 `json:"system"`
        Healthy   bool                   `json:"healthy"`
        Metrics   map[string]interface{} `json:"metrics"`
        Anomalies []string               `json:"anomalies"`
        Timestamp time.Time              `json:"timestamp"`
}

// FaultAlert represents a fault alert
type FaultAlert struct {
        ID          string                 `json:"id"`
        FaultID     string                 `json:"fault_id"`
        Severity    FaultSeverity          `json:"severity"`
        Message     string                 `json:"message"`
        Timestamp   time.Time              `json:"timestamp"`
        Handled     bool                   `json:"handled"`
        Metadata    map[string]interface{} `json:"metadata"`
}

// RecoveryEngine handles fault recovery
type RecoveryEngine struct {
        manager         *FaultToleranceManager
        strategies      map[FaultType][]RecoveryStrategy
        recoveryQueue   chan *RecoveryRequest
        recoveryHistory []*RecoveryAttempt
        historyMu       sync.RWMutex
}

// RecoveryStrategy interface for different recovery strategies
type RecoveryStrategy interface {
        Recover(ctx context.Context, fault *FaultDetection) (*RecoveryResult, error)
        GetName() string
        CanHandle(fault *FaultDetection) bool
}

// RecoveryRequest represents a recovery request
type RecoveryRequest struct {
        Fault     *FaultDetection
        Strategy  string
        Priority  int
        Timestamp time.Time
}

// RecoveryResult represents the result of a recovery attempt
type RecoveryResult struct {
        FaultID     string                 `json:"fault_id"`
        Strategy    string                 `json:"strategy"`
        Successful  bool                   `json:"successful"`
        Duration    time.Duration          `json:"duration"`
        Error       string                 `json:"error,omitempty"`
        Metadata    map[string]interface{} `json:"metadata"`
        Timestamp   time.Time              `json:"timestamp"`
}

// RecoveryAttempt represents a recovery attempt
type RecoveryAttempt struct {
        ID        string          `json:"id"`
        FaultID   string          `json:"fault_id"`
        Strategy  string          `json:"strategy"`
        Result    *RecoveryResult `json:"result"`
        Timestamp time.Time       `json:"timestamp"`
}

// ReplicationManager handles model and data replication
type ReplicationManager struct {
        manager         *FaultToleranceManager
        replicationJobs map[string]*ReplicationJob
        jobsMu          sync.RWMutex
        factor          int
        strategy        ReplicationStrategy
}

// ReplicationJob represents a replication job
type ReplicationJob struct {
        ID            string                 `json:"id"`
        Type          ReplicationType        `json:"type"`
        Source        string                 `json:"source"`
        Targets       []string               `json:"targets"`
        Status        ReplicationStatus      `json:"status"`
        Progress      float64                `json:"progress"`
        StartedAt     time.Time              `json:"started_at"`
        CompletedAt   *time.Time             `json:"completed_at,omitempty"`
        Error         string                 `json:"error,omitempty"`
        Metadata      map[string]interface{} `json:"metadata"`
}

// ReplicationType represents the type of replication
type ReplicationType string

const (
        ReplicationTypeModel ReplicationType = "model"
        ReplicationTypeData  ReplicationType = "data"
        ReplicationTypeState ReplicationType = "state"
)

// ReplicationStatus represents the status of replication
type ReplicationStatus string

const (
        ReplicationStatusPending    ReplicationStatus = "pending"
        ReplicationStatusInProgress ReplicationStatus = "in_progress"
        ReplicationStatusCompleted  ReplicationStatus = "completed"
        ReplicationStatusFailed     ReplicationStatus = "failed"
)

// ReplicationStrategy represents the replication strategy
type ReplicationStrategy string

const (
        ReplicationStrategyImmediate ReplicationStrategy = "immediate"
        ReplicationStrategyLazy      ReplicationStrategy = "lazy"
        ReplicationStrategyAdaptive  ReplicationStrategy = "adaptive"
)

// CircuitBreaker implements circuit breaker pattern
type CircuitBreaker struct {
        manager         *FaultToleranceManager
        circuits        map[string]*Circuit
        circuitsMu      sync.RWMutex
        defaultConfig   *CircuitConfig
}

// Circuit represents a circuit breaker
type Circuit struct {
        Name          string              `json:"name"`
        State         CircuitState        `json:"state"`
        Config        *CircuitConfig      `json:"config"`
        FailureCount  int                 `json:"failure_count"`
        SuccessCount  int                 `json:"success_count"`
        LastFailure   time.Time           `json:"last_failure"`
        LastSuccess   time.Time           `json:"last_success"`
        StateChanged  time.Time           `json:"state_changed"`
        mu            sync.RWMutex
}

// CircuitState represents the state of a circuit breaker
type CircuitState string

const (
        CircuitStateClosed   CircuitState = "closed"
        CircuitStateOpen     CircuitState = "open"
        CircuitStateHalfOpen CircuitState = "half_open"
)

// CircuitConfig holds circuit breaker configuration
type CircuitConfig struct {
        FailureThreshold int           `json:"failure_threshold"`
        SuccessThreshold int           `json:"success_threshold"`
        Timeout          time.Duration `json:"timeout"`
        ResetTimeout     time.Duration `json:"reset_timeout"`
}

// CheckpointManager handles checkpointing and recovery
type CheckpointManager struct {
        manager     *FaultToleranceManager
        storage     CheckpointStorage
        frequency   time.Duration
        compression CompressionAlgorithm
        encryption  EncryptionMethod
        cleanup     CleanupPolicy
        checkpoints map[string]*Checkpoint
        checkpointsMu sync.RWMutex
}

// CheckpointStorage interface for checkpoint storage
type CheckpointStorage interface {
        Store(checkpoint *Checkpoint) error
        Load(id string) (*Checkpoint, error)
        List() ([]*Checkpoint, error)
        Delete(id string) error
}

// CompressionAlgorithm interface for compression
type CompressionAlgorithm interface {
        Compress(data []byte) ([]byte, error)
        Decompress(data []byte) ([]byte, error)
        GetName() string
}

// EncryptionMethod interface for encryption
type EncryptionMethod interface {
        Encrypt(data []byte) ([]byte, error)
        Decrypt(data []byte) ([]byte, error)
        GetName() string
}

// CleanupPolicy interface for cleanup policies
type CleanupPolicy interface {
        ShouldCleanup(checkpoint *Checkpoint) bool
        GetName() string
}

// Checkpoint represents a system checkpoint
type Checkpoint struct {
        ID            string                 `json:"id"`
        Timestamp     time.Time              `json:"timestamp"`
        ModelState    ModelState             `json:"model_state"`
        RequestQueue  []Request              `json:"request_queue"`
        NodeStates    map[string]NodeState   `json:"node_states"`
        Metadata      map[string]interface{} `json:"metadata"`
        Size          int64                  `json:"size"`
        Compressed    bool                   `json:"compressed"`
        Encrypted     bool                   `json:"encrypted"`
}

// ModelState represents the state of a model
type ModelState struct {
        Name        string                 `json:"name"`
        Version     string                 `json:"version"`
        State       map[string]interface{} `json:"state"`
        Weights     []byte                 `json:"weights"`
        Metadata    map[string]interface{} `json:"metadata"`
}

// Request represents a request in the system
type Request struct {
        ID        string                 `json:"id"`
        Type      string                 `json:"type"`
        Payload   map[string]interface{} `json:"payload"`
        Timestamp time.Time              `json:"timestamp"`
}

// NodeState represents the state of a node
type NodeState struct {
        ID        string                 `json:"id"`
        Status    string                 `json:"status"`
        Resources map[string]interface{} `json:"resources"`
        Metadata  map[string]interface{} `json:"metadata"`
}

// FaultToleranceMetrics tracks fault tolerance metrics
type FaultToleranceMetrics struct {
        FaultsDetected      int64     `json:"faults_detected"`
        FaultsResolved      int64     `json:"faults_resolved"`
        RecoveryAttempts    int64     `json:"recovery_attempts"`
        SuccessfulRecoveries int64    `json:"successful_recoveries"`
        AverageRecoveryTime time.Duration `json:"average_recovery_time"`
        Uptime              time.Duration `json:"uptime"`
        LastFault           *time.Time    `json:"last_fault"`
        LastRecovery        *time.Time    `json:"last_recovery"`
}

// NewFaultToleranceManager creates a new fault tolerance manager
func NewFaultToleranceManager(config *Config) *FaultToleranceManager <span class="cov0" title="0">{
        ctx, cancel := context.WithCancel(context.Background())
        
        ftm := &amp;FaultToleranceManager{
                config:  config,
                ctx:     ctx,
                cancel:  cancel,
                metrics: &amp;FaultToleranceMetrics{},
        }
        
        // Initialize components
        ftm.initializeComponents()
        
        return ftm
}</span>

// initializeComponents initializes all fault tolerance components
func (ftm *FaultToleranceManager) initializeComponents() <span class="cov0" title="0">{
        // Initialize fault detector
        ftm.detectionSystem = &amp;FaultDetector{
                manager:        ftm,
                healthCheckers: make(map[string]HealthChecker),
                monitors:       make([]SystemMonitor, 0),
                thresholds:     make(map[string]float64),
                detections:     make(map[string]*FaultDetection),
        }
        
        // Initialize alerting system
        ftm.detectionSystem.alerting = &amp;AlertingSystem{
                alerts:   make([]*FaultAlert, 0),
                handlers: make(map[string]AlertHandler),
                config: &amp;AlertConfig{
                        Enabled:       true,
                        Channels:      []string{"log", "email"},
                        ThrottleTime:  5 * time.Minute,
                        SeverityLevel: "medium",
                },
        }
        
        // Initialize recovery engine
        ftm.recoveryEngine = &amp;RecoveryEngine{
                manager:         ftm,
                strategies:      make(map[FaultType][]RecoveryStrategy),
                recoveryQueue:   make(chan *RecoveryRequest, 100),
                recoveryHistory: make([]*RecoveryAttempt, 0),
        }
        
        // Initialize replication manager
        ftm.replicationMgr = &amp;ReplicationManager{
                manager:         ftm,
                replicationJobs: make(map[string]*ReplicationJob),
                factor:          ftm.config.ReplicationFactor,
                strategy:        ReplicationStrategyAdaptive,
        }
        
        // Initialize circuit breaker
        ftm.circuitBreaker = &amp;CircuitBreaker{
                manager:  ftm,
                circuits: make(map[string]*Circuit),
                defaultConfig: &amp;CircuitConfig{
                        FailureThreshold: 5,
                        SuccessThreshold: 3,
                        Timeout:          30 * time.Second,
                        ResetTimeout:     60 * time.Second,
                },
        }
        
        // Initialize checkpoint manager
        ftm.checkpointing = &amp;CheckpointManager{
                manager:     ftm,
                frequency:   ftm.config.CheckpointInterval,
                checkpoints: make(map[string]*Checkpoint),
        }
        
        // Register default recovery strategies
        ftm.registerDefaultStrategies()
        
        // Register default health checkers
        ftm.registerDefaultHealthCheckers()
}</span>

// registerDefaultStrategies registers default recovery strategies
func (ftm *FaultToleranceManager) registerDefaultStrategies() <span class="cov0" title="0">{
        // Node failure recovery strategies
        ftm.recoveryEngine.strategies[FaultTypeNodeFailure] = []RecoveryStrategy{
                &amp;GracefulDegradationStrategy{},
                &amp;RequestMigrationStrategy{},
                &amp;ModelReplicationStrategy{},
        }
        
        // Network partition recovery strategies
        ftm.recoveryEngine.strategies[FaultTypeNetworkPartition] = []RecoveryStrategy{
                &amp;PartitionToleranceStrategy{},
                &amp;RequestMigrationStrategy{},
        }
        
        // Resource exhaustion recovery strategies
        ftm.recoveryEngine.strategies[FaultTypeResourceExhaustion] = []RecoveryStrategy{
                &amp;ResourceScalingStrategy{},
                &amp;LoadSheddingStrategy{},
        }
        
        // Performance anomaly recovery strategies
        ftm.recoveryEngine.strategies[FaultTypePerformanceAnomaly] = []RecoveryStrategy{
                &amp;PerformanceTuningStrategy{},
                &amp;LoadBalancingStrategy{},
        }
}</span>

// registerDefaultHealthCheckers registers default health checkers
func (ftm *FaultToleranceManager) registerDefaultHealthCheckers() <span class="cov0" title="0">{
        ftm.detectionSystem.AddHealthChecker("node", NewNodeHealthChecker())
        ftm.detectionSystem.AddHealthChecker("network", NewNetworkHealthChecker())
        ftm.detectionSystem.AddHealthChecker("resource", NewResourceHealthChecker())
        ftm.detectionSystem.AddHealthChecker("performance", NewPerformanceHealthChecker())
}</span>

// Start starts the fault tolerance manager
func (ftm *FaultToleranceManager) Start() error <span class="cov0" title="0">{
        ftm.mu.Lock()
        defer ftm.mu.Unlock()
        
        if ftm.started </span><span class="cov0" title="0">{
                return fmt.Errorf("fault tolerance manager already started")
        }</span>
        
        // Start fault detection
        <span class="cov0" title="0">go ftm.detectionSystem.Start(ftm.ctx)
        
        // Start recovery engine
        go ftm.recoveryEngine.Start(ftm.ctx)
        
        // Start checkpointing
        go ftm.checkpointing.Start(ftm.ctx)
        
        ftm.started = true
        
        slog.Info("fault tolerance manager started",
                "replication_factor", ftm.config.ReplicationFactor,
                "health_check_interval", ftm.config.HealthCheckInterval,
                "circuit_breaker_enabled", ftm.config.CircuitBreakerEnabled)
        
        return nil</span>
}

// AddHealthChecker adds a health checker to the fault detector
func (fd *FaultDetector) AddHealthChecker(name string, checker HealthChecker) <span class="cov0" title="0">{
        fd.healthCheckers[name] = checker
}</span>

// Start method for FaultDetector
func (fd *FaultDetector) Start(ctx context.Context) error <span class="cov0" title="0">{
        // Implementation for starting fault detector
        slog.Info("fault detector started")
        return nil
}</span>

// Start method for RecoveryEngine
func (re *RecoveryEngine) Start(ctx context.Context) error <span class="cov0" title="0">{
        // Implementation for starting recovery engine
        slog.Info("recovery engine started")
        return nil
}</span>

// CreateCheckpoint creates a new checkpoint
func (cm *CheckpointManager) CreateCheckpoint() *Checkpoint <span class="cov0" title="0">{
        checkpoint := &amp;Checkpoint{
                ID:           fmt.Sprintf("checkpoint_%d", time.Now().UnixNano()),
                Timestamp:    time.Now(),
                ModelState:   ModelState{},
                RequestQueue: []Request{},
                NodeStates:   make(map[string]NodeState),
                Metadata:     make(map[string]interface{}),
                Size:         0,
                Compressed:   false,
                Encrypted:    false,
        }
        
        // Store system metadata (placeholder)
        checkpoint.Metadata["system_health"] = "ok"
        checkpoint.Metadata["active_connections"] = 100
        checkpoint.Metadata["memory_usage"] = "500MB"
        
        return checkpoint
}</span>

// Start method for CheckpointManager
func (cm *CheckpointManager) Start(ctx context.Context) error <span class="cov0" title="0">{
        // Implementation for starting checkpoint manager
        slog.Info("checkpoint manager started")
        return nil
}</span>

// DetectFault detects a fault in the system
func (ftm *FaultToleranceManager) DetectFault(faultType FaultType, target, description string, metadata map[string]interface{}) *FaultDetection <span class="cov0" title="0">{
        fault := &amp;FaultDetection{
                ID:          fmt.Sprintf("fault_%d", time.Now().UnixNano()),
                Type:        faultType,
                Severity:    ftm.determineSeverity(faultType, metadata),
                Target:      target,
                Description: description,
                DetectedAt:  time.Now(),
                Status:      FaultStatusDetected,
                Metadata:    metadata,
        }
        
        // Store fault detection
        ftm.detectionSystem.detectionsMu.Lock()
        ftm.detectionSystem.detections[fault.ID] = fault
        ftm.detectionSystem.detectionsMu.Unlock()
        
        // Update metrics
        ftm.metrics.FaultsDetected++
        now := time.Now()
        ftm.metrics.LastFault = &amp;now
        
        // Create alert
        alert := &amp;FaultAlert{
                ID:        fmt.Sprintf("alert_%d", time.Now().UnixNano()),
                FaultID:   fault.ID,
                Severity:  fault.Severity,
                Message:   fmt.Sprintf("Fault detected: %s - %s", fault.Type, fault.Description),
                Timestamp: time.Now(),
                Metadata:  metadata,
        }
        
        // Send alert
        ftm.detectionSystem.alerting.sendAlert(alert)
        
        // Trigger recovery
        go ftm.triggerRecovery(fault)
        
        slog.Warn("fault detected",
                "fault_id", fault.ID,
                "type", fault.Type,
                "severity", fault.Severity,
                "target", fault.Target,
                "description", fault.Description)
        
        return fault
}</span>

// determineSeverity determines the severity of a fault
func (ftm *FaultToleranceManager) determineSeverity(faultType FaultType, metadata map[string]interface{}) FaultSeverity <span class="cov0" title="0">{
        switch faultType </span>{
        case FaultTypeNodeFailure:<span class="cov0" title="0">
                return FaultSeverityHigh</span>
        case FaultTypeNetworkPartition:<span class="cov0" title="0">
                return FaultSeverityCritical</span>
        case FaultTypeResourceExhaustion:<span class="cov0" title="0">
                return FaultSeverityHigh</span>
        case FaultTypePerformanceAnomaly:<span class="cov0" title="0">
                return FaultSeverityMedium</span>
        case FaultTypeServiceUnavailable:<span class="cov0" title="0">
                return FaultSeverityHigh</span>
        default:<span class="cov0" title="0">
                return FaultSeverityMedium</span>
        }
}

// triggerRecovery triggers recovery for a fault
func (ftm *FaultToleranceManager) triggerRecovery(fault *FaultDetection) <span class="cov0" title="0">{
        recoveryRequest := &amp;RecoveryRequest{
                Fault:     fault,
                Priority:  ftm.getPriority(fault.Severity),
                Timestamp: time.Now(),
        }
        
        select </span>{
        case ftm.recoveryEngine.recoveryQueue &lt;- recoveryRequest:<span class="cov0" title="0">
                slog.Debug("recovery request queued", "fault_id", fault.ID)</span>
        case &lt;-time.After(5 * time.Second):<span class="cov0" title="0">
                slog.Warn("recovery queue full, dropping request", "fault_id", fault.ID)</span>
        }
}

// getPriority gets priority based on severity
func (ftm *FaultToleranceManager) getPriority(severity FaultSeverity) int <span class="cov0" title="0">{
        switch severity </span>{
        case FaultSeverityCritical:<span class="cov0" title="0">
                return 1</span>
        case FaultSeverityHigh:<span class="cov0" title="0">
                return 2</span>
        case FaultSeverityMedium:<span class="cov0" title="0">
                return 3</span>
        case FaultSeverityLow:<span class="cov0" title="0">
                return 4</span>
        default:<span class="cov0" title="0">
                return 5</span>
        }
}

// GetMetrics returns fault tolerance metrics
func (ftm *FaultToleranceManager) GetMetrics() *FaultToleranceMetrics <span class="cov0" title="0">{
        ftm.mu.RLock()
        defer ftm.mu.RUnlock()
        
        // Calculate uptime
        if ftm.started </span><span class="cov0" title="0">{
                ftm.metrics.Uptime = time.Since(time.Now().Add(-ftm.metrics.Uptime))
        }</span>
        
        // Calculate average recovery time
        <span class="cov0" title="0">ftm.recoveryEngine.historyMu.RLock()
        if len(ftm.recoveryEngine.recoveryHistory) &gt; 0 </span><span class="cov0" title="0">{
                totalTime := time.Duration(0)
                for _, attempt := range ftm.recoveryEngine.recoveryHistory </span><span class="cov0" title="0">{
                        if attempt.Result != nil </span><span class="cov0" title="0">{
                                totalTime += attempt.Result.Duration
                        }</span>
                }
                <span class="cov0" title="0">ftm.metrics.AverageRecoveryTime = totalTime / time.Duration(len(ftm.recoveryEngine.recoveryHistory))</span>
        }
        <span class="cov0" title="0">ftm.recoveryEngine.historyMu.RUnlock()
        
        return ftm.metrics</span>
}

// GetFaultDetections returns all fault detections
func (ftm *FaultToleranceManager) GetFaultDetections() []*FaultDetection <span class="cov0" title="0">{
        ftm.detectionSystem.detectionsMu.RLock()
        defer ftm.detectionSystem.detectionsMu.RUnlock()
        
        detections := make([]*FaultDetection, 0, len(ftm.detectionSystem.detections))
        for _, detection := range ftm.detectionSystem.detections </span><span class="cov0" title="0">{
                detections = append(detections, detection)
        }</span>
        
        <span class="cov0" title="0">return detections</span>
}

// GetRecoveryHistory returns recovery history
func (ftm *FaultToleranceManager) GetRecoveryHistory() []*RecoveryAttempt <span class="cov0" title="0">{
        ftm.recoveryEngine.historyMu.RLock()
        defer ftm.recoveryEngine.historyMu.RUnlock()
        
        history := make([]*RecoveryAttempt, len(ftm.recoveryEngine.recoveryHistory))
        copy(history, ftm.recoveryEngine.recoveryHistory)
        
        return history
}</span>

// Shutdown gracefully shuts down the fault tolerance manager
func (ftm *FaultToleranceManager) Shutdown(ctx context.Context) error <span class="cov0" title="0">{
        ftm.mu.Lock()
        defer ftm.mu.Unlock()
        
        if !ftm.started </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        <span class="cov0" title="0">slog.Info("shutting down fault tolerance manager")
        
        // Cancel context
        ftm.cancel()
        
        // Wait for components to shutdown
        shutdownCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
        defer cancel()
        
        // Shutdown components
        if err := ftm.shutdownComponents(shutdownCtx); err != nil </span><span class="cov0" title="0">{
                slog.Warn("error during shutdown", "error", err)
        }</span>
        
        <span class="cov0" title="0">ftm.started = false
        
        return nil</span>
}

// shutdownComponents shuts down all components
func (ftm *FaultToleranceManager) shutdownComponents(ctx context.Context) error <span class="cov0" title="0">{
        // Create final checkpoint
        if ftm.checkpointing != nil </span><span class="cov0" title="0">{
                checkpoint := ftm.checkpointing.CreateCheckpoint()
                if checkpoint == nil </span><span class="cov0" title="0">{
                        slog.Warn("failed to create final checkpoint")
                }</span>
        }
        
        // Close recovery queue
        <span class="cov0" title="0">close(ftm.recoveryEngine.recoveryQueue)
        
        return nil</span>
}
</pre>
		
		<pre class="file" id="file42" style="display: none">package fault_tolerance

import (
        "context"
        "net"
        "runtime"
        "time"
)

// NodeHealthChecker checks node health
type NodeHealthChecker struct {
        name string
}

func NewNodeHealthChecker() *NodeHealthChecker <span class="cov0" title="0">{
        return &amp;NodeHealthChecker{
                name: "node_health",
        }
}</span>

func (nhc *NodeHealthChecker) GetName() string <span class="cov0" title="0">{
        return nhc.name
}</span>

func (nhc *NodeHealthChecker) Check(ctx context.Context, target string) (*HealthResult, error) <span class="cov0" title="0">{
        start := time.Now()
        result := &amp;HealthResult{
                Target:    target,
                Timestamp: start,
                Metrics:   make(map[string]interface{}),
        }

        // Check if we can connect to the target node
        conn, err := net.DialTimeout("tcp", target, 5*time.Second)
        if err != nil </span><span class="cov0" title="0">{
                result.Healthy = false
                result.Error = err.Error()
                result.Latency = time.Since(start)
                result.Metrics["reachable"] = false
                return result, nil
        }</span>
        <span class="cov0" title="0">defer conn.Close()

        result.Healthy = true
        result.Latency = time.Since(start)
        result.Metrics["reachable"] = true
        result.Metrics["latency_ms"] = result.Latency.Milliseconds()

        return result, nil</span>
}

// NetworkHealthChecker checks network health
type NetworkHealthChecker struct {
        name string
}

func NewNetworkHealthChecker() *NetworkHealthChecker <span class="cov0" title="0">{
        return &amp;NetworkHealthChecker{
                name: "network_health",
        }
}</span>

func (nwc *NetworkHealthChecker) GetName() string <span class="cov0" title="0">{
        return nwc.name
}</span>

func (nwc *NetworkHealthChecker) Check(ctx context.Context, target string) (*HealthResult, error) <span class="cov0" title="0">{
        start := time.Now()
        result := &amp;HealthResult{
                Target:    target,
                Timestamp: start,
                Metrics:   make(map[string]interface{}),
        }

        // Check network connectivity
        conn, err := net.DialTimeout("tcp", target, 3*time.Second)
        if err != nil </span><span class="cov0" title="0">{
                result.Healthy = false
                result.Error = err.Error()
                result.Latency = time.Since(start)
                result.Metrics["connectivity"] = false
                return result, nil
        }</span>
        <span class="cov0" title="0">defer conn.Close()

        result.Healthy = true
        result.Latency = time.Since(start)
        result.Metrics["connectivity"] = true
        result.Metrics["bandwidth"] = "100Mbps" // Placeholder

        return result, nil</span>
}

// ResourceHealthChecker checks resource health
type ResourceHealthChecker struct {
        name string
}

func NewResourceHealthChecker() *ResourceHealthChecker <span class="cov0" title="0">{
        return &amp;ResourceHealthChecker{
                name: "resource_health",
        }
}</span>

func (rhc *ResourceHealthChecker) GetName() string <span class="cov0" title="0">{
        return rhc.name
}</span>

func (rhc *ResourceHealthChecker) Check(ctx context.Context, target string) (*HealthResult, error) <span class="cov0" title="0">{
        start := time.Now()
        result := &amp;HealthResult{
                Target:    target,
                Timestamp: start,
                Metrics:   make(map[string]interface{}),
        }

        // Check system resources
        var m runtime.MemStats
        runtime.ReadMemStats(&amp;m)

        cpuUsage := 0.5 // Placeholder CPU usage
        memUsage := float64(m.Alloc) / float64(m.Sys)

        result.Metrics["cpu_usage"] = cpuUsage
        result.Metrics["memory_usage"] = memUsage
        result.Metrics["goroutines"] = runtime.NumGoroutine()
        result.Latency = time.Since(start)

        // Consider healthy if CPU &lt; 80% and Memory &lt; 90%
        result.Healthy = cpuUsage &lt; 0.8 &amp;&amp; memUsage &lt; 0.9

        if !result.Healthy </span><span class="cov0" title="0">{
                result.Error = "resource_exhaustion"
        }</span>

        <span class="cov0" title="0">return result, nil</span>
}

// PerformanceHealthChecker checks performance health
type PerformanceHealthChecker struct {
        name string
}

func NewPerformanceHealthChecker() *PerformanceHealthChecker <span class="cov0" title="0">{
        return &amp;PerformanceHealthChecker{
                name: "performance_health",
        }
}</span>

func (phc *PerformanceHealthChecker) GetName() string <span class="cov0" title="0">{
        return phc.name
}</span>

func (phc *PerformanceHealthChecker) Check(ctx context.Context, target string) (*HealthResult, error) <span class="cov0" title="0">{
        start := time.Now()
        result := &amp;HealthResult{
                Target:    target,
                Timestamp: start,
                Metrics:   make(map[string]interface{}),
        }

        // Simulate performance metrics
        responseTime := 100 * time.Millisecond // Placeholder
        throughput := 1000.0                   // Placeholder requests/sec
        errorRate := 0.01                      // Placeholder error rate

        result.Metrics["response_time_ms"] = responseTime.Milliseconds()
        result.Metrics["throughput"] = throughput
        result.Metrics["error_rate"] = errorRate
        result.Latency = time.Since(start)

        // Consider healthy if response time &lt; 500ms and error rate &lt; 5%
        result.Healthy = responseTime &lt; 500*time.Millisecond &amp;&amp; errorRate &lt; 0.05

        if !result.Healthy </span><span class="cov0" title="0">{
                result.Error = "performance_degradation"
        }</span>

        <span class="cov0" title="0">return result, nil</span>
}</pre>
		
		<pre class="file" id="file43" style="display: none">package fault_tolerance

import (
        "context"
        "fmt"
        "log/slog"
        "time"
)

// GracefulDegradationStrategy implements graceful degradation recovery
type GracefulDegradationStrategy struct {
        name string
}

func (gds *GracefulDegradationStrategy) GetName() string <span class="cov0" title="0">{
        return "graceful_degradation"
}</span>

func (gds *GracefulDegradationStrategy) CanHandle(fault *FaultDetection) bool <span class="cov0" title="0">{
        return fault.Type == FaultTypeNodeFailure || fault.Type == FaultTypeResourceExhaustion
}</span>

func (gds *GracefulDegradationStrategy) Recover(ctx context.Context, fault *FaultDetection) (*RecoveryResult, error) <span class="cov0" title="0">{
        start := time.Now()
        
        // Implement graceful degradation
        // 1. Reduce quality/speed for availability
        // 2. Fallback to smaller models
        // 3. Skip optional processing steps
        
        slog.Info("implementing graceful degradation", "fault_id", fault.ID, "target", fault.Target)
        
        // Simulate degradation implementation
        time.Sleep(100 * time.Millisecond)
        
        return &amp;RecoveryResult{
                FaultID:    fault.ID,
                Strategy:   gds.GetName(),
                Successful: true,
                Duration:   time.Since(start),
                Metadata: map[string]interface{}{
                        "degradation_level": "moderate",
                        "fallback_model":    "small",
                        "quality_reduction": 0.2,
                },
                Timestamp: time.Now(),
        }, nil
}</span>

// RequestMigrationStrategy implements request migration recovery
type RequestMigrationStrategy struct {
        name string
}

func (rms *RequestMigrationStrategy) GetName() string <span class="cov0" title="0">{
        return "request_migration"
}</span>

func (rms *RequestMigrationStrategy) CanHandle(fault *FaultDetection) bool <span class="cov0" title="0">{
        return fault.Type == FaultTypeNodeFailure || fault.Type == FaultTypeNetworkPartition
}</span>

func (rms *RequestMigrationStrategy) Recover(ctx context.Context, fault *FaultDetection) (*RecoveryResult, error) <span class="cov0" title="0">{
        start := time.Now()
        
        // Implement request migration
        // 1. Transparent request redistribution
        // 2. Stateful session recovery
        // 3. Progressive retry with backoff
        
        slog.Info("migrating requests", "fault_id", fault.ID, "target", fault.Target)
        
        // Simulate migration implementation
        time.Sleep(200 * time.Millisecond)
        
        return &amp;RecoveryResult{
                FaultID:    fault.ID,
                Strategy:   rms.GetName(),
                Successful: true,
                Duration:   time.Since(start),
                Metadata: map[string]interface{}{
                        "migrated_requests": 15,
                        "target_nodes":      []string{"node-2", "node-3"},
                        "session_restored":  true,
                },
                Timestamp: time.Now(),
        }, nil
}</span>

// ModelReplicationStrategy implements model replication recovery
type ModelReplicationStrategy struct {
        name string
}

func (mrs *ModelReplicationStrategy) GetName() string <span class="cov0" title="0">{
        return "model_replication"
}</span>

func (mrs *ModelReplicationStrategy) CanHandle(fault *FaultDetection) bool <span class="cov0" title="0">{
        return fault.Type == FaultTypeNodeFailure
}</span>

func (mrs *ModelReplicationStrategy) Recover(ctx context.Context, fault *FaultDetection) (*RecoveryResult, error) <span class="cov0" title="0">{
        start := time.Now()
        
        // Implement model replication
        // 1. Hot standby replicas
        // 2. Automatic failover
        // 3. Consistency maintenance
        
        slog.Info("replicating models", "fault_id", fault.ID, "target", fault.Target)
        
        // Simulate replication implementation
        time.Sleep(500 * time.Millisecond)
        
        return &amp;RecoveryResult{
                FaultID:    fault.ID,
                Strategy:   mrs.GetName(),
                Successful: true,
                Duration:   time.Since(start),
                Metadata: map[string]interface{}{
                        "replicated_models": []string{"model-1", "model-2"},
                        "replica_nodes":     []string{"node-4", "node-5"},
                        "failover_complete": true,
                },
                Timestamp: time.Now(),
        }, nil
}</span>

// PartitionToleranceStrategy implements partition tolerance recovery
type PartitionToleranceStrategy struct {
        name string
}

func (pts *PartitionToleranceStrategy) GetName() string <span class="cov0" title="0">{
        return "partition_tolerance"
}</span>

func (pts *PartitionToleranceStrategy) CanHandle(fault *FaultDetection) bool <span class="cov0" title="0">{
        return fault.Type == FaultTypeNetworkPartition
}</span>

func (pts *PartitionToleranceStrategy) Recover(ctx context.Context, fault *FaultDetection) (*RecoveryResult, error) <span class="cov0" title="0">{
        start := time.Now()
        
        // Implement partition tolerance
        // 1. Detect network partitions
        // 2. Maintain operation in majority partition
        // 3. Reconcile when partition heals
        
        slog.Info("handling network partition", "fault_id", fault.ID, "target", fault.Target)
        
        // Simulate partition handling
        time.Sleep(300 * time.Millisecond)
        
        return &amp;RecoveryResult{
                FaultID:    fault.ID,
                Strategy:   pts.GetName(),
                Successful: true,
                Duration:   time.Since(start),
                Metadata: map[string]interface{}{
                        "partition_detected": true,
                        "majority_partition": true,
                        "isolated_nodes":     []string{"node-6"},
                        "reconciliation_pending": false,
                },
                Timestamp: time.Now(),
        }, nil
}</span>

// ResourceScalingStrategy implements resource scaling recovery
type ResourceScalingStrategy struct {
        name string
}

func (rss *ResourceScalingStrategy) GetName() string <span class="cov0" title="0">{
        return "resource_scaling"
}</span>

func (rss *ResourceScalingStrategy) CanHandle(fault *FaultDetection) bool <span class="cov0" title="0">{
        return fault.Type == FaultTypeResourceExhaustion
}</span>

func (rss *ResourceScalingStrategy) Recover(ctx context.Context, fault *FaultDetection) (*RecoveryResult, error) <span class="cov0" title="0">{
        start := time.Now()
        
        // Implement resource scaling
        // 1. Scale up resources
        // 2. Add additional nodes
        // 3. Redistribute load
        
        slog.Info("scaling resources", "fault_id", fault.ID, "target", fault.Target)
        
        // Simulate scaling implementation
        time.Sleep(1000 * time.Millisecond)
        
        return &amp;RecoveryResult{
                FaultID:    fault.ID,
                Strategy:   rss.GetName(),
                Successful: true,
                Duration:   time.Since(start),
                Metadata: map[string]interface{}{
                        "scaled_resources": map[string]interface{}{
                                "cpu_cores": 8,
                                "memory_gb": 32,
                                "gpu_count": 2,
                        },
                        "new_nodes": []string{"node-7", "node-8"},
                        "load_redistributed": true,
                },
                Timestamp: time.Now(),
        }, nil
}</span>

// LoadSheddingStrategy implements load shedding recovery
type LoadSheddingStrategy struct {
        name string
}

func (lss *LoadSheddingStrategy) GetName() string <span class="cov0" title="0">{
        return "load_shedding"
}</span>

func (lss *LoadSheddingStrategy) CanHandle(fault *FaultDetection) bool <span class="cov0" title="0">{
        return fault.Type == FaultTypeResourceExhaustion
}</span>

func (lss *LoadSheddingStrategy) Recover(ctx context.Context, fault *FaultDetection) (*RecoveryResult, error) <span class="cov0" title="0">{
        start := time.Now()
        
        // Implement load shedding
        // 1. Drop low-priority requests
        // 2. Implement rate limiting
        // 3. Prioritize critical requests
        
        slog.Info("shedding load", "fault_id", fault.ID, "target", fault.Target)
        
        // Simulate load shedding implementation
        time.Sleep(50 * time.Millisecond)
        
        return &amp;RecoveryResult{
                FaultID:    fault.ID,
                Strategy:   lss.GetName(),
                Successful: true,
                Duration:   time.Since(start),
                Metadata: map[string]interface{}{
                        "dropped_requests": 25,
                        "rate_limit_applied": true,
                        "priority_threshold": 3,
                        "load_reduction": 0.4,
                },
                Timestamp: time.Now(),
        }, nil
}</span>

// PerformanceTuningStrategy implements performance tuning recovery
type PerformanceTuningStrategy struct {
        name string
}

func (pts *PerformanceTuningStrategy) GetName() string <span class="cov0" title="0">{
        return "performance_tuning"
}</span>

func (pts *PerformanceTuningStrategy) CanHandle(fault *FaultDetection) bool <span class="cov0" title="0">{
        return fault.Type == FaultTypePerformanceAnomaly
}</span>

func (pts *PerformanceTuningStrategy) Recover(ctx context.Context, fault *FaultDetection) (*RecoveryResult, error) <span class="cov0" title="0">{
        start := time.Now()
        
        // Implement performance tuning
        // 1. Adjust model parameters
        // 2. Optimize resource allocation
        // 3. Tune scheduling algorithms
        
        slog.Info("tuning performance", "fault_id", fault.ID, "target", fault.Target)
        
        // Simulate performance tuning
        time.Sleep(150 * time.Millisecond)
        
        return &amp;RecoveryResult{
                FaultID:    fault.ID,
                Strategy:   pts.GetName(),
                Successful: true,
                Duration:   time.Since(start),
                Metadata: map[string]interface{}{
                        "tuned_parameters": map[string]interface{}{
                                "batch_size": 16,
                                "num_threads": 4,
                                "memory_pool_size": "2GB",
                        },
                        "performance_improvement": 0.25,
                },
                Timestamp: time.Now(),
        }, nil
}</span>

// LoadBalancingStrategy implements load balancing recovery
type LoadBalancingStrategy struct {
        name string
}

func (lbs *LoadBalancingStrategy) GetName() string <span class="cov0" title="0">{
        return "load_balancing"
}</span>

func (lbs *LoadBalancingStrategy) CanHandle(fault *FaultDetection) bool <span class="cov0" title="0">{
        return fault.Type == FaultTypePerformanceAnomaly
}</span>

func (lbs *LoadBalancingStrategy) Recover(ctx context.Context, fault *FaultDetection) (*RecoveryResult, error) <span class="cov0" title="0">{
        start := time.Now()
        
        // Implement load balancing recovery
        // 1. Rebalance load across nodes
        // 2. Adjust routing weights
        // 3. Migrate heavy workloads
        
        slog.Info("rebalancing load", "fault_id", fault.ID, "target", fault.Target)
        
        // Simulate load balancing
        time.Sleep(200 * time.Millisecond)
        
        return &amp;RecoveryResult{
                FaultID:    fault.ID,
                Strategy:   lbs.GetName(),
                Successful: true,
                Duration:   time.Since(start),
                Metadata: map[string]interface{}{
                        "rebalanced_load": true,
                        "adjusted_weights": map[string]float64{
                                "node-1": 0.3,
                                "node-2": 0.4,
                                "node-3": 0.3,
                        },
                        "migrated_workloads": 3,
                },
                Timestamp: time.Now(),
        }, nil
}</span>

// RecoveryEngine methods

// start starts the recovery engine
func (re *RecoveryEngine) start(ctx context.Context) <span class="cov0" title="0">{
        slog.Info("recovery engine started")
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        slog.Info("recovery engine shutting down")
                        return</span>
                case request := &lt;-re.recoveryQueue:<span class="cov0" title="0">
                        go re.processRecoveryRequest(ctx, request)</span>
                }
        }
}

// processRecoveryRequest processes a recovery request
func (re *RecoveryEngine) processRecoveryRequest(ctx context.Context, request *RecoveryRequest) <span class="cov0" title="0">{
        attemptID := fmt.Sprintf("attempt_%d", time.Now().UnixNano())
        
        slog.Info("processing recovery request",
                "attempt_id", attemptID,
                "fault_id", request.Fault.ID,
                "fault_type", request.Fault.Type,
                "priority", request.Priority)
        
        // Get strategies for this fault type
        strategies, exists := re.strategies[request.Fault.Type]
        if !exists </span><span class="cov0" title="0">{
                slog.Warn("no recovery strategies available", "fault_type", request.Fault.Type)
                return
        }</span>
        
        // Try each strategy until one succeeds
        <span class="cov0" title="0">for _, strategy := range strategies </span><span class="cov0" title="0">{
                if !strategy.CanHandle(request.Fault) </span><span class="cov0" title="0">{
                        continue</span>
                }
                
                // Attempt recovery
                <span class="cov0" title="0">result, err := strategy.Recover(ctx, request.Fault)
                if err != nil </span><span class="cov0" title="0">{
                        slog.Warn("recovery strategy failed",
                                "strategy", strategy.GetName(),
                                "fault_id", request.Fault.ID,
                                "error", err)
                        continue</span>
                }
                
                // Record attempt
                <span class="cov0" title="0">attempt := &amp;RecoveryAttempt{
                        ID:        attemptID,
                        FaultID:   request.Fault.ID,
                        Strategy:  strategy.GetName(),
                        Result:    result,
                        Timestamp: time.Now(),
                }
                
                re.historyMu.Lock()
                re.recoveryHistory = append(re.recoveryHistory, attempt)
                
                // Keep only last 1000 attempts
                if len(re.recoveryHistory) &gt; 1000 </span><span class="cov0" title="0">{
                        re.recoveryHistory = re.recoveryHistory[len(re.recoveryHistory)-1000:]
                }</span>
                <span class="cov0" title="0">re.historyMu.Unlock()
                
                // Update metrics
                re.manager.metrics.RecoveryAttempts++
                if result.Successful </span><span class="cov0" title="0">{
                        re.manager.metrics.SuccessfulRecoveries++
                        re.manager.metrics.FaultsResolved++
                        now := time.Now()
                        re.manager.metrics.LastRecovery = &amp;now
                        
                        // Mark fault as resolved
                        re.manager.detectionSystem.detectionsMu.Lock()
                        if fault, exists := re.manager.detectionSystem.detections[request.Fault.ID]; exists </span><span class="cov0" title="0">{
                                fault.Status = FaultStatusResolved
                                resolvedAt := time.Now()
                                fault.ResolvedAt = &amp;resolvedAt
                        }</span>
                        <span class="cov0" title="0">re.manager.detectionSystem.detectionsMu.Unlock()
                        
                        slog.Info("recovery successful",
                                "attempt_id", attemptID,
                                "strategy", strategy.GetName(),
                                "fault_id", request.Fault.ID,
                                "duration", result.Duration)
                        return</span>
                }
        }
        
        // All strategies failed
        <span class="cov0" title="0">slog.Error("all recovery strategies failed", "fault_id", request.Fault.ID)
        
        // Mark fault as persistent
        re.manager.detectionSystem.detectionsMu.Lock()
        if fault, exists := re.manager.detectionSystem.detections[request.Fault.ID]; exists </span><span class="cov0" title="0">{
                fault.Status = FaultStatusPersistent
        }</span>
        <span class="cov0" title="0">re.manager.detectionSystem.detectionsMu.Unlock()</span>
}

// AlertingSystem methods

// sendAlert sends an alert
func (as *AlertingSystem) sendAlert(alert *FaultAlert) <span class="cov0" title="0">{
        if !as.config.Enabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        // Check if alert should be throttled
        <span class="cov0" title="0">if as.shouldThrottle(alert) </span><span class="cov0" title="0">{
                return
        }</span>
        
        // Store alert
        <span class="cov0" title="0">as.alertsMu.Lock()
        as.alerts = append(as.alerts, alert)
        
        // Keep only last 1000 alerts
        if len(as.alerts) &gt; 1000 </span><span class="cov0" title="0">{
                as.alerts = as.alerts[len(as.alerts)-1000:]
        }</span>
        <span class="cov0" title="0">as.alertsMu.Unlock()
        
        // Send to handlers
        for _, handler := range as.handlers </span><span class="cov0" title="0">{
                go func(h AlertHandler) </span><span class="cov0" title="0">{
                        if err := h.Handle(alert); err != nil </span><span class="cov0" title="0">{
                                slog.Warn("alert handler failed",
                                        "handler", h.GetName(),
                                        "alert_id", alert.ID,
                                        "error", err)
                        }</span>
                }(handler)
        }
        
        <span class="cov0" title="0">slog.Info("alert sent",
                "alert_id", alert.ID,
                "fault_id", alert.FaultID,
                "severity", alert.Severity,
                "message", alert.Message)</span>
}

// shouldThrottle checks if an alert should be throttled
func (as *AlertingSystem) shouldThrottle(alert *FaultAlert) bool <span class="cov0" title="0">{
        if as.config.ThrottleTime == 0 </span><span class="cov0" title="0">{
                return false
        }</span>
        
        // Check for similar recent alerts
        <span class="cov0" title="0">as.alertsMu.RLock()
        defer as.alertsMu.RUnlock()
        
        for _, existingAlert := range as.alerts </span><span class="cov0" title="0">{
                if existingAlert.FaultID == alert.FaultID &amp;&amp;
                        time.Since(existingAlert.Timestamp) &lt; as.config.ThrottleTime </span><span class="cov0" title="0">{
                        return true
                }</span>
        }
        
        <span class="cov0" title="0">return false</span>
}
</pre>
		
		<pre class="file" id="file44" style="display: none">package loadbalancer

import (
        "fmt"
        "math"
        "math/rand"
        "sort"
        "time"
)

// WeightedRoundRobinAlgorithm implements weighted round-robin with prediction
type WeightedRoundRobinAlgorithm struct {
        name    string
        metrics *AlgorithmMetrics
        counter int
        weights map[string]float64
}

// NewWeightedRoundRobinAlgorithm creates a new weighted round-robin algorithm
func NewWeightedRoundRobinAlgorithm() *WeightedRoundRobinAlgorithm <span class="cov0" title="0">{
        return &amp;WeightedRoundRobinAlgorithm{
                name:    "weighted_round_robin",
                metrics: &amp;AlgorithmMetrics{LastUsed: time.Now()},
                weights: make(map[string]float64),
        }
}</span>

func (wrr *WeightedRoundRobinAlgorithm) GetName() string <span class="cov0" title="0">{
        return wrr.name
}</span>

func (wrr *WeightedRoundRobinAlgorithm) GetMetrics() *AlgorithmMetrics <span class="cov0" title="0">{
        return wrr.metrics
}</span>

func (wrr *WeightedRoundRobinAlgorithm) SelectNodes(task interface{}, nodes []*NodeInfo) ([]*NodeInfo, error) <span class="cov0" title="0">{
        if len(nodes) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no nodes available")
        }</span>
        
        // Update weights based on current node performance
        <span class="cov0" title="0">for _, node := range nodes </span><span class="cov0" title="0">{
                weight := wrr.calculateWeight(node)
                wrr.weights[node.ID] = weight
        }</span>
        
        // Select node using weighted round-robin
        <span class="cov0" title="0">totalWeight := 0.0
        for _, weight := range wrr.weights </span><span class="cov0" title="0">{
                totalWeight += weight
        }</span>
        
        <span class="cov0" title="0">if totalWeight == 0 </span><span class="cov0" title="0">{
                // Fallback to simple round-robin
                selectedIndex := wrr.counter % len(nodes)
                wrr.counter++
                return []*NodeInfo{nodes[selectedIndex]}, nil
        }</span>
        
        // Weighted selection
        <span class="cov0" title="0">target := rand.Float64() * totalWeight
        currentSum := 0.0
        
        for _, node := range nodes </span><span class="cov0" title="0">{
                currentSum += wrr.weights[node.ID]
                if currentSum &gt;= target </span><span class="cov0" title="0">{
                        return []*NodeInfo{node}, nil
                }</span>
        }
        
        // Fallback to first node
        <span class="cov0" title="0">return []*NodeInfo{nodes[0]}, nil</span>
}

func (wrr *WeightedRoundRobinAlgorithm) calculateWeight(node *NodeInfo) float64 <span class="cov0" title="0">{
        // Weight based on capacity and inverse of utilization
        capacityScore := node.PerformanceScore
        utilizationPenalty := (node.Usage.CPUUtilization + node.Usage.MemoryUtilization) / 2.0
        healthBonus := node.HealthScore
        
        weight := capacityScore * healthBonus * (1.0 - utilizationPenalty)
        return math.Max(weight, 0.1) // Minimum weight
}</span>

func (wrr *WeightedRoundRobinAlgorithm) UpdateMetrics(result *SelectionResult) <span class="cov0" title="0">{
        wrr.metrics.Selections++
        wrr.metrics.LastUsed = time.Now()
        
        if result.Successful </span><span class="cov0" title="0">{
                wrr.metrics.SuccessRate = float64(wrr.metrics.Selections) / float64(wrr.metrics.Selections)
                wrr.metrics.AverageLatency = (wrr.metrics.AverageLatency + result.ExecutionLatency) / 2
                wrr.metrics.Throughput = (wrr.metrics.Throughput + result.Throughput) / 2
        }</span>
}

// LeastEffectiveLoadAlgorithm implements least effective load balancing
type LeastEffectiveLoadAlgorithm struct {
        name    string
        metrics *AlgorithmMetrics
}

// NewLeastEffectiveLoadAlgorithm creates a new least effective load algorithm
func NewLeastEffectiveLoadAlgorithm() *LeastEffectiveLoadAlgorithm <span class="cov0" title="0">{
        return &amp;LeastEffectiveLoadAlgorithm{
                name:    "least_effective_load",
                metrics: &amp;AlgorithmMetrics{LastUsed: time.Now()},
        }
}</span>

func (lel *LeastEffectiveLoadAlgorithm) GetName() string <span class="cov0" title="0">{
        return lel.name
}</span>

func (lel *LeastEffectiveLoadAlgorithm) GetMetrics() *AlgorithmMetrics <span class="cov0" title="0">{
        return lel.metrics
}</span>

func (lel *LeastEffectiveLoadAlgorithm) SelectNodes(task interface{}, nodes []*NodeInfo) ([]*NodeInfo, error) <span class="cov0" title="0">{
        if len(nodes) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no nodes available")
        }</span>
        
        // Calculate effective load for each node
        <span class="cov0" title="0">type nodeScore struct {
                node         *NodeInfo
                effectiveLoad float64
        }
        
        scores := make([]nodeScore, len(nodes))
        for i, node := range nodes </span><span class="cov0" title="0">{
                scores[i] = nodeScore{
                        node:         node,
                        effectiveLoad: lel.calculateEffectiveLoad(node),
                }
        }</span>
        
        // Sort by effective load (ascending)
        <span class="cov0" title="0">sort.Slice(scores, func(i, j int) bool </span><span class="cov0" title="0">{
                return scores[i].effectiveLoad &lt; scores[j].effectiveLoad
        }</span>)
        
        // Select the node with least effective load
        <span class="cov0" title="0">return []*NodeInfo{scores[0].node}, nil</span>
}

func (lel *LeastEffectiveLoadAlgorithm) calculateEffectiveLoad(node *NodeInfo) float64 <span class="cov0" title="0">{
        // Effective load considers both utilization and capacity
        cpuLoad := node.Usage.CPUUtilization / math.Max(float64(node.Capacity.CPUCores), 1.0)
        memoryLoad := node.Usage.MemoryUtilization
        gpuLoad := node.Usage.GPUUtilization
        networkLoad := node.Usage.NetworkUtilization
        
        // Queue load
        queueLoad := float64(node.Usage.ActiveRequests+node.Usage.QueuedRequests) / 10.0
        
        // Weighted effective load
        effectiveLoad := 0.3*cpuLoad + 0.3*memoryLoad + 0.2*gpuLoad + 0.1*networkLoad + 0.1*queueLoad
        
        // Adjust for health score
        effectiveLoad = effectiveLoad / math.Max(node.HealthScore, 0.1)
        
        return effectiveLoad
}</span>

func (lel *LeastEffectiveLoadAlgorithm) UpdateMetrics(result *SelectionResult) <span class="cov0" title="0">{
        lel.metrics.Selections++
        lel.metrics.LastUsed = time.Now()
        
        if result.Successful </span><span class="cov0" title="0">{
                lel.metrics.SuccessRate = float64(lel.metrics.Selections) / float64(lel.metrics.Selections)
                lel.metrics.AverageLatency = (lel.metrics.AverageLatency + result.ExecutionLatency) / 2
                lel.metrics.Throughput = (lel.metrics.Throughput + result.Throughput) / 2
        }</span>
}

// LocalityAwareAlgorithm implements locality-aware scheduling
type LocalityAwareAlgorithm struct {
        name    string
        metrics *AlgorithmMetrics
        cache   map[string][]string // model -&gt; preferred nodes
}

// NewLocalityAwareAlgorithm creates a new locality-aware algorithm
func NewLocalityAwareAlgorithm() *LocalityAwareAlgorithm <span class="cov0" title="0">{
        return &amp;LocalityAwareAlgorithm{
                name:    "locality_aware",
                metrics: &amp;AlgorithmMetrics{LastUsed: time.Now()},
                cache:   make(map[string][]string),
        }
}</span>

func (laa *LocalityAwareAlgorithm) GetName() string <span class="cov0" title="0">{
        return laa.name
}</span>

func (laa *LocalityAwareAlgorithm) GetMetrics() *AlgorithmMetrics <span class="cov0" title="0">{
        return laa.metrics
}</span>

func (laa *LocalityAwareAlgorithm) SelectNodes(task interface{}, nodes []*NodeInfo) ([]*NodeInfo, error) <span class="cov0" title="0">{
        if len(nodes) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no nodes available")
        }</span>
        
        // Try to determine model name from task
        <span class="cov0" title="0">modelName := laa.getModelName(task)
        
        // Check cache for preferred nodes
        if preferredNodes, exists := laa.cache[modelName]; exists </span><span class="cov0" title="0">{
                for _, preferredNodeID := range preferredNodes </span><span class="cov0" title="0">{
                        for _, node := range nodes </span><span class="cov0" title="0">{
                                if node.ID == preferredNodeID </span><span class="cov0" title="0">{
                                        // Check if node is still suitable
                                        if laa.isSuitableNode(node) </span><span class="cov0" title="0">{
                                                return []*NodeInfo{node}, nil
                                        }</span>
                                }
                        }
                }
        }
        
        // No cached preference or preferred nodes unavailable
        // Select based on locality factors
        <span class="cov0" title="0">type nodeScore struct {
                node         *NodeInfo
                localityScore float64
        }
        
        scores := make([]nodeScore, len(nodes))
        for i, node := range nodes </span><span class="cov0" title="0">{
                scores[i] = nodeScore{
                        node:         node,
                        localityScore: laa.calculateLocalityScore(node, modelName),
                }
        }</span>
        
        // Sort by locality score (descending)
        <span class="cov0" title="0">sort.Slice(scores, func(i, j int) bool </span><span class="cov0" title="0">{
                return scores[i].localityScore &gt; scores[j].localityScore
        }</span>)
        
        // Update cache with selected node
        <span class="cov0" title="0">selectedNode := scores[0].node
        laa.updateCache(modelName, selectedNode.ID)
        
        return []*NodeInfo{selectedNode}, nil</span>
}

func (laa *LocalityAwareAlgorithm) getModelName(task interface{}) string <span class="cov0" title="0">{
        // Extract model name from task
        // This is a simplified implementation
        return "default_model"
}</span>

func (laa *LocalityAwareAlgorithm) isSuitableNode(node *NodeInfo) bool <span class="cov0" title="0">{
        // Check if node is suitable for execution
        return node.HealthScore &gt; 0.5 &amp;&amp; 
                   node.Usage.CPUUtilization &lt; 0.9 &amp;&amp; 
                   node.Usage.MemoryUtilization &lt; 0.9
}</span>

func (laa *LocalityAwareAlgorithm) calculateLocalityScore(node *NodeInfo, modelName string) float64 <span class="cov0" title="0">{
        // Locality score based on:
        // 1. Model cache hit (if model is already loaded)
        // 2. Network latency
        // 3. Data locality
        // 4. Session affinity
        
        // Check if model is cached on this node
        modelCacheHit := laa.hasModelCached(node, modelName)
        
        // Network latency score (inverse of latency)
        latencyScore := 1.0 / (1.0 + float64(node.Latency)/float64(time.Millisecond))
        
        // Data locality score (placeholder)
        dataLocalityScore := 0.8
        
        // Session affinity score (placeholder)
        sessionAffinityScore := 0.7
        
        // Combine scores
        localityScore := 0.4*modelCacheHit + 0.3*latencyScore + 0.2*dataLocalityScore + 0.1*sessionAffinityScore
        
        return localityScore
}</span>

func (laa *LocalityAwareAlgorithm) hasModelCached(node *NodeInfo, modelName string) float64 <span class="cov0" title="0">{
        // Check if model is cached on the node
        // This would interface with the actual model cache
        // For now, return a placeholder value
        return 0.5
}</span>

func (laa *LocalityAwareAlgorithm) updateCache(modelName, nodeID string) <span class="cov0" title="0">{
        if _, exists := laa.cache[modelName]; !exists </span><span class="cov0" title="0">{
                laa.cache[modelName] = make([]string, 0)
        }</span>
        
        // Add node to preferred list if not already present
        <span class="cov0" title="0">for _, id := range laa.cache[modelName] </span><span class="cov0" title="0">{
                if id == nodeID </span><span class="cov0" title="0">{
                        return
                }</span>
        }
        
        <span class="cov0" title="0">laa.cache[modelName] = append(laa.cache[modelName], nodeID)
        
        // Keep only top 3 preferred nodes
        if len(laa.cache[modelName]) &gt; 3 </span><span class="cov0" title="0">{
                laa.cache[modelName] = laa.cache[modelName][:3]
        }</span>
}

func (laa *LocalityAwareAlgorithm) UpdateMetrics(result *SelectionResult) <span class="cov0" title="0">{
        laa.metrics.Selections++
        laa.metrics.LastUsed = time.Now()
        
        if result.Successful </span><span class="cov0" title="0">{
                laa.metrics.SuccessRate = float64(laa.metrics.Selections) / float64(laa.metrics.Selections)
                laa.metrics.AverageLatency = (laa.metrics.AverageLatency + result.ExecutionLatency) / 2
                laa.metrics.Throughput = (laa.metrics.Throughput + result.Throughput) / 2
        }</span>
}

// PredictiveAlgorithm implements predictive load balancing
type PredictiveAlgorithm struct {
        name      string
        metrics   *AlgorithmMetrics
        predictor *PerformancePredictor
}

// NewPredictiveAlgorithm creates a new predictive algorithm
func NewPredictiveAlgorithm(predictor *PerformancePredictor) *PredictiveAlgorithm <span class="cov0" title="0">{
        return &amp;PredictiveAlgorithm{
                name:      "predictive",
                metrics:   &amp;AlgorithmMetrics{LastUsed: time.Now()},
                predictor: predictor,
        }
}</span>

func (pa *PredictiveAlgorithm) GetName() string <span class="cov0" title="0">{
        return pa.name
}</span>

func (pa *PredictiveAlgorithm) GetMetrics() *AlgorithmMetrics <span class="cov0" title="0">{
        return pa.metrics
}</span>

func (pa *PredictiveAlgorithm) SelectNodes(task interface{}, nodes []*NodeInfo) ([]*NodeInfo, error) <span class="cov0" title="0">{
        if len(nodes) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no nodes available")
        }</span>
        
        <span class="cov0" title="0">taskType := pa.getTaskType(task)
        
        // Get predictions for all nodes
        type nodePrediction struct {
                node               *NodeInfo
                predictedLatency   time.Duration
                predictedThroughput float64
                predictionScore    float64
        }
        
        predictions := make([]nodePrediction, len(nodes))
        for i, node := range nodes </span><span class="cov0" title="0">{
                latency, throughput := pa.predictor.PredictPerformance(node, taskType)
                score := pa.calculatePredictionScore(latency, throughput)
                
                predictions[i] = nodePrediction{
                        node:               node,
                        predictedLatency:   latency,
                        predictedThroughput: throughput,
                        predictionScore:    score,
                }
        }</span>
        
        // Sort by prediction score (descending)
        <span class="cov0" title="0">sort.Slice(predictions, func(i, j int) bool </span><span class="cov0" title="0">{
                return predictions[i].predictionScore &gt; predictions[j].predictionScore
        }</span>)
        
        // Select the node with best predicted performance
        <span class="cov0" title="0">return []*NodeInfo{predictions[0].node}, nil</span>
}

func (pa *PredictiveAlgorithm) getTaskType(task interface{}) string <span class="cov0" title="0">{
        // Extract task type from task
        // This is a simplified implementation
        return "inference"
}</span>

func (pa *PredictiveAlgorithm) calculatePredictionScore(latency time.Duration, throughput float64) float64 <span class="cov0" title="0">{
        // Score based on predicted performance
        latencyScore := 1.0 / (1.0 + float64(latency)/float64(time.Second))
        throughputScore := throughput / 100.0 // Normalize to 100 ops/sec
        
        // Weighted combination
        return 0.6*latencyScore + 0.4*throughputScore
}</span>

func (pa *PredictiveAlgorithm) UpdateMetrics(result *SelectionResult) <span class="cov0" title="0">{
        pa.metrics.Selections++
        pa.metrics.LastUsed = time.Now()
        
        if result.Successful </span><span class="cov0" title="0">{
                pa.metrics.SuccessRate = float64(pa.metrics.Selections) / float64(pa.metrics.Selections)
                pa.metrics.AverageLatency = (pa.metrics.AverageLatency + result.ExecutionLatency) / 2
                pa.metrics.Throughput = (pa.metrics.Throughput + result.Throughput) / 2
        }</span>
}

// AdaptiveAlgorithm implements adaptive load balancing
type AdaptiveAlgorithm struct {
        name    string
        metrics *AlgorithmMetrics
        history *RequestHistory
        strategies []string
        currentStrategy string
}

// NewAdaptiveAlgorithm creates a new adaptive algorithm
func NewAdaptiveAlgorithm(history *RequestHistory) *AdaptiveAlgorithm <span class="cov0" title="0">{
        return &amp;AdaptiveAlgorithm{
                name:    "adaptive",
                metrics: &amp;AlgorithmMetrics{LastUsed: time.Now()},
                history: history,
                strategies: []string{"round_robin", "least_load", "locality_aware"},
                currentStrategy: "round_robin",
        }
}</span>

func (aa *AdaptiveAlgorithm) GetName() string <span class="cov0" title="0">{
        return aa.name
}</span>

func (aa *AdaptiveAlgorithm) GetMetrics() *AlgorithmMetrics <span class="cov0" title="0">{
        return aa.metrics
}</span>

func (aa *AdaptiveAlgorithm) SelectNodes(task interface{}, nodes []*NodeInfo) ([]*NodeInfo, error) <span class="cov0" title="0">{
        if len(nodes) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no nodes available")
        }</span>
        
        // Adapt strategy based on current conditions
        <span class="cov0" title="0">aa.adaptStrategy(nodes)
        
        // Select node based on current strategy
        switch aa.currentStrategy </span>{
        case "round_robin":<span class="cov0" title="0">
                return aa.selectRoundRobin(nodes)</span>
        case "least_load":<span class="cov0" title="0">
                return aa.selectLeastLoad(nodes)</span>
        case "locality_aware":<span class="cov0" title="0">
                return aa.selectLocalityAware(nodes)</span>
        default:<span class="cov0" title="0">
                return []*NodeInfo{nodes[0]}, nil</span>
        }
}

func (aa *AdaptiveAlgorithm) adaptStrategy(nodes []*NodeInfo) <span class="cov0" title="0">{
        // Analyze current system state
        loadVariance := aa.calculateLoadVariance(nodes)
        latencyVariance := aa.calculateLatencyVariance(nodes)
        
        // Adapt strategy based on conditions
        if loadVariance &gt; 0.5 </span><span class="cov0" title="0">{
                aa.currentStrategy = "least_load"
        }</span> else<span class="cov0" title="0"> if latencyVariance &gt; 0.3 </span><span class="cov0" title="0">{
                aa.currentStrategy = "locality_aware"
        }</span> else<span class="cov0" title="0"> {
                aa.currentStrategy = "round_robin"
        }</span>
}

func (aa *AdaptiveAlgorithm) calculateLoadVariance(nodes []*NodeInfo) float64 <span class="cov0" title="0">{
        if len(nodes) == 0 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        // Calculate average load
        <span class="cov0" title="0">totalLoad := 0.0
        for _, node := range nodes </span><span class="cov0" title="0">{
                totalLoad += node.LoadScore
        }</span>
        <span class="cov0" title="0">averageLoad := totalLoad / float64(len(nodes))
        
        // Calculate variance
        variance := 0.0
        for _, node := range nodes </span><span class="cov0" title="0">{
                deviation := node.LoadScore - averageLoad
                variance += deviation * deviation
        }</span>
        
        <span class="cov0" title="0">return variance / float64(len(nodes))</span>
}

func (aa *AdaptiveAlgorithm) calculateLatencyVariance(nodes []*NodeInfo) float64 <span class="cov0" title="0">{
        if len(nodes) == 0 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        // Calculate average latency
        <span class="cov0" title="0">totalLatency := time.Duration(0)
        for _, node := range nodes </span><span class="cov0" title="0">{
                totalLatency += node.Latency
        }</span>
        <span class="cov0" title="0">averageLatency := totalLatency / time.Duration(len(nodes))
        
        // Calculate variance
        variance := 0.0
        for _, node := range nodes </span><span class="cov0" title="0">{
                deviation := float64(node.Latency - averageLatency)
                variance += deviation * deviation
        }</span>
        
        <span class="cov0" title="0">return variance / float64(len(nodes))</span>
}

func (aa *AdaptiveAlgorithm) selectRoundRobin(nodes []*NodeInfo) ([]*NodeInfo, error) <span class="cov0" title="0">{
        // Simple round-robin selection
        static := struct {
                counter int
        }{}
        selectedIndex := static.counter % len(nodes)
        static.counter++
        return []*NodeInfo{nodes[selectedIndex]}, nil
}</span>

func (aa *AdaptiveAlgorithm) selectLeastLoad(nodes []*NodeInfo) ([]*NodeInfo, error) <span class="cov0" title="0">{
        // Select node with least load
        minLoad := math.MaxFloat64
        var selectedNode *NodeInfo
        
        for _, node := range nodes </span><span class="cov0" title="0">{
                if node.LoadScore &lt; minLoad </span><span class="cov0" title="0">{
                        minLoad = node.LoadScore
                        selectedNode = node
                }</span>
        }
        
        <span class="cov0" title="0">return []*NodeInfo{selectedNode}, nil</span>
}

func (aa *AdaptiveAlgorithm) selectLocalityAware(nodes []*NodeInfo) ([]*NodeInfo, error) <span class="cov0" title="0">{
        // Select node with lowest latency
        minLatency := time.Duration(math.MaxInt64)
        var selectedNode *NodeInfo
        
        for _, node := range nodes </span><span class="cov0" title="0">{
                if node.Latency &lt; minLatency </span><span class="cov0" title="0">{
                        minLatency = node.Latency
                        selectedNode = node
                }</span>
        }
        
        <span class="cov0" title="0">return []*NodeInfo{selectedNode}, nil</span>
}

func (aa *AdaptiveAlgorithm) UpdateMetrics(result *SelectionResult) <span class="cov0" title="0">{
        aa.metrics.Selections++
        aa.metrics.LastUsed = time.Now()
        
        if result.Successful </span><span class="cov0" title="0">{
                aa.metrics.SuccessRate = float64(aa.metrics.Selections) / float64(aa.metrics.Selections)
                aa.metrics.AverageLatency = (aa.metrics.AverageLatency + result.ExecutionLatency) / 2
                aa.metrics.Throughput = (aa.metrics.Throughput + result.Throughput) / 2
        }</span>
}
</pre>
		
		<pre class="file" id="file45" style="display: none">package loadbalancer

import (
        "fmt"
        "log/slog"
        "math"
        "sort"
        "sync"
        "time"
)

// IntelligentLoadBalancer implements intelligent load balancing with prediction
type IntelligentLoadBalancer struct {
        config      *Config
        algorithms  map[string]LoadBalancingAlgorithm
        predictor   *PerformancePredictor
        history     *RequestHistory
        constraints []LoadBalancingConstraint
        metrics     *LoadBalancerMetrics
        mu          sync.RWMutex
}

// Config holds load balancer configuration
type Config struct {
        Algorithm     string                 `json:"algorithm"`
        LatencyTarget time.Duration          `json:"latency_target"`
        WeightFactors map[string]float64     `json:"weight_factors"`
        Adaptive      bool                   `json:"adaptive"`
        PredictionEnabled bool               `json:"prediction_enabled"`
        HistorySize   int                    `json:"history_size"`
}

// LoadBalancingAlgorithm defines the interface for load balancing algorithms
type LoadBalancingAlgorithm interface {
        SelectNodes(task interface{}, nodes []*NodeInfo) ([]*NodeInfo, error)
        GetName() string
        GetMetrics() *AlgorithmMetrics
        UpdateMetrics(result *SelectionResult)
}

// NodeInfo represents node information for load balancing
type NodeInfo struct {
        ID               string                 `json:"id"`
        Address          string                 `json:"address"`
        Capacity         *ResourceCapacity      `json:"capacity"`
        Usage            *ResourceUsage         `json:"usage"`
        Latency          time.Duration          `json:"latency"`
        Bandwidth        int64                  `json:"bandwidth"`
        HealthScore      float64                `json:"health_score"`
        LoadScore        float64                `json:"load_score"`
        PerformanceScore float64                `json:"performance_score"`
        Capabilities     []string               `json:"capabilities"`
        Metadata         map[string]interface{} `json:"metadata"`
}

// ResourceCapacity represents node resource capacity
type ResourceCapacity struct {
        CPUCores         int64   `json:"cpu_cores"`
        MemoryBytes      int64   `json:"memory_bytes"`
        GPUCount         int     `json:"gpu_count"`
        GPUMemoryBytes   int64   `json:"gpu_memory_bytes"`
        NetworkBandwidth int64   `json:"network_bandwidth"`
        ComputeScore     float64 `json:"compute_score"`
}

// ResourceUsage represents node resource usage
type ResourceUsage struct {
        CPUUtilization    float64 `json:"cpu_utilization"`
        MemoryUtilization float64 `json:"memory_utilization"`
        GPUUtilization    float64 `json:"gpu_utilization"`
        NetworkUtilization float64 `json:"network_utilization"`
        ActiveRequests    int     `json:"active_requests"`
        QueuedRequests    int     `json:"queued_requests"`
        LoadAverage       float64 `json:"load_average"`
}

// LoadBalancingConstraint represents a constraint for load balancing
type LoadBalancingConstraint struct {
        Type     string      `json:"type"`     // "memory", "gpu", "latency", "cost"
        Value    interface{} `json:"value"`
        Operator string      `json:"operator"` // "&lt;", "&gt;", "=", "&lt;=", "&gt;="
        Priority int         `json:"priority"`
}

// PerformancePredictor predicts node performance
type PerformancePredictor struct {
        models     map[string]*PredictionModel
        history    []*PerformanceSample
        historyMu  sync.RWMutex
        learning   bool
        accuracy   float64
}

// PredictionModel represents a performance prediction model
type PredictionModel struct {
        Name       string                 `json:"name"`
        Type       string                 `json:"type"`
        Weights    map[string]float64     `json:"weights"`
        Accuracy   float64                `json:"accuracy"`
        LastTrained time.Time             `json:"last_trained"`
        Metadata   map[string]interface{} `json:"metadata"`
}

// PerformanceSample represents a performance sample for learning
type PerformanceSample struct {
        NodeID          string        `json:"node_id"`
        TaskType        string        `json:"task_type"`
        ResourceState   *ResourceUsage `json:"resource_state"`
        PredictedLatency time.Duration `json:"predicted_latency"`
        ActualLatency   time.Duration `json:"actual_latency"`
        PredictedThroughput float64   `json:"predicted_throughput"`
        ActualThroughput float64      `json:"actual_throughput"`
        Timestamp       time.Time     `json:"timestamp"`
}

// RequestHistory tracks request history for patterns
type RequestHistory struct {
        requests   []*RequestRecord
        requestsMu sync.RWMutex
        patterns   map[string]*RequestPattern
        patternsMu sync.RWMutex
}

// RequestRecord represents a request record
type RequestRecord struct {
        ID               string                 `json:"id"`
        Type             string                 `json:"type"`
        SelectedNodes    []string               `json:"selected_nodes"`
        Latency          time.Duration          `json:"latency"`
        Throughput       float64                `json:"throughput"`
        ResourceUsage    map[string]interface{} `json:"resource_usage"`
        Timestamp        time.Time              `json:"timestamp"`
        Successful       bool                   `json:"successful"`
}

// RequestPattern represents a request pattern
type RequestPattern struct {
        Type              string        `json:"type"`
        AverageLatency    time.Duration `json:"average_latency"`
        AverageThroughput float64       `json:"average_throughput"`
        PreferredNodes    []string      `json:"preferred_nodes"`
        ResourceProfile   map[string]float64 `json:"resource_profile"`
        Confidence        float64       `json:"confidence"`
        LastUpdated       time.Time     `json:"last_updated"`
}

// LoadBalancerMetrics represents load balancer metrics
type LoadBalancerMetrics struct {
        TotalRequests      int64         `json:"total_requests"`
        SuccessfulRequests int64         `json:"successful_requests"`
        FailedRequests     int64         `json:"failed_requests"`
        AverageLatency     time.Duration `json:"average_latency"`
        Throughput         float64       `json:"throughput"`
        AlgorithmMetrics   map[string]*AlgorithmMetrics `json:"algorithm_metrics"`
        LastUpdated        time.Time     `json:"last_updated"`
}

// AlgorithmMetrics represents metrics for a specific algorithm
type AlgorithmMetrics struct {
        Selections        int64         `json:"selections"`
        SuccessRate       float64       `json:"success_rate"`
        AverageLatency    time.Duration `json:"average_latency"`
        Throughput        float64       `json:"throughput"`
        LastUsed          time.Time     `json:"last_used"`
}

// SelectionResult represents the result of a node selection
type SelectionResult struct {
        Nodes            []*NodeInfo   `json:"nodes"`
        Algorithm        string        `json:"algorithm"`
        SelectionTime    time.Duration `json:"selection_time"`
        ExecutionLatency time.Duration `json:"execution_latency"`
        Throughput       float64       `json:"throughput"`
        Successful       bool          `json:"successful"`
        Timestamp        time.Time     `json:"timestamp"`
}

// NewIntelligentLoadBalancer creates a new intelligent load balancer
func NewIntelligentLoadBalancer(config *Config) *IntelligentLoadBalancer <span class="cov0" title="0">{
        ilb := &amp;IntelligentLoadBalancer{
                config:      config,
                algorithms:  make(map[string]LoadBalancingAlgorithm),
                constraints: make([]LoadBalancingConstraint, 0),
                metrics: &amp;LoadBalancerMetrics{
                        AlgorithmMetrics: make(map[string]*AlgorithmMetrics),
                        LastUpdated:      time.Now(),
                },
        }
        
        // Initialize performance predictor
        ilb.predictor = &amp;PerformancePredictor{
                models:   make(map[string]*PredictionModel),
                history:  make([]*PerformanceSample, 0),
                learning: config.PredictionEnabled,
                accuracy: 0.7, // Initial accuracy
        }
        
        // Initialize request history
        ilb.history = &amp;RequestHistory{
                requests: make([]*RequestRecord, 0),
                patterns: make(map[string]*RequestPattern),
        }
        
        // Register algorithms
        ilb.RegisterAlgorithm(NewWeightedRoundRobinAlgorithm())
        ilb.RegisterAlgorithm(NewLeastEffectiveLoadAlgorithm())
        ilb.RegisterAlgorithm(NewLocalityAwareAlgorithm())
        ilb.RegisterAlgorithm(NewPredictiveAlgorithm(ilb.predictor))
        ilb.RegisterAlgorithm(NewAdaptiveAlgorithm(ilb.history))
        
        return ilb
}</span>

// RegisterAlgorithm registers a load balancing algorithm
func (ilb *IntelligentLoadBalancer) RegisterAlgorithm(algorithm LoadBalancingAlgorithm) <span class="cov0" title="0">{
        ilb.mu.Lock()
        defer ilb.mu.Unlock()
        
        ilb.algorithms[algorithm.GetName()] = algorithm
        ilb.metrics.AlgorithmMetrics[algorithm.GetName()] = &amp;AlgorithmMetrics{
                LastUsed: time.Now(),
        }
}</span>

// SelectNodes selects the best nodes for a task
func (ilb *IntelligentLoadBalancer) SelectNodes(task interface{}, availableNodes []*NodeInfo) ([]*NodeInfo, error) <span class="cov0" title="0">{
        start := time.Now()
        
        // Update metrics
        ilb.metrics.TotalRequests++
        
        // Apply constraints
        constrainedNodes := ilb.applyConstraints(availableNodes)
        if len(constrainedNodes) == 0 </span><span class="cov0" title="0">{
                ilb.metrics.FailedRequests++
                return nil, fmt.Errorf("no nodes satisfy constraints")
        }</span>
        
        // Select algorithm
        <span class="cov0" title="0">algorithm, err := ilb.selectAlgorithm(task, constrainedNodes)
        if err != nil </span><span class="cov0" title="0">{
                ilb.metrics.FailedRequests++
                return nil, fmt.Errorf("failed to select algorithm: %v", err)
        }</span>
        
        // Select nodes using the chosen algorithm
        <span class="cov0" title="0">selectedNodes, err := algorithm.SelectNodes(task, constrainedNodes)
        if err != nil </span><span class="cov0" title="0">{
                ilb.metrics.FailedRequests++
                return nil, fmt.Errorf("algorithm selection failed: %v", err)
        }</span>
        
        // Update metrics
        <span class="cov0" title="0">ilb.metrics.SuccessfulRequests++
        selectionTime := time.Since(start)
        
        // Record selection result
        result := &amp;SelectionResult{
                Nodes:         selectedNodes,
                Algorithm:     algorithm.GetName(),
                SelectionTime: selectionTime,
                Successful:    true,
                Timestamp:     time.Now(),
        }
        
        // Update algorithm metrics
        algorithm.UpdateMetrics(result)
        
        slog.Debug("node selection completed",
                "algorithm", algorithm.GetName(),
                "selected_nodes", len(selectedNodes),
                "selection_time", selectionTime,
                "available_nodes", len(availableNodes))
        
        return selectedNodes, nil</span>
}

// applyConstraints applies load balancing constraints to nodes
func (ilb *IntelligentLoadBalancer) applyConstraints(nodes []*NodeInfo) []*NodeInfo <span class="cov0" title="0">{
        if len(ilb.constraints) == 0 </span><span class="cov0" title="0">{
                return nodes
        }</span>
        
        <span class="cov0" title="0">constrained := make([]*NodeInfo, 0)
        
        for _, node := range nodes </span><span class="cov0" title="0">{
                satisfies := true
                
                for _, constraint := range ilb.constraints </span><span class="cov0" title="0">{
                        if !ilb.satisfiesConstraint(node, constraint) </span><span class="cov0" title="0">{
                                satisfies = false
                                break</span>
                        }
                }
                
                <span class="cov0" title="0">if satisfies </span><span class="cov0" title="0">{
                        constrained = append(constrained, node)
                }</span>
        }
        
        <span class="cov0" title="0">return constrained</span>
}

// satisfiesConstraint checks if a node satisfies a constraint
func (ilb *IntelligentLoadBalancer) satisfiesConstraint(node *NodeInfo, constraint LoadBalancingConstraint) bool <span class="cov0" title="0">{
        switch constraint.Type </span>{
        case "memory":<span class="cov0" title="0">
                memoryUtilization := node.Usage.MemoryUtilization
                threshold := constraint.Value.(float64)
                return ilb.compareValues(memoryUtilization, threshold, constraint.Operator)</span>
                
        case "gpu":<span class="cov0" title="0">
                gpuUtilization := node.Usage.GPUUtilization
                threshold := constraint.Value.(float64)
                return ilb.compareValues(gpuUtilization, threshold, constraint.Operator)</span>
                
        case "latency":<span class="cov0" title="0">
                latency := node.Latency
                threshold := constraint.Value.(time.Duration)
                return ilb.compareLatency(latency, threshold, constraint.Operator)</span>
                
        case "cost":<span class="cov0" title="0">
                // Cost constraint implementation would go here
                return true</span>
                
        default:<span class="cov0" title="0">
                return true</span>
        }
}

// compareValues compares two float64 values using an operator
func (ilb *IntelligentLoadBalancer) compareValues(value, threshold float64, operator string) bool <span class="cov0" title="0">{
        switch operator </span>{
        case "&lt;":<span class="cov0" title="0">
                return value &lt; threshold</span>
        case "&gt;":<span class="cov0" title="0">
                return value &gt; threshold</span>
        case "=":<span class="cov0" title="0">
                return math.Abs(value-threshold) &lt; 0.001</span>
        case "&lt;=":<span class="cov0" title="0">
                return value &lt;= threshold</span>
        case "&gt;=":<span class="cov0" title="0">
                return value &gt;= threshold</span>
        default:<span class="cov0" title="0">
                return true</span>
        }
}

// compareLatency compares two latency values using an operator
func (ilb *IntelligentLoadBalancer) compareLatency(latency, threshold time.Duration, operator string) bool <span class="cov0" title="0">{
        switch operator </span>{
        case "&lt;":<span class="cov0" title="0">
                return latency &lt; threshold</span>
        case "&gt;":<span class="cov0" title="0">
                return latency &gt; threshold</span>
        case "=":<span class="cov0" title="0">
                return latency == threshold</span>
        case "&lt;=":<span class="cov0" title="0">
                return latency &lt;= threshold</span>
        case "&gt;=":<span class="cov0" title="0">
                return latency &gt;= threshold</span>
        default:<span class="cov0" title="0">
                return true</span>
        }
}

// selectAlgorithm selects the best algorithm for a task
func (ilb *IntelligentLoadBalancer) selectAlgorithm(task interface{}, nodes []*NodeInfo) (LoadBalancingAlgorithm, error) <span class="cov0" title="0">{
        // If adaptive mode is disabled, use configured algorithm
        if !ilb.config.Adaptive </span><span class="cov0" title="0">{
                if algorithm, exists := ilb.algorithms[ilb.config.Algorithm]; exists </span><span class="cov0" title="0">{
                        return algorithm, nil
                }</span>
                <span class="cov0" title="0">return nil, fmt.Errorf("algorithm not found: %s", ilb.config.Algorithm)</span>
        }
        
        // Adaptive algorithm selection
        <span class="cov0" title="0">return ilb.selectAdaptiveAlgorithm(task, nodes)</span>
}

// selectAdaptiveAlgorithm selects an algorithm adaptively based on context
func (ilb *IntelligentLoadBalancer) selectAdaptiveAlgorithm(task interface{}, nodes []*NodeInfo) (LoadBalancingAlgorithm, error) <span class="cov0" title="0">{
        // Analyze task characteristics
        taskType := ilb.getTaskType(task)
        nodeCount := len(nodes)
        loadVariance := ilb.calculateLoadVariance(nodes)
        
        // Select algorithm based on context
        if nodeCount &lt;= 2 </span><span class="cov0" title="0">{
                // Simple round-robin for small clusters
                return ilb.algorithms["weighted_round_robin"], nil
        }</span>
        
        <span class="cov0" title="0">if loadVariance &gt; 0.5 </span><span class="cov0" title="0">{
                // Use least effective load for unbalanced clusters
                return ilb.algorithms["least_effective_load"], nil
        }</span>
        
        <span class="cov0" title="0">if taskType == "latency_sensitive" </span><span class="cov0" title="0">{
                // Use locality-aware for latency-sensitive tasks
                return ilb.algorithms["locality_aware"], nil
        }</span>
        
        <span class="cov0" title="0">if ilb.config.PredictionEnabled </span><span class="cov0" title="0">{
                // Use predictive algorithm when prediction is enabled
                return ilb.algorithms["predictive"], nil
        }</span>
        
        // Default to adaptive algorithm
        <span class="cov0" title="0">return ilb.algorithms["adaptive"], nil</span>
}

// getTaskType determines the type of task
func (ilb *IntelligentLoadBalancer) getTaskType(task interface{}) string <span class="cov0" title="0">{
        // This would analyze the task to determine its type
        // For now, return a default type
        return "general"
}</span>

// calculateLoadVariance calculates the variance in load across nodes
func (ilb *IntelligentLoadBalancer) calculateLoadVariance(nodes []*NodeInfo) float64 <span class="cov0" title="0">{
        if len(nodes) == 0 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        // Calculate average load
        <span class="cov0" title="0">totalLoad := 0.0
        for _, node := range nodes </span><span class="cov0" title="0">{
                totalLoad += node.LoadScore
        }</span>
        <span class="cov0" title="0">averageLoad := totalLoad / float64(len(nodes))
        
        // Calculate variance
        variance := 0.0
        for _, node := range nodes </span><span class="cov0" title="0">{
                deviation := node.LoadScore - averageLoad
                variance += deviation * deviation
        }</span>
        
        <span class="cov0" title="0">return variance / float64(len(nodes))</span>
}

// AddConstraint adds a load balancing constraint
func (ilb *IntelligentLoadBalancer) AddConstraint(constraint LoadBalancingConstraint) <span class="cov0" title="0">{
        ilb.mu.Lock()
        defer ilb.mu.Unlock()
        
        ilb.constraints = append(ilb.constraints, constraint)
        
        // Sort constraints by priority
        sort.Slice(ilb.constraints, func(i, j int) bool </span><span class="cov0" title="0">{
                return ilb.constraints[i].Priority &gt; ilb.constraints[j].Priority
        }</span>)
}

// RemoveConstraint removes a load balancing constraint
func (ilb *IntelligentLoadBalancer) RemoveConstraint(constraintType string) <span class="cov0" title="0">{
        ilb.mu.Lock()
        defer ilb.mu.Unlock()
        
        for i, constraint := range ilb.constraints </span><span class="cov0" title="0">{
                if constraint.Type == constraintType </span><span class="cov0" title="0">{
                        ilb.constraints = append(ilb.constraints[:i], ilb.constraints[i+1:]...)
                        break</span>
                }
        }
}

// GetMetrics returns load balancer metrics
func (ilb *IntelligentLoadBalancer) GetMetrics() *LoadBalancerMetrics <span class="cov0" title="0">{
        ilb.mu.RLock()
        defer ilb.mu.RUnlock()
        
        // Calculate average latency
        if ilb.metrics.SuccessfulRequests &gt; 0 </span><span class="cov0" title="0">{
                // This would be calculated from actual measurements
                ilb.metrics.AverageLatency = 100 * time.Millisecond
        }</span>
        
        // Calculate throughput
        <span class="cov0" title="0">if ilb.metrics.SuccessfulRequests &gt; 0 </span><span class="cov0" title="0">{
                // This would be calculated from actual measurements
                ilb.metrics.Throughput = float64(ilb.metrics.SuccessfulRequests) / time.Since(ilb.metrics.LastUpdated).Seconds()
        }</span>
        
        <span class="cov0" title="0">return ilb.metrics</span>
}

// GetAvailableAlgorithms returns all available algorithms
func (ilb *IntelligentLoadBalancer) GetAvailableAlgorithms() []string <span class="cov0" title="0">{
        ilb.mu.RLock()
        defer ilb.mu.RUnlock()
        
        algorithms := make([]string, 0, len(ilb.algorithms))
        for name := range ilb.algorithms </span><span class="cov0" title="0">{
                algorithms = append(algorithms, name)
        }</span>
        
        <span class="cov0" title="0">return algorithms</span>
}

// UpdateConfig updates the load balancer configuration
func (ilb *IntelligentLoadBalancer) UpdateConfig(config *Config) <span class="cov0" title="0">{
        ilb.mu.Lock()
        defer ilb.mu.Unlock()
        
        ilb.config = config
        ilb.predictor.learning = config.PredictionEnabled
        
        slog.Info("load balancer configuration updated",
                "algorithm", config.Algorithm,
                "adaptive", config.Adaptive,
                "prediction_enabled", config.PredictionEnabled)
}</span>

// RecordResult records the result of a load balancing decision
func (ilb *IntelligentLoadBalancer) RecordResult(result *SelectionResult) <span class="cov0" title="0">{
        // Record in history
        ilb.history.recordRequest(&amp;RequestRecord{
                ID:            fmt.Sprintf("req_%d", time.Now().UnixNano()),
                Type:          "load_balancing",
                SelectedNodes: ilb.getNodeIDs(result.Nodes),
                Latency:       result.ExecutionLatency,
                Throughput:    result.Throughput,
                Timestamp:     result.Timestamp,
                Successful:    result.Successful,
        })
        
        // Update predictor if enabled
        if ilb.config.PredictionEnabled </span><span class="cov0" title="0">{
                ilb.predictor.recordSample(&amp;PerformanceSample{
                        TaskType:         "load_balancing",
                        ActualLatency:    result.ExecutionLatency,
                        ActualThroughput: result.Throughput,
                        Timestamp:        result.Timestamp,
                })
        }</span>
}

// getNodeIDs extracts node IDs from a slice of nodes
func (ilb *IntelligentLoadBalancer) getNodeIDs(nodes []*NodeInfo) []string <span class="cov0" title="0">{
        ids := make([]string, len(nodes))
        for i, node := range nodes </span><span class="cov0" title="0">{
                ids[i] = node.ID
        }</span>
        <span class="cov0" title="0">return ids</span>
}

// RequestHistory methods

// recordRequest records a request in the history
func (rh *RequestHistory) recordRequest(record *RequestRecord) <span class="cov0" title="0">{
        rh.requestsMu.Lock()
        defer rh.requestsMu.Unlock()
        
        rh.requests = append(rh.requests, record)
        
        // Keep only last 1000 requests
        if len(rh.requests) &gt; 1000 </span><span class="cov0" title="0">{
                rh.requests = rh.requests[len(rh.requests)-1000:]
        }</span>
        
        // Update patterns
        <span class="cov0" title="0">go rh.updatePatterns(record)</span>
}

// updatePatterns updates request patterns based on new records
func (rh *RequestHistory) updatePatterns(record *RequestRecord) <span class="cov0" title="0">{
        rh.patternsMu.Lock()
        defer rh.patternsMu.Unlock()
        
        pattern, exists := rh.patterns[record.Type]
        if !exists </span><span class="cov0" title="0">{
                pattern = &amp;RequestPattern{
                        Type:            record.Type,
                        PreferredNodes:  record.SelectedNodes,
                        ResourceProfile: make(map[string]float64),
                        Confidence:      0.5,
                        LastUpdated:     time.Now(),
                }
                rh.patterns[record.Type] = pattern
        }</span>
        
        // Update pattern with new data
        <span class="cov0" title="0">pattern.AverageLatency = (pattern.AverageLatency + record.Latency) / 2
        pattern.AverageThroughput = (pattern.AverageThroughput + record.Throughput) / 2
        pattern.LastUpdated = time.Now()
        
        // Update confidence based on success rate
        if record.Successful </span><span class="cov0" title="0">{
                pattern.Confidence = math.Min(pattern.Confidence*1.1, 1.0)
        }</span> else<span class="cov0" title="0"> {
                pattern.Confidence = math.Max(pattern.Confidence*0.9, 0.1)
        }</span>
}

// PerformancePredictor methods

// recordSample records a performance sample
func (pp *PerformancePredictor) recordSample(sample *PerformanceSample) <span class="cov0" title="0">{
        pp.historyMu.Lock()
        defer pp.historyMu.Unlock()
        
        pp.history = append(pp.history, sample)
        
        // Keep only last 1000 samples
        if len(pp.history) &gt; 1000 </span><span class="cov0" title="0">{
                pp.history = pp.history[len(pp.history)-1000:]
        }</span>
        
        // Update models if learning is enabled
        <span class="cov0" title="0">if pp.learning </span><span class="cov0" title="0">{
                go pp.updateModels()
        }</span>
}

// updateModels updates prediction models based on new samples
func (pp *PerformancePredictor) updateModels() <span class="cov0" title="0">{
        // This would implement actual machine learning model updates
        // For now, just update accuracy based on recent samples
        pp.historyMu.RLock()
        samples := pp.history
        pp.historyMu.RUnlock()
        
        if len(samples) &gt; 10 </span><span class="cov0" title="0">{
                // Calculate accuracy based on recent samples
                recentSamples := samples[len(samples)-10:]
                correctPredictions := 0
                
                for _, sample := range recentSamples </span><span class="cov0" title="0">{
                        // Simple accuracy calculation
                        if sample.PredictedLatency &gt; 0 </span><span class="cov0" title="0">{
                                error := math.Abs(float64(sample.ActualLatency-sample.PredictedLatency)) / float64(sample.ActualLatency)
                                if error &lt; 0.2 </span><span class="cov0" title="0">{ // 20% accuracy threshold
                                        correctPredictions++
                                }</span>
                        }
                }
                
                <span class="cov0" title="0">pp.accuracy = float64(correctPredictions) / float64(len(recentSamples))</span>
        }
}

// PredictPerformance predicts the performance of a node for a task
func (pp *PerformancePredictor) PredictPerformance(node *NodeInfo, taskType string) (time.Duration, float64) <span class="cov0" title="0">{
        if !pp.learning </span><span class="cov0" title="0">{
                // Return simple estimates if prediction is disabled
                return 100 * time.Millisecond, 10.0
        }</span>
        
        // Use historical data and models to predict performance
        <span class="cov0" title="0">pp.historyMu.RLock()
        defer pp.historyMu.RUnlock()
        
        // Find similar samples
        similarSamples := make([]*PerformanceSample, 0)
        for _, sample := range pp.history </span><span class="cov0" title="0">{
                if sample.NodeID == node.ID &amp;&amp; sample.TaskType == taskType </span><span class="cov0" title="0">{
                        similarSamples = append(similarSamples, sample)
                }</span>
        }
        
        <span class="cov0" title="0">if len(similarSamples) == 0 </span><span class="cov0" title="0">{
                // No historical data, return estimates
                return time.Duration(float64(100*time.Millisecond) / math.Max(node.PerformanceScore, 0.1)), node.PerformanceScore * 10.0
        }</span>
        
        // Calculate weighted average based on recent samples
        <span class="cov0" title="0">totalLatency := time.Duration(0)
        totalThroughput := 0.0
        weightSum := 0.0
        
        for i, sample := range similarSamples </span><span class="cov0" title="0">{
                // Weight recent samples more heavily
                weight := float64(i+1) / float64(len(similarSamples))
                totalLatency += time.Duration(float64(sample.ActualLatency) * weight)
                totalThroughput += sample.ActualThroughput * weight
                weightSum += weight
        }</span>
        
        <span class="cov0" title="0">predictedLatency := time.Duration(float64(totalLatency) / weightSum)
        predictedThroughput := totalThroughput / weightSum
        
        return predictedLatency, predictedThroughput</span>
}
</pre>
		
		<pre class="file" id="file46" style="display: none">package orchestration

import (
        "fmt"
        "time"
)

// ConcatAggregationStrategy concatenates partial results
type ConcatAggregationStrategy struct {
        name string
}

func (cas *ConcatAggregationStrategy) GetName() string <span class="cov0" title="0">{
        return "concat"
}</span>

func (cas *ConcatAggregationStrategy) Aggregate(context *AggregationContext) (*AggregatedResponse, error) <span class="cov0" title="0">{
        start := time.Now()
        
        // Concatenate all partial results
        results := make([]interface{}, 0)
        for _, partial := range context.PartialResults </span><span class="cov0" title="0">{
                if partial.Error == "" </span><span class="cov0" title="0">{
                        results = append(results, partial.Data)
                }</span>
        }
        
        <span class="cov0" title="0">return &amp;AggregatedResponse{
                TaskID:    context.TaskID,
                Strategy:  cas.GetName(),
                Data:      results,
                Metadata: map[string]interface{}{
                        "concatenated_count": len(results),
                        "total_partitions":   len(context.PartialResults),
                },
                Latency:   time.Since(start),
                Timestamp: time.Now(),
        }, nil</span>
}

// AverageAggregationStrategy averages partial results
type AverageAggregationStrategy struct {
        name string
}

func (aas *AverageAggregationStrategy) GetName() string <span class="cov0" title="0">{
        return "average"
}</span>

func (aas *AverageAggregationStrategy) Aggregate(context *AggregationContext) (*AggregatedResponse, error) <span class="cov0" title="0">{
        start := time.Now()
        
        // Average numeric results
        var total float64
        var count int
        
        for _, partial := range context.PartialResults </span><span class="cov0" title="0">{
                if partial.Error == "" </span><span class="cov0" title="0">{
                        if value, ok := partial.Data.(float64); ok </span><span class="cov0" title="0">{
                                total += value
                                count++
                        }</span>
                }
        }
        
        <span class="cov0" title="0">if count == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no valid numeric results to average")
        }</span>
        
        <span class="cov0" title="0">average := total / float64(count)
        
        return &amp;AggregatedResponse{
                TaskID:    context.TaskID,
                Strategy:  aas.GetName(),
                Data:      average,
                Metadata: map[string]interface{}{
                        "total_sum":        total,
                        "count":            count,
                        "average":          average,
                        "total_partitions": len(context.PartialResults),
                },
                Latency:   time.Since(start),
                Timestamp: time.Now(),
        }, nil</span>
}

// WeightedAggregationStrategy performs weighted aggregation
type WeightedAggregationStrategy struct {
        name string
}

func (was *WeightedAggregationStrategy) GetName() string <span class="cov0" title="0">{
        return "weighted"
}</span>

func (was *WeightedAggregationStrategy) Aggregate(context *AggregationContext) (*AggregatedResponse, error) <span class="cov0" title="0">{
        start := time.Now()
        
        // Perform weighted aggregation
        var weightedSum float64
        var totalWeight float64
        
        for _, partial := range context.PartialResults </span><span class="cov0" title="0">{
                if partial.Error == "" </span><span class="cov0" title="0">{
                        if value, ok := partial.Data.(float64); ok </span><span class="cov0" title="0">{
                                // Get weight from metadata, default to 1.0
                                weight := 1.0
                                if w, exists := partial.Metadata["weight"]; exists </span><span class="cov0" title="0">{
                                        if weightVal, ok := w.(float64); ok </span><span class="cov0" title="0">{
                                                weight = weightVal
                                        }</span>
                                }
                                
                                <span class="cov0" title="0">weightedSum += value * weight
                                totalWeight += weight</span>
                        }
                }
        }
        
        <span class="cov0" title="0">if totalWeight == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no valid weighted results to aggregate")
        }</span>
        
        <span class="cov0" title="0">weightedAverage := weightedSum / totalWeight
        
        return &amp;AggregatedResponse{
                TaskID:    context.TaskID,
                Strategy:  was.GetName(),
                Data:      weightedAverage,
                Metadata: map[string]interface{}{
                        "weighted_sum":     weightedSum,
                        "total_weight":     totalWeight,
                        "weighted_average": weightedAverage,
                        "total_partitions": len(context.PartialResults),
                },
                Latency:   time.Since(start),
                Timestamp: time.Now(),
        }, nil</span>
}

// RoundRobinPartitioningStrategy implements round-robin partitioning
type RoundRobinPartitioningStrategy struct {
        name    string
        counter int
}

func (rrps *RoundRobinPartitioningStrategy) GetName() string <span class="cov0" title="0">{
        return "round_robin"
}</span>

func (rrps *RoundRobinPartitioningStrategy) Partition(request *OrchestrationRequest) (*PartitionPlan, error) <span class="cov0" title="0">{
        // Simple round-robin partitioning
        nodeCount := 3 // Mock node count
        partitions := make([]*TaskPartition, nodeCount)
        
        for i := 0; i &lt; nodeCount; i++ </span><span class="cov0" title="0">{
                partitions[i] = &amp;TaskPartition{
                        ID:           fmt.Sprintf("partition_%d", i),
                        NodeID:       fmt.Sprintf("node_%d", i),
                        Type:         "round_robin",
                        Data:         fmt.Sprintf("partition_data_%d", i),
                        Dependencies: []string{},
                        Metadata: map[string]interface{}{
                                "partition_index": i,
                                "total_partitions": nodeCount,
                        },
                }
        }</span>
        
        <span class="cov0" title="0">return &amp;PartitionPlan{
                ID:        fmt.Sprintf("plan_%d", time.Now().UnixNano()),
                Strategy:  rrps.GetName(),
                Partitions: partitions,
                Metadata: map[string]interface{}{
                        "strategy": "round_robin",
                        "node_count": nodeCount,
                },
                CreatedAt: time.Now(),
        }, nil</span>
}

// LoadBasedPartitioningStrategy implements load-based partitioning
type LoadBasedPartitioningStrategy struct {
        name string
}

func (lbps *LoadBasedPartitioningStrategy) GetName() string <span class="cov0" title="0">{
        return "load_based"
}</span>

func (lbps *LoadBasedPartitioningStrategy) Partition(request *OrchestrationRequest) (*PartitionPlan, error) <span class="cov0" title="0">{
        // Mock load-based partitioning
        nodeLoads := map[string]float64{
                "node_0": 0.3,
                "node_1": 0.7,
                "node_2": 0.5,
        }
        
        partitions := make([]*TaskPartition, 0)
        partitionIndex := 0
        
        for nodeID, load := range nodeLoads </span><span class="cov0" title="0">{
                // Assign more partitions to nodes with lower load
                partitionCount := int((1.0 - load) * 3) + 1
                
                for i := 0; i &lt; partitionCount; i++ </span><span class="cov0" title="0">{
                        partitions = append(partitions, &amp;TaskPartition{
                                ID:           fmt.Sprintf("partition_%d", partitionIndex),
                                NodeID:       nodeID,
                                Type:         "load_based",
                                Data:         fmt.Sprintf("partition_data_%d", partitionIndex),
                                Dependencies: []string{},
                                Metadata: map[string]interface{}{
                                        "node_load": load,
                                        "partition_weight": 1.0 - load,
                                },
                        })
                        partitionIndex++
                }</span>
        }
        
        <span class="cov0" title="0">return &amp;PartitionPlan{
                ID:        fmt.Sprintf("plan_%d", time.Now().UnixNano()),
                Strategy:  lbps.GetName(),
                Partitions: partitions,
                Metadata: map[string]interface{}{
                        "strategy": "load_based",
                        "node_loads": nodeLoads,
                        "total_partitions": len(partitions),
                },
                CreatedAt: time.Now(),
        }, nil</span>
}

// CapabilityBasedPartitioningStrategy implements capability-based partitioning
type CapabilityBasedPartitioningStrategy struct {
        name string
}

func (cbps *CapabilityBasedPartitioningStrategy) GetName() string <span class="cov0" title="0">{
        return "capability_based"
}</span>

func (cbps *CapabilityBasedPartitioningStrategy) Partition(request *OrchestrationRequest) (*PartitionPlan, error) <span class="cov0" title="0">{
        // Mock capability-based partitioning
        nodeCapabilities := map[string][]string{
                "node_0": {"cpu", "memory"},
                "node_1": {"gpu", "memory"},
                "node_2": {"cpu", "gpu", "memory"},
        }
        
        partitions := make([]*TaskPartition, 0)
        partitionIndex := 0
        
        for nodeID, capabilities := range nodeCapabilities </span><span class="cov0" title="0">{
                // Assign partitions based on capabilities
                for _, capability := range capabilities </span><span class="cov0" title="0">{
                        partitions = append(partitions, &amp;TaskPartition{
                                ID:           fmt.Sprintf("partition_%d", partitionIndex),
                                NodeID:       nodeID,
                                Type:         "capability_based",
                                Data:         fmt.Sprintf("partition_data_%s_%s", nodeID, capability),
                                Dependencies: []string{},
                                Metadata: map[string]interface{}{
                                        "required_capability": capability,
                                        "node_capabilities": capabilities,
                                },
                        })
                        partitionIndex++
                }</span>
        }
        
        <span class="cov0" title="0">return &amp;PartitionPlan{
                ID:        fmt.Sprintf("plan_%d", time.Now().UnixNano()),
                Strategy:  cbps.GetName(),
                Partitions: partitions,
                Metadata: map[string]interface{}{
                        "strategy": "capability_based",
                        "node_capabilities": nodeCapabilities,
                        "total_partitions": len(partitions),
                },
                CreatedAt: time.Now(),
        }, nil</span>
}
</pre>
		
		<pre class="file" id="file47" style="display: none">package orchestration

import (
        "context"
        "fmt"
        "log/slog"
        "sync"
        "time"
)

// OrchestrationEngine manages distributed task orchestration
type OrchestrationEngine struct {
        config         *Config
        scheduler      *DistributedScheduler
        coordinator    *RequestCoordinator
        aggregator     *ResponseAggregator
        monitor        *OrchestrationMonitor
        activeTasks    map[string]*OrchestrationTask
        activeTasksMu  sync.RWMutex
        metrics        *OrchestrationMetrics
        mu             sync.RWMutex
        ctx            context.Context
        cancel         context.CancelFunc
        started        bool
}

// Config holds orchestration configuration
type Config struct {
        ClusterManager interface{} `json:"cluster_manager"`
        LoadBalancer   interface{} `json:"load_balancer"`
        FaultTolerance interface{} `json:"fault_tolerance"`
        MaxConcurrentTasks int     `json:"max_concurrent_tasks"`
        TaskTimeout        time.Duration `json:"task_timeout"`
        RetryPolicy        *RetryPolicy  `json:"retry_policy"`
        CoordinationMode   string        `json:"coordination_mode"`
}

// RetryPolicy defines retry behavior
type RetryPolicy struct {
        MaxRetries    int           `json:"max_retries"`
        InitialDelay  time.Duration `json:"initial_delay"`
        MaxDelay      time.Duration `json:"max_delay"`
        BackoffFactor float64       `json:"backoff_factor"`
}

// DistributedScheduler interface for scheduler operations
type DistributedScheduler interface {
        GetNodes() []interface{}
        GetMetrics() interface{}
}

// RequestCoordinator handles request coordination
type RequestCoordinator struct {
        engine      *OrchestrationEngine
        router      *RequestRouter
        partitioner *RequestPartitioner
        synchronizer *RequestSynchronizer
        stateManager *SessionStateManager
}

// RequestRouter handles request routing
type RequestRouter struct {
        coordinator *RequestCoordinator
        rules       []RoutingRule
        balancer    interface{}
        fallback    *FallbackStrategy
        metrics     *RoutingMetrics
}

// RoutingRule defines routing rules
type RoutingRule struct {
        ID        string                 `json:"id"`
        Condition string                 `json:"condition"`
        Action    string                 `json:"action"`
        Target    string                 `json:"target"`
        Priority  int                    `json:"priority"`
        Metadata  map[string]interface{} `json:"metadata"`
}

// FallbackStrategy defines fallback behavior
type FallbackStrategy struct {
        Type        string                 `json:"type"`
        Target      string                 `json:"target"`
        Timeout     time.Duration          `json:"timeout"`
        Metadata    map[string]interface{} `json:"metadata"`
}

// RoutingMetrics tracks routing performance
type RoutingMetrics struct {
        TotalRequests      int64         `json:"total_requests"`
        SuccessfulRoutes   int64         `json:"successful_routes"`
        FailedRoutes       int64         `json:"failed_routes"`
        AverageLatency     time.Duration `json:"average_latency"`
        RuleHitRate        float64       `json:"rule_hit_rate"`
        FallbackUsage      int64         `json:"fallback_usage"`
        LastUpdated        time.Time     `json:"last_updated"`
}

// RequestPartitioner handles request partitioning
type RequestPartitioner struct {
        coordinator *RequestCoordinator
        strategies  map[string]PartitioningStrategy
        optimizer   *PartitionOptimizer
}

// PartitioningStrategy interface for partitioning
type PartitioningStrategy interface {
        Partition(request *OrchestrationRequest) (*PartitionPlan, error)
        GetName() string
}

// PartitionOptimizer optimizes partitioning decisions
type PartitionOptimizer struct {
        partitioner *RequestPartitioner
        history     []*PartitionResult
        historyMu   sync.RWMutex
        optimizationWeights map[string]float64
}

// PartitionPlan represents a partitioning plan
type PartitionPlan struct {
        ID          string                 `json:"id"`
        Strategy    string                 `json:"strategy"`
        Partitions  []*TaskPartition       `json:"partitions"`
        Metadata    map[string]interface{} `json:"metadata"`
        CreatedAt   time.Time              `json:"created_at"`
}

// TaskPartition represents a task partition
type TaskPartition struct {
        ID           string                 `json:"id"`
        NodeID       string                 `json:"node_id"`
        Type         string                 `json:"type"`
        Data         interface{}            `json:"data"`
        Dependencies []string               `json:"dependencies"`
        Metadata     map[string]interface{} `json:"metadata"`
}

// PartitionResult represents partitioning results
type PartitionResult struct {
        Plan         *PartitionPlan `json:"plan"`
        Success      bool           `json:"success"`
        Latency      time.Duration  `json:"latency"`
        Throughput   float64        `json:"throughput"`
        Timestamp    time.Time      `json:"timestamp"`
}

// RequestSynchronizer handles request synchronization
type RequestSynchronizer struct {
        coordinator   *RequestCoordinator
        syncPoints    map[string]*SyncPoint
        syncPointsMu  sync.RWMutex
        barriers      map[string]*SyncBarrier
        barriersMu    sync.RWMutex
}

// SyncPoint represents a synchronization point
type SyncPoint struct {
        ID          string                 `json:"id"`
        Type        string                 `json:"type"`
        Condition   string                 `json:"condition"`
        WaitingTasks []string              `json:"waiting_tasks"`
        Completed   bool                   `json:"completed"`
        Metadata    map[string]interface{} `json:"metadata"`
        CreatedAt   time.Time              `json:"created_at"`
}

// SyncBarrier represents a synchronization barrier
type SyncBarrier struct {
        ID            string                 `json:"id"`
        RequiredTasks []string               `json:"required_tasks"`
        CompletedTasks []string              `json:"completed_tasks"`
        WaitingTasks  []string               `json:"waiting_tasks"`
        Released      bool                   `json:"released"`
        Metadata      map[string]interface{} `json:"metadata"`
        CreatedAt     time.Time              `json:"created_at"`
}

// SessionStateManager manages session state
type SessionStateManager struct {
        coordinator *RequestCoordinator
        sessions    map[string]*SessionState
        sessionsMu  sync.RWMutex
        persistence SessionPersistence
}

// SessionState represents session state
type SessionState struct {
        ID          string                 `json:"id"`
        Status      string                 `json:"status"`
        Requests    []string               `json:"requests"`
        Responses   []string               `json:"responses"`
        Metadata    map[string]interface{} `json:"metadata"`
        CreatedAt   time.Time              `json:"created_at"`
        UpdatedAt   time.Time              `json:"updated_at"`
}

// SessionPersistence interface for session persistence
type SessionPersistence interface {
        Save(session *SessionState) error
        Load(id string) (*SessionState, error)
        Delete(id string) error
        List() ([]*SessionState, error)
}

// ResponseAggregator handles response aggregation
type ResponseAggregator struct {
        engine      *OrchestrationEngine
        strategies  map[string]AggregationStrategy
        pendingResults map[string]*AggregationContext
        pendingMu   sync.RWMutex
}

// AggregationStrategy interface for aggregation
type AggregationStrategy interface {
        Aggregate(context *AggregationContext) (*AggregatedResponse, error)
        GetName() string
}

// AggregationContext holds aggregation context
type AggregationContext struct {
        TaskID      string                 `json:"task_id"`
        Strategy    string                 `json:"strategy"`
        PartialResults []PartialResult     `json:"partial_results"`
        Metadata    map[string]interface{} `json:"metadata"`
        CreatedAt   time.Time              `json:"created_at"`
}

// PartialResult represents a partial result
type PartialResult struct {
        PartitionID string                 `json:"partition_id"`
        NodeID      string                 `json:"node_id"`
        Data        interface{}            `json:"data"`
        Error       string                 `json:"error,omitempty"`
        Metadata    map[string]interface{} `json:"metadata"`
        Timestamp   time.Time              `json:"timestamp"`
}

// AggregatedResponse represents an aggregated response
type AggregatedResponse struct {
        TaskID      string                 `json:"task_id"`
        Strategy    string                 `json:"strategy"`
        Data        interface{}            `json:"data"`
        Metadata    map[string]interface{} `json:"metadata"`
        Latency     time.Duration          `json:"latency"`
        Timestamp   time.Time              `json:"timestamp"`
}

// OrchestrationMonitor monitors orchestration performance
type OrchestrationMonitor struct {
        engine    *OrchestrationEngine
        metrics   *OrchestrationMetrics
        monitors  []Monitor
        interval  time.Duration
        stopCh    chan struct{}
}

// Monitor interface for monitoring
type Monitor interface {
        Collect() (map[string]interface{}, error)
        GetName() string
}

// OrchestrationMetrics tracks orchestration metrics
type OrchestrationMetrics struct {
        TotalTasks         int64         `json:"total_tasks"`
        ActiveTasks        int64         `json:"active_tasks"`
        CompletedTasks     int64         `json:"completed_tasks"`
        FailedTasks        int64         `json:"failed_tasks"`
        AverageLatency     time.Duration `json:"average_latency"`
        Throughput         float64       `json:"throughput"`
        ResourceUtilization float64      `json:"resource_utilization"`
        ErrorRate          float64       `json:"error_rate"`
        LastUpdated        time.Time     `json:"last_updated"`
}

// OrchestrationTask represents a task being orchestrated
type OrchestrationTask struct {
        ID              string                 `json:"id"`
        Type            string                 `json:"type"`
        Request         *OrchestrationRequest  `json:"request"`
        PartitionPlan   *PartitionPlan         `json:"partition_plan"`
        PartialResults  []PartialResult        `json:"partial_results"`
        AggregatedResult *AggregatedResponse   `json:"aggregated_result"`
        Status          TaskStatus             `json:"status"`
        StartedAt       time.Time              `json:"started_at"`
        CompletedAt     *time.Time             `json:"completed_at"`
        Metadata        map[string]interface{} `json:"metadata"`
        RetryCount      int                    `json:"retry_count"`
        LastError       string                 `json:"last_error"`
}

// TaskStatus represents task status
type TaskStatus string

const (
        TaskStatusPending     TaskStatus = "pending"
        TaskStatusPartitioned TaskStatus = "partitioned"
        TaskStatusExecuting   TaskStatus = "executing"
        TaskStatusAggregating TaskStatus = "aggregating"
        TaskStatusCompleted   TaskStatus = "completed"
        TaskStatusFailed      TaskStatus = "failed"
        TaskStatusRetrying    TaskStatus = "retrying"
)

// OrchestrationRequest represents a request for orchestration
type OrchestrationRequest struct {
        ID          string                 `json:"id"`
        Type        string                 `json:"type"`
        Payload     interface{}            `json:"payload"`
        Options     map[string]interface{} `json:"options"`
        Priority    int                    `json:"priority"`
        Timeout     time.Duration          `json:"timeout"`
        Metadata    map[string]interface{} `json:"metadata"`
        CreatedAt   time.Time              `json:"created_at"`
}

// NewOrchestrationEngine creates a new orchestration engine
func NewOrchestrationEngine(config *Config) *OrchestrationEngine <span class="cov0" title="0">{
        ctx, cancel := context.WithCancel(context.Background())
        
        oe := &amp;OrchestrationEngine{
                config:      config,
                activeTasks: make(map[string]*OrchestrationTask),
                metrics:     &amp;OrchestrationMetrics{LastUpdated: time.Now()},
                ctx:         ctx,
                cancel:      cancel,
        }
        
        // Initialize components
        oe.initializeComponents()
        
        return oe
}</span>

// initializeComponents initializes all orchestration components
func (oe *OrchestrationEngine) initializeComponents() <span class="cov0" title="0">{
        // Initialize request coordinator
        oe.coordinator = &amp;RequestCoordinator{
                engine: oe,
        }
        
        // Initialize request router
        oe.coordinator.router = &amp;RequestRouter{
                coordinator: oe.coordinator,
                rules:       make([]RoutingRule, 0),
                fallback: &amp;FallbackStrategy{
                        Type:    "local",
                        Timeout: 30 * time.Second,
                },
                metrics: &amp;RoutingMetrics{LastUpdated: time.Now()},
        }
        
        // Initialize request partitioner
        oe.coordinator.partitioner = &amp;RequestPartitioner{
                coordinator: oe.coordinator,
                strategies:  make(map[string]PartitioningStrategy),
                optimizer: &amp;PartitionOptimizer{
                        history: make([]*PartitionResult, 0),
                        optimizationWeights: map[string]float64{
                                "latency":    0.4,
                                "throughput": 0.3,
                                "resource":   0.2,
                                "reliability": 0.1,
                        },
                },
        }
        
        // Initialize request synchronizer
        oe.coordinator.synchronizer = &amp;RequestSynchronizer{
                coordinator: oe.coordinator,
                syncPoints:  make(map[string]*SyncPoint),
                barriers:    make(map[string]*SyncBarrier),
        }
        
        // Initialize session state manager
        oe.coordinator.stateManager = &amp;SessionStateManager{
                coordinator: oe.coordinator,
                sessions:    make(map[string]*SessionState),
        }
        
        // Initialize response aggregator
        oe.aggregator = &amp;ResponseAggregator{
                engine:         oe,
                strategies:     make(map[string]AggregationStrategy),
                pendingResults: make(map[string]*AggregationContext),
        }
        
        // Initialize orchestration monitor
        oe.monitor = &amp;OrchestrationMonitor{
                engine:   oe,
                metrics:  oe.metrics,
                monitors: make([]Monitor, 0),
                interval: 10 * time.Second,
                stopCh:   make(chan struct{}),
        }
        
        // Register default strategies
        oe.registerDefaultStrategies()
}</span>

// registerDefaultStrategies registers default strategies
func (oe *OrchestrationEngine) registerDefaultStrategies() <span class="cov0" title="0">{
        // Register aggregation strategies
        oe.aggregator.strategies["concat"] = &amp;ConcatAggregationStrategy{}
        oe.aggregator.strategies["average"] = &amp;AverageAggregationStrategy{}
        oe.aggregator.strategies["weighted"] = &amp;WeightedAggregationStrategy{}
        
        // Register partitioning strategies
        oe.coordinator.partitioner.strategies["round_robin"] = &amp;RoundRobinPartitioningStrategy{}
        oe.coordinator.partitioner.strategies["load_based"] = &amp;LoadBasedPartitioningStrategy{}
        oe.coordinator.partitioner.strategies["capability_based"] = &amp;CapabilityBasedPartitioningStrategy{}
}</span>

// Start starts the orchestration engine
func (oe *OrchestrationEngine) Start(ctx context.Context) error <span class="cov0" title="0">{
        oe.mu.Lock()
        defer oe.mu.Unlock()
        
        if oe.started </span><span class="cov0" title="0">{
                return fmt.Errorf("orchestration engine already started")
        }</span>
        
        // Start monitoring
        <span class="cov0" title="0">go oe.monitor.start(oe.ctx)
        
        // Start request processing
        go oe.processRequests(oe.ctx)
        
        // Start result aggregation
        go oe.processAggregation(oe.ctx)
        
        oe.started = true
        
        slog.Info("orchestration engine started",
                "max_concurrent_tasks", oe.config.MaxConcurrentTasks,
                "coordination_mode", oe.config.CoordinationMode)
        
        return nil</span>
}

// ExecuteTask executes a distributed task
func (oe *OrchestrationEngine) ExecuteTask(ctx context.Context, task interface{}) error <span class="cov0" title="0">{
        // Convert task to orchestration request
        request := oe.convertToOrchestrationRequest(task)
        
        // Create orchestration task
        orchTask := &amp;OrchestrationTask{
                ID:         request.ID,
                Type:       request.Type,
                Request:    request,
                Status:     TaskStatusPending,
                StartedAt:  time.Now(),
                Metadata:   make(map[string]interface{}),
                RetryCount: 0,
        }
        
        // Store active task
        oe.activeTasksMu.Lock()
        oe.activeTasks[orchTask.ID] = orchTask
        oe.activeTasksMu.Unlock()
        
        // Update metrics
        oe.metrics.TotalTasks++
        oe.metrics.ActiveTasks++
        
        // Execute task asynchronously
        go oe.executeTaskAsync(ctx, orchTask)
        
        return nil
}</span>

// convertToOrchestrationRequest converts a task to orchestration request
func (oe *OrchestrationEngine) convertToOrchestrationRequest(task interface{}) *OrchestrationRequest <span class="cov0" title="0">{
        return &amp;OrchestrationRequest{
                ID:        fmt.Sprintf("req_%d", time.Now().UnixNano()),
                Type:      "distributed_inference",
                Payload:   task,
                Options:   make(map[string]interface{}),
                Priority:  1,
                Timeout:   oe.config.TaskTimeout,
                Metadata:  make(map[string]interface{}),
                CreatedAt: time.Now(),
        }
}</span>

// executeTaskAsync executes a task asynchronously
func (oe *OrchestrationEngine) executeTaskAsync(ctx context.Context, task *OrchestrationTask) <span class="cov0" title="0">{
        defer func() </span><span class="cov0" title="0">{
                // Clean up task
                oe.activeTasksMu.Lock()
                delete(oe.activeTasks, task.ID)
                oe.activeTasksMu.Unlock()
                
                // Update metrics
                oe.metrics.ActiveTasks--
                if task.Status == TaskStatusCompleted </span><span class="cov0" title="0">{
                        oe.metrics.CompletedTasks++
                }</span> else<span class="cov0" title="0"> {
                        oe.metrics.FailedTasks++
                }</span>
        }()
        
        <span class="cov0" title="0">for </span><span class="cov0" title="0">{
                switch task.Status </span>{
                case TaskStatusPending:<span class="cov0" title="0">
                        if err := oe.partitionTask(ctx, task); err != nil </span><span class="cov0" title="0">{
                                if oe.shouldRetry(task, err) </span><span class="cov0" title="0">{
                                        oe.retryTask(task, err)
                                        continue</span>
                                }
                                <span class="cov0" title="0">oe.failTask(task, err)
                                return</span>
                        }
                        <span class="cov0" title="0">task.Status = TaskStatusPartitioned</span>
                        
                case TaskStatusPartitioned:<span class="cov0" title="0">
                        if err := oe.executePartitions(ctx, task); err != nil </span><span class="cov0" title="0">{
                                if oe.shouldRetry(task, err) </span><span class="cov0" title="0">{
                                        oe.retryTask(task, err)
                                        continue</span>
                                }
                                <span class="cov0" title="0">oe.failTask(task, err)
                                return</span>
                        }
                        <span class="cov0" title="0">task.Status = TaskStatusExecuting</span>
                        
                case TaskStatusExecuting:<span class="cov0" title="0">
                        if oe.arePartitionsComplete(task) </span><span class="cov0" title="0">{
                                task.Status = TaskStatusAggregating
                        }</span> else<span class="cov0" title="0"> {
                                // Wait for partitions to complete
                                time.Sleep(100 * time.Millisecond)
                        }</span>
                        
                case TaskStatusAggregating:<span class="cov0" title="0">
                        if err := oe.aggregateResults(ctx, task); err != nil </span><span class="cov0" title="0">{
                                if oe.shouldRetry(task, err) </span><span class="cov0" title="0">{
                                        oe.retryTask(task, err)
                                        continue</span>
                                }
                                <span class="cov0" title="0">oe.failTask(task, err)
                                return</span>
                        }
                        <span class="cov0" title="0">task.Status = TaskStatusCompleted
                        completedAt := time.Now()
                        task.CompletedAt = &amp;completedAt</span>
                        
                case TaskStatusCompleted:<span class="cov0" title="0">
                        slog.Info("task completed", "task_id", task.ID, "duration", time.Since(task.StartedAt))
                        return</span>
                        
                case TaskStatusFailed:<span class="cov0" title="0">
                        slog.Error("task failed", "task_id", task.ID, "error", task.LastError)
                        return</span>
                        
                case TaskStatusRetrying:<span class="cov0" title="0">
                        // Wait before retrying
                        delay := oe.calculateRetryDelay(task.RetryCount)
                        time.Sleep(delay)
                        task.Status = TaskStatusPending</span>
                        
                default:<span class="cov0" title="0">
                        slog.Error("unknown task status", "task_id", task.ID, "status", task.Status)
                        return</span>
                }
        }
}

// partitionTask partitions a task for distributed execution
func (oe *OrchestrationEngine) partitionTask(ctx context.Context, task *OrchestrationTask) error <span class="cov0" title="0">{
        // Select partitioning strategy
        strategy, err := oe.selectPartitioningStrategy(task)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to select partitioning strategy: %v", err)
        }</span>
        
        // Partition the task
        <span class="cov0" title="0">plan, err := strategy.Partition(task.Request)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to partition task: %v", err)
        }</span>
        
        <span class="cov0" title="0">task.PartitionPlan = plan
        return nil</span>
}

// selectPartitioningStrategy selects the best partitioning strategy
func (oe *OrchestrationEngine) selectPartitioningStrategy(task *OrchestrationTask) (PartitioningStrategy, error) <span class="cov0" title="0">{
        // Simple strategy selection based on task type
        switch task.Type </span>{
        case "distributed_inference":<span class="cov0" title="0">
                return oe.coordinator.partitioner.strategies["load_based"], nil</span>
        case "batch_processing":<span class="cov0" title="0">
                return oe.coordinator.partitioner.strategies["round_robin"], nil</span>
        default:<span class="cov0" title="0">
                return oe.coordinator.partitioner.strategies["capability_based"], nil</span>
        }
}

// executePartitions executes task partitions
func (oe *OrchestrationEngine) executePartitions(ctx context.Context, task *OrchestrationTask) error <span class="cov0" title="0">{
        // Execute partitions in parallel
        for _, partition := range task.PartitionPlan.Partitions </span><span class="cov0" title="0">{
                go oe.executePartition(ctx, task, partition)
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// executePartition executes a single partition
func (oe *OrchestrationEngine) executePartition(ctx context.Context, task *OrchestrationTask, partition *TaskPartition) <span class="cov0" title="0">{
        start := time.Now()
        
        // Simulate partition execution
        time.Sleep(100 * time.Millisecond)
        
        // Create partial result
        result := PartialResult{
                PartitionID: partition.ID,
                NodeID:      partition.NodeID,
                Data:        "mock_result",
                Metadata:    make(map[string]interface{}),
                Timestamp:   time.Now(),
        }
        
        // Store partial result
        task.PartialResults = append(task.PartialResults, result)
        
        slog.Debug("partition executed", "task_id", task.ID, "partition_id", partition.ID, "duration", time.Since(start))
}</span>

// arePartitionsComplete checks if all partitions are complete
func (oe *OrchestrationEngine) arePartitionsComplete(task *OrchestrationTask) bool <span class="cov0" title="0">{
        return len(task.PartialResults) &gt;= len(task.PartitionPlan.Partitions)
}</span>

// aggregateResults aggregates partial results
func (oe *OrchestrationEngine) aggregateResults(ctx context.Context, task *OrchestrationTask) error <span class="cov0" title="0">{
        // Create aggregation context
        aggCtx := &amp;AggregationContext{
                TaskID:         task.ID,
                Strategy:       "concat", // Default strategy
                PartialResults: task.PartialResults,
                Metadata:       make(map[string]interface{}),
                CreatedAt:      time.Now(),
        }
        
        // Select aggregation strategy
        strategy := oe.aggregator.strategies[aggCtx.Strategy]
        if strategy == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("aggregation strategy not found: %s", aggCtx.Strategy)
        }</span>
        
        // Aggregate results
        <span class="cov0" title="0">aggregated, err := strategy.Aggregate(aggCtx)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to aggregate results: %v", err)
        }</span>
        
        <span class="cov0" title="0">task.AggregatedResult = aggregated
        return nil</span>
}

// shouldRetry determines if a task should be retried
func (oe *OrchestrationEngine) shouldRetry(task *OrchestrationTask, err error) bool <span class="cov0" title="0">{
        if oe.config.RetryPolicy == nil </span><span class="cov0" title="0">{
                return false
        }</span>
        
        <span class="cov0" title="0">return task.RetryCount &lt; oe.config.RetryPolicy.MaxRetries</span>
}

// retryTask prepares a task for retry
func (oe *OrchestrationEngine) retryTask(task *OrchestrationTask, err error) <span class="cov0" title="0">{
        task.RetryCount++
        task.LastError = err.Error()
        task.Status = TaskStatusRetrying
        
        slog.Warn("retrying task", "task_id", task.ID, "retry_count", task.RetryCount, "error", err)
}</span>

// failTask marks a task as failed
func (oe *OrchestrationEngine) failTask(task *OrchestrationTask, err error) <span class="cov0" title="0">{
        task.Status = TaskStatusFailed
        task.LastError = err.Error()
        completedAt := time.Now()
        task.CompletedAt = &amp;completedAt
        
        slog.Error("task failed", "task_id", task.ID, "error", err)
}</span>

// calculateRetryDelay calculates retry delay with exponential backoff
func (oe *OrchestrationEngine) calculateRetryDelay(retryCount int) time.Duration <span class="cov0" title="0">{
        if oe.config.RetryPolicy == nil </span><span class="cov0" title="0">{
                return time.Second
        }</span>
        
        <span class="cov0" title="0">delay := oe.config.RetryPolicy.InitialDelay
        for i := 0; i &lt; retryCount; i++ </span><span class="cov0" title="0">{
                delay = time.Duration(float64(delay) * oe.config.RetryPolicy.BackoffFactor)
                if delay &gt; oe.config.RetryPolicy.MaxDelay </span><span class="cov0" title="0">{
                        delay = oe.config.RetryPolicy.MaxDelay
                        break</span>
                }
        }
        
        <span class="cov0" title="0">return delay</span>
}

// processRequests processes incoming requests
func (oe *OrchestrationEngine) processRequests(ctx context.Context) <span class="cov0" title="0">{
        slog.Info("request processor started")
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        slog.Info("request processor shutting down")
                        return</span>
                default:<span class="cov0" title="0">
                        // Process any pending requests
                        time.Sleep(100 * time.Millisecond)</span>
                }
        }
}

// processAggregation processes result aggregation
func (oe *OrchestrationEngine) processAggregation(ctx context.Context) <span class="cov0" title="0">{
        slog.Info("aggregation processor started")
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        slog.Info("aggregation processor shutting down")
                        return</span>
                default:<span class="cov0" title="0">
                        // Process any pending aggregations
                        time.Sleep(100 * time.Millisecond)</span>
                }
        }
}

// GetMetrics returns orchestration metrics
func (oe *OrchestrationEngine) GetMetrics() *OrchestrationMetrics <span class="cov0" title="0">{
        oe.mu.RLock()
        defer oe.mu.RUnlock()
        
        // Update metrics
        if oe.metrics.TotalTasks &gt; 0 </span><span class="cov0" title="0">{
                oe.metrics.ErrorRate = float64(oe.metrics.FailedTasks) / float64(oe.metrics.TotalTasks)
                oe.metrics.Throughput = float64(oe.metrics.CompletedTasks) / time.Since(oe.metrics.LastUpdated).Seconds()
        }</span>
        
        <span class="cov0" title="0">return oe.metrics</span>
}

// GetActiveTasks returns active tasks
func (oe *OrchestrationEngine) GetActiveTasks() []*OrchestrationTask <span class="cov0" title="0">{
        oe.activeTasksMu.RLock()
        defer oe.activeTasksMu.RUnlock()
        
        tasks := make([]*OrchestrationTask, 0, len(oe.activeTasks))
        for _, task := range oe.activeTasks </span><span class="cov0" title="0">{
                tasks = append(tasks, task)
        }</span>
        
        <span class="cov0" title="0">return tasks</span>
}

// Shutdown gracefully shuts down the orchestration engine
func (oe *OrchestrationEngine) Shutdown(ctx context.Context) error <span class="cov0" title="0">{
        oe.mu.Lock()
        defer oe.mu.Unlock()
        
        if !oe.started </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        <span class="cov0" title="0">slog.Info("shutting down orchestration engine")
        
        // Stop monitoring
        close(oe.monitor.stopCh)
        
        // Cancel context
        oe.cancel()
        
        // Wait for active tasks to complete
        shutdownCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
        defer cancel()
        
        for </span><span class="cov0" title="0">{
                oe.activeTasksMu.RLock()
                activeCount := len(oe.activeTasks)
                oe.activeTasksMu.RUnlock()
                
                if activeCount == 0 </span><span class="cov0" title="0">{
                        break</span>
                }
                
                <span class="cov0" title="0">select </span>{
                case &lt;-shutdownCtx.Done():<span class="cov0" title="0">
                        slog.Warn("shutdown timeout, forcing shutdown with active tasks", "active_tasks", activeCount)
                        return nil</span>
                default:<span class="cov0" title="0">
                        time.Sleep(100 * time.Millisecond)</span>
                }
        }
        
        <span class="cov0" title="0">oe.started = false
        
        return nil</span>
}

// Monitor methods

// start starts the orchestration monitor
func (om *OrchestrationMonitor) start(ctx context.Context) <span class="cov0" title="0">{
        ticker := time.NewTicker(om.interval)
        defer ticker.Stop()
        
        slog.Info("orchestration monitor started")
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        slog.Info("orchestration monitor shutting down")
                        return</span>
                case &lt;-om.stopCh:<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        om.collectMetrics()</span>
                }
        }
}

// collectMetrics collects metrics from all monitors
func (om *OrchestrationMonitor) collectMetrics() <span class="cov0" title="0">{
        for _, monitor := range om.monitors </span><span class="cov0" title="0">{
                metrics, err := monitor.Collect()
                if err != nil </span><span class="cov0" title="0">{
                        slog.Warn("failed to collect metrics", "monitor", monitor.GetName(), "error", err)
                        continue</span>
                }
                
                // Process metrics
                <span class="cov0" title="0">om.processMetrics(monitor.GetName(), metrics)</span>
        }
        
        // Update last updated time
        <span class="cov0" title="0">om.metrics.LastUpdated = time.Now()</span>
}

// processMetrics processes collected metrics
func (om *OrchestrationMonitor) processMetrics(monitorName string, metrics map[string]interface{}) <span class="cov0" title="0">{
        // Process metrics based on monitor type
        switch monitorName </span>{
        case "resource_monitor":<span class="cov0" title="0">
                if util, ok := metrics["resource_utilization"].(float64); ok </span><span class="cov0" title="0">{
                        om.metrics.ResourceUtilization = util
                }</span>
        case "performance_monitor":<span class="cov0" title="0">
                if latency, ok := metrics["average_latency"].(time.Duration); ok </span><span class="cov0" title="0">{
                        om.metrics.AverageLatency = latency
                }</span>
        case "throughput_monitor":<span class="cov0" title="0">
                if throughput, ok := metrics["throughput"].(float64); ok </span><span class="cov0" title="0">{
                        om.metrics.Throughput = throughput
                }</span>
        }
}
</pre>
		
		</div>
	</body>
	<script>
	(function() {
		var files = document.getElementById('files');
		var visible;
		files.addEventListener('change', onChange, false);
		function select(part) {
			if (visible)
				visible.style.display = 'none';
			visible = document.getElementById(part);
			if (!visible)
				return;
			files.value = part;
			visible.style.display = 'block';
			location.hash = part;
		}
		function onChange() {
			select(files.value);
			window.scrollTo(0, 0);
		}
		if (location.hash != "") {
			select(location.hash.substr(1));
		}
		if (!visible) {
			select("file0");
		}
	})();
	</script>
</html>
