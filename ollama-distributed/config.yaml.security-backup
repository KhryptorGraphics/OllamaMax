# Distributed Ollama Configuration

# API Configuration - HTTPS ENABLED
api:
  port: 11434
  host: "0.0.0.0"
  tls:
    enabled: true
    cert_file: "/etc/certs/server.crt"
    key_file: "/etc/certs/server.key"
    min_version: "1.3"  # TLS 1.3 minimum
  cors_enabled: true
  rate_limiting:
    enabled: true
    requests_per_minute: 100

# P2P Network Configuration - SECURE
p2p:
  port: 4001
  host: "0.0.0.0"
  bootstrap_peers: []
  discovery:
    enabled: true
    interval: "30s"
  connection_manager:
    low_water: 50
    high_water: 100
    grace_period: "30s"
  security:
    tls_enabled: true
    cert_file: "/etc/certs/p2p.crt"
    key_file: "/etc/certs/p2p.key"

# Model Management Configuration
models:
  storage_path: "./models"
  cache_size: "10GB"
  replication:
    min_replicas: 2
    max_replicas: 5
    strategy: "geographic"
  sync:
    enabled: true
    interval: "5m"

# Distributed Inference Configuration
inference:
  max_concurrent: 10
  timeout: "5m"
  partitioning:
    strategy: "layerwise"
    min_partition_size: "1MB"
    max_partitions: 10
  aggregation:
    strategy: "concat"
    timeout: "30s"
  load_balancing:
    enabled: true
    algorithm: "round_robin"
  fault_tolerance:
    enabled: true
    retry_attempts: 3
    retry_delay: "1s"

    # Basic fault tolerance settings
    health_check_interval: "30s"
    recovery_timeout: "5m"
    circuit_breaker_enabled: true
    checkpoint_interval: "30s"
    max_retries: 3
    retry_backoff: "5s"
    replication_factor: 2

    # Enhanced predictive detection
    predictive_detection:
      enabled: true
      confidence_threshold: 0.8
      prediction_interval: "30s"
      window_size: "30s"
      threshold: 0.8
      enable_ml_detection: false
      enable_statistical: true
      enable_pattern_recognition: true

    # Self-healing configuration
    self_healing:
      enabled: true
      healing_threshold: 0.7
      healing_interval: "60s"
      monitoring_interval: "30s"
      learning_interval: "60s"
      service_restart: true
      resource_reallocation: true
      load_redistribution: true
      enable_learning: true
      enable_predictive: true
      enable_proactive: true
      enable_failover: true
      enable_scaling: true

    # Redundancy management
    redundancy:
      enabled: true
      default_factor: 2
      max_factor: 5
      update_interval: "5m"

    # Performance tracking
    performance_tracking:
      enabled: true
      window_size: "60s"

    # Configuration adaptation
    config_adaptation:
      enabled: true
      interval: "5m"

# Scheduler Configuration
scheduler:
  algorithm: "priority"
  queue_size: 1000
  worker_pool_size: 10
  task_timeout: "10m"
  resource_allocation:
    cpu_weight: 0.3
    memory_weight: 0.4
    network_weight: 0.3

# Monitoring Configuration
monitoring:
  enabled: true
  metrics_port: 9090
  health_check_interval: "30s"
  log_level: "info"
  tracing:
    enabled: false
    endpoint: ""
    sample_rate: 0.1

# Security Configuration - ENHANCED
security:
  authentication:
    jwt:
      secret_key_file: "/etc/secrets/jwt-secret"
      expiry: "24h"
    api_keys:
      enabled: true
      key_file: "/etc/secrets/api-keys"
  encryption:
    at_rest:
      enabled: true
      algorithm: "AES-256-GCM"
      key_file: "/etc/secrets/encryption-key"
  audit:
    enabled: true
    log_file: "/var/log/ollama-distributed/audit.log"
  input_validation:
    enabled: true
    strict_mode: true

# Performance Configuration
performance:
  caching:
    enabled: true
    size: "1GB"
    ttl: "1h"
  compression:
    enabled: true
    algorithm: "gzip"
    level: 6
  connection_pooling:
    enabled: true
    max_connections: 100
    idle_timeout: "5m"

# Logging Configuration
logging:
  level: "info"
  format: "json"
  output: "stdout"
  file:
    enabled: false
    path: "./logs/distributed-ollama.log"
    max_size: "100MB"
    max_backups: 5
    max_age: 30
